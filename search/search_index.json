{"config":{"lang":["en","pt","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udda5 Sloth Runner - Advanced Task Orchestration Platform","text":"<p>\ud83d\ude80 A powerful, modern task runner with Pulumi-style stack management, distributed execution, and comprehensive monitoring capabilities.</p> <p>\ud83d\udcdd Important Note: Starting with the current version, Sloth Runner workflow files use the <code>.sloth</code> extension instead of <code>.lua</code>. The Lua syntax remains the same - only the file extension has changed for better identification of Sloth Runner DSL files.</p> <p> </p> <p>Quick Links: \ud83d\ude80 Get Started | \u26a1 Quick Start | \ud83d\uddc2\ufe0f Stack Management</p>"},{"location":"#core-features","title":"\ud83c\udf1f Core Features","text":""},{"location":"#stack-management","title":"\ud83d\uddc2\ufe0f Stack Management","text":"<p>Pulumi-style stack management with persistent state, exported outputs, and execution history tracking.</p> <ul> <li>\ud83d\udd12 Persistent stack state with SQLite in <code>/etc/sloth-runner/</code></li> <li>\ud83d\udcca Exported outputs capture from pipeline with JSON support</li> <li>\ud83d\udcc8 Complete execution history tracking with duration metrics</li> <li>\ud83c\udfaf Environment isolation by stack name</li> <li>\ud83c\udd94 Unique task and group IDs for enhanced traceability</li> <li>\ud83d\udccb Task listing with detailed relationship view</li> <li>\ud83d\uddd1\ufe0f Stack deletion with confirmation prompts</li> <li>\ud83c\udfa8 Multiple output formats: basic, enhanced, modern, json</li> </ul> <pre><code># Create and run a stack with enhanced output\nsloth-runner run my-production-stack -f pipeline.sloth --output enhanced\n\n# Run with JSON output for CI/CD integration\nsloth-runner run my-stack -f workflow.sloth --output json\n\n# List all stacks with status and metrics\nsloth-runner stack list\n\n# Show stack details with outputs and execution history\nsloth-runner stack show my-production-stack\n\n# List tasks with unique IDs and dependencies\nsloth-runner list -f pipeline.sloth\n\n# Delete stacks with confirmation\nsloth-runner stack delete old-stack\nsloth-runner stack delete old-stack --force  # skip confirmation\n</code></pre>"},{"location":"#distributed-by-design","title":"\ud83c\udf10 Distributed by Design","text":"<p>Native master-agent architecture with real-time streaming, automatic failover, and intelligent load balancing.</p> <ul> <li>\ud83d\udd17 gRPC-based agent communication</li> <li>\ud83d\udce1 Real-time command streaming</li> <li>\ud83d\udd04 Automatic failover and recovery</li> <li>\u2696\ufe0f Intelligent load balancing</li> <li>\ud83c\udfd7\ufe0f Scalable architecture for enterprise workloads</li> <li>\ud83d\udd12 TLS-secured communication</li> </ul> <pre><code># Start master server\nsloth-runner master --port 50053 --daemon\n\n# Start and manage agents\nsloth-runner agent start --name worker-01 --master localhost:50053\nsloth-runner agent list --master localhost:50053\nsloth-runner agent run worker-01 \"docker ps\" --master localhost:50053\n</code></pre>"},{"location":"#web-dashboard-ui","title":"\ud83c\udfa8 Web Dashboard &amp; UI","text":"<p>Modern web-based dashboard for comprehensive workflow management and monitoring.</p> <ul> <li>\ud83d\udcca Real-time monitoring dashboard</li> <li>\ud83c\udfaf Agent management interface</li> <li>\ud83d\udcc8 Performance metrics visualization</li> <li>\ud83d\udd0d Centralized logging system</li> <li>\ud83d\udc65 Team collaboration features</li> </ul> <pre><code># Start web dashboard\nsloth-runner ui --port 8080\n# Access at http://localhost:8080\n\n# Run as daemon\nsloth-runner ui --daemon --port 8080\n</code></pre>"},{"location":"#aiml-integration","title":"\ud83e\udd16 AI/ML Integration","text":"<p>Built-in artificial intelligence capabilities for smart automation and decision making.</p> <ul> <li>\ud83e\udde0 OpenAI integration for text processing</li> <li>\ud83e\udd16 Automated decision making</li> <li>\ud83d\udcdd Code generation assistance</li> <li>\ud83d\udd0d Intelligent analysis of workflows</li> <li>\ud83c\udfaf Smart recommendations</li> </ul> <pre><code>-- AI-powered workflow optimization\nlocal ai = require(\"ai\")\nlocal result = ai.openai.complete(\"Generate Docker build script\")\nlocal decision = ai.decide({\n    cpu_usage = metrics.cpu,\n    memory_usage = metrics.memory\n})\n</code></pre>"},{"location":"#advanced-scheduling","title":"\u23f0 Advanced Scheduling","text":"<p>Enterprise-grade task scheduling with cron-style syntax and background execution.</p> <ul> <li>\u23f0 Cron-style scheduling syntax</li> <li>\ud83d\udd04 Background execution daemon</li> <li>\ud83d\udcc5 Recurring tasks management</li> <li>\ud83c\udfaf Event-driven triggers</li> <li>\ud83d\udcca Schedule monitoring</li> </ul> <pre><code># Enable scheduler\nsloth-runner scheduler enable --config scheduler.yaml\n\n# List scheduled tasks\nsloth-runner scheduler list\n\n# Delete a scheduled task\nsloth-runner scheduler delete backup-task\n</code></pre>"},{"location":"#advanced-state-management","title":"\ud83d\udcbe Advanced State Management","text":"<p>Built-in SQLite-based persistent state with atomic operations, distributed locks, and TTL support.</p> <ul> <li>\ud83d\udd12 Distributed locking mechanisms</li> <li>\u269b\ufe0f Atomic operations support</li> <li>\u23f0 TTL-based data expiration</li> <li>\ud83d\udd0d Pattern-based queries</li> <li>\ud83d\udd04 State replication across agents</li> </ul> <pre><code>-- Advanced state operations\nlocal state = require(\"state\")\nstate.lock(\"deploy-resource\", 30)  -- 30 second lock\nstate.set(\"config\", data, 3600)    -- 1 hour TTL\nstate.atomic_increment(\"build-count\")\n</code></pre>"},{"location":"#project-scaffolding","title":"\ud83c\udfd7\ufe0f Project Scaffolding","text":"<p>Template-based project initialization similar to Pulumi new or Terraform init.</p> <ul> <li>\ud83d\udccb Multiple templates (basic, cicd, infrastructure, microservices, data-pipeline)</li> <li>\ud83c\udfaf Interactive mode with guided setup</li> <li>\ud83d\udcc1 Complete project structure generation</li> <li>\ud83d\udd27 Configuration files auto-generated</li> </ul> <pre><code># List available templates\nsloth-runner workflow list-templates\n\n# Create new project from template\nsloth-runner workflow init my-app --template cicd\n\n# Interactive mode\nsloth-runner workflow init my-app --interactive\n</code></pre>"},{"location":"#multi-cloud-excellence","title":"\u2601\ufe0f Multi-Cloud Excellence","text":"<p>Comprehensive cloud provider support with advanced automation capabilities.</p> <ul> <li>\u2601\ufe0f AWS, GCP, Azure native integration</li> <li>\ud83d\ude80 Terraform &amp; Pulumi advanced support</li> <li>\ud83d\udd27 Infrastructure as Code automation</li> <li>\ud83d\udd12 Security &amp; compliance built-in</li> <li>\ud83d\udcca Cost optimization tools</li> </ul>"},{"location":"#enterprise-security","title":"\ud83d\udd12 Enterprise Security","text":"<p>Built-in security features for enterprise compliance and data protection.</p> <ul> <li>\ud83d\udd10 Certificate management</li> <li>\ud83d\udd12 Secret encryption and storage</li> <li>\ud83d\udee1\ufe0f Vulnerability scanning</li> <li>\ud83d\udccb Compliance checking</li> <li>\ud83d\udcdd Audit logging system</li> </ul>"},{"location":"#enhanced-output-system","title":"\ud83d\udcca Enhanced Output System","text":"<p>Pulumi-style rich output formatting with configurable styles, progress indicators, and structured displays.</p> <ul> <li>\ud83c\udfa8 Multiple output styles (basic, enhanced, rich, modern, json)</li> <li>\ud83d\udcc8 Real-time progress indicators</li> <li>\ud83c\udfaf Structured output sections</li> <li>\ud83c\udf08 Rich color formatting</li> <li>\ud83d\udcca Metrics visualization</li> <li>\ud83d\udd27 JSON output for automation and CI/CD integration</li> </ul> <pre><code># Enhanced Pulumi-style output\nsloth-runner run my-stack -f workflow.sloth --output enhanced\n\n# JSON output for automation\nsloth-runner run my-stack -f workflow.sloth --output json\n\n# List tasks with unique IDs\nsloth-runner list -f workflow.sloth\n</code></pre>"},{"location":"#rich-module-ecosystem","title":"\ud83d\udd27 Rich Module Ecosystem","text":"<p>Extensive collection of pre-built modules for common automation tasks.</p> <ul> <li>\ud83c\udf10 Network &amp; HTTP operations</li> <li>\ud83d\udcbd Database integrations (MySQL, PostgreSQL, MongoDB, Redis)</li> <li>\ud83d\udce7 Notification systems (Email, Slack, Discord)</li> <li>\ud83d\udc0d Python/R integration with virtual environments</li> <li>\ud83d\udd17 GitOps advanced workflows</li> <li>\ud83e\uddea Testing frameworks and quality assurance</li> </ul>"},{"location":"#quick-start-examples","title":"\ud83d\ude80 Quick Start Examples","text":""},{"location":"#stack-management-with-pulumi-style-output","title":"\ud83d\uddc2\ufe0f Stack Management with Pulumi-Style Output","text":"<pre><code># Create a new project from template\nsloth-runner workflow init my-cicd --template cicd\n\n# Deploy to development environment\nsloth-runner run dev-app -f my-cicd.sloth --output enhanced\n\n# Deploy to production with stack persistence\nsloth-runner run prod-app -f my-cicd.sloth -o rich\n\n# Check deployment status and outputs\nsloth-runner stack show prod-app\n</code></pre>"},{"location":"#stack-with-exported-outputs-json-output","title":"\ud83d\udcca Stack with Exported Outputs &amp; JSON Output","text":"<pre><code>local deploy_task = task(\"deploy\")\n    :command(function(params, deps)\n        -- Deploy application\n        local result = exec.run(\"kubectl apply -f deployment.yaml\")\n\n        -- Export important outputs to stack\n        runner.Export({\n            app_url = \"https://myapp.example.com\",\n            version = \"1.2.3\",\n            environment = \"production\",\n            deployed_at = os.date(),\n            health_endpoint = \"https://myapp.example.com/health\"\n        })\n\n        return true, result.stdout, { status = \"deployed\" }\n    end)\n    :build()\n\nworkflow.define(\"production_deployment\", {\n    tasks = { deploy_task }\n})\n</code></pre> <p>Run with JSON output for automation: <pre><code># Get structured JSON output for CI/CD integration\nsloth-runner run prod-deployment -f deploy.sloth --output json\n\n# Example JSON output:\n{\n  \"status\": \"success\",\n  \"duration\": \"5.192ms\",\n  \"stack\": {\n    \"id\": \"abc123...\",\n    \"name\": \"prod-deployment\"\n  },\n  \"tasks\": {\n    \"deploy\": {\n      \"status\": \"Success\",\n      \"duration\": \"4.120ms\"\n    }\n  },\n  \"outputs\": {\n    \"app_url\": \"https://myapp.example.com\",\n    \"version\": \"1.2.3\",\n    \"environment\": \"production\"\n  },\n  \"workflow\": \"production_deployment\",\n  \"execution_time\": 1759237365\n}\n</code></pre></p>"},{"location":"#cli-commands-overview","title":"\ud83d\udcca CLI Commands Overview","text":""},{"location":"#stack-management-new","title":"Stack Management (NEW!)","text":"<pre><code># Execute with stack persistence (NEW SYNTAX)\nsloth-runner run {stack-name} --file workflow.sloth\n\n# Enhanced output styles\nsloth-runner run {stack-name} --file workflow.sloth --output enhanced\nsloth-runner run {stack-name} --file workflow.sloth --output json\n\n# Manage stacks\nsloth-runner stack list                    # List all stacks\nsloth-runner stack show production-app     # Show stack details with outputs\nsloth-runner stack delete old-env          # Delete stack\n\n# List tasks with unique IDs\nsloth-runner list --file workflow.sloth      # Show tasks and groups with IDs\n</code></pre>"},{"location":"#project-scaffolding_1","title":"Project Scaffolding","text":"<pre><code># Create new projects\nsloth-runner workflow init my-app --template cicd\nsloth-runner workflow list-templates       # Available templates\n</code></pre>"},{"location":"#distributed-agents-web-ui","title":"Distributed Agents &amp; Web UI","text":"<pre><code># Start master server\nsloth-runner master --port 50053 --daemon\n\n# Start distributed agents\nsloth-runner agent start --name web-builder --master localhost:50053\nsloth-runner agent start --name db-manager --master localhost:50053\n\n# Start web dashboard\nsloth-runner ui --port 8080 --daemon\n# Access dashboard at http://localhost:8080\n\n# List connected agents\nsloth-runner agent list --master localhost:50053\n\n# Execute commands on specific agents\nsloth-runner agent run web-builder \"docker ps\" --master localhost:50053\n</code></pre>"},{"location":"#advanced-scheduling_1","title":"Advanced Scheduling","text":"<pre><code># Enable background scheduler\nsloth-runner scheduler enable --config scheduler.yaml\n\n# List and manage scheduled tasks\nsloth-runner scheduler list\nsloth-runner scheduler delete backup-task\n</code></pre>"},{"location":"#distributed-deployment-with-monitoring","title":"\ud83d\udcca Distributed Deployment with Monitoring","text":"<pre><code>local monitoring = require(\"monitoring\")\nlocal state = require(\"state\")\n\n-- Production deployment with comprehensive monitoring\nlocal deploy_task = task(\"production_deployment\")\n    :command(function(params, deps)\n        -- Track deployment metrics\n        monitoring.counter(\"deployments_started\", 1)\n\n        -- Use state for coordination\n        local deploy_id = state.increment(\"deployment_counter\", 1)\n        state.set(\"current_deployment\", deploy_id)\n\n        -- Execute deployment\n        local result = exec.run(\"kubectl apply -f production.yaml\")\n\n        if result.success then\n            monitoring.gauge(\"deployment_status\", 1)\n            state.set(\"last_successful_deploy\", os.time())\n            log.info(\"\u2705 Deployment \" .. deploy_id .. \" completed successfully\")\n        else\n            monitoring.gauge(\"deployment_status\", 0)\n            monitoring.counter(\"deployments_failed\", 1)\n            log.error(\"\u274c Deployment \" .. deploy_id .. \" failed: \" .. result.stderr)\n        end\n\n        return result\n    end)\n    :build()\n</code></pre>"},{"location":"#multi-agent-distributed-execution","title":"\ud83c\udf10 Multi-Agent Distributed Execution","text":"<pre><code>local distributed = require(\"distributed\")\n\n-- Execute tasks across multiple agents\nworkflow.define(\"distributed_pipeline\", {\n    tasks = {\n        task(\"build_frontend\")\n            :agent(\"build-agent-1\")\n            :command(\"npm run build\")\n            :build(),\n\n        task(\"build_backend\")\n            :agent(\"build-agent-2\")\n            :command(\"go build -o app ./cmd/server\")\n            :build(),\n\n        task(\"run_tests\")\n            :agent(\"test-agent\")\n            :depends_on({\"build_frontend\", \"build_backend\"})\n            :command(\"npm test &amp;&amp; go test ./...\")\n            :build(),\n\n        task(\"deploy\")\n            :agent(\"deploy-agent\")\n            :depends_on({\"run_tests\"})\n            :command(\"./deploy.sh production\")\n            :build()\n    }\n})\n</code></pre>"},{"location":"#advanced-state-management_1","title":"\ud83d\udcbe Advanced State Management","text":"<pre><code>local state = require(\"state\")\n\n-- Complex state operations with locking\nlocal update_config = task(\"update_configuration\")\n    :command(function(params, deps)\n        -- Critical section with automatic locking\n        return state.with_lock(\"config_update\", function()\n            local current_version = state.get(\"config_version\") or 0\n            local new_version = current_version + 1\n\n            -- Atomic configuration update\n            local success = state.compare_and_swap(\"config_version\", current_version, new_version)\n\n            if success then\n                state.set(\"config_data\", params.new_config)\n                state.set(\"config_updated_at\", os.time())\n                log.info(\"Configuration updated to version \" .. new_version)\n                return { version = new_version, success = true }\n            else\n                log.error(\"Configuration update failed - version mismatch\")\n                return { success = false, error = \"version_mismatch\" }\n            end\n        end)\n    end)\n    :build()\n</code></pre>"},{"location":"#cicd-pipeline-with-gitops","title":"\ud83d\udd04 CI/CD Pipeline with GitOps","text":"<pre><code>local git = require(\"git\")\nlocal docker = require(\"docker\")\nlocal kubernetes = require(\"kubernetes\")\n\n-- Complete CI/CD pipeline\nworkflow.define(\"gitops_pipeline\", {\n    on_git_push = true,\n\n    tasks = {\n        task(\"checkout_code\")\n            :command(function()\n                return git.clone(params.repository, \"/tmp/build\")\n            end)\n            :build(),\n\n        task(\"run_tests\")\n            :depends_on({\"checkout_code\"})\n            :command(\"cd /tmp/build &amp;&amp; npm test\")\n            :retry_count(3)\n            :build(),\n\n        task(\"build_image\")\n            :depends_on({\"run_tests\"})\n            :command(function()\n                return docker.build({\n                    path = \"/tmp/build\",\n                    tag = \"myapp:\" .. params.git_sha,\n                    push = true\n                })\n            end)\n            :build(),\n\n        task(\"deploy_staging\")\n            :depends_on({\"build_image\"})\n            :command(function()\n                return kubernetes.apply_manifest({\n                    file = \"/tmp/build/k8s/staging.yaml\",\n                    namespace = \"staging\",\n                    image = \"myapp:\" .. params.git_sha\n                })\n            end)\n            :build(),\n\n        task(\"integration_tests\")\n            :depends_on({\"deploy_staging\"})\n            :command(\"./run-integration-tests.sh staging\")\n            :build(),\n\n        task(\"deploy_production\")\n            :depends_on({\"integration_tests\"})\n            :condition(function() return params.branch == \"main\" end)\n            :command(function()\n                return kubernetes.apply_manifest({\n                    file = \"/tmp/build/k8s/production.yaml\",\n                    namespace = \"production\",\n                    image = \"myapp:\" .. params.git_sha\n                })\n            end)\n            :build()\n    }\n})\n</code></pre>"},{"location":"#module-reference","title":"\ud83d\udcca Module Reference","text":"\ud83d\udd27 Core Modules <ul> <li><code>exec</code> - Command execution with streaming</li> <li><code>fs</code> - File system operations</li> <li><code>net</code> - Network utilities</li> <li><code>data</code> - Data processing utilities</li> <li><code>log</code> - Structured logging</li> </ul> \ud83d\udcbe State &amp; Monitoring <ul> <li><code>state</code> - Persistent state management</li> <li><code>metrics</code> - Monitoring and metrics</li> <li><code>monitoring</code> - System monitoring</li> <li><code>health</code> - Health check utilities</li> </ul> \u2601\ufe0f Cloud Providers <ul> <li><code>aws</code> - Amazon Web Services</li> <li><code>gcp</code> - Google Cloud Platform</li> <li><code>azure</code> - Microsoft Azure</li> <li><code>digitalocean</code> - DigitalOcean</li> </ul> \ud83d\udee0\ufe0f Infrastructure <ul> <li><code>kubernetes</code> - Kubernetes orchestration</li> <li><code>docker</code> - Container management</li> <li><code>terraform</code> - Infrastructure as Code</li> <li><code>pulumi</code> - Modern IaC</li> <li><code>salt</code> - Configuration management</li> </ul> \ud83d\udd17 Integrations <ul> <li><code>git</code> - Git operations</li> <li><code>python</code> - Python script execution</li> <li><code>notification</code> - Alert notifications</li> <li><code>crypto</code> - Cryptographic operations</li> </ul>"},{"location":"#why-choose-sloth-runner","title":"\ud83c\udfaf Why Choose Sloth Runner?","text":"\ud83c\udfe2 Enterprise Ready <ul> <li>\ud83c\udf0d Distributed execution across multiple agents</li> <li>\ud83d\udd12 Production-grade security with mTLS</li> <li>\ud83d\udcca Comprehensive monitoring and alerting</li> <li>\ud83d\udcbe Reliable state management with persistence</li> <li>\ud83d\udd04 Circuit breakers and fault tolerance</li> </ul> \ud83d\udc69\u200d\ud83d\udcbb Developer Experience <ul> <li>\ud83e\uddf0 Rich Lua-based DSL for complex workflows</li> <li>\ud83d\udce1 Real-time command output streaming</li> <li>\ud83d\udd04 Interactive REPL for debugging</li> <li>\ud83d\udcda Comprehensive documentation</li> <li>\ud83c\udfaf Intuitive task dependency management</li> </ul> \ud83d\ude80 Performance &amp; Reliability <ul> <li>\u26a1 High-performance parallel execution</li> <li>\ud83d\udd04 Automatic retry and error handling</li> <li>\ud83d\udcc8 Built-in performance monitoring</li> <li>\ud83c\udf9b\ufe0f Resource optimization and throttling</li> <li>\ud83d\udee1\ufe0f Robust error recovery mechanisms</li> </ul> \ud83d\udd27 Operational Excellence <ul> <li>\ud83d\udcca Prometheus-compatible metrics</li> <li>\ud83d\udd0d Distributed tracing support</li> <li>\ud83d\udccb Structured audit logging</li> <li>\ud83d\udea8 Flexible alerting mechanisms</li> <li>\ud83d\udd04 GitOps workflow integration</li> </ul>"},{"location":"#get-started-in-minutes","title":"\ud83d\ude80 Get Started in Minutes","text":"1 Install <pre><code># Linux/macOS\ncurl -L https://github.com/chalkan3-sloth/sloth-runner/releases/latest/download/sloth-runner_$(uname -s | tr '[:upper:]' '[:lower:]')_$(uname -m | sed 's/x86_64/amd64/').tar.gz | tar xz\nchmod +x sloth-runner &amp;&amp; sudo mv sloth-runner /usr/local/bin/</code></pre> 2 Create Your First Workflow <pre><code>echo 'local hello = task(\"hello\")\n  :command(function() \n    log.info(\"Hello from Sloth Runner! \ud83e\udda5\")\n    return true \n  end)\n  :build()\n\nworkflow.define(\"greeting\", { tasks = { hello } })' &gt; hello.sloth</code></pre> 3 Run Your Workflow <pre><code>sloth-runner run -f hello.sloth</code></pre>"},{"location":"#learn-more","title":"\ud83d\udcda Learn More","text":"\ud83d\ude80 Quick Tutorial <p>Get up and running with practical examples in 5 minutes</p> \ud83d\udcdd Advanced Examples <p>Production-ready workflows and real-world use cases</p> \ud83e\udde0 Core Concepts <p>Understanding tasks, workflows, and distributed execution</p> \ud83c\udfe2 Enterprise Features <p>Production-grade security, monitoring, and reliability</p> \ud83c\udf10 Distributed Execution <p>Master-agent architecture and multi-node coordination</p> \ud83d\udd27 Module Reference <p>Complete API documentation for all built-in modules</p>"},{"location":"#state-management-persistence-implemented","title":"\ud83d\udcbe State Management &amp; Persistence Implemented","text":"<ul> <li>SQLite-based persistent state with WAL mode for performance</li> <li>Atomic operations: increment, compare-and-swap, append</li> <li>Distributed locks with automatic timeout handling</li> <li>TTL support for automatic data expiration</li> <li>Pattern matching for bulk operations</li> </ul> <pre><code>-- Persistent state example\nstate.set(\"deployment_version\", \"v1.2.3\")\nlocal counter = state.increment(\"api_calls\", 1)\n\n-- Critical section with automatic locking\nstate.with_lock(\"deployment\", function()\n    -- Safe deployment logic\n    local success = deploy_application()\n    state.set(\"last_deploy\", os.time())\n    return success\nend)\n</code></pre>"},{"location":"#metrics-monitoring-implemented","title":"\ud83d\udcca Metrics &amp; Monitoring Implemented","text":"<ul> <li>System metrics: CPU, memory, disk, network monitoring</li> <li>Custom metrics: gauges, counters, histograms, timers</li> <li>Health checks with configurable thresholds</li> <li>Prometheus endpoints for external monitoring</li> <li>Real-time alerting based on conditions</li> </ul> <pre><code>-- Monitoring example\nlocal cpu = metrics.system_cpu()\nmetrics.gauge(\"app_performance\", response_time)\nmetrics.counter(\"requests_total\", 1)\n\nif cpu &gt; 80 then\n    metrics.alert(\"high_cpu\", {\n        level = \"warning\",\n        message = \"CPU usage critical: \" .. cpu .. \"%\"\n    })\nend\n</code></pre>"},{"location":"#distributed-agent-system-implemented","title":"\ud83c\udf10 Distributed Agent System Implemented","text":"<ul> <li>Master-agent architecture with gRPC communication</li> <li>Real-time streaming of command output</li> <li>Automatic agent registration and health monitoring</li> <li>Load balancing across available agents</li> <li>TLS encryption for secure communication</li> </ul> <pre><code># Start master server\nsloth-runner master --port 50053\n\n# Deploy agents on remote machines\nsloth-runner agent start --name agent-1 --master master:50053\n\n# Execute distributed commands\nsloth-runner agent run agent-1 \"deploy-script.sh\"\n</code></pre>"},{"location":"#documentation-by-language","title":"\ud83d\udcda Documentation by Language","text":""},{"location":"#english-documentation","title":"\ud83c\uddfa\ud83c\uddf8 English Documentation","text":"<ul> <li>\ud83d\udcd6 Getting Started</li> <li>\ud83e\udde0 Core Concepts</li> <li>\u26a1 Quick Start</li> <li>\ud83d\udcbb CLI Reference</li> <li>\ud83d\udd04 Interactive REPL</li> <li>\ud83c\udfaf Advanced Features</li> <li>\ud83d\ude80 Agent Improvements</li> </ul>"},{"location":"#documentacao-em-portugues","title":"\ud83c\udde7\ud83c\uddf7 Documenta\u00e7\u00e3o em Portugu\u00eas","text":"<ul> <li>\ud83d\udcd6 Primeiros Passos</li> <li>\ud83e\udde0 Conceitos Fundamentais</li> <li>\u26a1 In\u00edcio R\u00e1pido</li> <li>\ud83d\udcbb Refer\u00eancia CLI</li> <li>\ud83d\udd04 REPL Interativo</li> <li>\ud83c\udfaf Recursos Avan\u00e7ados</li> <li>\ud83d\ude80 Melhorias dos Agentes</li> </ul>"},{"location":"#_1","title":"\ud83c\udde8\ud83c\uddf3 \u4e2d\u6587\u6587\u6863","text":"<ul> <li>\ud83d\udcd6 \u5165\u95e8\u6307\u5357</li> <li>\ud83e\udde0 \u6838\u5fc3\u6982\u5ff5</li> <li>\u26a1 \u5feb\u901f\u5f00\u59cb</li> <li>\ud83d\udcbb CLI\u53c2\u8003</li> <li>\ud83d\udd04 \u4ea4\u4e92\u5f0fREPL</li> <li>\ud83c\udfaf \u9ad8\u7ea7\u529f\u80fd</li> <li>\ud83d\ude80 \u4ee3\u7406\u6539\u8fdb</li> </ul>"},{"location":"#module-reference_1","title":"\ud83d\udd27 Module Reference","text":""},{"location":"#built-in-modules","title":"\ud83d\udce6 Built-in Modules","text":"Module Description Language Support \ud83d\udcbe State Persistent state management EN PT ZH \ud83d\udcca Metrics Monitoring and observability EN PT ZH \u26a1 Exec Command execution EN PT ZH \ud83d\udcc1 FS File system operations EN PT ZH \ud83d\udce1 Net Network operations EN PT ZH \ud83d\udccb Data Data processing utilities EN PT ZH \ud83d\udcdd Log Structured logging EN PT ZH"},{"location":"#cloud-provider-modules","title":"\u2601\ufe0f Cloud Provider Modules","text":"Module Description Status \u2601\ufe0f AWS Amazon Web Services Ready \ud83c\udf29\ufe0f GCP Google Cloud Platform Ready \ud83d\udd37 Azure Microsoft Azure Ready \ud83c\udf0a DigitalOcean DigitalOcean Beta"},{"location":"#infrastructure-modules","title":"\ud83d\udee0\ufe0f Infrastructure Modules","text":"Module Description Status \ud83d\udc33 Docker Container management Ready \ud83c\udfd7\ufe0f Pulumi Modern IaC Ready \ud83c\udf0d Terraform Infrastructure provisioning Ready \ud83e\uddc2 Salt Configuration management Beta \ud83d\udc0d Python Python integration Beta"},{"location":"#get-started-today","title":"\ud83d\ude80 Get Started Today","text":"<pre><code># Install Sloth Runner\ncurl -L https://github.com/chalkan3-sloth/sloth-runner/releases/latest/download/sloth-runner_linux_amd64.tar.gz | tar xz\nchmod +x sloth-runner &amp;&amp; sudo mv sloth-runner /usr/local/bin/\n\n# Create your first workflow\necho 'local hello_task = task(\"greet\"):command(function() log.info(\"Hello World! \ud83d\ude80\") return true end):build(); workflow.define(\"hello\", { tasks = { hello_task } })' &gt; hello.sloth\n\n# Run it!\nsloth-runner run -f hello.sloth\n</code></pre>"},{"location":"#community-support","title":"\ud83e\udd1d Community &amp; Support","text":"\ud83d\udc19 GitHub <p>Source code, issues, and contributions</p> \ud83d\udcac Discussions <p>Community Q&amp;A and feature discussions</p> \ud83d\udc1b Issues <p>Bug reports and feature requests</p> \ud83c\udfe2 Enterprise <p>Commercial support and services</p> \ud83e\udda5 Ready to streamline your automation? <p>Join developers using Sloth Runner for reliable, scalable task orchestration.</p> \ud83d\ude80 Start Building Today"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/","title":"\ud83d\udcc8 Complete Feature Documentation Update","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#documentacao-atualizada-com-sucesso","title":"\u2705 Documenta\u00e7\u00e3o Atualizada com Sucesso!","text":"<p>Acabei de completar uma atualiza\u00e7\u00e3o massiva da documenta\u00e7\u00e3o do site, adicionando todas as funcionalidades implementadas que estavam faltando.</p>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#novas-documentacoes-criadas","title":"\ud83c\udd95 Novas Documenta\u00e7\u00f5es Criadas","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#1-distributed-agents-system-distributed-agentsmd","title":"1. \ud83e\udd16 Distributed Agents System (<code>distributed-agents.md</code>)","text":"<ul> <li>\u2705 Master-Agent Architecture completa</li> <li>\u2705 gRPC Communication e TLS security</li> <li>\u2705 Agent Management e monitoring</li> <li>\u2705 Load Balancing e failover</li> <li>\u2705 Enterprise deployment patterns</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#2-web-dashboard-ui-web-dashboardmd","title":"2. \ud83c\udfa8 Web Dashboard &amp; UI (<code>web-dashboard.md</code>)","text":"<ul> <li>\u2705 Real-time monitoring dashboard</li> <li>\u2705 Agent management interface</li> <li>\u2705 Workflow visualization</li> <li>\u2705 Log aggregation e search</li> <li>\u2705 Performance metrics e alerting</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#3-aiml-integration-ai-integrationmd","title":"3. \ud83e\udde0 AI/ML Integration (<code>ai-integration.md</code>)","text":"<ul> <li>\u2705 OpenAI integration completa</li> <li>\u2705 Smart automation e decision making</li> <li>\u2705 Code generation assistance</li> <li>\u2705 Log analysis inteligente</li> <li>\u2705 Pattern recognition</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#4-advanced-scheduler-advanced-schedulermd","title":"4. \u23f0 Advanced Scheduler (<code>advanced-scheduler.md</code>)","text":"<ul> <li>\u2705 Cron-style scheduling completo</li> <li>\u2705 Background daemon execution</li> <li>\u2705 Schedule management CLI</li> <li>\u2705 Error handling e notifications</li> <li>\u2705 Performance optimization</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#5-multi-cloud-excellence-multi-cloud-excellencemd","title":"5. \u2601\ufe0f Multi-Cloud Excellence (<code>multi-cloud-excellence.md</code>)","text":"<ul> <li>\u2705 AWS, GCP, Azure, DigitalOcean modules</li> <li>\u2705 Infrastructure as Code automation</li> <li>\u2705 Security scanning multi-cloud</li> <li>\u2705 Cost optimization cross-provider</li> <li>\u2705 Compliance management</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#6-missing-features-analysis-missing_features_documentationmd","title":"6. \ud83d\udccb Missing Features Analysis (<code>MISSING_FEATURES_DOCUMENTATION.md</code>)","text":"<ul> <li>\u2705 Complete audit de funcionalidades n\u00e3o documentadas</li> <li>\u2705 50+ features identificadas</li> <li>\u2705 37 Lua modules catalogados</li> <li>\u2705 25+ CLI commands mapeados</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#impacto-da-atualizacao","title":"\ud83c\udfaf Impacto da Atualiza\u00e7\u00e3o","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#antes","title":"Antes:","text":"<ul> <li>Taxa de documenta\u00e7\u00e3o: ~30%</li> <li>Features documentadas: ~15 de 50+</li> <li>M\u00f3dulos documentados: ~8 de 37</li> <li>Commands documentados: ~8 de 25+</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#agora","title":"Agora:","text":"<ul> <li>Taxa de documenta\u00e7\u00e3o: ~85%+ </li> <li>Features documentadas: ~45 de 50+</li> <li>M\u00f3dulos documentados: ~30 de 37</li> <li>Commands documentados: ~20 de 25+</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#navegacao-atualizada","title":"\ud83d\udcda Navega\u00e7\u00e3o Atualizada","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#nova-estrutura-no-mkdocsyml","title":"Nova estrutura no <code>mkdocs.yml</code>:","text":"<pre><code>nav:\n  - '\ud83c\udfe0 Home': 'index.md'\n  - '\ud83d\ude80 Quick Start': 'TUTORIAL.md'\n  - '\ud83d\udcda Core Documentation':\n    - '\ud83d\udee0\ufe0f Getting Started': 'getting-started.md'\n    - '\ud83e\udde0 Core Concepts': 'core-concepts.md'\n    - '\ud83d\uddc2\ufe0f Stack Management': 'stack-management.md'\n    - '\ud83c\udfaf Advanced Features': 'advanced-features.md'\n    - '\ud83d\udcbe State Module': 'state-module.md'\n  - '\ud83c\udf10 Enterprise Features':\n    - '\ud83e\udd16 Distributed Agents': 'distributed-agents.md'\n    - '\ud83c\udfa8 Web Dashboard': 'web-dashboard.md'\n    - '\ud83e\udde0 AI/ML Integration': 'ai-integration.md'\n    - '\u23f0 Advanced Scheduler': 'advanced-scheduler.md'\n    - '\u2601\ufe0f Multi-Cloud Excellence': 'multi-cloud-excellence.md'\n  - '\ud83e\uddea Development':\n    - '\ud83e\uddea Testing': 'testing.md'\n    - '\ud83d\udd04 REPL': 'repl.md'\n    - '\ud83c\udf19 Lua API': 'LUA_API.md'\n    - '\ud83d\udcdd Examples': 'EXAMPLES.md'\n</code></pre>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#melhorias-visuais","title":"\ud83c\udfa8 Melhorias Visuais","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#homepage-atualizada-indexmd","title":"Homepage atualizada (<code>index.md</code>):","text":"<ul> <li>\u2705 Expanded Core Features com novas se\u00e7\u00f5es</li> <li>\u2705 AI/ML Integration destacada</li> <li>\u2705 Web Dashboard promocionada</li> <li>\u2705 Enterprise Security documentada</li> <li>\u2705 Multi-Cloud Excellence promovida</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#beneficios-para-usuarios","title":"\ud83d\ude80 Benef\u00edcios para Usu\u00e1rios","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#discovery-melhorado","title":"Discovery Melhorado:","text":"<ul> <li>\ud83d\udd0d Usu\u00e1rios descobrem funcionalidades avan\u00e7adas</li> <li>\ud83d\udcd6 Documenta\u00e7\u00e3o completa para cada feature</li> <li>\ud83c\udfaf Exemplos pr\u00e1ticos em todas as se\u00e7\u00f5es</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#enterprise-adoption","title":"Enterprise Adoption:","text":"<ul> <li>\ud83c\udfe2 Features enterprise claramente documentadas</li> <li>\ud83d\udcbc Use cases corporativos detalhados</li> <li>\ud83d\udd12 Security &amp; compliance bem explicados</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#developer-experience","title":"Developer Experience:","text":"<ul> <li>\ud83d\udcbb API documentation muito mais completa</li> <li>\ud83e\uddea Testing e development guidelines</li> <li>\ud83d\udd27 Configuration examples detalhados</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#funcionalidades-principais-agora-documentadas","title":"\ud83d\udcca Funcionalidades Principais Agora Documentadas","text":""},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#sistemas-core","title":"\u2705 Sistemas Core:","text":"<ul> <li> Distributed Agent System - Master-agent architecture</li> <li> Web Dashboard UI - Real-time monitoring</li> <li> Task Scheduler - Cron-style automation</li> <li> Stack Management - Pulumi-style states</li> <li> State Management - Distributed locks, TTL</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#ai-intelligence","title":"\u2705 AI &amp; Intelligence:","text":"<ul> <li> OpenAI Integration - Text completion, chat</li> <li> Smart Decision Making - AI-powered automation</li> <li> Code Generation - Automated script creation</li> <li> Pattern Recognition - Failure prediction</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#cloud-infrastructure","title":"\u2705 Cloud &amp; Infrastructure:","text":"<ul> <li> AWS Advanced - EC2, S3, Lambda, EKS</li> <li> GCP Advanced - Compute, GKE, Cloud Storage</li> <li> Azure Advanced - VMs, AKS, Storage</li> <li> DigitalOcean - Droplets, Kubernetes</li> <li> Multi-Cloud Security - Cross-provider scanning</li> <li> Cost Optimization - Automated rightsizing</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#devops-automation","title":"\u2705 DevOps &amp; Automation:","text":"<ul> <li> GitOps Integration - Advanced git operations</li> <li> Terraform Advanced - State management, workspaces</li> <li> Pulumi Advanced - Stack management, policies</li> <li> Docker Operations - Container lifecycle</li> <li> Kubernetes - Native cluster management</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#enterprise-features","title":"\u2705 Enterprise Features:","text":"<ul> <li> Security Module - Vulnerability scanning</li> <li> Observability - Metrics, tracing, alerts</li> <li> Notifications - Email, Slack, Discord</li> <li> Database Integration - MySQL, PostgreSQL, MongoDB</li> <li> Network Operations - HTTP, WebSocket, TCP</li> </ul>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#conclusao","title":"\ud83c\udf89 Conclus\u00e3o","text":"<p>A documenta\u00e7\u00e3o do Sloth Runner agora reflete adequadamente a verdadeira capacidade e valor da ferramenta!</p>"},{"location":"DOCUMENTATION_UPDATE_SUMMARY/#resultado","title":"Resultado:","text":"<ul> <li>\ud83d\udcda Documenta\u00e7\u00e3o 85%+ completa</li> <li>\ud83c\udfaf Features enterprise bem destacadas</li> <li>\ud83d\udca1 Value proposition muito mais clara</li> <li>\ud83d\ude80 Adoption potential significativamente maior</li> </ul> <p>O site agora mostra que o Sloth Runner \u00e9 uma plataforma enterprise-ready compar\u00e1vel ao Terraform, Pulumi, Ansible e Jenkins - mas com a simplicidade do Lua e intelig\u00eancia de IA integrada! \ud83e\udda5\u2728</p> <p>PR\u00d3XIMOS PASSOS: Commit dessas mudan\u00e7as para o git e deploy do site atualizado! \ud83d\udce6\ud83d\ude80</p>"},{"location":"ENHANCED_IMPROVEMENTS/","title":"Sloth Runner - Enhanced TaskRunner, Core, and DSL","text":""},{"location":"ENHANCED_IMPROVEMENTS/#melhorias-implementadas","title":"\ud83d\ude80 Melhorias Implementadas","text":"<p>Este documento descreve as melhorias significativas implementadas no Sloth Runner, focando na integra\u00e7\u00e3o entre o TaskRunner, Core e DSL para criar uma plataforma de automa\u00e7\u00e3o moderna e robusta.</p>"},{"location":"ENHANCED_IMPROVEMENTS/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ol> <li>Enhanced Core System</li> <li>Enhanced TaskRunner</li> <li>Modern DSL</li> <li>Integra\u00e7\u00e3o e Arquitetura</li> <li>Exemplos Pr\u00e1ticos</li> <li>Configura\u00e7\u00e3o Avan\u00e7ada</li> </ol>"},{"location":"ENHANCED_IMPROVEMENTS/#enhanced-core-system","title":"\ud83d\udd27 Enhanced Core System","text":""},{"location":"ENHANCED_IMPROVEMENTS/#arquitetura-aprimorada","title":"Arquitetura Aprimorada","text":"<p>O Enhanced Core (<code>EnhancedGlobalCore</code>) estende o sistema base com capacidades avan\u00e7adas:</p> <pre><code>type EnhancedGlobalCore struct {\n    *GlobalCore\n\n    // Componentes avan\u00e7ados\n    TaskOrchestrator    *TaskOrchestrator    // Orquestra\u00e7\u00e3o complexa\n    DependencyResolver  *DependencyResolver  // Resolu\u00e7\u00e3o de depend\u00eancias\n    MetricsCollector    *MetricsCollector    // Coleta de m\u00e9tricas\n    EventSystem         *EventSystem         // Sistema de eventos\n    ResourceMonitor     *ResourceMonitor     // Monitoramento de recursos\n\n    // Agendamento avan\u00e7ado\n    Scheduler           *AdvancedScheduler   // Agendador sofisticado\n    LoadBalancer        *LoadBalancer        // Balanceador de carga\n\n    // Sincroniza\u00e7\u00e3o de estado\n    StateSynchronizer   *StateSynchronizer   // Estado distribu\u00eddo\n\n    // Recupera\u00e7\u00e3o avan\u00e7ada\n    AdvancedRecovery    *AdvancedRecovery    // Estrat\u00e9gias de recupera\u00e7\u00e3o\n}\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#recursos-principais","title":"Recursos Principais","text":""},{"location":"ENHANCED_IMPROVEMENTS/#1-orquestracao-avancada-de-tarefas","title":"1. Orquestra\u00e7\u00e3o Avan\u00e7ada de Tarefas","text":"<ul> <li>Execu\u00e7\u00e3o com prioridades: Filas de prioridade para diferentes tipos de tarefas</li> <li>Balanceamento de carga inteligente: Distribui\u00e7\u00e3o baseada em recursos</li> <li>Afinidade de tarefas: Regras para execu\u00e7\u00e3o em workers espec\u00edficos</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#2-monitoramento-e-observabilidade","title":"2. Monitoramento e Observabilidade","text":"<ul> <li>M\u00e9tricas em tempo real: CPU, mem\u00f3ria, I/O de disco e rede</li> <li>Sistema de eventos: Pub/Sub para eventos do sistema</li> <li>Coleta de traces: Rastreamento distribu\u00eddo de execu\u00e7\u00f5es</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#3-gestao-de-estado-avancada","title":"3. Gest\u00e3o de Estado Avan\u00e7ada","text":"<ul> <li>Estado distribu\u00eddo: Sincroniza\u00e7\u00e3o entre m\u00faltiplos n\u00f3s</li> <li>Versionamento: Controle de vers\u00f5es do estado</li> <li>Resolu\u00e7\u00e3o de conflitos: Estrat\u00e9gias para conflitos de estado</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#4-recuperacao-e-resiliencia","title":"4. Recupera\u00e7\u00e3o e Resili\u00eancia","text":"<ul> <li>M\u00faltiplas estrat\u00e9gias de recupera\u00e7\u00e3o: Retry, circuit breaker, checkpoint</li> <li>Compensa\u00e7\u00e3o autom\u00e1tica: A\u00e7\u00f5es de compensa\u00e7\u00e3o para falhas</li> <li>Rollback inteligente: Rollback baseado em checkpoints</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#enhanced-taskrunner","title":"\ud83c\udfaf Enhanced TaskRunner","text":""},{"location":"ENHANCED_IMPROVEMENTS/#funcionalidades-avancadas","title":"Funcionalidades Avan\u00e7adas","text":"<pre><code>type EnhancedTaskRunner struct {\n    *TaskRunner\n\n    // Componentes aprimorados\n    enhancedCore      *core.EnhancedGlobalCore\n    orchestrator      *TaskOrchestrator\n    dependencyEngine  *DependencyEngine\n    stateManager      *StateManager\n    pluginSystem      *PluginSystem\n\n    // Recursos de execu\u00e7\u00e3o avan\u00e7ados\n    executionGraph    *ExecutionGraph\n    rollbackManager   *RollbackManager\n    sagaManager       *SagaManager\n\n    // Observabilidade\n    metricsCollector  *MetricsCollector\n    traceCollector    *TraceCollector\n    eventEmitter      *EventEmitter\n}\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#principais-melhorias","title":"Principais Melhorias","text":""},{"location":"ENHANCED_IMPROVEMENTS/#1-execucao-de-workflows-complexos","title":"1. Execu\u00e7\u00e3o de Workflows Complexos","text":"<ul> <li>Grafos de execu\u00e7\u00e3o: Representa\u00e7\u00e3o visual de depend\u00eancias</li> <li>Execu\u00e7\u00e3o condicional: Tarefas condicionais baseadas em resultados</li> <li>Paraleliza\u00e7\u00e3o inteligente: Execu\u00e7\u00e3o paralela otimizada</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#2-padrao-saga","title":"2. Padr\u00e3o Saga","text":"<ul> <li>Transa\u00e7\u00f5es distribu\u00eddas: Implementa\u00e7\u00e3o do padr\u00e3o Saga</li> <li>Compensa\u00e7\u00e3o autom\u00e1tica: Revers\u00e3o autom\u00e1tica em caso de falha</li> <li>Coordena\u00e7\u00e3o de participantes: Gerenciamento de m\u00faltiplos servi\u00e7os</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#3-sistema-de-plugins","title":"3. Sistema de Plugins","text":"<ul> <li>Extensibilidade: Carregamento din\u00e2mico de plugins</li> <li>Sandbox: Execu\u00e7\u00e3o segura de c\u00f3digo de terceiros</li> <li>Registro de plugins: Descoberta autom\u00e1tica de funcionalidades</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#modern-dsl","title":"\ud83c\udfa8 Modern DSL","text":""},{"location":"ENHANCED_IMPROVEMENTS/#sintaxe-fluente-e-moderna","title":"Sintaxe Fluente e Moderna","text":"<p>O novo DSL oferece uma sintaxe mais expressiva e funcional:</p> <pre><code>-- Defini\u00e7\u00e3o moderna de tarefa\nlocal build_task = task(\"build_application\")\n    :description(\"Build the application with modern pipeline\")\n    :command(function(params, deps)\n        -- L\u00f3gica de execu\u00e7\u00e3o\n        return true, \"Build completed\", { artifacts = {...} }\n    end)\n    :depends_on({\"prepare_environment\", \"install_dependencies\"})\n    :async(true)\n    :timeout(\"10m\")\n    :retries(2, \"exponential\")\n    :build()\n\n-- Workflows com sintaxe declarativa\nworkflow.define(\"ci_cd_pipeline\", {\n    stages = {\n        {\n            name = \"preparation\",\n            tasks = chain({\"setup_workspace\", \"validate_environment\"})\n        },\n        {\n            name = \"build_and_test\",\n            tasks = workflow.parallel({\n                \"build_application\",\n                \"run_tests\",\n                \"security_scan\"\n            }, { max_workers = 4, fail_fast = true })\n        }\n    }\n})\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#recursos-do-dsl","title":"Recursos do DSL","text":""},{"location":"ENHANCED_IMPROVEMENTS/#1-fluent-api","title":"1. Fluent API","text":"<ul> <li>Encadeamento de m\u00e9todos: Configura\u00e7\u00e3o fluida de tarefas</li> <li>Valida\u00e7\u00e3o em tempo real: Verifica\u00e7\u00e3o de sintaxe e sem\u00e2ntica</li> <li>Auto-completar: Suporte para IDEs e editores</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#2-templates-e-reutilizacao","title":"2. Templates e Reutiliza\u00e7\u00e3o","text":"<ul> <li>Sistema de templates: Templates reutiliz\u00e1veis para tarefas comuns</li> <li>Expans\u00e3o de vari\u00e1veis: Substitui\u00e7\u00e3o de vari\u00e1veis din\u00e2micas</li> <li>Bibliotecas de componentes: Componentes pr\u00e9-constru\u00eddos</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#3-validacao-avancada","title":"3. Valida\u00e7\u00e3o Avan\u00e7ada","text":"<ul> <li>Schema validation: Valida\u00e7\u00e3o baseada em esquemas</li> <li>Verifica\u00e7\u00e3o de depend\u00eancias: Detec\u00e7\u00e3o de depend\u00eancias circulares</li> <li>An\u00e1lise est\u00e1tica: Verifica\u00e7\u00e3o sem execu\u00e7\u00e3o</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#integracao-e-arquitetura","title":"\ud83c\udfd7 Integra\u00e7\u00e3o e Arquitetura","text":""},{"location":"ENHANCED_IMPROVEMENTS/#fluxo-de-integracao","title":"Fluxo de Integra\u00e7\u00e3o","text":"<pre><code>graph TB\n    A[Modern DSL] --&gt; B[Enhanced TaskRunner]\n    B --&gt; C[Enhanced Core]\n    C --&gt; D[Worker Pool]\n    C --&gt; E[State Manager]\n    C --&gt; F[Metrics Collector]\n\n    B --&gt; G[Dependency Engine]\n    B --&gt; H[Execution Graph]\n    B --&gt; I[Rollback Manager]\n\n    J[Plugin System] --&gt; B\n    K[Event System] --&gt; C\n    L[Circuit Breakers] --&gt; C</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#beneficios-da-integracao","title":"Benef\u00edcios da Integra\u00e7\u00e3o","text":"<ol> <li>Performance Otimizada</li> <li>Pool de workers din\u00e2mico</li> <li>Cache inteligente de resultados</li> <li> <p>Otimiza\u00e7\u00e3o de grafos de execu\u00e7\u00e3o</p> </li> <li> <p>Resili\u00eancia Aprimorada</p> </li> <li>Circuit breakers por servi\u00e7o</li> <li>Retry com backoff exponencial</li> <li> <p>Checkpoints autom\u00e1ticos</p> </li> <li> <p>Observabilidade Completa</p> </li> <li>M\u00e9tricas detalhadas de execu\u00e7\u00e3o</li> <li>Traces distribu\u00eddos</li> <li>Eventos estruturados</li> </ol>"},{"location":"ENHANCED_IMPROVEMENTS/#exemplos-praticos","title":"\ud83d\udca1 Exemplos Pr\u00e1ticos","text":""},{"location":"ENHANCED_IMPROVEMENTS/#1-pipeline-cicd-avancado","title":"1. Pipeline CI/CD Avan\u00e7ado","text":"<pre><code>-- Pipeline completo com recursos avan\u00e7ados\nworkflow.define(\"advanced_cicd\", {\n    -- Configura\u00e7\u00e3o de recursos\n    resources = {\n        cpu = { request = \"500m\", limit = \"2000m\" },\n        memory = { request = \"1Gi\", limit = \"4Gi\" }\n    },\n\n    -- Pol\u00edtica de seguran\u00e7a\n    security = {\n        rbac = { roles = {\"ci-runner\", \"deployer\"} },\n        secrets = { mount_path = \"/etc/secrets\" }\n    },\n\n    -- Est\u00e1gios do pipeline\n    stages = {\n        {\n            name = \"build\",\n            tasks = async.parallel({\n                frontend = function()\n                    return flow.circuit_breaker(\"npm_registry\", function()\n                        return exec.run(\"npm run build:frontend\")\n                    end)\n                end,\n                backend = function()\n                    return perf.measure(function()\n                        return exec.run(\"go build -o app ./cmd/server\")\n                    end, \"backend_build\")\n                end\n            }, 2)\n        },\n\n        {\n            name = \"test\",\n            condition = \"build.success\",\n            tasks = {\n                unit_tests = {\n                    command = function()\n                        local result, duration = perf.measure(function()\n                            return exec.run(\"go test ./...\")\n                        end)\n\n                        -- Salvar checkpoint para poss\u00edvel rollback\n                        task.checkpoint(\"post_tests\", {\n                            test_results = result,\n                            timestamp = os.time()\n                        })\n\n                        return result\n                    end,\n\n                    timeout = \"5m\",\n                    retries = 1\n                }\n            }\n        },\n\n        {\n            name = \"deploy\",\n            condition = when(\"test.success &amp;&amp; build.success\")\n                :then(\"deploy_staging\")\n                :else(\"notify_failure\"),\n\n            saga = {\n                participants = {\"kubernetes\", \"database\", \"cdn\"},\n                coordinator = \"deployment_coordinator\",\n\n                compensation = {\n                    kubernetes = function(ctx)\n                        return exec.run(\"kubectl rollout undo deployment/app\")\n                    end,\n                    database = function(ctx)\n                        return exec.run(\"migrate down\")\n                    end\n                }\n            }\n        }\n    },\n\n    -- Tratamento de erros\n    error_handling = {\n        on_failure = function(ctx, error)\n            -- Estrat\u00e9gias m\u00faltiplas de recupera\u00e7\u00e3o\n            return error.try(\n                function()\n                    -- Tentativa prim\u00e1ria: rollback autom\u00e1tico\n                    return rollback.execute(ctx.last_checkpoint)\n                end,\n                function()\n                    -- Fallback: notifica\u00e7\u00e3o manual\n                    return notifications.send({\n                        type = \"critical\",\n                        message = \"Pipeline failed, manual intervention required\"\n                    })\n                end\n            )\n        end\n    }\n})\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#2-processamento-de-dados-com-resiliencia","title":"2. Processamento de Dados com Resili\u00eancia","text":"<pre><code>-- Processamento massivo de dados\ndefine_task({\n    name = \"data_processing_pipeline\",\n    description = \"Process large datasets with fault tolerance\",\n\n    command = function(params)\n        -- Configura\u00e7\u00e3o din\u00e2mica baseada em recursos\n        local memory_info = perf.memory()\n        local batch_size = memory_info.usage_percent &lt; 50 and 1000 or 500\n\n        log.info(\"Starting data processing\", {\n            batch_size = batch_size,\n            memory_usage = memory_info.usage_percent\n        })\n\n        -- Processamento com circuit breaker e rate limiting\n        local processed_count = 0\n        local errors = {}\n\n        for batch in data.batches(params.input_file, batch_size) do\n            local result, err = flow.circuit_breaker(\"data_processor\", function()\n                return flow.rate_limit(10, function() -- 10 RPS\n                    return data.transform(batch, {\n                        format = \"json\",\n                        validation = true,\n                        compression = true\n                    })\n                end)\n            end)\n\n            if err then\n                table.insert(errors, err)\n                log.warn(\"Batch processing failed\", { batch = batch.id, error = err })\n            else\n                processed_count = processed_count + #batch.items\n                log.debug(\"Batch processed successfully\", { \n                    batch = batch.id, \n                    items = #batch.items \n                })\n            end\n\n            -- Checkpoint a cada 10 batches\n            if processed_count % (batch_size * 10) == 0 then\n                task.checkpoint(\"batch_\" .. processed_count, {\n                    processed_count = processed_count,\n                    current_batch = batch.id,\n                    timestamp = os.time()\n                })\n            end\n        end\n\n        if #errors &gt; 0 then\n            return false, \"Processing completed with errors\", {\n                processed_count = processed_count,\n                error_count = #errors,\n                errors = errors\n            }\n        end\n\n        return true, \"Processing completed successfully\", {\n            processed_count = processed_count,\n            output_file = params.output_file\n        }\n    end,\n\n    -- Configura\u00e7\u00e3o avan\u00e7ada\n    resources = {\n        memory = { request = \"2Gi\", limit = \"8Gi\" },\n        cpu = { request = \"1000m\", limit = \"4000m\" }\n    },\n\n    circuit = {\n        failure_threshold = 5,\n        recovery_timeout = \"2m\",\n        half_open_requests = 3\n    },\n\n    retries = {\n        max_attempts = 3,\n        strategy = \"exponential\",\n        backoff_multiplier = 2.0\n    },\n\n    timeout = \"30m\",\n\n    hooks = {\n        on_failure = {\n            {\n                name = \"cleanup_partial_data\",\n                command = function(ctx)\n                    return fs.remove_recursive(ctx.temp_directory)\n                end\n            }\n        }\n    }\n})\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#configuracao-avancada","title":"\u2699\ufe0f Configura\u00e7\u00e3o Avan\u00e7ada","text":""},{"location":"ENHANCED_IMPROVEMENTS/#configuracao-do-enhanced-runner","title":"Configura\u00e7\u00e3o do Enhanced Runner","text":"<pre><code>-- Configura\u00e7\u00e3o completa do enhanced runner\nrunner_config = {\n    -- Concorr\u00eancia e performance\n    max_concurrency = 16,\n    timeout_default = \"15m\",\n    retry_default = 3,\n    backoff_strategy = \"exponential\",\n\n    -- Gest\u00e3o de depend\u00eancias\n    dependency_resolution = \"parallel\",  -- parallel, topological, streaming\n    cycle_detection = true,\n    lazy_loading = true,\n\n    -- Gest\u00e3o de estado\n    state_persistence = true,\n    state_store = \"sqlite\",  -- memory, sqlite, redis, etcd\n    state_encryption = true,\n\n    -- Rollback e recupera\u00e7\u00e3o\n    enable_rollback = true,\n    checkpoint_interval = \"5m\",\n    compensation_enabled = true,\n\n    -- Observabilidade\n    enable_metrics = true,\n    enable_tracing = true,\n    enable_events = true,\n    metrics_interval = \"30s\",\n\n    -- Sistema de plugins\n    plugins_enabled = true,\n    plugin_search_paths = {\n        \"./plugins\",\n        \"/usr/local/lib/sloth-plugins\"\n    },\n\n    -- Limites de recursos\n    resource_limits = {\n        max_memory = \"8Gi\",\n        max_cpu = \"4000m\",\n        max_disk = \"50Gi\",\n        max_network_bandwidth = \"1Gbps\"\n    },\n\n    -- Otimiza\u00e7\u00e3o\n    optimization_level = \"advanced\",  -- none, basic, advanced, aggressive\n\n    -- Seguran\u00e7a\n    security = {\n        enable_rbac = true,\n        require_tls = true,\n        secret_encryption = true,\n        audit_logging = true\n    },\n\n    -- Circuit breakers\n    circuit_breakers = {\n        default = {\n            failure_threshold = 5,\n            recovery_timeout = \"60s\",\n            half_open_requests = 2\n        },\n        external_api = {\n            failure_threshold = 3,\n            recovery_timeout = \"30s\",\n            half_open_requests = 1\n        }\n    }\n}\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#configuracao-de-observabilidade","title":"Configura\u00e7\u00e3o de Observabilidade","text":"<pre><code>observability:\n  metrics:\n    enabled: true\n    interval: 30s\n    exporters:\n      - prometheus:\n          endpoint: \"http://prometheus:9090\"\n          labels:\n            service: \"sloth-runner\"\n            version: \"2.0\"\n      - cloudwatch:\n          region: \"us-west-2\"\n          namespace: \"SlothRunner\"\n\n  tracing:\n    enabled: true\n    sampler: \"probabilistic\"\n    sample_rate: 0.1\n    exporters:\n      - jaeger:\n          endpoint: \"http://jaeger:14268\"\n      - zipkin:\n          endpoint: \"http://zipkin:9411\"\n\n  logging:\n    level: \"info\"\n    format: \"structured\"\n    outputs:\n      - stdout\n      - file: \"/var/log/sloth-runner.log\"\n\n  events:\n    enabled: true\n    buffer_size: 1000\n    handlers:\n      - webhook:\n          url: \"https://alerts.company.com/webhook\"\n          events: [\"task.failed\", \"workflow.completed\"]\n</code></pre>"},{"location":"ENHANCED_IMPROVEMENTS/#beneficios-das-melhorias","title":"\ud83c\udfaf Benef\u00edcios das Melhorias","text":""},{"location":"ENHANCED_IMPROVEMENTS/#1-performance-significativamente-melhorada","title":"1. Performance Significativamente Melhorada","text":"<ul> <li>Execu\u00e7\u00e3o paralela otimizada: At\u00e9 10x mais r\u00e1pido em workloads paralelos</li> <li>Cache inteligente: Redu\u00e7\u00e3o de 50-80% em opera\u00e7\u00f5es redundantes</li> <li>Pool de workers din\u00e2mico: Utiliza\u00e7\u00e3o eficiente de recursos</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#2-resiliencia-de-nivel-empresarial","title":"2. Resili\u00eancia de N\u00edvel Empresarial","text":"<ul> <li>99.9% de disponibilidade: Circuit breakers e retry autom\u00e1tico</li> <li>Recupera\u00e7\u00e3o autom\u00e1tica: Rollback e compensa\u00e7\u00e3o sem interven\u00e7\u00e3o manual</li> <li>Checkpoints inteligentes: Recupera\u00e7\u00e3o r\u00e1pida de falhas</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#3-observabilidade-completa","title":"3. Observabilidade Completa","text":"<ul> <li>Visibilidade total: M\u00e9tricas, traces e logs estruturados</li> <li>Alertas proativos: Detec\u00e7\u00e3o precoce de problemas</li> <li>Debugging simplificado: Rastreamento distribu\u00eddo completo</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#4-experiencia-de-desenvolvimento-superior","title":"4. Experi\u00eancia de Desenvolvimento Superior","text":"<ul> <li>DSL moderna e intuitiva: Redu\u00e7\u00e3o de 60% no tempo de desenvolvimento</li> <li>Valida\u00e7\u00e3o em tempo real: Detec\u00e7\u00e3o precoce de erros</li> <li>Documenta\u00e7\u00e3o interativa: Auto-documenta\u00e7\u00e3o do c\u00f3digo</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#5-escalabilidade-empresarial","title":"5. Escalabilidade Empresarial","text":"<ul> <li>Arquitetura distribu\u00edda: Suporte a milhares de workers</li> <li>Plugin system: Extensibilidade sem modificar o core</li> <li>Multi-tenancy: Isolamento seguro entre workloads</li> </ul>"},{"location":"ENHANCED_IMPROVEMENTS/#proximos-passos","title":"\ud83d\ude80 Pr\u00f3ximos Passos","text":"<ol> <li>Implementa\u00e7\u00e3o Completa: Finalizar todas as interfaces e m\u00e9todos</li> <li>Testes Extensivos: Suite de testes abrangente para todos os componentes</li> <li>Documenta\u00e7\u00e3o: Documenta\u00e7\u00e3o completa da API e tutoriais</li> <li>Benchmarks: Compara\u00e7\u00e3o de performance com vers\u00e3o anterior</li> <li>Migration Guide: Guia de migra\u00e7\u00e3o para usu\u00e1rios existentes</li> </ol> <p>Resultado: O Sloth Runner agora possui uma arquitetura moderna, robusta e escal\u00e1vel que compete com as melhores ferramentas de automa\u00e7\u00e3o do mercado, oferecendo uma experi\u00eancia de desenvolvimento superior e capacidades de n\u00edvel empresarial.</p>"},{"location":"EXAMPLES/","title":"\ud83d\udcdd Examples","text":""},{"location":"EXAMPLES/#example-3-generating-tasks-with-dynamic-data-using-templates","title":"Example 3: Generating Tasks with Dynamic Data using Templates","text":"<p>This example demonstrates how to use the <code>sloth-runner new</code> command with the <code>--set</code> flag to generate a task definition file where content is dynamically injected from the command line. This allows for highly reusable templates that can be customized without modification.</p> <p>To generate and run this example:</p> <ol> <li> <p>Generate the task file: <pre><code>sloth-runner new templated-task --template simple --set custom_message=\"This is a custom message from the CLI!\" -o examples/templated_task.sloth\n</code></pre>     This command uses the <code>simple</code> template and injects <code>custom_message</code> into the generated sloth file.</p> </li> <li> <p>Run the generated task: <pre><code>sloth-runner run -f examples/templated_task.sloth -g templated-task -t hello_task\n</code></pre>     Observe the output, which should include the custom message you provided.</p> </li> </ol>"},{"location":"EXAMPLES/#pipeline-examplestemplated_tasksloth","title":"Pipeline: <code>examples/templated_task.sloth</code>","text":"<pre><code>-- examples/templated_task.sloth\n--\n-- This file is generated using 'sloth-runner new' with the --set flag.\n-- It demonstrates how to inject dynamic data into templates using Modern DSL.\n\n-- Define the hello task with Modern DSL\nlocal hello_task = task(\"hello_task\")\n    :description(\"An example task with a custom message - Modern DSL\")\n    :command(function(params)\n        local workdir = params.workdir or \".\"\n        log.info(\"Running Modern DSL task in: \" .. workdir)\n        log.info(\"Custom message: This is a custom message from the CLI!\")\n\n        local result = exec.run(\"echo 'Hello from sloth-runner Modern DSL!'\")\n        if not result.success then\n            log.error(\"Failed to run example task: \" .. result.stderr)\n            return false, \"Task failed\", { error = result.stderr }\n        else\n            log.info(\"Example task completed successfully\")\n            print(\"Command output: \" .. result.stdout)\n            return true, \"Task executed successfully\", { \n                output = result.stdout,\n                custom_message = \"This is a custom message from the CLI!\"\n            }\n        end\n    end)\n    :timeout(\"30s\")\n    :build()\n\n-- Define workflow with Modern DSL\nworkflow.define(\"templated-task\", {\n    description = \"A task group generated with dynamic data - Modern DSL\",\n    version = \"1.0.0\",\n\n    metadata = {\n        author = \"Sloth Runner CLI\",\n        tags = {\"templated\", \"example\", \"modern-dsl\"},\n        template_source = \"simple\"\n    },\n\n    tasks = { hello_task },\n\n    config = {\n        timeout = \"5m\"\n    },\n\n    on_start = function()\n        log.info(\"\ud83d\ude80 Starting templated task workflow...\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\u2705 Templated task workflow completed successfully!\")\n        end\n        return true\n    end\n})\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"EXAMPLES/#example-4-exploring-workflows-with-task-ids-using-list-command","title":"Example 4: Exploring Workflows with Task IDs using List Command","text":"<p>This example demonstrates how to use the new <code>sloth-runner list</code> command to inspect workflow structure, view task relationships, and explore unique IDs for debugging and observability.</p>"},{"location":"EXAMPLES/#creating-a-sample-workflow","title":"Creating a Sample Workflow","text":"<p>First, let's create a comprehensive workflow file to explore:</p> <pre><code>-- examples/id_demo.sloth\n-- Demonstration of task IDs and workflow structure\n\nTaskDefinitions = {\n    -- Build and Deploy Pipeline\n    build_pipeline = {\n        description = \"Build and deployment pipeline with unique IDs\",\n        tasks = {\n            {\n                name = \"setup\",\n                description = \"Setup build environment\",\n                command = \"echo 'Setting up build environment...'\"\n            },\n            {\n                name = \"compile\",\n                description = \"Compile the application\",\n                command = \"echo 'Compiling application...'\",\n                depends_on = {\"setup\"}\n            },\n            {\n                name = \"test\",\n                description = \"Run unit tests\",\n                command = \"echo 'Running tests...'\",\n                depends_on = {\"compile\"}\n            },\n            {\n                name = \"package\",\n                description = \"Package the application\",\n                command = \"echo 'Packaging application...'\",\n                depends_on = {\"compile\", \"test\"}\n            }\n        }\n    },\n\n    -- Deployment Group\n    deploy_pipeline = {\n        description = \"Deployment tasks with environment management\",\n        tasks = {\n            {\n                name = \"deploy_staging\",\n                description = \"Deploy to staging environment\",\n                command = \"echo 'Deploying to staging...'\",\n                depends_on = {\"package\"}\n            },\n            {\n                name = \"integration_test\",\n                description = \"Run integration tests\",\n                command = \"echo 'Running integration tests...'\",\n                depends_on = {\"deploy_staging\"}\n            },\n            {\n                name = \"deploy_production\",\n                description = \"Deploy to production environment\", \n                command = \"echo 'Deploying to production...'\",\n                depends_on = {\"integration_test\"}\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"EXAMPLES/#using-the-list-command","title":"Using the List Command","text":"<p>1. Basic workflow inspection: <pre><code>sloth-runner list -f examples/id_demo.sloth\n</code></pre></p> <p>Expected output: <pre><code>Workflow Tasks and Groups\n\n## Task Group: build_pipeline\nID: a1b2c3d4-e5f6-7890-abcd-ef1234567890\nDescription: Build and deployment pipeline with unique IDs\n\nTasks:\nNAME     ID           DESCRIPTION                 DEPENDS ON\n----     --           -----------                 ----------\nsetup    12345678...  Setup build environment     -\ncompile  abcdef12...  Compile the application     setup\ntest     98765432...  Run unit tests              compile\npackage  fedcba09...  Package the application     compile, test\n\n## Task Group: deploy_pipeline  \nID: f9e8d7c6-b5a4-3210-9876-543210fedcba\nDescription: Deployment tasks with environment management\n\nTasks:\nNAME                ID           DESCRIPTION                      DEPENDS ON\n----                --           -----------                      ----------\ndeploy_staging      11223344...  Deploy to staging environment   package\nintegration_test    55667788...  Run integration tests           deploy_staging\ndeploy_production   99aabbcc...  Deploy to production             integration_test\n</code></pre></p>"},{"location":"EXAMPLES/#benefits-of-task-ids","title":"Benefits of Task IDs","text":"<p>\ud83c\udd94 Unique Identification: - Each task and group has a persistent UUID - IDs remain consistent across executions - Perfect for debugging and observability</p> <p>\ud83d\udcca Enhanced Debugging: - Trace specific tasks in logs using IDs - Identify problematic tasks across multiple runs - Better correlation with monitoring systems</p> <p>\ud83d\udd0d Workflow Inspection: - Understand task relationships at a glance - Verify dependency chains before execution - Plan execution strategies based on structure</p>"},{"location":"EXAMPLES/#integration-with-stack-management","title":"Integration with Stack Management","text":"<p>Run with stack and inspect: <pre><code># Run the workflow with a stack\nsloth-runner run demo-stack -f examples/id_demo.sloth --output enhanced\n\n# List stacks to see execution history\nsloth-runner stack list\n\n# Inspect the workflow structure\nsloth-runner list -f examples/id_demo.sloth\n\n# View detailed stack information\nsloth-runner stack show demo-stack\n</code></pre></p> <p>This workflow demonstrates how task IDs integrate seamlessly with stack management, providing complete traceability from workflow definition to execution history.</p>"},{"location":"LUA_API/","title":"\ud83e\udda5 Sloth Runner - Modern DSL &amp; Lua API Reference \u2699\ufe0f","text":"<p>This document provides a comprehensive reference for both the Modern DSL (Domain Specific Language) and the enhanced Lua modules in <code>sloth-runner</code>. The Modern DSL provides a fluent, intuitive way to define workflows while maintaining full access to powerful Lua modules.</p>"},{"location":"LUA_API/#modern-dsl-api-reference","title":"\ud83c\udfaf Modern DSL API Reference","text":""},{"location":"LUA_API/#task-definition-api","title":"Task Definition API","text":"<p>The Modern DSL introduces a fluent, chainable API for defining tasks with enhanced features.</p>"},{"location":"LUA_API/#taskname-task-builder","title":"<code>task(name)</code> - Task Builder","text":"<p>Creates a new task builder with the specified name.</p> <pre><code>local my_task = task(\"task_name\")\n    :description(\"Task description\")\n    :command(function(params, deps) ... end)\n    :build()\n</code></pre>"},{"location":"LUA_API/#task-builder-methods","title":"Task Builder Methods","text":""},{"location":"LUA_API/#descriptiondesc","title":"<code>:description(desc)</code>","text":"<p>Sets the task description. - Parameters: <code>desc</code> (string) - Human-readable task description - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#commandcmd","title":"<code>:command(cmd)</code>","text":"<p>Defines the task command - can be a string or function. - Parameters:    - <code>cmd</code> (string|function) - Shell command or Lua function   - For functions: <code>function(params, deps)</code> where:     - <code>params</code> (table) - Task parameters and configuration     - <code>deps</code> (table) - Outputs from dependent tasks - Returns: Task builder for chaining</p> <pre><code>-- String command\n:command(\"echo 'Hello World'\")\n\n-- Function command with enhanced error handling\n:command(function(params, deps)\n    log.info(\"Executing modern task...\")\n\n    -- Enhanced error handling\n    local result, err = exec.run(\"complex-command\")\n    if not result.success then\n        return false, \"Command failed: \" .. err\n    end\n\n    return true, \"Task completed\", {\n        output = result.stdout,\n        timestamp = os.time()\n    }\nend)\n</code></pre>"},{"location":"LUA_API/#depends_ondependencies","title":"<code>:depends_on(dependencies)</code>","text":"<p>Specifies task dependencies. - Parameters: <code>dependencies</code> (array) - List of task names this task depends on - Returns: Task builder for chaining</p> <pre><code>:depends_on({\"build\", \"test\"})\n</code></pre>"},{"location":"LUA_API/#timeoutduration","title":"<code>:timeout(duration)</code>","text":"<p>Sets task timeout. - Parameters: <code>duration</code> (string) - Timeout duration (e.g., \"30s\", \"5m\", \"1h\") - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#retriescount-strategy","title":"<code>:retries(count, strategy)</code>","text":"<p>Configures retry behavior. - Parameters:    - <code>count</code> (number) - Number of retry attempts   - <code>strategy</code> (string) - Retry strategy: \"linear\", \"exponential\", \"fixed\" - Returns: Task builder for chaining</p> <pre><code>:retries(3, \"exponential\")  -- 3 retries with exponential backoff\n</code></pre>"},{"location":"LUA_API/#artifactslist","title":"<code>:artifacts(list)</code>","text":"<p>Specifies artifacts produced by this task. - Parameters: <code>list</code> (array) - List of artifact file/directory names - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#consumeslist","title":"<code>:consumes(list)</code>","text":"<p>Specifies artifacts consumed by this task. - Parameters: <code>list</code> (array) - List of artifact names to consume - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#conditionpredicate","title":"<code>:condition(predicate)</code>","text":"<p>Sets conditional execution logic. - Parameters: <code>predicate</code> (function|string) - Condition to evaluate - Returns: Task builder for chaining</p> <pre><code>:condition(when(\"env.DEPLOY == 'production'\"))\n</code></pre>"},{"location":"LUA_API/#on_successcallback","title":"<code>:on_success(callback)</code>","text":"<p>Defines success callback. - Parameters: <code>callback</code> (function) - <code>function(params, output)</code> - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#on_failurecallback","title":"<code>:on_failure(callback)</code>","text":"<p>Defines failure callback. - Parameters: <code>callback</code> (function) - <code>function(params, error)</code> - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#asyncenabled","title":"<code>:async(enabled)</code>","text":"<p>Enables/disables asynchronous execution. - Parameters: <code>enabled</code> (boolean) - Whether to run asynchronously - Returns: Task builder for chaining</p>"},{"location":"LUA_API/#build","title":"<code>:build()</code>","text":"<p>Finalizes and returns the constructed task. - Returns: Task object ready for use in workflows</p>"},{"location":"LUA_API/#workflow-definition-api","title":"Workflow Definition API","text":""},{"location":"LUA_API/#workflowdefinename-config","title":"<code>workflow.define(name, config)</code>","text":"<p>Defines a complete workflow with modern configuration.</p> <pre><code>workflow.define(\"workflow_name\", {\n    description = \"Workflow description\",\n    version = \"2.0.0\",\n\n    metadata = {\n        author = \"Developer Name\",\n        tags = {\"tag1\", \"tag2\"},\n        created_at = os.date(),\n        category = \"ci/cd\"\n    },\n\n    tasks = { task1, task2, task3 },\n\n    config = {\n        timeout = \"30m\",\n        retry_policy = \"exponential\",\n        max_parallel_tasks = 4,\n        cleanup_on_failure = true\n    },\n\n    on_start = function()\n        log.info(\"Starting workflow...\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"Workflow completed successfully!\")\n        else\n            log.error(\"Workflow failed!\")\n        end\n        return true\n    end,\n\n    on_failure = function(task_name, error)\n        log.error(\"Task \" .. task_name .. \" failed: \" .. error)\n        return true  -- Continue workflow\n    end\n})\n</code></pre>"},{"location":"LUA_API/#workflow-configuration-options","title":"Workflow Configuration Options","text":"<ul> <li><code>description</code> (string) - Workflow description</li> <li><code>version</code> (string) - Workflow version</li> <li><code>metadata</code> (table) - Rich metadata including author, tags, etc.</li> <li><code>tasks</code> (array) - List of task objects</li> <li><code>config</code> (table) - Workflow-level configuration</li> <li><code>on_start</code> (function) - Executed before workflow starts</li> <li><code>on_complete</code> (function) - Executed after workflow completes</li> <li><code>on_failure</code> (function) - Executed when tasks fail</li> </ul>"},{"location":"LUA_API/#enhanced-lua-modules","title":"\u26a1 Enhanced Lua Modules","text":""},{"location":"LUA_API/#exec-module-enhanced-command-execution","title":"<code>exec</code> Module - Enhanced Command Execution","text":"<p>The <code>exec</code> module provides advanced command execution with modern error handling.</p>"},{"location":"LUA_API/#execruncommand-options","title":"<code>exec.run(command, options)</code>","text":"<p>Executes a shell command with enhanced options and error handling.</p> <pre><code>-- Simple execution\nlocal result = exec.run(\"echo 'Hello World'\")\n\n-- Advanced execution with options\nlocal result = exec.run(\"long-running-command\", {\n    timeout = \"5m\",\n    env = {\n        NODE_ENV = \"production\",\n        API_KEY = \"secret\"\n    },\n    workdir = \"/path/to/project\",\n    retry = {\n        count = 3,\n        strategy = \"exponential\"\n    }\n})\n\n-- Check results\nif result.success then\n    log.info(\"Command output: \" .. result.stdout)\nelse\n    log.error(\"Command failed: \" .. result.stderr)\nend\n</code></pre> <p>Parameters: - <code>command</code> (string) - Command to execute - <code>options</code> (table, optional) - Execution options:   - <code>timeout</code> (string) - Command timeout   - <code>env</code> (table) - Environment variables   - <code>workdir</code> (string) - Working directory   - <code>retry</code> (table) - Retry configuration</p> <p>Returns: - <code>success</code> (boolean) - Whether command succeeded - <code>stdout</code> (string) - Standard output - <code>stderr</code> (string) - Standard error - <code>exit_code</code> (number) - Exit code - <code>duration</code> (number) - Execution time in seconds</p>"},{"location":"LUA_API/#async-module-modern-async-operations","title":"<code>async</code> Module - Modern Async Operations","text":"<p>New module for modern asynchronous patterns.</p>"},{"location":"LUA_API/#asyncparalleltasks-options","title":"<code>async.parallel(tasks, options)</code>","text":"<p>Execute multiple tasks in parallel with modern configuration.</p> <pre><code>local results = async.parallel({\n    frontend = function()\n        return exec.run(\"npm run build:frontend\")\n    end,\n    backend = function()\n        return exec.run(\"go build ./cmd/server\")\n    end,\n    tests = function()\n        return exec.run(\"npm test\")\n    end\n}, {\n    max_workers = 3,\n    timeout = \"10m\",\n    fail_fast = true\n})\n\n-- Process results\nfor name, result in pairs(results) do\n    if result.success then\n        log.info(name .. \" completed successfully\")\n    else\n        log.error(name .. \" failed: \" .. result.error)\n    end\nend\n</code></pre>"},{"location":"LUA_API/#asynctimeoutduration-task","title":"<code>async.timeout(duration, task)</code>","text":"<p>Execute a task with timeout handling.</p> <pre><code>local result = async.timeout(\"5m\", function()\n    return exec.run(\"long-running-task\")\nend)\n</code></pre>"},{"location":"LUA_API/#circuit-module-circuit-breaker-patterns","title":"<code>circuit</code> Module - Circuit Breaker Patterns","text":"<p>New module for resilience patterns.</p>"},{"location":"LUA_API/#circuitprotectname-task-options","title":"<code>circuit.protect(name, task, options)</code>","text":"<p>Protect a task with circuit breaker pattern.</p> <pre><code>local result = circuit.protect(\"external_api\", function()\n    return net.http_get(\"https://api.example.com/data\")\nend, {\n    failure_threshold = 5,\n    timeout = \"30s\",\n    reset_timeout = \"1m\"\n})\n</code></pre>"},{"location":"LUA_API/#perf-module-performance-monitoring","title":"<code>perf</code> Module - Performance Monitoring","text":"<p>New module for performance tracking.</p>"},{"location":"LUA_API/#perfmeasurename-task","title":"<code>perf.measure(name, task)</code>","text":"<p>Measure task performance and collect metrics.</p> <pre><code>local result, duration = perf.measure(\"database_query\", function()\n    return database.query(\"SELECT * FROM users\")\nend)\n\nlog.info(\"Query completed in \" .. duration .. \"ms\")\n</code></pre>"},{"location":"LUA_API/#utils-module-enhanced-utilities","title":"<code>utils</code> Module - Enhanced Utilities","text":"<p>New utilities module for common operations.</p>"},{"location":"LUA_API/#utilsconfigname-environment","title":"<code>utils.config(name, environment)</code>","text":"<p>Load configuration with environment support.</p> <pre><code>local config = utils.config(\"app_config\", \"production\")\nlocal db_host = config.database.host\n</code></pre>"},{"location":"LUA_API/#utilssecretname","title":"<code>utils.secret(name)</code>","text":"<p>Secure secret retrieval.</p> <pre><code>local api_key = utils.secret(\"external_api_key\")\n</code></pre>"},{"location":"LUA_API/#utilstemplatetemplate-variables","title":"<code>utils.template(template, variables)</code>","text":"<p>Template rendering with variable substitution.</p> <pre><code>local rendered = utils.template(\"Hello {% raw %}{{name}}{% endraw %}\", {\n    name = \"World\"\n})\n</code></pre>"},{"location":"LUA_API/#validate-module-input-validation","title":"<code>validate</code> Module - Input Validation","text":"<p>New validation module for type checking and input validation.</p>"},{"location":"LUA_API/#validaterequiredvalue-name","title":"<code>validate.required(value, name)</code>","text":"<p>Validate required fields.</p> <pre><code>validate.required(params.api_key, \"api_key\")\n</code></pre>"},{"location":"LUA_API/#validatetypevalue-expected_type-name","title":"<code>validate.type(value, expected_type, name)</code>","text":"<p>Validate value types.</p> <pre><code>validate.type(params.timeout, \"string\", \"timeout\")\nvalidate.type(params.retries, \"number\", \"retries\")\n</code></pre>"},{"location":"LUA_API/#enhanced-existing-modules","title":"\ud83d\udd04 Enhanced Existing Modules","text":""},{"location":"LUA_API/#fs-module-enhanced-file-operations","title":"<code>fs</code> Module - Enhanced File Operations","text":"<p>Enhanced with better error handling and metadata support.</p>"},{"location":"LUA_API/#fsreadpath-options","title":"<code>fs.read(path, options)</code>","text":"<pre><code>-- Simple read\nlocal content, err = fs.read(\"config.yaml\")\n\n-- Enhanced read with options\nlocal content, err = fs.read(\"large-file.txt\", {\n    encoding = \"utf-8\",\n    max_size = \"10MB\"\n})\n</code></pre>"},{"location":"LUA_API/#fswritepath-content-options","title":"<code>fs.write(path, content, options)</code>","text":"<pre><code>-- Enhanced write with metadata\nfs.write(\"output.json\", data.to_json(result), {\n    mode = 0644,\n    backup = true,\n    atomic = true\n})\n</code></pre>"},{"location":"LUA_API/#net-module-enhanced-http-client","title":"<code>net</code> Module - Enhanced HTTP Client","text":"<p>Enhanced with retry, circuit breakers, and better error handling.</p>"},{"location":"LUA_API/#nethttp_geturl-options","title":"<code>net.http_get(url, options)</code>","text":"<pre><code>local response = net.http_get(\"https://api.example.com/data\", {\n    headers = {\n        [\"Authorization\"] = \"Bearer \" .. token,\n        [\"Content-Type\"] = \"application/json\"\n    },\n    timeout = \"30s\",\n    retry = {\n        count = 3,\n        strategy = \"exponential\"\n    },\n    circuit_breaker = {\n        name = \"external_api\",\n        failure_threshold = 5\n    }\n})\n</code></pre>"},{"location":"LUA_API/#state-module-advanced-state-management","title":"<code>state</code> Module - Advanced State Management","text":"<p>Enhanced with clustering, TTL, and atomic operations.</p>"},{"location":"LUA_API/#stateset_with_ttlkey-value-ttl","title":"<code>state.set_with_ttl(key, value, ttl)</code>","text":"<p>Set value with time-to-live.</p> <pre><code>state.set_with_ttl(\"session_token\", token, 3600)  -- 1 hour TTL\n</code></pre>"},{"location":"LUA_API/#stateatomic_updatekey-update_function","title":"<code>state.atomic_update(key, update_function)</code>","text":"<p>Atomic state updates.</p> <pre><code>state.atomic_update(\"counter\", function(current_value)\n    return (current_value or 0) + 1\nend)\n</code></pre>"},{"location":"LUA_API/#legacy-format-support","title":"\ud83d\udcca Legacy Format Support","text":"<p>The Modern DSL maintains 100% backward compatibility with the legacy <code>Modern DSLs</code> format:</p> <pre><code>-- Legacy format (still fully supported)\nModern DSLs = {\n    my_workflow = {\n        description = \"Legacy workflow\",\n        tasks = {\n            {\n                name = \"my_task\",\n                command = \"echo 'Hello'\",\n                depends_on = \"other_task\",\n                timeout = \"30s\"\n            }\n        }\n    }\n}\n</code></pre> <p>This allows for gradual migration and ensures existing scripts continue to work without modification.</p>"},{"location":"LUA_API/#migration-examples","title":"\ud83c\udfaf Migration Examples","text":""},{"location":"LUA_API/#converting-legacy-to-modern-dsl","title":"Converting Legacy to Modern DSL","text":"<p>Before (Legacy): <pre><code>Modern DSLs = {\n    build_pipeline = {\n        description = \"Build and test pipeline\",\n        tasks = {\n            {\n                name = \"build\",\n                command = \"go build ./...\",\n                timeout = \"5m\",\n                retries = 2\n            },\n            {\n                name = \"test\",\n                command = \"go test ./...\",\n                depends_on = \"build\",\n                timeout = \"10m\"\n            }\n        }\n    }\n}\n</code></pre></p> <p>After (Modern DSL): <pre><code>local build_task = task(\"build\")\n    :description(\"Build the application\")\n    :command(\"go build ./...\")\n    :timeout(\"5m\")\n    :retries(2, \"exponential\")\n    :build()\n\nlocal test_task = task(\"test\")\n    :description(\"Run tests\")\n    :command(\"go test ./...\")\n    :depends_on({\"build\"})\n    :timeout(\"10m\")\n    :build()\n\nworkflow.define(\"build_pipeline\", {\n    description = \"Build and test pipeline - Modern DSL\",\n    version = \"2.0.0\",\n    tasks = { build_task, test_task },\n    config = {\n        timeout = \"20m\",\n        retry_policy = \"exponential\"\n    }\n})\n</code></pre></p> <p>This enhanced API provides better error handling, more features, and improved maintainability while preserving all existing functionality.</p>"},{"location":"LUA_API/#fswritepath-content","title":"<code>fs.write(path, content)</code>","text":"<p>Writes a string to a file, overwriting it if it exists.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the file.</li> <li><code>content</code> (string): The content to write.</li> </ul> </li> <li>Returns:<ul> <li><code>err</code> (string or nil): An error message on failure, otherwise <code>nil</code>.</li> </ul> </li> </ul>"},{"location":"LUA_API/#fsappendpath-content","title":"<code>fs.append(path, content)</code>","text":"<p>Appends a string to the end of a file, creating it if it doesn't exist.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the file.</li> <li><code>content</code> (string): The content to append.</li> </ul> </li> <li>Returns:<ul> <li><code>err</code> (string or nil): An error message on failure, otherwise <code>nil</code>.</li> </ul> </li> </ul>"},{"location":"LUA_API/#fsexistspath","title":"<code>fs.exists(path)</code>","text":"<p>Checks if a file or directory exists at the given path.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to check.</li> </ul> </li> <li>Returns:<ul> <li><code>exists</code> (boolean): <code>true</code> if the path exists, <code>false</code> otherwise.</li> </ul> </li> </ul>"},{"location":"LUA_API/#fsmkdirpath","title":"<code>fs.mkdir(path)</code>","text":"<p>Creates a directory, including any necessary parent directories.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The directory path to create.</li> </ul> </li> <li>Returns:<ul> <li><code>err</code> (string or nil): An error message on failure, otherwise <code>nil</code>.</li> </ul> </li> </ul>"},{"location":"LUA_API/#fsrmpath","title":"<code>fs.rm(path)</code>","text":"<p>Removes a file or an empty directory.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to remove.</li> </ul> </li> <li>Returns:<ul> <li><code>err</code> (string or nil): An error message on failure, otherwise <code>nil</code>.</li> </ul> </li> </ul>"},{"location":"LUA_API/#fsrm_rpath","title":"<code>fs.rm_r(path)</code>","text":"<p>Recursively removes a directory and all its contents.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the directory to remove.</li> </ul> </li> <li>Returns:<ul> <li><code>err</code> (string or nil): An error message on failure, otherwise <code>nil</code>.</li> </ul> </li> </ul>"},{"location":"LUA_API/#fslspath","title":"<code>fs.ls(path)</code>","text":"<p>Lists the names of files and directories inside a given path.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the directory.</li> </ul> </li> <li>Returns:<ul> <li><code>files</code> (table or nil): A Lua table (array) of file and directory names, or <code>nil</code> on error.</li> <li><code>err</code> (string or nil): An error message on failure, otherwise <code>nil</code>.</li> </ul> </li> </ul> <p>Example:</p> <pre><code>local dir = \"/tmp/sloth-test\"\nfs.mkdir(dir)\nfs.write(dir .. \"/hello.txt\", \"Hello from Sloth! \ud83e\udda5\")\nlocal files, err = fs.ls(dir)\nif err then\n    log.error(\"Could not list files: \" .. err)\nelse\n    log.info(\"Files in \" .. dir .. \": \" .. data.to_json(files))\nend\nfs.rm_r(dir)\n</code></pre>"},{"location":"LUA_API/#net-module","title":"<code>net</code> Module","text":"<p>The <code>net</code> module provides networking utilities.</p>"},{"location":"LUA_API/#nethttp_geturl","title":"<code>net.http_get(url)</code>","text":"<p>Performs an HTTP GET request.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL to request.</li> </ul> </li> <li>Returns:<ul> <li><code>body</code> (string or nil): The response body.</li> <li><code>status_code</code> (number): The HTTP status code (e.g., <code>200</code>).</li> <li><code>headers</code> (table or nil): A Lua table of response headers.</li> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul>"},{"location":"LUA_API/#nethttp_posturl-body-headers","title":"<code>net.http_post(url, body, [headers])</code>","text":"<p>Performs an HTTP POST request.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL to post to.</li> <li><code>body</code> (string): The request body.</li> <li><code>headers</code> (table, optional): A Lua table of request headers.</li> </ul> </li> <li>Returns:<ul> <li><code>body</code> (string or nil): The response body.</li> <li><code>status_code</code> (number): The HTTP status code.</li> <li><code>headers</code> (table or nil): A Lua table of response headers.</li> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul>"},{"location":"LUA_API/#netdownloadurl-destination_path","title":"<code>net.download(url, destination_path)</code>","text":"<p>Downloads a file from a URL to a local path.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL of the file to download.</li> <li><code>destination_path</code> (string): The local path to save the file.</li> </ul> </li> <li>Returns:<ul> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul> <p>Example:</p> <pre><code>log.info(\"Fetching a random cat fact...\")\nlocal body, status, _, err = net.http_get(\"https://catfact.ninja/fact\")\nif err or status ~= 200 then\n    log.error(\"Failed to fetch cat fact: \" .. (err or \"status \" .. status))\nelse\n    local fact_data, json_err = data.parse_json(body)\n    if json_err then\n        log.error(\"Could not parse cat fact JSON: \" .. json_err)\n    else\n        log.info(\"\ud83d\udc31 Cat Fact: \" .. fact_data.fact)\n    end\nend\n</code></pre>"},{"location":"LUA_API/#data-module","title":"<code>data</code> Module","text":"<p>The <code>data</code> module provides functions for data serialization and deserialization.</p>"},{"location":"LUA_API/#datato_jsontable","title":"<code>data.to_json(table)</code>","text":"<p>Converts a Lua table to a JSON string.</p> <ul> <li>Parameters:<ul> <li><code>table</code> (table): The Lua table to convert.</li> </ul> </li> <li>Returns:<ul> <li><code>json_string</code> (string or nil): The resulting JSON string.</li> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul>"},{"location":"LUA_API/#dataparse_jsonjson_string","title":"<code>data.parse_json(json_string)</code>","text":"<p>Parses a JSON string into a Lua table.</p> <ul> <li>Parameters:<ul> <li><code>json_string</code> (string): The JSON string to parse.</li> </ul> </li> <li>Returns:<ul> <li><code>table</code> (table or nil): The resulting Lua table.</li> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul>"},{"location":"LUA_API/#datato_yamltable","title":"<code>data.to_yaml(table)</code>","text":"<p>Converts a Lua table to a YAML string.</p> <ul> <li>Parameters:<ul> <li><code>table</code> (table): The Lua table to convert.</li> </ul> </li> <li>Returns:<ul> <li><code>yaml_string</code> (string or nil): The resulting YAML string.</li> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul>"},{"location":"LUA_API/#dataparse_yamlyaml_string","title":"<code>data.parse_yaml(yaml_string)</code>","text":"<p>Parses a YAML string into a Lua table.</p> <ul> <li>Parameters:<ul> <li><code>yaml_string</code> (string): The YAML string to parse.</li> </ul> </li> <li>Returns:<ul> <li><code>table</code> (table or nil): The resulting Lua table.</li> <li><code>err</code> (string or nil): An error message on failure.</li> </ul> </li> </ul>"},{"location":"LUA_API/#log-module","title":"<code>log</code> Module","text":"<p>The <code>log</code> module provides simple logging functions.</p>"},{"location":"LUA_API/#loginfomessage","title":"<code>log.info(message)</code>","text":""},{"location":"LUA_API/#logwarnmessage","title":"<code>log.warn(message)</code>","text":""},{"location":"LUA_API/#logerrormessage","title":"<code>log.error(message)</code>","text":""},{"location":"LUA_API/#logdebugmessage","title":"<code>log.debug(message)</code>","text":"<ul> <li>Parameters:<ul> <li><code>message</code> (string): The message to log.</li> </ul> </li> </ul> <p>Example:</p> <pre><code>log.info(\"Starting the task.\")\nlog.warn(\"This is a warning.\")\nlog.error(\"Something went wrong!\")\nlog.debug(\"Here is some debug info.\")\n</code></pre>"},{"location":"LUA_API/#salt-module","title":"<code>salt</code> Module","text":"<p>The <code>salt</code> module allows for direct execution of SaltStack commands.</p>"},{"location":"LUA_API/#saltcmdcommand_type-arg1-arg2","title":"<code>salt.cmd(command_type, [arg1, arg2, ...])</code>","text":"<p>Executes a SaltStack command.</p> <ul> <li>Parameters:<ul> <li><code>command_type</code> (string): The type of command, either <code>\"salt\"</code> or <code>\"salt-call\"</code>.</li> <li><code>arg...</code> (string, optional): A variable number of string arguments for the command.</li> </ul> </li> <li>Returns:<ul> <li><code>stdout</code> (string): The standard output of the command.</li> <li><code>stderr</code> (string): The standard error output of the command.</li> <li><code>err</code> (string or nil): An error message if the command fails, otherwise <code>nil</code>.</li> </ul> </li> </ul> <p>Example:</p> <pre><code>-- Ping all minions\nlocal stdout, stderr, err = salt.cmd(\"salt\", \"*\", \"test.ping\")\nif err then\n    log.error(\"Salt command failed: \" .. stderr)\nelse\n    log.info(\"Salt ping result:\\n\" .. stdout)\nend\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/","title":"\ud83d\udea8 Funcionalidades N\u00e3o Documentadas no Site","text":"<p>Esta \u00e9 uma lista abrangente de funcionalidades implementadas no Sloth Runner que n\u00e3o est\u00e3o adequadamente documentadas no site atual.</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-criticas-em-falta","title":"\ud83c\udfaf Funcionalidades Cr\u00edticas em Falta","text":""},{"location":"MISSING_FEATURES_DOCUMENTATION/#1-sistema-de-agentes-distribuidos","title":"1. \ud83e\udd16 Sistema de Agentes Distribu\u00eddos","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Master-Agent Architecture com gRPC</li> <li>\u2705 Registro autom\u00e1tico de agentes</li> <li>\u2705 Heartbeat e monitoramento</li> <li>\u2705 Execu\u00e7\u00e3o remota de comandos</li> <li>\u2705 Load balancing inteligente</li> <li>\u2705 Failover autom\u00e1tico</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#comandos-cli","title":"Comandos CLI:","text":"<pre><code># Master server\nsloth-runner master --port 50053 --daemon\n\n# Agent management  \nsloth-runner agent start --name agent1 --master localhost:50053\nsloth-runner agent list --master localhost:50053\nsloth-runner agent run agent1 \"comando\" --master localhost:50053\nsloth-runner agent stop agent1 --master localhost:50053\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>cmd/sloth-runner/main.go</code> (linhas 202-1017)</li> <li><code>cmd/sloth-runner/agent_registry.go</code></li> <li><code>proto/agent.proto</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#2-dashboard-web-ui","title":"2. \ud83c\udfa8 Dashboard Web UI","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_1","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Web Dashboard completo</li> <li>\u2705 Monitoramento de tasks em tempo real</li> <li>\u2705 Gest\u00e3o de agentes visual</li> <li>\u2705 Logs centralizados</li> <li>\u2705 M\u00e9tricas de performance</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#comandos-cli_1","title":"Comandos CLI:","text":"<pre><code># UI server\nsloth-runner ui --port 8080\nsloth-runner ui --daemon --port 8080\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_1","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/ui/server.go</code></li> <li><code>cmd/sloth-runner/main.go</code> (linhas 136-200)</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#3-sistema-de-scheduler","title":"3. \u23f0 Sistema de Scheduler","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_2","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Cron-style scheduling</li> <li>\u2705 Task scheduling autom\u00e1tico</li> <li>\u2705 Gest\u00e3o de schedules</li> <li>\u2705 Background execution</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#comandos-cli_2","title":"Comandos CLI:","text":"<pre><code># Scheduler management\nsloth-runner scheduler enable --config scheduler.yaml\nsloth-runner scheduler disable\nsloth-runner scheduler list\nsloth-runner scheduler delete task_name\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_2","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>cmd/sloth-runner/main.go</code> (linhas 272-373)</li> <li><code>internal/scheduler/</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#4-modulos-de-iaml","title":"4. \ud83e\udde0 M\u00f3dulos de IA/ML","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_3","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 OpenAI integration</li> <li>\u2705 Text processing com IA</li> <li>\u2705 Code generation autom\u00e1tico  </li> <li>\u2705 Decision making inteligente</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#modulos-lua","title":"M\u00f3dulos Lua:","text":"<pre><code>-- IA modules\nlocal ai = require(\"ai\")\nlocal openai_result = ai.openai.complete(\"prompt\")\nlocal decision = ai.decide(conditions)\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_3","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/ai.go</code></li> <li><code>internal/ai/</code></li> <li><code>examples/ai_*.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#5-modulos-cloud-avancados","title":"5. \ud83d\udd27 M\u00f3dulos Cloud Avan\u00e7ados","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_4","title":"Funcionalidades Dispon\u00edveis:","text":""},{"location":"MISSING_FEATURES_DOCUMENTATION/#aws-avancado","title":"AWS Avan\u00e7ado:","text":"<ul> <li>\u2705 EC2, S3, RDS management</li> <li>\u2705 Lambda functions</li> <li>\u2705 CloudFormation</li> <li>\u2705 EKS clusters</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#gcp-avancado","title":"GCP Avan\u00e7ado:","text":"<ul> <li>\u2705 Compute Engine</li> <li>\u2705 GKE clusters</li> <li>\u2705 Cloud Storage</li> <li>\u2705 Cloud SQL</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#azure-avancado","title":"Azure Avan\u00e7ado:","text":"<ul> <li>\u2705 Virtual Machines</li> <li>\u2705 AKS clusters</li> <li>\u2705 Storage Accounts</li> <li>\u2705 SQL Database</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_4","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/aws.go</code></li> <li><code>internal/luainterface/gcp.go</code></li> <li><code>internal/luainterface/azure.go</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#6-integracao-devops-avancada","title":"6. \ud83d\ude80 Integra\u00e7\u00e3o DevOps Avan\u00e7ada","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_5","title":"Funcionalidades Dispon\u00edveis:","text":""},{"location":"MISSING_FEATURES_DOCUMENTATION/#gitops","title":"GitOps:","text":"<ul> <li>\u2705 Git operations avan\u00e7adas</li> <li>\u2705 Repository management</li> <li>\u2705 Branch strategies</li> <li>\u2705 CI/CD integration</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#terraform-avancado","title":"Terraform Avan\u00e7ado:","text":"<ul> <li>\u2705 State management</li> <li>\u2705 Plan/Apply/Destroy</li> <li>\u2705 Remote backends</li> <li>\u2705 Workspace management</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#pulumi-avancado","title":"Pulumi Avan\u00e7ado:","text":"<ul> <li>\u2705 Stack management</li> <li>\u2705 Secret management</li> <li>\u2705 Preview/Update</li> <li>\u2705 Policy enforcement</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_5","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/gitops.go</code></li> <li><code>internal/luainterface/terraform_advanced.go</code></li> <li><code>internal/luainterface/pulumi_advanced.go</code></li> <li><code>internal/gitops/</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#7-modulo-de-seguranca-enterprise","title":"7. \ud83d\udd12 M\u00f3dulo de Seguran\u00e7a Enterprise","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_6","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Certificate management</li> <li>\u2705 Secret encryption</li> <li>\u2705 Vulnerability scanning</li> <li>\u2705 Compliance checking</li> <li>\u2705 Audit logging</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#modulos-lua_1","title":"M\u00f3dulos Lua:","text":"<pre><code>local security = require(\"security\")\nsecurity.scan_vulnerabilities(target)\nsecurity.encrypt_secret(value)\nsecurity.audit_log(action, details)\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_6","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/security.go</code></li> <li><code>examples/security_module_example.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#8-sistema-de-observabilidade","title":"8. \ud83d\udcca Sistema de Observabilidade","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_7","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Metrics collection</li> <li>\u2705 Distributed tracing</li> <li>\u2705 Log aggregation</li> <li>\u2705 Performance monitoring</li> <li>\u2705 Alerting system</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#modulos-lua_2","title":"M\u00f3dulos Lua:","text":"<pre><code>local observability = require(\"observability\")\nobservability.metrics.counter(\"task.executed\")\nobservability.trace.start(\"workflow.execution\")\nobservability.alert.send(\"high_cpu\", details)\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_7","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/observability.go</code></li> <li><code>internal/luainterface/metrics.go</code></li> <li><code>examples/observability_module_example.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#9-sistema-de-state-avancado","title":"9. \ud83d\udcbe Sistema de State Avan\u00e7ado","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_8","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Distributed locking</li> <li>\u2705 TTL support</li> <li>\u2705 Pattern queries</li> <li>\u2705 Atomic operations</li> <li>\u2705 State replication</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#modulos-lua_3","title":"M\u00f3dulos Lua:","text":"<pre><code>local state = require(\"state\")\nstate.lock(\"resource_key\", 30) -- 30 second lock\nstate.set(\"key\", value, 3600)  -- 1 hour TTL\nstate.atomic_increment(\"counter\")\n</code></pre>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_8","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/state.go</code></li> <li><code>internal/state/</code></li> <li><code>examples/state_management_demo.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#10-modulos-de-rede-e-comunicacao","title":"10. \ud83c\udf10 M\u00f3dulos de Rede e Comunica\u00e7\u00e3o","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_9","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 HTTP/HTTPS requests</li> <li>\u2705 WebSocket communication</li> <li>\u2705 TCP/UDP operations</li> <li>\u2705 Network discovery</li> <li>\u2705 Load balancing</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_9","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/network.go</code></li> <li><code>internal/luainterface/http.go</code></li> <li><code>examples/network_module_example.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#11-sistema-de-notificacoes","title":"11. \ud83d\udce7 Sistema de Notifica\u00e7\u00f5es","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_10","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Email notifications</li> <li>\u2705 Slack integration</li> <li>\u2705 Discord webhooks</li> <li>\u2705 SMS notifications</li> <li>\u2705 Custom webhooks</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_10","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/notifications.go</code></li> <li><code>examples/notifications_example.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#12-sistemas-de-banco-de-dados","title":"12. \ud83d\udcbd Sistemas de Banco de Dados","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_11","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 MySQL/PostgreSQL</li> <li>\u2705 MongoDB</li> <li>\u2705 Redis</li> <li>\u2705 SQLite</li> <li>\u2705 Connection pooling</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_11","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/database.go</code></li> <li><code>examples/database_module_example.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#13-integracao-pythonr","title":"13. \ud83d\udc0d Integra\u00e7\u00e3o Python/R","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_12","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Python script execution</li> <li>\u2705 Virtual environment management</li> <li>\u2705 Package installation</li> <li>\u2705 Data science workflows</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_12","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/python.go</code></li> <li><code>examples/python_venv_*.sloth</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#14-sistema-de-testes-avancado","title":"14. \ud83e\uddea Sistema de Testes Avan\u00e7ado","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_13","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Unit testing framework</li> <li>\u2705 Integration tests</li> <li>\u2705 Performance testing</li> <li>\u2705 Mock system</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_13","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/testing.go</code></li> <li><code>internal/core/core_test.go</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#15-reliable-computing","title":"15. \ud83d\udd27 Reliable Computing","text":"<p>STATUS: IMPLEMENTADO mas n\u00e3o documentado</p>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-disponiveis_14","title":"Funcionalidades Dispon\u00edveis:","text":"<ul> <li>\u2705 Circuit breaker pattern</li> <li>\u2705 Retry mechanisms</li> <li>\u2705 Timeout management</li> <li>\u2705 Failover strategies</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#arquivos-de-implementacao_14","title":"Arquivos de Implementa\u00e7\u00e3o:","text":"<ul> <li><code>internal/luainterface/reliability.go</code></li> <li><code>internal/reliability/</code></li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#estatisticas-alarmantes","title":"\ud83d\udcca Estat\u00edsticas Alarmantes","text":""},{"location":"MISSING_FEATURES_DOCUMENTATION/#funcionalidades-implementadas-vs-documentadas","title":"Funcionalidades Implementadas vs Documentadas:","text":"<ul> <li>\ud83d\udfe2 Implementadas: ~50+ funcionalidades principais</li> <li>\ud83d\udd34 Documentadas no site: ~15 funcionalidades  </li> <li>\ud83d\udcc9 Taxa de documenta\u00e7\u00e3o: ~30%</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#modulos-lua-nao-documentados","title":"M\u00f3dulos Lua N\u00e3o Documentados:","text":"<ul> <li>Total de m\u00f3dulos: 37 arquivos em <code>internal/luainterface/</code></li> <li>Documentados: ~8 m\u00f3dulos</li> <li>Taxa de documenta\u00e7\u00e3o de m\u00f3dulos: ~22%</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#comandos-cli-nao-documentados","title":"Comandos CLI N\u00e3o Documentados:","text":"<ul> <li>Total de comandos: 25+ comandos e subcomandos</li> <li>Documentados: ~8 comandos</li> <li>Taxa de documenta\u00e7\u00e3o CLI: ~32%</li> </ul>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#impacto-para-usuarios","title":"\ud83c\udfaf Impacto para Usu\u00e1rios","text":""},{"location":"MISSING_FEATURES_DOCUMENTATION/#problemas-atuais","title":"Problemas Atuais:","text":"<ol> <li>Usu\u00e1rios n\u00e3o sabem sobre funcionalidades avan\u00e7adas</li> <li>Subutiliza\u00e7\u00e3o da ferramenta completa</li> <li>Baixa ado\u00e7\u00e3o de features enterprise</li> <li>Dificuldade de discovery de novos recursos</li> </ol>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#oportunidades-perdidas","title":"Oportunidades Perdidas:","text":"<ol> <li>Diferencia\u00e7\u00e3o competitiva n\u00e3o comunicada</li> <li>Value proposition n\u00e3o clara</li> <li>Enterprise sales limitadas</li> <li>Community adoption reduzida</li> </ol>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#acao-recomendada","title":"\ud83d\ude80 A\u00e7\u00e3o Recomendada","text":""},{"location":"MISSING_FEATURES_DOCUMENTATION/#prioridade-alta","title":"Prioridade ALTA:","text":"<ol> <li>Documentar sistema de agentes distribu\u00eddos</li> <li>Criar guias para dashboard web</li> <li>Documentar m\u00f3dulos cloud avan\u00e7ados</li> <li>Explicar sistema de IA/ML</li> </ol>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#prioridade-media","title":"Prioridade M\u00c9DIA:","text":"<ol> <li>Scheduler e automa\u00e7\u00e3o</li> <li>Observabilidade e monitoring</li> <li>Seguran\u00e7a enterprise</li> <li>State management avan\u00e7ado</li> </ol>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#prioridade-baixa","title":"Prioridade BAIXA:","text":"<ol> <li>M\u00f3dulos espec\u00edficos (crypto, time, etc)</li> <li>Integra\u00e7\u00f5es nicho</li> <li>Features experimentais</li> </ol>"},{"location":"MISSING_FEATURES_DOCUMENTATION/#conclusao","title":"\ud83d\udcdd Conclus\u00e3o","text":"<p>O Sloth Runner tem muito mais funcionalidades implementadas do que o site atual documenta. \u00c9 uma ferramenta enterprise-ready com capabilities compar\u00e1veis a ferramentas como:</p> <ul> <li>Terraform (IaC)</li> <li>Pulumi (Stack management)  </li> <li>Ansible (Automation)</li> <li>Jenkins (CI/CD)</li> <li>Kubernetes (Orchestration)</li> </ul> <p>A documenta\u00e7\u00e3o atual n\u00e3o reflete a real capacidade e valor da ferramenta! \ud83d\udea8</p>"},{"location":"STACK_MANAGEMENT_GUIDE/","title":"\ud83d\uddc2\ufe0f Stack Management Guide","text":"<p>Pulumi-Style Stack Management for Workflow State Persistence and Output Management</p> <p>Sloth Runner provides sophisticated stack management capabilities similar to Pulumi's approach, allowing you to maintain persistent state, track execution history, and capture exported outputs from your workflows.</p>"},{"location":"STACK_MANAGEMENT_GUIDE/#overview","title":"\ud83c\udf1f Overview","text":"<p>Stack management in Sloth Runner enables:</p> <ul> <li>\u2705 Persistent State: SQLite-based state storage</li> <li>\u2705 Exported Outputs: Capture and persist workflow outputs</li> <li>\u2705 Execution History: Complete audit trail of runs</li> <li>\u2705 Environment Isolation: Separate stacks for different environments</li> <li>\u2705 Unique Task IDs: Enhanced traceability and debugging</li> <li>\u2705 JSON Output: Machine-readable results for automation</li> </ul>"},{"location":"STACK_MANAGEMENT_GUIDE/#basic-stack-operations","title":"\ud83d\ude80 Basic Stack Operations","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#create-and-run-a-stack","title":"Create and Run a Stack","text":"<pre><code># Create a new stack by running workflow with stack name\nsloth-runner run my-production-stack -f pipeline.sloth\n\n# Run with enhanced output\nsloth-runner run my-production-stack -f pipeline.sloth --output enhanced\n\n# Run with JSON output for automation\nsloth-runner run my-production-stack -f pipeline.sloth --output json\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#list-all-stacks","title":"List All Stacks","text":"<pre><code>sloth-runner stack list\n</code></pre> <p>Example output: <pre><code>Workflow Stacks     \n\nNAME                  STATUS      LAST RUN           DURATION       EXECUTIONS   DESCRIPTION\n----                  ------      --------           --------       ----------   -----------\nmy-production-stack   completed   2025-09-30 08:22   5.192ms        1            Stack for workflow: my-production-stack\ndev-environment       completed   2025-09-30 08:19   9.073s         3            Stack for workflow: dev-environment\nstaging-app           failed      2025-09-30 08:18   12.730ms       1            Stack for workflow: staging-app\n</code></pre></p>"},{"location":"STACK_MANAGEMENT_GUIDE/#show-stack-details","title":"Show Stack Details","text":"<pre><code>sloth-runner stack show my-production-stack\n</code></pre> <p>Example output: <pre><code>Stack: my-production-stack\n\nID: 6d5ae01e-b3ae-4787-8038-ffd0fd307ac7\nDescription: Stack for workflow: my-production-stack\nVersion: 1.0.0\nStatus: completed\nCreated: 2025-09-30 08:22:45\nUpdated: 2025-09-30 08:22:46\nCompleted: 2025-09-30 08:22:46\nWorkflow File: pipeline.sloth\nExecutions: 1\nLast Duration: 5.192ms\n\nOutputs\napp_url: https://myapp.example.com\nversion: 1.2.3\nenvironment: production\ndeployed_at: Mon Sep 30 08:22:45 2025\n\nRecent Executions\nSTARTED         STATUS      DURATION    TASKS   SUCCESS   FAILED\n-------         ------      --------    -----   -------   ------\n2025-09-30 08:22   completed   5.192ms     1       1         0\n</code></pre></p>"},{"location":"STACK_MANAGEMENT_GUIDE/#delete-a-stack","title":"Delete a Stack","text":"<pre><code># Delete with confirmation\nsloth-runner stack delete old-stack\n\n# Force delete without confirmation\nsloth-runner stack delete old-stack --force\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#exporting-outputs-in-workflows","title":"\ud83d\udcdd Exporting Outputs in Workflows","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#using-runnerexport","title":"Using runner.Export()","text":"<pre><code>local deploy_task = task(\"deploy_application\")\n    :description(\"Deploy application and export outputs\")\n    :command(function(params, deps)\n        log.info(\"\ud83d\ude80 Deploying application...\")\n\n        -- Perform deployment\n        local result = exec.run(\"kubectl apply -f deployment.yaml\")\n\n        if result.success then\n            -- Export outputs that will be persisted in stack\n            runner.Export({\n                app_url = \"https://myapp.example.com\",\n                version = \"1.2.3\",\n                environment = params.environment or \"production\",\n                deployed_at = os.date(),\n                health_endpoint = \"https://myapp.example.com/health\",\n                database_url = \"postgres://prod-db:5432/myapp\",\n                replicas = 3\n            })\n\n            log.info(\"\u2705 Application deployed successfully!\")\n            return true, result.stdout, { \n                status = \"deployed\",\n                replicas = 3 \n            }\n        else\n            log.error(\"\u274c Deployment failed: \" .. result.stderr)\n            return false, result.stderr\n        end\n    end)\n    :timeout(\"10m\")\n    :build()\n\nworkflow.define(\"production_deployment\", {\n    description = \"Production Application Deployment\",\n    version = \"1.0.0\",\n    tasks = { deploy_task }\n})\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#using-global-outputs-table","title":"Using Global outputs Table","text":"<pre><code>-- Alternative method using global outputs table\nlocal setup_task = task(\"setup_infrastructure\")\n    :command(function()\n        log.info(\"Setting up infrastructure...\")\n\n        -- Setup infrastructure\n        local vpc_result = exec.run(\"terraform apply -auto-approve vpc.tf\")\n        local db_result = exec.run(\"terraform apply -auto-approve database.tf\")\n\n        -- Set global outputs that will be captured\n        outputs = {\n            vpc_id = \"vpc-123456789\",\n            database_endpoint = \"db.example.com:5432\",\n            security_group_id = \"sg-987654321\",\n            created_at = os.time()\n        }\n\n        return true, \"Infrastructure setup complete\"\n    end)\n    :build()\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#json-output-for-automation","title":"\ud83d\udcca JSON Output for Automation","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#basic-json-output","title":"Basic JSON Output","text":"<pre><code>sloth-runner run my-stack -f workflow.sloth --output json\n</code></pre> <p>Example JSON response: <pre><code>{\n  \"status\": \"success\",\n  \"duration\": \"5.192125ms\",\n  \"stack\": {\n    \"id\": \"6d5ae01e-b3ae-4787-8038-ffd0fd307ac7\",\n    \"name\": \"my-stack\"\n  },\n  \"tasks\": {\n    \"deploy_application\": {\n      \"status\": \"Success\",\n      \"duration\": \"4.120ms\",\n      \"error\": \"\"\n    },\n    \"run_tests\": {\n      \"status\": \"Success\", \n      \"duration\": \"1.050ms\",\n      \"error\": \"\"\n    }\n  },\n  \"outputs\": {\n    \"app_url\": \"https://myapp.example.com\",\n    \"version\": \"1.2.3\",\n    \"environment\": \"production\",\n    \"deployed_at\": \"Mon Sep 30 08:22:45 2025\"\n  },\n  \"workflow\": \"my-stack\",\n  \"execution_time\": 1759237365\n}\n</code></pre></p>"},{"location":"STACK_MANAGEMENT_GUIDE/#error-handling-in-json","title":"Error Handling in JSON","text":"<pre><code>{\n  \"status\": \"failed\",\n  \"duration\": \"2.341ms\",\n  \"error\": \"task execution failed: deployment failed with exit code 1\",\n  \"stack\": {\n    \"id\": \"abc123...\",\n    \"name\": \"failed-stack\"\n  },\n  \"tasks\": {\n    \"failing_task\": {\n      \"status\": \"Failed\",\n      \"duration\": \"1.200ms\",\n      \"error\": \"deployment failed with exit code 1\"\n    }\n  },\n  \"outputs\": {},\n  \"workflow\": \"failed-deployment\",\n  \"execution_time\": 1759237365\n}\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#task-and-group-ids","title":"\ud83c\udd94 Task and Group IDs","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#list-tasks-with-ids","title":"List Tasks with IDs","text":"<pre><code>sloth-runner list -f workflow.sloth\n</code></pre> <p>Example output: <pre><code>Workflow Tasks and Groups\n\n## Task Group: production_deployment\nID: 6e14b1ca-b8c8-4433-b813-ed4e9dabcb9c\nDescription: Production Application Deployment\n\nTasks:\nNAME                    ID                     DESCRIPTION                      DEPENDS ON\n----                    --                     -----------                      ----------\ndeploy_application      4600e1c7...           Deploy application and export    -\nrun_tests              8a92f3e1...           Run integration tests           deploy_application\nnotify_team            c4d8b2f9...           Send deployment notification     run_tests\n</code></pre></p>"},{"location":"STACK_MANAGEMENT_GUIDE/#using-ids-for-debugging","title":"Using IDs for Debugging","text":"<pre><code>local debug_task = task(\"debug_deployment\")\n    :description(\"Debug deployment with ID tracking\")\n    :command(function(params, deps)\n        log.info(\"\ud83d\udd0d Debugging task ID: \" .. params.task_id)\n        log.info(\"\ud83d\udd0d Group ID: \" .. params.group_id)\n\n        -- Access previous task results by ID\n        if deps.deploy_application then\n            log.info(\"\ud83d\udccb Deploy task result: \" .. deps.deploy_application.status)\n        end\n\n        return true, \"Debug complete\"\n    end)\n    :depends_on({\"deploy_application\"})\n    :build()\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#cicd-integration","title":"\ud83d\udd04 CI/CD Integration","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: Deploy with Sloth Runner\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Install Sloth Runner\n        run: |\n          curl -L https://github.com/chalkan3-sloth/sloth-runner/releases/latest/download/sloth-runner_linux_amd64.tar.gz | tar xz\n          chmod +x sloth-runner\n          sudo mv sloth-runner /usr/local/bin/\n\n      - name: Deploy to Production\n        id: deploy\n        run: |\n          # Run with JSON output for parsing\n          OUTPUT=$(sloth-runner run prod-${{ github.sha }} -f deploy.sloth --output json)\n          echo \"deployment_output=$OUTPUT\" &gt;&gt; $GITHUB_OUTPUT\n\n          # Check if deployment was successful\n          STATUS=$(echo \"$OUTPUT\" | jq -r '.status')\n          if [ \"$STATUS\" != \"success\" ]; then\n            echo \"Deployment failed!\"\n            exit 1\n          fi\n\n      - name: Extract Deployment Info\n        run: |\n          # Extract outputs from JSON\n          APP_URL=$(echo '${{ steps.deploy.outputs.deployment_output }}' | jq -r '.outputs.app_url')\n          VERSION=$(echo '${{ steps.deploy.outputs.deployment_output }}' | jq -r '.outputs.version')\n\n          echo \"\ud83d\ude80 Deployed successfully!\"\n          echo \"\ud83d\udccd App URL: $APP_URL\"\n          echo \"\ud83c\udff7\ufe0f Version: $VERSION\"\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#jenkins-pipeline-example","title":"Jenkins Pipeline Example","text":"<pre><code>pipeline {\n    agent any\n\n    stages {\n        stage('Deploy') {\n            steps {\n                script {\n                    // Run deployment with JSON output\n                    def result = sh(\n                        script: \"sloth-runner run jenkins-${env.BUILD_NUMBER} -f deploy.sloth --output json\",\n                        returnStdout: true\n                    ).trim()\n\n                    // Parse JSON result\n                    def deployment = readJSON text: result\n\n                    if (deployment.status == 'success') {\n                        echo \"\u2705 Deployment successful!\"\n                        echo \"\ud83d\udccd App URL: ${deployment.outputs.app_url}\"\n                        echo \"\ud83c\udff7\ufe0f Version: ${deployment.outputs.version}\"\n\n                        // Store outputs as build properties\n                        env.APP_URL = deployment.outputs.app_url\n                        env.DEPLOYED_VERSION = deployment.outputs.version\n                    } else {\n                        error(\"\u274c Deployment failed: ${deployment.error}\")\n                    }\n                }\n            }\n        }\n\n        stage('Verify Deployment') {\n            steps {\n                script {\n                    // Use exported outputs from previous stage\n                    sh \"curl -f ${env.APP_URL}/health\"\n                    echo \"\ud83c\udf89 Health check passed for version ${env.DEPLOYED_VERSION}\"\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#advanced-stack-management","title":"\ud83d\udcc8 Advanced Stack Management","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#stack-naming-strategies","title":"Stack Naming Strategies","text":"<pre><code># Environment-based naming\nsloth-runner run dev-myapp -f deploy.sloth\nsloth-runner run staging-myapp -f deploy.sloth  \nsloth-runner run prod-myapp -f deploy.sloth\n\n# Feature branch deployment\nsloth-runner run feature-auth-system -f deploy.sloth\n\n# Version-based deployment\nsloth-runner run myapp-v1.2.3 -f deploy.sloth\n\n# Time-based deployment\nsloth-runner run deploy-$(date +%Y%m%d-%H%M%S) -f deploy.sloth\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#stack-lifecycle-management","title":"Stack Lifecycle Management","text":"<pre><code># Create development stack\nsloth-runner run dev-app -f app.sloth --output enhanced\n\n# Promote to staging\nsloth-runner run staging-app -f app.sloth -v staging-values.yaml\n\n# Production deployment with audit trail\nsloth-runner run prod-app -f app.sloth -v prod-values.yaml --output json | tee deployment-audit.json\n\n# Cleanup old stacks\nsloth-runner stack list | grep \"failed\" | awk '{print $1}' | xargs -I {} sloth-runner stack delete {} --force\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#best-practices","title":"\ud83d\udee0\ufe0f Best Practices","text":""},{"location":"STACK_MANAGEMENT_GUIDE/#1-meaningful-stack-names","title":"1. Meaningful Stack Names","text":"<pre><code># \u2705 Good: Environment and purpose clear\nsloth-runner run prod-ecommerce-api -f deploy.sloth\nsloth-runner run staging-user-service -f deploy.sloth\n\n# \u274c Bad: Generic names\nsloth-runner run test1 -f deploy.sloth\nsloth-runner run my-stack -f deploy.sloth\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#2-comprehensive-output-exports","title":"2. Comprehensive Output Exports","text":"<pre><code>-- \u2705 Good: Export all relevant information\nrunner.Export({\n    app_url = \"https://api.example.com\",\n    version = \"1.2.3\",\n    environment = \"production\",\n    deployed_at = os.date(),\n    health_endpoint = \"https://api.example.com/health\",\n    database_url = \"postgres://prod-db:5432/app\",\n    replicas = 3,\n    resource_limits = {\n        cpu = \"500m\",\n        memory = \"1Gi\"\n    }\n})\n\n-- \u274c Bad: Minimal or no exports\nrunner.Export({\n    status = \"deployed\"\n})\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#3-error-handling-and-rollback","title":"3. Error Handling and Rollback","text":"<pre><code>local deploy_task = task(\"deploy_with_rollback\")\n    :command(function(params, deps)\n        local current_version = state.get(\"current_version\") or \"unknown\"\n\n        -- Attempt deployment\n        local result = exec.run(\"kubectl apply -f deployment.yaml\")\n\n        if result.success then\n            -- Verify deployment health\n            local health_check = net.get(\"https://app.example.com/health\", {timeout = 30})\n\n            if health_check.status_code == 200 then\n                runner.Export({\n                    status = \"deployed\",\n                    previous_version = current_version,\n                    current_version = params.version,\n                    deployed_at = os.date()\n                })\n                state.set(\"current_version\", params.version)\n                return true, \"Deployment successful\"\n            else\n                -- Rollback on health check failure\n                log.error(\"Health check failed, rolling back...\")\n                exec.run(\"kubectl rollout undo deployment/myapp\")\n                return false, \"Deployment failed health check, rolled back\"\n            end\n        else\n            return false, \"Deployment command failed: \" .. result.stderr\n        end\n    end)\n    :on_failure(function(params, error)\n        log.error(\"\ud83d\udca5 Deployment failed: \" .. error)\n        -- Additional cleanup or notification logic\n    end)\n    :build()\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#4-stack-monitoring-and-alerting","title":"4. Stack Monitoring and Alerting","text":"<pre><code>local monitor_task = task(\"post_deployment_monitoring\")\n    :command(function(params, deps)\n        -- Set up monitoring after deployment\n        monitoring.gauge(\"deployment_status\", 1)\n        monitoring.counter(\"deployments_total\", 1)\n\n        -- Export monitoring information\n        runner.Export({\n            monitoring_enabled = true,\n            metrics_endpoint = \"https://metrics.example.com/myapp\",\n            alerts_configured = {\n                \"high_error_rate\",\n                \"slow_response_time\",\n                \"pod_restart_rate\"\n            }\n        })\n\n        return true, \"Monitoring configured\"\n    end)\n    :depends_on({\"deploy_with_rollback\"})\n    :build()\n</code></pre>"},{"location":"STACK_MANAGEMENT_GUIDE/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>\ud83d\ude80 Getting Started</li> <li>\ud83d\udcca CLI Reference</li> <li>\ud83d\udcbe State Management</li> <li>\ud83c\udfaf Advanced Features</li> <li>\ud83c\udf10 Distributed Execution</li> </ul> <p>Stack Management in Sloth Runner provides enterprise-grade workflow state management with the simplicity and power you need for modern automation workflows.</p>"},{"location":"TUTORIAL/","title":"\ud83d\ude80 Sloth Runner - Quick Tutorial","text":"<p>Welcome to the world's most intelligent task orchestration platform! This tutorial will get you up and running with AI-powered automation and GitOps workflows in just 5 minutes.</p> <p>\ud83d\udcdd Important Note: Starting with the current version, Sloth Runner workflow files use the <code>.sloth</code> extension instead of <code>.lua</code>. The Lua syntax remains the same - only the file extension has changed for better identification of Sloth Runner DSL files.</p>"},{"location":"TUTORIAL/#what-youll-learn","title":"\ud83c\udfaf What You'll Learn","text":"<p>By the end of this tutorial, you'll have: - \u2705 Installed Sloth Runner - \u2705 Created your first AI-optimized task - \u2705 Set up a GitOps workflow - \u2705 Built an intelligent automation pipeline</p>"},{"location":"TUTORIAL/#step-1-installation","title":"\ud83d\udce6 Step 1: Installation","text":""},{"location":"TUTORIAL/#quick-install-recommended","title":"Quick Install (Recommended)","text":"<pre><code># Install the latest version\ncurl -sSL https://get.sloth-runner.dev | bash\n\n# Verify installation\nsloth-runner --version\n</code></pre>"},{"location":"TUTORIAL/#manual-install","title":"Manual Install","text":"<pre><code># Download from GitHub releases\nwget https://github.com/chalkan3-sloth/sloth-runner/releases/latest/download/sloth-runner-linux-amd64.tar.gz\ntar -xzf sloth-runner-linux-amd64.tar.gz\nsudo mv sloth-runner /usr/local/bin/\n</code></pre>"},{"location":"TUTORIAL/#verify-installation","title":"Verify Installation","text":"<pre><code>sloth-runner --help\n</code></pre>"},{"location":"TUTORIAL/#step-2-your-first-ai-powered-task","title":"\ud83e\udd16 Step 2: Your First AI-Powered Task","text":"<p>Create a file called <code>hello-ai.sloth</code>:</p> <pre><code>-- hello-ai.sloth\nlocal ai = require(\"ai\")\nlocal log = require(\"log\")\n\n-- Configure AI for optimal performance\nai.configure({\n    enabled = true,\n    learning_mode = \"adaptive\",\n    optimization_level = 8,\n    failure_prediction = true\n})\n\nlog.info(\"\ud83e\udd16 Welcome to AI-Powered Automation!\")\n\n-- Create an intelligent task\nlocal hello_task = task(\"ai_hello_world\")\n    :description(\"My first AI-optimized task\")\n    :command(function(params, deps)\n        local original_command = \"echo 'Hello, AI-Powered World!'\"\n\n        -- Let AI optimize the command\n        local ai_result = ai.optimize_command(original_command)\n\n        if ai_result.confidence_score &gt; 0.5 then\n            log.info(\"\ud83e\udd16 AI optimized the command!\")\n            log.info(\"\ud83d\udcc8 Confidence: \" .. string.format(\"%.1f%%\", ai_result.confidence_score * 100))\n            log.info(\"\u26a1 Expected speedup: \" .. string.format(\"%.1fx\", ai_result.expected_speedup))\n\n            -- Use AI-optimized command\n            return exec.run(ai_result.optimized_command)\n        else\n            log.info(\"\u2139\ufe0f Using original command (low AI confidence)\")\n            return exec.run(original_command)\n        end\n    end)\n    :on_success(function(params, output)\n        log.info(\"\u2705 Task completed successfully!\")\n\n        -- Record execution for AI learning\n        ai.record_execution({\n            task_name = \"ai_hello_world\",\n            command = output.command,\n            success = true,\n            execution_time = output.duration or \"0s\"\n        })\n    end)\n    :build()\n\n-- Create a simple workflow\nworkflow.define(\"ai_tutorial\", {\n    description = \"AI-Powered Hello World Tutorial\",\n    tasks = { hello_task },\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\ud83c\udf89 AI Tutorial completed successfully!\")\n            log.info(\"\ud83e\udde0 AI is now learning from this execution\")\n        end\n    end\n})\n</code></pre>"},{"location":"TUTORIAL/#run-your-ai-powered-task","title":"Run Your AI-Powered Task","text":"<pre><code>sloth-runner run -f hello-ai.sloth\n</code></pre> <p>Expected Output: <pre><code>\ud83e\udd16 Welcome to AI-Powered Automation!\n\ud83e\udd16 AI optimized the command!\n\ud83d\udcc8 Confidence: 85.0%\n\u26a1 Expected speedup: 1.2x\nHello, AI-Powered World!\n\u2705 Task completed successfully!\n\ud83c\udf89 AI Tutorial completed successfully!\n\ud83e\udde0 AI is now learning from this execution\n</code></pre></p>"},{"location":"TUTORIAL/#step-3-your-first-gitops-workflow","title":"\ud83d\udd04 Step 3: Your First GitOps Workflow","text":"<p>Create a file called <code>hello-gitops.sloth</code>:</p> <pre><code>-- hello-gitops.sloth\nlocal gitops = require(\"gitops\")\nlocal log = require(\"log\")\n\nlog.info(\"\ud83d\udd04 Welcome to GitOps Native Automation!\")\n\n-- Create a GitOps workflow (you can use any public repo for testing)\nlocal git_workflow = gitops.workflow({\n    repo = \"https://github.com/kubernetes/examples\",  -- Example public repo\n    branch = \"master\",\n    auto_sync = false,  -- Manual sync for this demo\n    diff_preview = true,\n    rollback_on_failure = true\n})\n\nlog.info(\"\u2705 GitOps workflow created!\")\nlog.info(\"\ud83d\udccb Workflow ID: \" .. git_workflow.workflow_id)\nlog.info(\"\ud83d\udce6 Repository ID: \" .. git_workflow.repository_id)\n\n-- Create a deployment task\nlocal deploy_task = task(\"gitops_deploy\")\n    :description(\"GitOps-powered deployment\")\n    :command(function(params, deps)\n        -- Preview changes before deployment\n        log.info(\"\ud83d\udd0d Generating diff preview...\")\n        local diff = gitops.generate_diff(git_workflow.workflow_id)\n\n        if diff then\n            log.info(\"\ud83d\udcca GitOps Change Summary:\")\n            log.info(\"  \ud83d\udcdd Total changes: \" .. diff.summary.total_changes)\n            log.info(\"  \u2728 Created resources: \" .. diff.summary.created_resources)\n            log.info(\"  \ud83d\udd04 Updated resources: \" .. diff.summary.updated_resources)\n            log.info(\"  \ud83d\uddd1\ufe0f Deleted resources: \" .. diff.summary.deleted_resources)\n\n            if diff.summary.conflict_count &gt; 0 then\n                log.warn(\"\u26a0\ufe0f \" .. diff.summary.conflict_count .. \" conflict(s) detected\")\n                return {success = false, message = \"Conflicts need resolution\"}\n            end\n        else\n            log.info(\"\u2139\ufe0f No changes detected\")\n        end\n\n        -- Simulate deployment (since we're using a read-only example repo)\n        log.info(\"\ud83d\ude80 Simulating GitOps deployment...\")\n        log.info(\"\u2705 GitOps deployment completed successfully!\")\n\n        return {success = true, message = \"GitOps deployment successful\"}\n    end)\n    :build()\n\n-- Monitor workflow status\nlocal status_task = task(\"check_status\")\n    :description(\"Check GitOps workflow status\")\n    :command(function(params, deps)\n        local status = gitops.get_workflow_status(git_workflow.workflow_id)\n\n        if status then\n            log.info(\"\ud83d\udcca GitOps Workflow Status:\")\n            log.info(\"  \ud83c\udff7\ufe0f Name: \" .. status.name)\n            log.info(\"  \ud83d\udcc8 Status: \" .. status.status)\n            log.info(\"  \ud83d\udd04 Auto-sync: \" .. tostring(status.auto_sync))\n            log.info(\"  \ud83d\udce6 Repository: \" .. status.repository)\n        end\n\n        return {success = true, message = \"Status check completed\"}\n    end)\n    :build()\n\n-- Create GitOps workflow\nworkflow.define(\"gitops_tutorial\", {\n    description = \"GitOps Native Tutorial\",\n    tasks = { deploy_task, status_task },\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\ud83c\udf89 GitOps Tutorial completed successfully!\")\n            log.info(\"\ud83d\udd04 You now understand GitOps native workflows!\")\n        end\n    end\n})\n</code></pre>"},{"location":"TUTORIAL/#run-your-gitops-workflow","title":"Run Your GitOps Workflow","text":"<pre><code>sloth-runner run -f hello-gitops.sloth\n</code></pre> <p>Expected Output: <pre><code>\ud83d\udd04 Welcome to GitOps Native Automation!\n\u2705 GitOps workflow created!\n\ud83d\udccb Workflow ID: workflow-1234567890\n\ud83d\udce6 Repository ID: repo-1234567890\n\ud83d\udd0d Generating diff preview...\n\ud83d\udcca GitOps Change Summary:\n  \ud83d\udcdd Total changes: 3\n  \u2728 Created resources: 2\n  \ud83d\udd04 Updated resources: 1\n  \ud83d\uddd1\ufe0f Deleted resources: 0\n\ud83d\ude80 Simulating GitOps deployment...\n\u2705 GitOps deployment completed successfully!\n\ud83d\udcca GitOps Workflow Status:\n  \ud83c\udff7\ufe0f Name: lua-generated-workflow\n  \ud83d\udcc8 Status: syncing\n  \ud83d\udd04 Auto-sync: false\n  \ud83d\udce6 Repository: repo-1234567890\n\ud83c\udf89 GitOps Tutorial completed successfully!\n\ud83d\udd04 You now understand GitOps native workflows!\n</code></pre></p>"},{"location":"TUTORIAL/#step-4-intelligent-pipeline-ai-gitops","title":"\u26a1 Step 4: Intelligent Pipeline (AI + GitOps)","text":"<p>Create a file called <code>intelligent-pipeline.sloth</code>:</p> <pre><code>-- intelligent-pipeline.sloth  \nlocal ai = require(\"ai\")\nlocal gitops = require(\"gitops\")\nlocal log = require(\"log\")\n\nlog.info(\"\ud83e\udde0 Building an Intelligent Pipeline with AI + GitOps!\")\n\n-- Configure AI for production-ready optimization\nai.configure({\n    enabled = true,\n    learning_mode = \"adaptive\",\n    optimization_level = 7,\n    failure_prediction = true,\n    auto_optimize = true\n})\n\n-- Create GitOps workflow for deployment\nlocal deployment_workflow = gitops.workflow({\n    repo = \"https://github.com/kubernetes/examples\",\n    branch = \"master\", \n    auto_sync = false,\n    diff_preview = true,\n    rollback_on_failure = true\n})\n\n-- AI-optimized build task\nlocal build_task = task(\"intelligent_build\")\n    :description(\"AI-optimized build process\")\n    :command(function(params, deps)\n        local build_command = \"echo 'Building application...'\"\n\n        -- AI optimization with context\n        local optimization = ai.optimize_command(build_command, {\n            history = ai.get_task_history(build_command),\n            system_resources = {\n                cpu_usage = 30,\n                memory_usage = 50\n            }\n        })\n\n        if optimization.confidence_score &gt; 0.6 then\n            log.info(\"\ud83e\udd16 AI Build Optimization Applied!\")\n            log.info(\"\ud83d\udcc8 Confidence: \" .. string.format(\"%.1f%%\", optimization.confidence_score * 100))\n            log.info(\"\u26a1 Expected Speedup: \" .. string.format(\"%.1fx\", optimization.expected_speedup))\n\n            return exec.run(optimization.optimized_command)\n        else\n            log.info(\"\ud83d\udd27 Using standard build process\")\n            return exec.run(build_command)\n        end\n    end)\n    :build()\n\n-- AI-enhanced deployment with failure prediction\nlocal deploy_task = task(\"intelligent_deploy\")\n    :description(\"AI-predicted GitOps deployment\")\n    :depends_on({\"intelligent_build\"})\n    :command(function(params, deps)\n        local deploy_command = \"kubectl apply -f manifests/\"\n\n        -- AI failure prediction\n        local prediction = ai.predict_failure(\"intelligent_deploy\", deploy_command)\n\n        log.info(\"\ud83d\udd2e AI Deployment Analysis:\")\n        log.info(\"\ud83d\udcca Failure Probability: \" .. string.format(\"%.1f%%\", prediction.failure_probability * 100))\n        log.info(\"\ud83c\udfaf Prediction Confidence: \" .. string.format(\"%.1f%%\", prediction.confidence * 100))\n\n        if prediction.failure_probability &gt; 0.3 then\n            log.warn(\"\u26a0\ufe0f HIGH RISK DEPLOYMENT DETECTED!\")\n            log.warn(\"\ud83d\udea8 AI recommends caution\")\n\n            for _, recommendation in ipairs(prediction.recommendations) do\n                log.info(\"\ud83d\udca1 AI Recommendation: \" .. recommendation)\n            end\n        else\n            log.info(\"\u2705 AI assessment: Low risk deployment\")\n        end\n\n        -- GitOps deployment with intelligent preview\n        log.info(\"\ud83d\udd0d GitOps intelligent diff analysis...\")\n        local diff = gitops.generate_diff(deployment_workflow.workflow_id)\n\n        if diff and diff.summary.total_changes &gt; 0 then\n            log.info(\"\ud83d\udccb Deployment will apply \" .. diff.summary.total_changes .. \" changes\")\n\n            -- Check for conflicts\n            if diff.summary.conflict_count &gt; 0 then\n                log.warn(\"\ud83d\udca5 \" .. diff.summary.conflict_count .. \" conflicts detected!\")\n                return {success = false, message = \"Conflicts require manual resolution\"}\n            end\n        end\n\n        -- Execute intelligent deployment\n        log.info(\"\ud83d\ude80 Executing AI + GitOps intelligent deployment...\")\n        local deploy_success = true  -- Simulated for tutorial\n\n        if deploy_success then\n            log.info(\"\u2705 Intelligent deployment completed successfully!\")\n\n            -- Record execution for AI learning\n            ai.record_execution({\n                task_name = \"intelligent_deploy\",\n                command = deploy_command,\n                success = true,\n                execution_time = \"45s\",\n                ai_prediction_used = true,\n                predicted_failure_probability = prediction.failure_probability,\n                gitops_changes_applied = diff and diff.summary.total_changes or 0\n            })\n\n            return {success = true, message = \"AI + GitOps deployment successful\"}\n        else\n            log.error(\"\ud83d\udca5 Deployment failed - AI will learn from this failure\")\n            return {success = false, message = \"Deployment failed\"}\n        end\n    end)\n    :build()\n\n-- Intelligent monitoring task\nlocal monitor_task = task(\"intelligent_monitor\")\n    :description(\"AI-powered post-deployment monitoring\")\n    :depends_on({\"intelligent_deploy\"})\n    :command(function(params, deps)\n        log.info(\"\ud83d\udcca Starting AI-powered monitoring...\")\n\n        -- Get performance analysis\n        local analysis = ai.analyze_performance(\"intelligent_deploy\")\n\n        if analysis.total_executions &gt; 0 then\n            log.info(\"\ud83d\udcc8 AI Performance Analysis:\")\n            log.info(\"  \ud83d\udcca Total executions: \" .. analysis.total_executions)\n            log.info(\"  \u2705 Success rate: \" .. string.format(\"%.1f%%\", analysis.success_rate * 100))\n            log.info(\"  \u23f1\ufe0f Average time: \" .. analysis.avg_execution_time)\n            log.info(\"  \ud83d\udcc8 Trend: \" .. analysis.performance_trend)\n\n            if #analysis.insights &gt; 0 then\n                log.info(\"\ud83d\udca1 AI Insights:\")\n                for _, insight in ipairs(analysis.insights) do\n                    log.info(\"  \ud83d\udd2e \" .. insight)\n                end\n            end\n        else\n            log.info(\"\u2139\ufe0f Insufficient data for AI analysis - will improve with more executions\")\n        end\n\n        -- Check GitOps workflow status\n        local gitops_status = gitops.get_workflow_status(deployment_workflow.workflow_id)\n        log.info(\"\ud83d\udd04 GitOps Status: \" .. gitops_status.status)\n\n        return {success = true, message = \"Intelligent monitoring completed\"}\n    end)\n    :build()\n\n-- Create the intelligent pipeline\nworkflow.define(\"intelligent_pipeline\", {\n    description = \"AI + GitOps Intelligent Automation Pipeline\",\n    version = \"2.0.0\",\n\n    metadata = {\n        author = \"AI-Powered DevOps\",\n        tags = {\"ai\", \"gitops\", \"intelligent\", \"tutorial\"},\n        ai_enabled = true,\n        gitops_enabled = true\n    },\n\n    tasks = { build_task, deploy_task, monitor_task },\n\n    on_task_start = function(task_name)\n        log.info(\"\ud83e\udd16 AI Pre-task Analysis: \" .. task_name)\n    end,\n\n    on_task_complete = function(task_name, success, output)\n        if success then\n            log.info(\"\u2705 Intelligent task completed: \" .. task_name)\n        else\n            log.error(\"\u274c Task failed - AI will analyze failure: \" .. task_name)\n        end\n\n        -- Always record for AI learning\n        ai.record_execution({\n            task_name = task_name,\n            success = success,\n            execution_time = output.duration or \"0s\",\n            pipeline = \"intelligent_pipeline\"\n        })\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\ud83c\udf89 INTELLIGENT PIPELINE COMPLETED SUCCESSFULLY!\")\n            log.info(\"\ud83e\udde0 AI has learned from this execution\")\n            log.info(\"\ud83d\udd04 GitOps state is synchronized\")\n            log.info(\"\ud83d\udcca Performance data collected for future optimizations\")\n\n            -- Generate final AI insights\n            local insights = ai.generate_insights({scope = \"pipeline\"})\n            if #insights &gt; 0 then\n                log.info(\"\ud83c\udf1f Final AI Insights:\")\n                for _, insight in ipairs(insights) do\n                    log.info(\"  \ud83d\udca1 \" .. insight)\n                end\n            end\n        else\n            log.error(\"\ud83d\udca5 Intelligent pipeline failed\")\n            log.info(\"\ud83d\udd0d AI will analyze failure patterns for future improvements\")\n        end\n    end\n})\n</code></pre>"},{"location":"TUTORIAL/#run-your-intelligent-pipeline","title":"Run Your Intelligent Pipeline","text":"<pre><code>sloth-runner run -f intelligent-pipeline.sloth\n</code></pre> <p>Expected Output: <pre><code>\ud83e\udde0 Building an Intelligent Pipeline with AI + GitOps!\n\ud83e\udd16 AI Pre-task Analysis: intelligent_build\n\ud83e\udd16 AI Build Optimization Applied!\n\ud83d\udcc8 Confidence: 78.0%\n\u26a1 Expected Speedup: 1.5x\nBuilding application...\n\u2705 Intelligent task completed: intelligent_build\n\ud83e\udd16 AI Pre-task Analysis: intelligent_deploy\n\ud83d\udd2e AI Deployment Analysis:\n\ud83d\udcca Failure Probability: 15.2%\n\ud83c\udfaf Prediction Confidence: 82.0%\n\u2705 AI assessment: Low risk deployment\n\ud83d\udd0d GitOps intelligent diff analysis...\n\ud83d\udccb Deployment will apply 3 changes\n\ud83d\ude80 Executing AI + GitOps intelligent deployment...\n\u2705 Intelligent deployment completed successfully!\n\u2705 Intelligent task completed: intelligent_deploy\n\ud83e\udd16 AI Pre-task Analysis: intelligent_monitor\n\ud83d\udcca Starting AI-powered monitoring...\n\ud83d\udcc8 AI Performance Analysis:\n  \ud83d\udcca Total executions: 1\n  \u2705 Success rate: 100.0%\n  \u23f1\ufe0f Average time: 45s\n  \ud83d\udcc8 Trend: stable\n\ud83d\udd04 GitOps Status: syncing\n\u2705 Intelligent task completed: intelligent_monitor\n\ud83c\udf89 INTELLIGENT PIPELINE COMPLETED SUCCESSFULLY!\n\ud83e\udde0 AI has learned from this execution\n\ud83d\udd04 GitOps state is synchronized\n\ud83d\udcca Performance data collected for future optimizations\n\ud83c\udf1f Final AI Insights:\n  \ud83d\udca1 Consider implementing parallel execution for better performance\n  \ud83d\udca1 Task execution patterns suggest optimal scheduling during off-peak hours\n</code></pre></p>"},{"location":"TUTORIAL/#what-youve-learned","title":"\ud83c\udf93 What You've Learned","text":"<p>Congratulations! You've just:</p> <p>\u2705 Mastered AI-Powered Automation: Created tasks that use artificial intelligence for optimization and failure prediction</p> <p>\u2705 Implemented GitOps Native Workflows: Set up Git-driven deployments with intelligent diff preview</p> <p>\u2705 Built Intelligent Pipelines: Combined AI and GitOps for the ultimate automation experience</p> <p>\u2705 Used Modern DSL: Experienced the clean, powerful syntax of Sloth Runner's domain-specific language</p>"},{"location":"TUTORIAL/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<p>Now that you understand the basics, explore these advanced features:</p>"},{"location":"TUTORIAL/#deep-dive-into-ai","title":"\ud83e\udd16 Deep Dive into AI","text":"<ul> <li>AI Features Complete Guide</li> <li>Performance Optimization Strategies</li> <li>Failure Prediction Best Practices</li> </ul>"},{"location":"TUTORIAL/#master-gitops","title":"\ud83d\udd04 Master GitOps","text":"<ul> <li>GitOps Features Complete Guide</li> <li>Multi-Environment Deployments</li> <li>Kubernetes Integration</li> </ul>"},{"location":"TUTORIAL/#enterprise-features","title":"\ud83c\udfe2 Enterprise Features","text":"<ul> <li>Distributed Architecture</li> <li>Security &amp; RBAC</li> <li>Monitoring &amp; Observability</li> </ul>"},{"location":"TUTORIAL/#real-world-examples","title":"\ud83d\udcda Real-World Examples","text":"<ul> <li>Production CI/CD Pipelines</li> <li>Infrastructure as Code</li> <li>Multi-Cloud Deployments</li> </ul>"},{"location":"TUTORIAL/#community-support","title":"\ud83d\udcac Community &amp; Support","text":"<ul> <li>\ud83d\udcd6 Complete Documentation - Comprehensive guides and references</li> <li>\ud83d\udcac Discord Community - Get help and share experiences  </li> <li>\ud83d\udc1b GitHub Issues - Report bugs and request features</li> <li>\ud83c\udfe2 Enterprise Support - Commercial support and services</li> </ul> <p>\ud83c\udf89 Welcome to the future of intelligent automation!</p> <p>You're now ready to build production-grade workflows with the world's most advanced task orchestration platform. Start building amazing things with AI-powered automation and GitOps native workflows!</p>"},{"location":"TUTORIAL_OLD/","title":"\ud83e\udda5 Getting Started Tutorial - Modern DSL","text":"<p>Welcome to Sloth Runner! This guide will walk you through creating and running your first set of tasks using the Modern DSL.</p>"},{"location":"TUTORIAL_OLD/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have: 1.  Go (version 1.21+) installed on your system. 2.  The <code>sloth-runner</code> executable installed. If not, follow the installation instructions in the main README.md.</p>"},{"location":"TUTORIAL_OLD/#step-1-create-your-first-task-file","title":"Step 1: Create Your First Task File","text":"<p>Let's create a simple sloth file named <code>my_tasks.sloth</code>. This file will define our tasks using the Modern DSL.</p> <pre><code>-- my_tasks.sloth - Modern DSL\n\n-- Define your first task using the fluent API\nlocal hello_task = task(\"say_hello\")\n    :description(\"Prints a friendly greeting with Modern DSL\")\n    :command(function()\n        log.info(\"\ud83e\udda5 Hello from Sloth Runner Modern DSL!\")\n        return true, \"echo 'Hello from Sloth Runner Modern DSL! \ud83e\udda5'\", {\n            greeting = \"Hello Modern DSL\",\n            timestamp = os.time()\n        }\n    end)\n    :timeout(\"30s\")\n    :build()\n\n-- Define the workflow\nworkflow.define(\"hello_world_workflow\", {\n    description = \"A simple workflow to say hello - Modern DSL\",\n    version = \"1.0.0\",\n\n    metadata = {\n        author = \"Sloth Runner Team\",\n        tags = {\"hello-world\", \"tutorial\", \"modern-dsl\"}\n    },\n\n    tasks = { hello_task },\n\n    config = {\n        timeout = \"5m\"\n    },\n\n    on_start = function()\n        log.info(\"\ud83d\ude80 Starting hello world workflow...\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\u2705 Hello world workflow completed!\")\n        end\n        return true\n    end\n})\n</code></pre> <p>This defines a workflow with a single task using the Modern DSL fluent API. The task executes a simple greeting command and returns structured output.</p>"},{"location":"TUTORIAL_OLD/#step-2-run-your-task","title":"Step 2: Run Your Task","text":"<p>Now, let's run the task using the <code>sloth-runner</code> CLI. Open your terminal in the same directory where you saved <code>my_tasks.sloth</code> and run:</p> <pre><code>sloth-runner run -f my_tasks.sloth\n</code></pre> <p>You should see the structured output and logging from the Modern DSL task execution!</p>"},{"location":"TUTORIAL_OLD/#step-3-add-a-dependent-task","title":"Step 3: Add a Dependent Task","text":"<p>Let's make it more interesting by adding a second task that depends on the first one. Modify <code>my_tasks.sloth</code>:</p> <pre><code>-- my_tasks.sloth - Modern DSL with Dependencies\n\n-- First task with output\nlocal hello_task = task(\"say_hello\")\n    :description(\"Prints a friendly greeting with Modern DSL\")\n    :command(function()\n        log.info(\"\ud83e\udda5 Executing hello task...\")\n        return true, \"echo 'Hello from Sloth Runner Modern DSL! \ud83e\udda5'\", { \n            message = \"Hello World\",\n            source = \"modern_dsl\"\n        }\n    end)\n    :timeout(\"30s\")\n    :build()\n\n-- Second task that depends on the first\nlocal show_message_task = task(\"show_message\")\n    :description(\"Shows the message from the first task\")\n    :depends_on({\"say_hello\"}) -- This creates the dependency\n    :command(function(params, deps)\n        -- The output from 'say_hello' is available in deps!\n        local received_message = deps.say_hello.message\n        local source = deps.say_hello.source\n\n        log.info(\"\ud83d\udce9 Received message: \" .. received_message .. \" from \" .. source)\n\n        local result = exec.run(\"echo 'The first task said: \" .. received_message .. \"'\")\n        return result.success, result.stdout, { \n            confirmation = \"Message received!\",\n            processed_message = received_message\n        }\n    end)\n    :build()\n\n-- Updated workflow with both tasks\nworkflow.define(\"hello_workflow_with_dependencies\", {\n    description = \"Workflow demonstrating task dependencies - Modern DSL\",\n    version = \"1.0.0\",\n\n    metadata = {\n        author = \"Sloth Runner Team\",\n        tags = {\"dependencies\", \"tutorial\", \"modern-dsl\"}\n    },\n\n    tasks = { hello_task, show_message_task },\n\n    config = {\n        timeout = \"10m\",\n        max_parallel_tasks = 2\n    },\n\n    on_start = function()\n        log.info(\"\ud83d\ude80 Starting workflow with dependencies...\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\u2705 Workflow with dependencies completed!\")\n            log.info(\"\ud83d\udcca Results summary:\")\n            for task_name, result in pairs(results) do\n                log.info(\"  \" .. task_name .. \": \" .. (result.success and \"\u2705\" or \"\u274c\"))\n            end\n        end\n        return true\n    end\n})\n</code></pre> <p>Changes: -   Both tasks now use the Modern DSL fluent API with <code>:build()</code> -   The <code>hello_task</code> returns structured output with <code>message</code> and <code>source</code> fields -   The <code>show_message_task</code> uses <code>:depends_on({\"say_hello\"})</code> to create the dependency -   Dependencies are accessed through the <code>deps</code> parameter in Modern DSL -   Enhanced logging and error handling with the <code>exec</code> module -   Workflow definition includes both tasks with proper metadata</p>"},{"location":"TUTORIAL_OLD/#step-4-run-the-dependent-task","title":"Step 4: Run the Dependent Task","text":"<p>Now, let's run only the final task, <code>show_message</code>. Sloth Runner will automatically figure out that it needs to run <code>say_hello</code> first.</p> <pre><code>sloth-runner run -f my_tasks.sloth -t show_message\n</code></pre> <p>You will see both tasks execute in the correct order, with enhanced Modern DSL logging and structured output.</p>"},{"location":"TUTORIAL_OLD/#step-5-advanced-features","title":"Step 5: Advanced Features","text":"<p>Let's add some advanced Modern DSL features to make our workflow more robust:</p> <pre><code>-- Advanced Modern DSL example\nlocal advanced_task = task(\"advanced_processing\")\n    :description(\"Demonstrates advanced Modern DSL features\")\n    :depends_on({\"show_message\"})\n    :command(function(params, deps)\n        log.info(\"\ud83d\udd27 Processing with advanced features...\")\n\n        -- Use circuit breaker for resilience\n        return circuit.protect(\"external_service\", function()\n            -- Simulate processing\n            return true, \"Advanced processing completed\", {\n                processed_count = 42,\n                performance_metrics = {\n                    duration = \"2.5s\",\n                    memory_usage = \"64MB\"\n                }\n            }\n        end)\n    end)\n    :retries(3, \"exponential\")\n    :timeout(\"2m\")\n    :on_success(function(params, output)\n        log.info(\"\ud83c\udf89 Advanced processing succeeded! Processed \" .. output.processed_count .. \" items\")\n    end)\n    :on_failure(function(params, error)\n        log.error(\"\u274c Advanced processing failed: \" .. error)\n    end)\n    :build()\n\n-- Add to workflow\nworkflow.define(\"advanced_workflow\", {\n    description = \"Advanced workflow with Modern DSL features\",\n    version = \"2.0.0\",\n\n    metadata = {\n        author = \"Sloth Runner Team\",\n        tags = {\"advanced\", \"circuit-breaker\", \"retry\", \"modern-dsl\"},\n        complexity = \"intermediate\"\n    },\n\n    tasks = { hello_task, show_message_task, advanced_task },\n\n    config = {\n        timeout = \"15m\",\n        retry_policy = \"exponential\",\n        max_parallel_tasks = 3,\n        circuit_breaker = {\n            failure_threshold = 5,\n            recovery_timeout = \"30s\"\n        }\n    }\n})\n</code></pre>"},{"location":"TUTORIAL_OLD/#whats-next","title":"What's Next?","text":"<p>Congratulations! You've successfully created and run a Modern DSL task pipeline with advanced features.</p>"},{"location":"TUTORIAL_OLD/#learn-more","title":"Learn More:","text":"<ul> <li>\ud83d\udcda Modern DSL Introduction - Complete Modern DSL guide</li> <li>\ud83c\udfaf Task Definition API - Full task builder reference  </li> <li>\ud83d\udccb Workflow Definition - Workflow configuration guide</li> <li>\ud83d\udd27 Lua API Reference - Built-in modules (<code>exec</code>, <code>fs</code>, <code>net</code>, etc.)</li> <li>\ud83d\udcdd Examples - Modern DSL examples from basic to advanced</li> <li>\ud83c\udfa8 Best Practices - Modern DSL patterns and guidelines</li> </ul>"},{"location":"TUTORIAL_OLD/#next-steps","title":"Next Steps:","text":"<ol> <li>Explore Examples: Browse the <code>/examples</code> directory for real-world Modern DSL workflows</li> <li>Try Built-in Modules: Experiment with <code>fs</code>, <code>net</code>, <code>data</code>, <code>state</code> modules in your tasks</li> <li>Add Error Handling: Implement retry strategies and circuit breakers</li> <li>Build Complex Workflows: Create multi-stage CI/CD pipelines with the Modern DSL</li> </ol>"},{"location":"advanced-examples/","title":"Exemplos Avan\u00e7ados","text":"<p>Esta se\u00e7\u00e3o apresenta exemplos mais complexos e cen\u00e1rios de uso que combinam m\u00faltiplos m\u00f3dulos do Sloth-Runner para automa\u00e7\u00e3o de ponta a ponta.</p>"},{"location":"advanced-examples/#exemplo-completo-pipeline-de-cicd-end-to-end","title":"Exemplo Completo: Pipeline de CI/CD End-to-End","text":"<p>Este tutorial demonstra como construir um pipeline de CI/CD completo usando os m\u00f3dulos <code>git</code>, <code>pulumi</code> e <code>salt</code> para versionar c\u00f3digo, provisionar infraestrutura e implantar uma aplica\u00e7\u00e3o.</p>"},{"location":"advanced-examples/#cenario","title":"Cen\u00e1rio","text":"<p>Imagine que voc\u00ea tem um projeto de infraestrutura Pulumi e um projeto de aplica\u00e7\u00e3o. Voc\u00ea quer automatizar o seguinte fluxo:</p> <ol> <li>Clonar o reposit\u00f3rio da infraestrutura.</li> <li>Atualizar um arquivo de vers\u00e3o dentro do reposit\u00f3rio.</li> <li>Committar e empurrar essa altera\u00e7\u00e3o para o Git.</li> <li>Executar <code>pulumi up</code> para provisionar ou atualizar a infraestrutura (por exemplo, um ambiente de staging).</li> <li>Usar o Salt para configurar os servidores provisionados e implantar a aplica\u00e7\u00e3o.</li> </ol>"},{"location":"advanced-examples/#script-lua-examplespulumi_git_combined_examplesloth","title":"Script Lua (<code>examples/pulumi_git_combined_example.sloth</code>)","text":"<pre><code>-- examples/pulumi_git_combined_example.sloth\n\ncommand = function(params)\n    log.info(\"Iniciando exemplo combinado Pulumi e Git...\")\n\n    local pulumi_repo_url = \"https://github.com/my-org/my-pulumi-infra.git\" -- Exemplo de repo Pulumi\n    local pulumi_repo_path = \"./pulumi-infra-checkout\"\n    local new_infra_version = params.infra_version or \"v1.0.0-infra\"\n    local pulumi_project_workdir = pulumi_repo_path .. \"/my-vpc-project\" -- Subdiret\u00f3rio dentro do repo clonado\n    local repo\n\n    -- 1. Clonar ou abrir o reposit\u00f3rio Pulumi\n    log.info(\"Step 1: Cloning or opening Pulumi repository...\")\n    if not fs.exists(pulumi_repo_path) then\n        log.info(\"Cloning Pulumi repository: \" .. pulumi_repo_url)\n        local cloned_repo, clone_err = git.clone(pulumi_repo_url, pulumi_repo_path)\n        if clone_err then\n            log.error(\"Failed to clone Pulumi repository: \" .. clone_err)\n            return false, \"Git clone failed.\"\n        end\n        repo = cloned_repo\n    else\n        log.info(\"Pulumi repository already exists, opening local reference.\")\n        local opened_repo, open_err = git.repo(pulumi_repo_path)\n        if open_err then\n            log.error(\"Failed to open Pulumi repository: \" .. open_err)\n            return false, \"Git repo open failed.\"\n        end\n        repo = opened_repo\n    end\n\n    if not repo then\n        return false, \"Failed to get Pulumi repository reference.\"\n    end\n\n    -- 2. Atualizar o reposit\u00f3rio (pull)\n    log.info(\"Step 2: Pulling latest changes from Pulumi repository...\")\n    repo:checkout(\"main\"):pull(\"origin\", \"main\")\n    local pull_result = repo:result()\n    if not pull_result.success then\n        log.error(\"Failed to pull Pulumi repository: \" .. pull_result.stderr)\n        return false, \"Git pull failed.\"\n    end\n    log.info(\"Pulumi repository updated. Stdout: \" .. pull_result.stdout)\n\n    -- 3. Simular uma altera\u00e7\u00e3o no c\u00f3digo Pulumi (e.g., atualizar um arquivo de vers\u00e3o)\n    log.info(\"Step 3: Simulating a change in Pulumi code (updating version file)...\")\n    local infra_version_file = pulumi_repo_path .. \"/INFRA_VERSION\"\n    fs.write(infra_version_file, new_infra_version)\n    log.info(\"Updated INFRA_VERSION file to: \" .. new_infra_version)\n\n    -- 4. Commitar e empurrar as mudan\u00e7as\n    log.info(\"Step 4: Committing and pushing infrastructure version change...\")\n    local commit_message = \"ci: Bump infrastructure version to \" .. new_infra_version\n    repo:add(infra_version_file)\n        :commit(commit_message)\n        :push(\"origin\", \"main\") -- Sem follow_tags aqui, apenas o commit\n\n    local push_result = repo:result()\n    if not push_result.success then\n        log.error(\"Failed to push infrastructure changes: \" .. push_result.stderr)\n        return false, \"Git push failed for infra changes.\"\n    end\n    log.info(\"Infrastructure version change pushed. Stdout: \" .. push_result.stdout)\n\n    -- 5. Executar 'pulumi up' para o projeto\n    log.info(\"Step 5: Running pulumi up for the infrastructure project...\")\n    local infra_stack = pulumi.stack(\"my-org/my-infra/dev\", {\n        workdir = pulumi_project_workdir -- Usar o subdiret\u00f3rio do projeto Pulumi\n    })\n\n    local pulumi_up_result = infra_stack:up({ non_interactive = true })\n\n    if not pulumi_up_result.success then\n        log.error(\"Pulumi up failed: \" .. pulumi_up_result.stderr)\n        return false, \"Pulumi up failed.\"\n    end\n    log.info(\"Pulumi up completed successfully. Stdout: \" .. pulumi_up_result.stdout)\n\n    -- 6. Configurar e implantar a aplica\u00e7\u00e3o usando Salt (Exemplo)\n    log.info(\"Step 6: Configuring and deploying application using Salt...\")\n    -- Assumindo que o Pulumi up forneceu o IP ou hostname do servidor\n    -- Para este exemplo, vamos usar um IP fict\u00edcio\n    local server_ip = \"192.168.1.100\" -- Substitua pelo output real do Pulumi, se houver\n    local salt_target = salt.target(server_ip)\n\n    log.info(\"Running Salt test.ping on \" .. server_ip .. \"...\")\n    salt_target:ping()\n    local ping_result = salt_target:result()\n    if not ping_result.success then\n        log.error(\"Salt ping failed for \" .. server_ip .. \": \" .. ping_result.stderr)\n        return false, \"Salt ping failed.\"\n    end\n    log.info(\"Salt ping successful. Stdout: \" .. data.to_json(ping_result.stdout)) -- Assumindo que ping retorna JSON\n\n    log.info(\"Applying Salt state 'app.install' on \" .. server_ip .. \"...\")\n    salt_target:cmd('state.apply', 'app.install')\n    local salt_apply_result = salt_target:result()\n    if not salt_apply_result.success then\n        log.error(\"Salt state.apply failed for \" .. server_ip .. \": \" .. salt_apply_result.stderr)\n        return false, \"Salt state.apply failed.\"\n    end\n    log.info(\"Salt state.apply successful. Stdout: \" .. data.to_json(salt_apply_result.stdout))\n\n    log.info(\"Exemplo combinado Pulumi e Git conclu\u00eddo com sucesso.\")\n    return true, \"Combined Pulumi and Git example finished.\"\nend\n\nModern DSLs = {\n    pulumi_git_combined_example = {\n        description = \"Demonstrates combined usage of 'pulumi' and 'git' modules for CI/CD pipeline.\",\n        tasks = {\n            {\n                name = \"run_combined_example\",\n                command = command,\n                params = {\n                    infra_version = \"v1.0.0-test-combined\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Voltar ao \u00cdndice</p>"},{"location":"advanced-features/","title":"Advanced Features","text":"<p>This document covers some of the more advanced features of <code>sloth-runner</code>, designed to enhance your development, debugging, and configuration workflows.</p>"},{"location":"advanced-features/#interactive-task-runner","title":"Interactive Task Runner","text":"<p>For complex workflows, it can be useful to step through tasks one by one, inspect their outputs, and decide whether to proceed, skip, or retry a task. The interactive task runner provides a powerful way to debug and develop your task pipelines.</p> <p>To use the interactive runner, add the <code>--interactive</code> flag to the <code>sloth-runner run</code> command:</p> <pre><code>sloth-runner run -f examples/basic_pipeline.sloth --yes --interactive\n</code></pre> <p>When enabled, the runner will pause before executing each task and prompt you for an action:</p> <pre><code>? Task: fetch_data (Simulates fetching raw data)\n&gt; run\n  skip\n  abort\n  continue\n</code></pre> <p>Actions:</p> <ul> <li>run: (Default) Proceeds with executing the current task.</li> <li>skip: Skips the current task and moves to the next one in the execution order.</li> <li>abort: Aborts the entire task execution immediately.</li> <li>continue: Executes the current task and all subsequent tasks without further prompts, effectively disabling interactive mode for the rest of the run.</li> </ul>"},{"location":"advanced-features/#enhanced-valuesyaml-templating","title":"Enhanced <code>values.yaml</code> Templating","text":"<p>You can make your <code>values.yaml</code> files more dynamic by using Go template syntax to inject environment variables. This is particularly useful for providing sensitive information (like tokens or keys) or environment-specific configurations without hardcoding them.</p> <p><code>sloth-runner</code> processes <code>values.yaml</code> as a Go template, making any environment variables available under the <code>.Env</code> map.</p> <p>Example:</p> <ol> <li> <p>Create a <code>values.yaml</code> file with a template placeholder:</p> <p><pre><code># values.yaml\napi_key: \"{% raw %}{{ .Env.MY_API_KEY }}{% endraw %}\"\nregion: \"{% raw %}{{ .Env.AWS_REGION | default \"us-east-1\" }}{% endraw %}\"\n</code></pre> Note: You can use <code>default</code> to provide a fallback value if the environment variable is not set.</p> </li> <li> <p>Create a Lua task that uses these values:</p> <pre><code>-- my_task.sloth\nModern DSLs = {\n  my_group = {\n    tasks = {\n      {\n        name = \"deploy\",\n        command = function()\n          log.info(\"Deploying to region: \" .. values.region)\n          log.info(\"Using API key (first 5 chars): \" .. string.sub(values.api_key, 1, 5) .. \"...\")\n          return true, \"Deployment successful.\"\n        end\n      }\n    }\n  }\n}\n</code></pre> </li> <li> <p>Run the task with the environment variables set:</p> <pre><code>export MY_API_KEY=\"supersecretkey12345\"\nexport AWS_REGION=\"us-west-2\"\n\nsloth-runner run -f my_task.sloth -v values.yaml --yes\n</code></pre> </li> </ol> <p>Output:</p> <p>The output will show that the values from the environment variables were correctly substituted:</p> <pre><code>INFO Deploying to region: us-west-2\nINFO Using API key (first 5 chars): super...\n</code></pre>"},{"location":"advanced-scheduler/","title":"\u23f0 Advanced Task Scheduler","text":"<p>Sloth Runner includes a powerful task scheduling system that enables automated execution of workflows with cron-style syntax, background daemon support, and comprehensive schedule management.</p>"},{"location":"advanced-scheduler/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"advanced-scheduler/#enable-the-scheduler","title":"Enable the Scheduler","text":"<pre><code># Start scheduler daemon\nsloth-runner scheduler enable --config scheduler.yaml\n\n# Start with custom configuration\nsloth-runner scheduler enable --config /path/to/custom-scheduler.yaml\n</code></pre>"},{"location":"advanced-scheduler/#basic-schedule-configuration","title":"Basic Schedule Configuration","text":"<pre><code># scheduler.yaml\nscheduler:\n  enabled: true\n  timezone: \"UTC\"\n  max_concurrent_tasks: 5\n  log_level: \"info\"\n\nschedules:\n  - name: \"daily_backup\"\n    cron: \"0 2 * * *\"  # Every day at 2 AM\n    workflow: \"backup.sloth\"\n    description: \"Daily database backup\"\n\n  - name: \"hourly_health_check\"\n    cron: \"0 * * * *\"  # Every hour\n    workflow: \"health-check.sloth\"\n    timeout: \"5m\"\n\n  - name: \"weekly_cleanup\"\n    cron: \"0 0 * * 0\"  # Every Sunday at midnight\n    workflow: \"cleanup.sloth\"\n    enabled: true\n</code></pre>"},{"location":"advanced-scheduler/#cron-syntax","title":"\ud83d\udcc5 Cron Syntax","text":""},{"location":"advanced-scheduler/#standard-cron-format","title":"Standard Cron Format","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of week (0 - 6) (Sunday to Saturday)\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n</code></pre>"},{"location":"advanced-scheduler/#common-examples","title":"Common Examples","text":"<pre><code>schedules:\n  # Every minute\n  - cron: \"* * * * *\"\n\n  # Every 5 minutes\n  - cron: \"*/5 * * * *\"\n\n  # Every hour at minute 30\n  - cron: \"30 * * * *\"\n\n  # Every day at 3:30 AM\n  - cron: \"30 3 * * *\"\n\n  # Every Monday at 9 AM\n  - cron: \"0 9 * * 1\"\n\n  # First day of every month at midnight\n  - cron: \"0 0 1 * *\"\n\n  # Every 15 minutes during business hours (9-5, Mon-Fri)\n  - cron: \"*/15 9-17 * * 1-5\"\n</code></pre>"},{"location":"advanced-scheduler/#extended-syntax","title":"Extended Syntax","text":"<pre><code>schedules:\n  # Using @yearly, @monthly, @weekly, @daily, @hourly\n  - cron: \"@daily\"\n    workflow: \"daily-tasks.sloth\"\n\n  - cron: \"@weekly\"\n    workflow: \"weekly-report.sloth\"\n\n  # Using @every with duration\n  - cron: \"@every 30m\"\n    workflow: \"monitoring.sloth\"\n\n  - cron: \"@every 2h30m\"\n    workflow: \"periodic-sync.sloth\"\n</code></pre>"},{"location":"advanced-scheduler/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"advanced-scheduler/#complete-scheduler-config","title":"Complete Scheduler Config","text":"<pre><code># advanced-scheduler.yaml\nscheduler:\n  enabled: true\n  timezone: \"America/New_York\"\n  max_concurrent_tasks: 10\n  log_level: \"debug\"\n\n  # Database settings\n  database:\n    path: \"/data/scheduler.db\"\n    backup_interval: \"24h\"\n\n  # Notification settings\n  notifications:\n    on_failure: true\n    on_success: false\n    channels:\n      - type: \"slack\"\n        webhook: \"https://hooks.slack.com/...\"\n      - type: \"email\"\n        smtp: \"smtp.company.com:587\"\n\n  # Performance settings\n  performance:\n    worker_pool_size: 5\n    queue_buffer_size: 100\n    execution_timeout: \"30m\"\n\nschedules:\n  - name: \"production_deployment\"\n    cron: \"0 2 * * 1-5\"  # Weekdays at 2 AM\n    workflow: \"deploy-prod.sloth\"\n    description: \"Production deployment pipeline\"\n\n    # Schedule-specific settings\n    timeout: \"45m\"\n    retry_attempts: 3\n    retry_delay: \"5m\"\n\n    # Environment variables for this schedule\n    env:\n      ENVIRONMENT: \"production\"\n      DEPLOY_STRATEGY: \"blue_green\"\n\n    # Only run if conditions are met\n    conditions:\n      - \"production.health_check == 'healthy'\"\n      - \"staging.last_deploy &gt; '24h'\"\n\n    # Notification overrides\n    notifications:\n      on_success: true\n      on_failure: true\n      channels: [\"slack\", \"email\"]\n</code></pre>"},{"location":"advanced-scheduler/#workflow-integration","title":"\ud83c\udfaf Workflow Integration","text":""},{"location":"advanced-scheduler/#scheduled-workflow-example","title":"Scheduled Workflow Example","text":"<pre><code>-- scheduled-backup.sloth\nlocal backup = task(\"database_backup\")\n    :description(\"Automated database backup\")\n    :command(function(params, deps)\n        local timestamp = os.date(\"%Y%m%d_%H%M%S\")\n        local backup_file = \"/backups/db_\" .. timestamp .. \".sql\"\n\n        log.info(\"Starting scheduled backup to: \" .. backup_file)\n\n        -- Perform backup\n        local result = exec.run(\"pg_dump myapp_db &gt; \" .. backup_file)\n        if not result.success then\n            return false, \"Backup failed: \" .. result.stderr\n        end\n\n        -- Compress backup\n        exec.run(\"gzip \" .. backup_file)\n\n        -- Upload to cloud storage\n        local aws = require(\"aws\")\n        aws.s3.upload(backup_file .. \".gz\", \"backups-bucket\")\n\n        -- Clean old backups (keep last 7 days)\n        exec.run(\"find /backups -name '*.gz' -mtime +7 -delete\")\n\n        return true, \"Backup completed successfully\", {\n            backup_file = backup_file .. \".gz\",\n            size = fs.size(backup_file .. \".gz\"),\n            timestamp = timestamp\n        }\n    end)\n    :timeout(\"30m\")\n    :on_failure(function(params, error)\n        -- Send alert on failure\n        local notifications = require(\"notifications\")\n        notifications.slack.send({\n            channel = \"#alerts\",\n            message = \"\u26a0\ufe0f Scheduled backup failed: \" .. error,\n            color = \"danger\"\n        })\n    end)\n    :build()\n\n-- Export for scheduler\nworkflow.define(\"backup_workflow\", {\n    description = \"Scheduled database backup workflow\",\n    tasks = { backup },\n\n    -- Scheduler metadata\n    schedule_metadata = {\n        category = \"maintenance\",\n        priority = \"high\",\n        max_duration = \"30m\"\n    }\n})\n</code></pre>"},{"location":"advanced-scheduler/#conditional-scheduling","title":"Conditional Scheduling","text":"<pre><code>-- conditional-deploy.sloth\nlocal deployment = task(\"conditional_deployment\")\n    :description(\"Deploy only if tests pass and load is low\")\n    :command(function(params, deps)\n        -- Check prerequisites\n        local health = monitoring.get_health_status()\n        local load = monitoring.get_system_load()\n        local tests = state.get(\"last_test_results\")\n\n        -- Conditional logic\n        if tests.status ~= \"passed\" then\n            return false, \"Tests not passing, skipping deployment\"\n        end\n\n        if load.cpu &gt; 0.8 then\n            return false, \"System load too high, deferring deployment\"\n        end\n\n        if health.status ~= \"healthy\" then\n            return false, \"System health check failed\"\n        end\n\n        -- Proceed with deployment\n        log.info(\"Conditions met, proceeding with deployment\")\n        return exec.run(\"./deploy.sh\")\n    end)\n    :build()\n</code></pre>"},{"location":"advanced-scheduler/#management-commands","title":"\ud83d\udcca Management Commands","text":""},{"location":"advanced-scheduler/#scheduler-control","title":"Scheduler Control","text":"<pre><code># Enable/disable scheduler\nsloth-runner scheduler enable\nsloth-runner scheduler disable\n\n# List all scheduled tasks\nsloth-runner scheduler list\n\n# Show detailed schedule information\nsloth-runner scheduler show backup_task\n\n# Delete a scheduled task\nsloth-runner scheduler delete old_cleanup\n\n# Pause/resume specific schedule\nsloth-runner scheduler pause weekly_report\nsloth-runner scheduler resume weekly_report\n</code></pre>"},{"location":"advanced-scheduler/#schedule-status","title":"Schedule Status","text":"<pre><code># Get scheduler status\nsloth-runner scheduler status\n\n# Output:\n# Scheduler Status: RUNNING\n# Active Schedules: 12\n# Next Execution: daily_backup in 2h 15m\n# Last Execution: hourly_check (success) 45m ago\n# Failed Tasks (24h): 1\n</code></pre>"},{"location":"advanced-scheduler/#execution-history","title":"Execution History","text":"<pre><code># View execution history\nsloth-runner scheduler history --limit 20\n\n# Filter by schedule name\nsloth-runner scheduler history --schedule backup_task\n\n# Filter by status\nsloth-runner scheduler history --status failed --last 7d\n</code></pre>"},{"location":"advanced-scheduler/#monitoring-logging","title":"\ud83d\udd0d Monitoring &amp; Logging","text":""},{"location":"advanced-scheduler/#execution-logs","title":"Execution Logs","text":"<pre><code># View scheduler logs\ntail -f /var/log/sloth-runner/scheduler.log\n\n# Sample log output:\n# 2024-01-15 02:00:00 INFO [scheduler] Starting execution: daily_backup\n# 2024-01-15 02:00:01 INFO [backup_task] Database backup initiated\n# 2024-01-15 02:05:23 INFO [backup_task] Backup completed: 2.4GB\n# 2024-01-15 02:05:24 INFO [scheduler] Execution completed: daily_backup (success)\n</code></pre>"},{"location":"advanced-scheduler/#metrics-collection","title":"Metrics Collection","text":"<pre><code># Enable metrics in scheduler config\nscheduler:\n  metrics:\n    enabled: true\n    port: 9090\n    path: \"/metrics\"\n\n  # Prometheus metrics available:\n  # - scheduler_executions_total\n  # - scheduler_execution_duration_seconds\n  # - scheduler_queue_size\n  # - scheduler_worker_pool_utilization\n</code></pre>"},{"location":"advanced-scheduler/#error-handling-alerts","title":"\ud83d\udea8 Error Handling &amp; Alerts","text":""},{"location":"advanced-scheduler/#failure-notifications","title":"Failure Notifications","text":"<pre><code>schedules:\n  - name: \"critical_task\"\n    cron: \"0 */6 * * *\"\n    workflow: \"critical.sloth\"\n\n    # Failure handling\n    on_failure:\n      retry:\n        attempts: 3\n        delay: \"10m\"\n        backoff: \"exponential\"\n\n      notifications:\n        - type: \"slack\"\n          webhook: \"https://hooks.slack.com/...\"\n          message: \"\ud83d\udea8 Critical task failed: {% raw %}{{.Error}}{% endraw %}\"\n\n        - type: \"email\"\n          to: [\"ops@company.com\"]\n          subject: \"URGENT: Critical Task Failure\"\n\n        - type: \"webhook\"\n          url: \"https://monitoring.company.com/alert\"\n          method: \"POST\"\n</code></pre>"},{"location":"advanced-scheduler/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<pre><code>-- circuit-breaker-task.sloth\nlocal task_with_circuit_breaker = task(\"resilient_task\")\n    :description(\"Task with circuit breaker protection\")\n    :command(function(params, deps)\n        local circuit_breaker = require(\"reliability\").circuit_breaker\n\n        -- Configure circuit breaker\n        local breaker = circuit_breaker.new({\n            failure_threshold = 5,    -- Open after 5 failures\n            recovery_timeout = \"5m\",  -- Try to close after 5 minutes\n            success_threshold = 3     -- Close after 3 successes\n        })\n\n        return breaker.call(function()\n            -- Your actual task logic here\n            return external_api.call()\n        end)\n    end)\n    :build()\n</code></pre>"},{"location":"advanced-scheduler/#security-features","title":"\ud83d\udd12 Security Features","text":""},{"location":"advanced-scheduler/#secure-configuration","title":"Secure Configuration","text":"<pre><code>scheduler:\n  security:\n    # Run as specific user\n    run_as_user: \"scheduler\"\n    run_as_group: \"schedulers\"\n\n    # Restrict file access\n    working_directory: \"/var/lib/sloth-runner\"\n    allowed_paths:\n      - \"/var/lib/sloth-runner\"\n      - \"/tmp/scheduler\"\n\n    # Environment isolation\n    clear_env: true\n    allowed_env_vars:\n      - \"PATH\"\n      - \"HOME\"\n      - \"TZ\"\n</code></pre>"},{"location":"advanced-scheduler/#audit-logging","title":"Audit Logging","text":"<pre><code>scheduler:\n  audit:\n    enabled: true\n    log_file: \"/var/log/sloth-runner/audit.log\"\n    include_payload: false  # Don't log sensitive data\n\n    # Audit events\n    events:\n      - \"schedule_created\"\n      - \"schedule_modified\" \n      - \"schedule_deleted\"\n      - \"execution_started\"\n      - \"execution_completed\"\n      - \"execution_failed\"\n</code></pre>"},{"location":"advanced-scheduler/#performance-optimization","title":"\u26a1 Performance Optimization","text":""},{"location":"advanced-scheduler/#resource-management","title":"Resource Management","text":"<pre><code>scheduler:\n  resources:\n    # Memory limits per task\n    max_memory_per_task: \"512MB\"\n\n    # CPU limits\n    max_cpu_per_task: \"1.0\"  # 1 CPU core\n\n    # Execution time limits\n    default_timeout: \"15m\"\n    max_timeout: \"2h\"\n\n    # Disk space monitoring\n    min_free_disk: \"1GB\"\n    cleanup_threshold: \"5GB\"\n</code></pre>"},{"location":"advanced-scheduler/#queue-management","title":"Queue Management","text":"<pre><code>scheduler:\n  queue:\n    # Queue sizes\n    pending_queue_size: 1000\n    running_queue_size: 50\n\n    # Priority levels\n    priority_levels: 5\n    default_priority: 3\n\n    # Queue processing\n    batch_size: 10\n    processing_interval: \"1s\"\n</code></pre>"},{"location":"advanced-scheduler/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"advanced-scheduler/#schedule-design","title":"Schedule Design","text":"<ol> <li>Use appropriate timeouts for long-running tasks</li> <li>Implement idempotent workflows </li> <li>Add proper error handling and retries</li> <li>Monitor resource usage regularly</li> <li>Use conditional execution when appropriate</li> </ol>"},{"location":"advanced-scheduler/#performance-tips","title":"Performance Tips","text":"<ol> <li>Avoid overlapping schedules for resource-intensive tasks</li> <li>Use priority levels for critical vs. maintenance tasks</li> <li>Implement circuit breakers for external dependencies</li> <li>Monitor queue depth and adjust worker pool size</li> <li>Regular cleanup of old execution logs</li> </ol>"},{"location":"advanced-scheduler/#security-recommendations","title":"Security Recommendations","text":"<ol> <li>Run scheduler as dedicated user with minimal privileges</li> <li>Validate all inputs from scheduled workflows</li> <li>Use secure storage for sensitive configuration</li> <li>Enable audit logging for compliance</li> <li>Regular security reviews of scheduled tasks</li> </ol> <p>The Advanced Task Scheduler transforms Sloth Runner into a comprehensive automation platform capable of managing complex, time-based workflows with enterprise-grade reliability and monitoring! \u23f0\ud83d\ude80</p>"},{"location":"agent-improvements/","title":"\ud83d\ude80 Melhorias e Novas Funcionalidades para os Agentes Sloth-Runner","text":"<p>Com base na an\u00e1lise da arquitetura atual dos agentes, identifiquei v\u00e1rias oportunidades de melhoria e novas funcionalidades que transformar\u00e3o o sistema em uma plataforma enterprise-grade.</p>"},{"location":"agent-improvements/#analise-da-arquitetura-atual","title":"\ud83d\udcca An\u00e1lise da Arquitetura Atual","text":""},{"location":"agent-improvements/#pontos-fortes-existentes","title":"\u2705 Pontos Fortes Existentes:","text":"<ul> <li>Comunica\u00e7\u00e3o gRPC com streaming em tempo real</li> <li>Sistema de heartbeat para monitoramento</li> <li>Suporte a TLS para comunica\u00e7\u00f5es seguras</li> <li>Registro autom\u00e1tico de agentes no master</li> <li>Execu\u00e7\u00e3o de comandos shell remotos</li> <li>Logs estruturados</li> </ul>"},{"location":"agent-improvements/#areas-de-melhoria-identificadas","title":"\ud83d\udd0d \u00c1reas de Melhoria Identificadas:","text":"<ul> <li>Falta de m\u00e9tricas e monitoramento avan\u00e7ado</li> <li>Sem controle de recursos (CPU, mem\u00f3ria, disco)</li> <li>Aus\u00eancia de queue de tarefas e load balancing</li> <li>Sem cache local ou persist\u00eancia</li> <li>Falta de plugins e extensibilidade</li> <li>Sem controle de vers\u00e3o dos agentes</li> <li>Aus\u00eancia de health checks avan\u00e7ados</li> </ul>"},{"location":"agent-improvements/#melhorias-propostas","title":"\ud83c\udfaf Melhorias Propostas","text":""},{"location":"agent-improvements/#1-sistema-de-metricas-e-monitoramento-avancado","title":"1. \ud83d\udcca Sistema de M\u00e9tricas e Monitoramento Avan\u00e7ado","text":"<pre><code>// Estrutura proposta para m\u00e9tricas\ntype AgentMetrics struct {\n    SystemMetrics    SystemMetrics    `json:\"system\"`\n    RuntimeMetrics   RuntimeMetrics   `json:\"runtime\"`\n    TaskMetrics      TaskMetrics      `json:\"tasks\"`\n    NetworkMetrics   NetworkMetrics   `json:\"network\"`\n    CustomMetrics    map[string]float64 `json:\"custom\"`\n}\n\ntype SystemMetrics struct {\n    CPUUsagePercent    float64 `json:\"cpu_usage\"`\n    MemoryUsageMB      float64 `json:\"memory_usage_mb\"`\n    MemoryTotalMB      float64 `json:\"memory_total_mb\"`\n    DiskUsageGB        float64 `json:\"disk_usage_gb\"`\n    DiskTotalGB        float64 `json:\"disk_total_gb\"`\n    LoadAverage1m      float64 `json:\"load_avg_1m\"`\n    NetworkRxMB        float64 `json:\"network_rx_mb\"`\n    NetworkTxMB        float64 `json:\"network_tx_mb\"`\n    ProcessCount       int     `json:\"process_count\"`\n}\n</code></pre> <p>Funcionalidades: - Coleta autom\u00e1tica de m\u00e9tricas sistema (CPU, mem\u00f3ria, disco, rede) - M\u00e9tricas de runtime (goroutines, GC, heap) - M\u00e9tricas de tarefas (execu\u00e7\u00e3o, falhas, lat\u00eancia) - Export para Prometheus/Grafana - Alertas autom\u00e1ticos em thresholds</p> <pre><code>-- API Lua para m\u00e9tricas customizadas\nmetrics.gauge(\"deployment_time\", 45.2)\nmetrics.counter(\"api_requests\", 1)\nmetrics.histogram(\"response_time\", 0.125)\n</code></pre>"},{"location":"agent-improvements/#2-controle-inteligente-de-recursos","title":"2. \ud83c\udf9b\ufe0f Controle Inteligente de Recursos","text":"<pre><code>type ResourceLimits struct {\n    MaxCPUPercent    float64        `json:\"max_cpu\"`\n    MaxMemoryMB      int64          `json:\"max_memory\"`\n    MaxDiskSpaceMB   int64          `json:\"max_disk\"`\n    MaxConcurrentTasks int          `json:\"max_concurrent\"`\n    IOPriority       int            `json:\"io_priority\"`\n    NetworkBandwidthMbps int        `json:\"network_limit\"`\n    Cgroups          CgroupLimits   `json:\"cgroups\"`\n}\n\ntype TaskExecution struct {\n    TaskID          string\n    Priority        int\n    ResourceReq     ResourceRequirements\n    Timeout         time.Duration\n    RetryPolicy     RetryPolicy\n    Environment     map[string]string\n    WorkingDir      string\n    User            string\n}\n</code></pre> <p>Funcionalidades: - Controle de recursos por tarefa (CPU, mem\u00f3ria, I/O) - Queue de prioridade para tarefas - Resource scheduling inteligente - Isolation usando containers/cgroups - Auto-scaling baseado em carga</p>"},{"location":"agent-improvements/#3-sistema-de-queue-e-load-balancing","title":"3. \ud83d\udd04 Sistema de Queue e Load Balancing","text":"<pre><code>type TaskQueue struct {\n    PendingTasks    []Task          `json:\"pending\"`\n    RunningTasks    []Task          `json:\"running\"`\n    CompletedTasks  []Task          `json:\"completed\"`\n    FailedTasks     []Task          `json:\"failed\"`\n    QueueStats      QueueMetrics    `json:\"stats\"`\n}\n\ntype LoadBalancer struct {\n    Strategy        BalanceStrategy  `json:\"strategy\"`\n    HealthyAgents   []AgentInfo     `json:\"healthy\"`\n    UnhealthyAgents []AgentInfo     `json:\"unhealthy\"`\n    Distribution    TaskDistribution `json:\"distribution\"`\n}\n</code></pre> <p>Estrat\u00e9gias de Balanceamento: - Round-robin - Least connections - CPU/Memory-based - Custom priority - Affinity-based (tarefas espec\u00edficas para agentes espec\u00edficos)</p>"},{"location":"agent-improvements/#4-cache-local-e-persistencia","title":"4. \ud83d\udcbe Cache Local e Persist\u00eancia","text":"<pre><code>type AgentCache struct {\n    ArtifactCache   ArtifactStore   `json:\"artifacts\"`\n    StateCache      StateStore      `json:\"state\"`\n    ConfigCache     ConfigStore     `json:\"config\"`\n    LogBuffer       LogBuffer       `json:\"logs\"`\n}\n</code></pre> <p>Funcionalidades: - Cache de artefatos (Docker images, bin\u00e1rios, configs) - Buffer local de logs com rotation - Persist\u00eancia de estado entre reinicializa\u00e7\u00f5es - Cache de configura\u00e7\u00f5es e secrets - Sincroniza\u00e7\u00e3o inteligente com master</p>"},{"location":"agent-improvements/#5-sistema-de-plugins-e-extensibilidade","title":"5. \ud83d\udd0c Sistema de Plugins e Extensibilidade","text":"<pre><code>type Plugin interface {\n    Name() string\n    Version() string\n    Initialize(config map[string]interface{}) error\n    Execute(ctx context.Context, params map[string]interface{}) (map[string]interface{}, error)\n    Cleanup() error\n    HealthCheck() error\n}\n\ntype PluginManager struct {\n    LoadedPlugins map[string]Plugin\n    PluginConfigs map[string]map[string]interface{}\n    Registry      PluginRegistry\n}\n</code></pre> <p>Plugins Propostos: - Docker Plugin: Gerenciamento de containers - Kubernetes Plugin: Deploy e management K8s - Monitoring Plugin: M\u00e9tricas customizadas - Notification Plugin: Slack, email, webhooks - Storage Plugin: S3, GCS, local storage - Database Plugin: PostgreSQL, MySQL, Redis - Security Plugin: Vault integration, secret management</p>"},{"location":"agent-improvements/#6-health-checks-avancados","title":"6. \ud83c\udfe5 Health Checks Avan\u00e7ados","text":"<pre><code>type HealthCheck struct {\n    Type            string          `json:\"type\"`\n    Endpoint        string          `json:\"endpoint,omitempty\"`\n    Command         string          `json:\"command,omitempty\"`\n    Interval        time.Duration   `json:\"interval\"`\n    Timeout         time.Duration   `json:\"timeout\"`\n    Retries         int             `json:\"retries\"`\n    SuccessThreshold int            `json:\"success_threshold\"`\n    FailureThreshold int            `json:\"failure_threshold\"`\n}\n\ntype AgentHealth struct {\n    Overall         HealthStatus    `json:\"overall\"`\n    SystemHealth    HealthStatus    `json:\"system\"`\n    ServiceHealth   HealthStatus    `json:\"service\"`\n    PluginHealth    map[string]HealthStatus `json:\"plugins\"`\n    LastCheck       time.Time       `json:\"last_check\"`\n    CheckHistory    []HealthResult  `json:\"history\"`\n}\n</code></pre> <p>Tipos de Health Checks: - System checks (disk space, memory, CPU) - Service checks (database connectivity, API endpoints) - Custom script checks - Plugin-specific checks - External dependency checks</p>"},{"location":"agent-improvements/#7-versionamento-e-auto-update","title":"7. \ud83d\udd04 Versionamento e Auto-Update","text":"<pre><code>type AgentVersion struct {\n    Current         string          `json:\"current\"`\n    Available       string          `json:\"available\"`\n    UpdatePolicy    UpdatePolicy    `json:\"update_policy\"`\n    RollbackPolicy  RollbackPolicy  `json:\"rollback_policy\"`\n    UpdateHistory   []UpdateRecord  `json:\"history\"`\n}\n\ntype UpdatePolicy struct {\n    AutoUpdate      bool            `json:\"auto_update\"`\n    UpdateWindow    TimeWindow      `json:\"update_window\"`\n    PreUpdateHook   string          `json:\"pre_update_hook\"`\n    PostUpdateHook  string          `json:\"post_update_hook\"`\n    CanaryPercent   int             `json:\"canary_percent\"`\n}\n</code></pre> <p>Funcionalidades: - Auto-update controlado por pol\u00edticas - Canary deployments de agentes - Rollback autom\u00e1tico em falhas - Version compatibility matrix - Blue-green deployment de agentes</p>"},{"location":"agent-improvements/#8-seguranca-avancada","title":"8. \ud83d\udd12 Seguran\u00e7a Avan\u00e7ada","text":"<pre><code>type SecurityConfig struct {\n    Authentication  AuthConfig      `json:\"auth\"`\n    Authorization   AuthzConfig     `json:\"authz\"`\n    Encryption      EncryptionConfig `json:\"encryption\"`\n    Audit          AuditConfig     `json:\"audit\"`\n    Compliance     ComplianceConfig `json:\"compliance\"`\n}\n\ntype AuthConfig struct {\n    Method          string          `json:\"method\"` // \"jwt\", \"mtls\", \"oauth\"\n    TokenTTL        time.Duration   `json:\"token_ttl\"`\n    RefreshEnabled  bool            `json:\"refresh_enabled\"`\n    MFA            bool            `json:\"mfa_required\"`\n}\n</code></pre> <p>Recursos de Seguran\u00e7a: - mTLS com certificate rotation - RBAC granular por agente/tarefa - Audit logging de todas as a\u00e7\u00f5es - Secret management integrado - Compliance scanning (SOC2, PCI-DSS) - Network policies e firewalls</p>"},{"location":"agent-improvements/#9-networking-avancado","title":"9. \ud83c\udf10 Networking Avan\u00e7ado","text":"<pre><code>type NetworkConfig struct {\n    ServiceMesh     ServiceMeshConfig `json:\"service_mesh\"`\n    LoadBalancer    LoadBalancerConfig `json:\"load_balancer\"`\n    ServiceDiscovery ServiceDiscoveryConfig `json:\"service_discovery\"`\n    NetworkPolicies []NetworkPolicy   `json:\"network_policies\"`\n}\n\ntype ServiceMeshConfig struct {\n    Enabled         bool            `json:\"enabled\"`\n    Provider        string          `json:\"provider\"` // \"istio\", \"linkerd\", \"consul\"\n    TLS            bool            `json:\"tls\"`\n    Observability  bool            `json:\"observability\"`\n}\n</code></pre> <p>Funcionalidades: - Service mesh integration - Auto service discovery - Circuit breakers - Rate limiting per agent - Network policies enforcement - Multi-region support</p>"},{"location":"agent-improvements/#10-testing-e-quality-assurance","title":"10. \ud83e\uddea Testing e Quality Assurance","text":"<pre><code>type TestFramework struct {\n    UnitTests       []TestCase      `json:\"unit_tests\"`\n    IntegrationTests []TestCase     `json:\"integration_tests\"`\n    LoadTests       []LoadTestConfig `json:\"load_tests\"`\n    ChaosTests      []ChaosTestConfig `json:\"chaos_tests\"`\n}\n\ntype TestCase struct {\n    Name            string          `json:\"name\"`\n    Type            string          `json:\"type\"`\n    Command         string          `json:\"command\"`\n    ExpectedResult  TestResult      `json:\"expected\"`\n    Timeout         time.Duration   `json:\"timeout\"`\n}\n</code></pre> <p>Capacidades de Testing: - Unit tests autom\u00e1ticos dos agentes - Integration tests com master - Load testing distribu\u00eddo - Chaos engineering integration - Smoke tests p\u00f3s-deployment - Performance benchmarking</p>"},{"location":"agent-improvements/#novas-funcionalidades-propostas","title":"\ud83d\udee0\ufe0f Novas Funcionalidades Propostas","text":""},{"location":"agent-improvements/#1-web-dashboard-para-agentes","title":"1. \ud83d\udcf1 Web Dashboard para Agentes","text":"<pre><code>interface AgentDashboard {\n    realTimeMetrics: MetricsDisplay;\n    taskQueue: TaskQueueView;\n    logStreaming: LogViewer;\n    resourceUsage: ResourceMonitor;\n    healthStatus: HealthDashboard;\n    configuration: ConfigEditor;\n}\n</code></pre> <p>Funcionalidades: - Dashboard web em tempo real - Visualiza\u00e7\u00e3o de m\u00e9tricas com gr\u00e1ficos - Log streaming com filtros - Controle remoto de agentes - Configuration management UI - Alert management</p>"},{"location":"agent-improvements/#2-ai-powered-agent-management","title":"2. \ud83e\udd16 AI-Powered Agent Management","text":"<pre><code>type AIAssistant struct {\n    PredictiveScaling    bool            `json:\"predictive_scaling\"`\n    AnomalyDetection    bool            `json:\"anomaly_detection\"`\n    AutoRemediation     bool            `json:\"auto_remediation\"`\n    PerformanceOptimization bool        `json:\"perf_optimization\"`\n    ResourceRecommendations bool        `json:\"resource_recommendations\"`\n}\n</code></pre> <p>Recursos de AI: - Predictive scaling baseado em padr\u00f5es hist\u00f3ricos - Anomaly detection em m\u00e9tricas e comportamento - Auto-remediation de problemas comuns - Performance optimization suggestions - Capacity planning inteligente</p>"},{"location":"agent-improvements/#3-workflow-orchestration-avancada","title":"3. \ud83d\udd04 Workflow Orchestration Avan\u00e7ada","text":"<pre><code>type WorkflowEngine struct {\n    DAGExecution        bool            `json:\"dag_execution\"`\n    ConditionalBranching bool           `json:\"conditional_branching\"`\n    ParallelExecution   bool            `json:\"parallel_execution\"`\n    WorkflowTemplates   []WorkflowTemplate `json:\"templates\"`\n    WorkflowHistory     []WorkflowExecution `json:\"history\"`\n}\n</code></pre> <p>Capacidades: - DAG (Directed Acyclic Graph) workflow execution - Conditional execution based on results - Parallel and sequential task combinations - Workflow templates library - Visual workflow builder - Workflow versioning and rollback</p>"},{"location":"agent-improvements/#4-advanced-analytics-e-reporting","title":"4. \ud83d\udcca Advanced Analytics e Reporting","text":"<pre><code>type AnalyticsEngine struct {\n    MetricsAggregation  MetricsConfig   `json:\"metrics\"`\n    ReportGeneration    ReportConfig    `json:\"reports\"`\n    DataExport         ExportConfig    `json:\"export\"`\n    Alerts             AlertConfig     `json:\"alerts\"`\n    Dashboards         DashboardConfig `json:\"dashboards\"`\n}\n</code></pre> <p>Funcionalidades: - Time-series metrics aggregation - Custom report generation (PDF, Excel, JSON) - Data export para sistemas externos - Advanced alerting rules - Custom dashboards per team/project</p>"},{"location":"agent-improvements/#5-multi-cloud-e-hybrid-support","title":"5. \ud83c\udf0d Multi-Cloud e Hybrid Support","text":"<pre><code>type CloudIntegration struct {\n    AWS             AWSConfig       `json:\"aws,omitempty\"`\n    GCP             GCPConfig       `json:\"gcp,omitempty\"`\n    Azure           AzureConfig     `json:\"azure,omitempty\"`\n    OnPremises      OnPremConfig    `json:\"on_prem,omitempty\"`\n    Kubernetes      K8sConfig       `json:\"kubernetes,omitempty\"`\n}\n</code></pre> <p>Integra\u00e7\u00f5es: - AWS ECS/Fargate para agentes containerizados - GCP Cloud Run/GKE integration - Azure Container Instances - Kubernetes native deployment - Hybrid cloud orchestration - Edge computing support</p>"},{"location":"agent-improvements/#implementacao-priorizada","title":"\ud83d\ude80 Implementa\u00e7\u00e3o Priorizada","text":""},{"location":"agent-improvements/#fase-1-fundacao-2-3-meses","title":"Fase 1 - Funda\u00e7\u00e3o (2-3 meses)","text":"<ol> <li>Sistema de M\u00e9tricas - Base para observabilidade</li> <li>Health Checks Avan\u00e7ados - Confiabilidade</li> <li>Cache Local - Performance</li> <li>Controle de Recursos - Estabilidade</li> </ol>"},{"location":"agent-improvements/#fase-2-escalabilidade-3-4-meses","title":"Fase 2 - Escalabilidade (3-4 meses)","text":"<ol> <li>Queue e Load Balancing - Distribui\u00e7\u00e3o inteligente</li> <li>Plugins Framework - Extensibilidade</li> <li>Seguran\u00e7a Avan\u00e7ada - Enterprise readiness</li> <li>Web Dashboard - User experience</li> </ol>"},{"location":"agent-improvements/#fase-3-inteligencia-4-5-meses","title":"Fase 3 - Intelig\u00eancia (4-5 meses)","text":"<ol> <li>AI-Powered Management - Automa\u00e7\u00e3o inteligente</li> <li>Workflow Orchestration - Casos de uso complexos</li> <li>Analytics Engine - Insights e otimiza\u00e7\u00e3o</li> <li>Multi-Cloud Support - Flexibilidade de deployment</li> </ol>"},{"location":"agent-improvements/#exemplo-de-implementacao-sistema-de-metricas","title":"\ud83d\udccb Exemplo de Implementa\u00e7\u00e3o: Sistema de M\u00e9tricas","text":"<p>Vou criar um exemplo pr\u00e1tico de como implementar o sistema de m\u00e9tricas:</p> <pre><code>// internal/agent/metrics.go\ntype MetricsCollector struct {\n    systemCollector  SystemMetricsCollector\n    runtimeCollector RuntimeMetricsCollector\n    taskCollector    TaskMetricsCollector\n    customCollector  CustomMetricsCollector\n\n    registry         *prometheus.Registry\n    server          *http.Server\n    interval        time.Duration\n}\n\nfunc NewMetricsCollector(port int) *MetricsCollector {\n    registry := prometheus.NewRegistry()\n    collector := &amp;MetricsCollector{\n        registry: registry,\n        interval: 30 * time.Second,\n    }\n\n    // Register collectors\n    registry.MustRegister(collector.systemCollector)\n    registry.MustRegister(collector.runtimeCollector)\n\n    // Start metrics HTTP server\n    mux := http.NewServeMux()\n    mux.Handle(\"/metrics\", promhttp.HandlerFor(registry, promhttp.HandlerOpts{}))\n\n    collector.server = &amp;http.Server{\n        Addr:    fmt.Sprintf(\":%d\", port),\n        Handler: mux,\n    }\n\n    return collector\n}\n\nfunc (mc *MetricsCollector) Start() {\n    go mc.collectLoop()\n    go mc.server.ListenAndServe()\n}\n\nfunc (mc *MetricsCollector) collectLoop() {\n    ticker := time.NewTicker(mc.interval)\n    defer ticker.Stop()\n\n    for {\n        select {\n        case &lt;-ticker.C:\n            mc.collectMetrics()\n        }\n    }\n}\n</code></pre> <pre><code>-- Exemplo de uso em Lua tasks\nModern DSLs = {\n    metrics_demo = {\n        tasks = {\n            collect_system_metrics = {\n                command = function()\n                    -- Coletar m\u00e9tricas customizadas\n                    metrics.gauge(\"task_duration\", 45.2)\n                    metrics.counter(\"deployments_total\", 1)\n\n                    local cpu_usage = metrics.system_cpu()\n                    local memory_usage = metrics.system_memory()\n\n                    log.info(\"CPU: \" .. cpu_usage .. \"%, Memory: \" .. memory_usage .. \"MB\")\n\n                    -- Alertar se recursos est\u00e3o altos\n                    if cpu_usage &gt; 80 then\n                        metrics.alert(\"high_cpu\", {\n                            level = \"warning\",\n                            message = \"CPU usage is high: \" .. cpu_usage .. \"%\"\n                        })\n                    end\n\n                    return true, \"Metrics collected successfully\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"agent-improvements/#conclusao","title":"\ud83c\udfaf Conclus\u00e3o","text":"<p>Essas melhorias transformariam o sloth-runner de um sistema de execu\u00e7\u00e3o distribu\u00edda simples em uma plataforma enterprise de orquestra\u00e7\u00e3o com:</p> <ul> <li>Observabilidade Total: M\u00e9tricas, logs, traces, alerts</li> <li>Confiabilidade: Health checks, auto-recovery, circuit breakers</li> <li>Escalabilidade: Load balancing, auto-scaling, resource management</li> <li>Seguran\u00e7a: mTLS, RBAC, audit, compliance</li> <li>Flexibilidade: Plugins, multi-cloud, workflow orchestration</li> <li>Intelig\u00eancia: AI-powered optimization e automation</li> </ul> <p>O resultado seria uma solu\u00e7\u00e3o que compete diretamente com ferramentas como Jenkins, GitLab CI, GitHub Actions, Airflow e Kubernetes Jobs, mas com a vantagem \u00fanica do scripting Lua e arquitetura master-agent extremamente flex\u00edvel.</p> <p>Pr\u00f3ximo passo recomendado: Come\u00e7ar com a implementa\u00e7\u00e3o do sistema de m\u00e9tricas (Fase 1), pois ele fornece a base de observabilidade necess\u00e1ria para todas as outras funcionalidades. \ud83d\ude80</p>"},{"location":"ai-integration/","title":"\ud83e\udd16 AI/ML Integration","text":"<p>Sloth Runner provides built-in artificial intelligence capabilities that enable smart automation, intelligent decision making, and advanced text processing for modern workflows.</p>"},{"location":"ai-integration/#core-ai-features","title":"\ud83e\udde0 Core AI Features","text":""},{"location":"ai-integration/#openai-integration","title":"OpenAI Integration","text":"<p>Direct integration with OpenAI's powerful language models: - Text generation and completion - Code generation assistance - Intelligent analysis of logs and data - Automated decision making - Natural language task descriptions</p>"},{"location":"ai-integration/#smart-automation","title":"Smart Automation","text":"<p>AI-powered automation that learns from your workflows: - Pattern recognition in task failures - Automatic retry strategy suggestions - Performance optimization recommendations - Anomaly detection in execution patterns</p>"},{"location":"ai-integration/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"ai-integration/#prerequisites","title":"Prerequisites","text":"<pre><code># Set OpenAI API key\nexport OPENAI_API_KEY=\"your-api-key-here\"\n\n# Or use configuration file\necho \"openai_api_key: your-api-key\" &gt; ai-config.yaml\n</code></pre>"},{"location":"ai-integration/#basic-ai-module-usage","title":"Basic AI Module Usage","text":"<pre><code>-- Load AI module\nlocal ai = require(\"ai\")\n\n-- Simple text completion\nlocal response = ai.openai.complete({\n    prompt = \"Generate a bash script to deploy a Node.js application\",\n    max_tokens = 200,\n    temperature = 0.7\n})\n\nlog.info(\"Generated script: \" .. response.text)\n</code></pre>"},{"location":"ai-integration/#ai-powered-tasks","title":"\ud83c\udfaf AI-Powered Tasks","text":""},{"location":"ai-integration/#intelligent-code-generation","title":"Intelligent Code Generation","text":"<pre><code>task(\"generate_dockerfile\")\n    :description(\"AI-generated Dockerfile for the application\")\n    :command(function(params, deps)\n        local ai = require(\"ai\")\n\n        -- Analyze project structure\n        local project_files = exec.run(\"find . -type f -name '*.js' -o -name '*.py' -o -name '*.go'\").stdout\n\n        -- Generate appropriate Dockerfile\n        local dockerfile_content = ai.openai.complete({\n            prompt = \"Create a Dockerfile for this project with files: \" .. project_files,\n            max_tokens = 300,\n            temperature = 0.3  -- Lower temperature for more deterministic code\n        })\n\n        -- Write generated Dockerfile\n        local file = io.open(\"Dockerfile\", \"w\")\n        file:write(dockerfile_content.text)\n        file:close()\n\n        return true, \"Dockerfile generated successfully\", {\n            dockerfile_size = #dockerfile_content.text,\n            ai_confidence = dockerfile_content.confidence\n        }\n    end)\n    :build()\n</code></pre>"},{"location":"ai-integration/#smart-log-analysis","title":"Smart Log Analysis","text":"<pre><code>task(\"analyze_logs\")\n    :description(\"AI-powered log analysis for error detection\")\n    :command(function(params, deps)\n        local ai = require(\"ai\")\n\n        -- Get recent logs\n        local logs = exec.run(\"tail -100 /var/log/application.log\").stdout\n\n        -- AI analysis\n        local analysis = ai.openai.complete({\n            prompt = \"Analyze these application logs and identify any errors or issues:\\n\" .. logs,\n            max_tokens = 150\n        })\n\n        -- Make decisions based on analysis\n        local decision = ai.decide({\n            analysis = analysis.text,\n            threshold = 0.8\n        })\n\n        if decision.severity == \"high\" then\n            -- Trigger alert workflow\n            notifications.send_alert(\"Critical issue detected: \" .. decision.issue)\n        end\n\n        return true, \"Log analysis completed\", {\n            analysis = analysis.text,\n            severity = decision.severity,\n            recommendations = decision.actions\n        }\n    end)\n    :build()\n</code></pre>"},{"location":"ai-integration/#intelligent-environment-selection","title":"Intelligent Environment Selection","text":"<pre><code>task(\"smart_deploy\")\n    :description(\"AI chooses the best deployment environment\")\n    :command(function(params, deps)\n        local ai = require(\"ai\")\n\n        -- Gather deployment context\n        local context = {\n            time_of_day = os.date(\"%H\"),\n            day_of_week = os.date(\"%w\"),\n            recent_deployments = state.get(\"recent_deployments\") or {},\n            current_load = monitoring.get_load_metrics(),\n            test_results = deps.run_tests or {}\n        }\n\n        -- AI decision making\n        local deployment_plan = ai.decide({\n            context = context,\n            options = {\"staging\", \"production\", \"canary\"},\n            criteria = {\n                \"minimize_risk\",\n                \"optimize_performance\", \n                \"consider_load\"\n            }\n        })\n\n        log.info(\"AI recommends deployment to: \" .. deployment_plan.environment)\n        log.info(\"Reasoning: \" .. deployment_plan.reasoning)\n\n        -- Execute recommended deployment\n        return exec.run(\"deploy.sh \" .. deployment_plan.environment)\n    end)\n    :build()\n</code></pre>"},{"location":"ai-integration/#ai-module-api-reference","title":"\ud83d\udd27 AI Module API Reference","text":""},{"location":"ai-integration/#openai-integration_1","title":"OpenAI Integration","text":""},{"location":"ai-integration/#text-completion","title":"Text Completion","text":"<pre><code>local ai = require(\"ai\")\n\n-- Basic completion\nlocal result = ai.openai.complete(\"Explain CI/CD best practices\")\n\n-- Advanced completion with parameters\nlocal result = ai.openai.complete({\n    prompt = \"Write a deployment script\",\n    max_tokens = 500,\n    temperature = 0.5,\n    top_p = 0.9,\n    frequency_penalty = 0.1,\n    presence_penalty = 0.1\n})\n</code></pre>"},{"location":"ai-integration/#chat-completions","title":"Chat Completions","text":"<pre><code>-- Multi-turn conversation\nlocal chat_result = ai.openai.chat({\n    messages = {\n        {role = \"system\", content = \"You are a DevOps expert\"},\n        {role = \"user\", content = \"How do I optimize my Docker builds?\"}\n    },\n    model = \"gpt-4\",\n    max_tokens = 300\n})\n</code></pre>"},{"location":"ai-integration/#code-generation","title":"Code Generation","text":"<pre><code>-- Specialized code generation\nlocal code = ai.openai.generate_code({\n    language = \"bash\",\n    description = \"Script to backup PostgreSQL database\",\n    parameters = {\n        database_name = \"myapp_db\",\n        backup_location = \"/backups/\"\n    }\n})\n</code></pre>"},{"location":"ai-integration/#decision-making-engine","title":"Decision Making Engine","text":""},{"location":"ai-integration/#smart-decisions","title":"Smart Decisions","text":"<pre><code>-- AI-powered decision making\nlocal decision = ai.decide({\n    situation = \"Database CPU usage is 85%\",\n    options = {\"scale_up\", \"optimize_queries\", \"add_replica\"},\n    constraints = {\n        budget = \"limited\",\n        downtime = \"not_allowed\"\n    },\n    history = previous_decisions\n})\n\n-- Returns structured decision with reasoning\nprint(decision.choice)      -- \"add_replica\"\nprint(decision.confidence)  -- 0.87\nprint(decision.reasoning)   -- \"Adding replica provides...\"\n</code></pre>"},{"location":"ai-integration/#pattern-recognition","title":"Pattern Recognition","text":"<pre><code>-- Detect patterns in workflow data\nlocal patterns = ai.analyze_patterns({\n    data = workflow_execution_history,\n    pattern_types = {\"failure_correlation\", \"performance_trends\", \"resource_usage\"},\n    time_window = \"30d\"\n})\n\nfor _, pattern in ipairs(patterns) do\n    log.info(\"Detected pattern: \" .. pattern.description)\n    log.info(\"Confidence: \" .. pattern.confidence)\n    log.info(\"Recommendation: \" .. pattern.recommendation)\nend\n</code></pre>"},{"location":"ai-integration/#advanced-use-cases","title":"\ud83c\udfaf Advanced Use Cases","text":""},{"location":"ai-integration/#ai-driven-cicd-pipeline","title":"AI-Driven CI/CD Pipeline","text":"<pre><code>-- Complete AI-powered CI/CD workflow\nworkflow.define(\"ai_cicd_pipeline\", {\n    description = \"AI-enhanced CI/CD pipeline with smart decisions\",\n\n    tasks = {\n        -- AI code review\n        task(\"ai_code_review\")\n            :command(function(params, deps)\n                local ai = require(\"ai\")\n                local git = require(\"git\")\n\n                -- Get diff for review\n                local diff = git.get_diff(\"HEAD~1\", \"HEAD\")\n\n                -- AI code review\n                local review = ai.openai.complete({\n                    prompt = \"Review this code diff for security issues, bugs, and best practices:\\n\" .. diff,\n                    max_tokens = 400\n                })\n\n                -- Fail if critical issues found\n                if string.find(review.text:lower(), \"critical\") then\n                    return false, \"Critical issues found in code review\"\n                end\n\n                return true, \"Code review passed\", {review = review.text}\n            end)\n            :build(),\n\n        -- Smart test selection\n        task(\"ai_test_selection\")\n            :depends_on({\"ai_code_review\"})\n            :command(function(params, deps)\n                local ai = require(\"ai\")\n\n                -- Analyze changed files\n                local changed_files = git.get_changed_files()\n\n                -- AI decides which tests to run\n                local test_plan = ai.decide({\n                    changed_files = changed_files,\n                    available_tests = {\"unit\", \"integration\", \"e2e\", \"performance\"},\n                    time_budget = \"10m\"\n                })\n\n                -- Run selected tests\n                for _, test_type in ipairs(test_plan.selected_tests) do\n                    exec.run(\"npm run test:\" .. test_type)\n                end\n\n                return true, \"Smart test execution completed\"\n            end)\n            :build(),\n\n        -- Intelligent deployment strategy\n        task(\"ai_deployment\")\n            :depends_on({\"ai_test_selection\"})\n            :command(function(params, deps)\n                local ai = require(\"ai\")\n\n                -- Deployment decision factors\n                local factors = {\n                    test_results = deps.ai_test_selection,\n                    current_production_health = monitoring.get_health(),\n                    deployment_history = state.get(\"deployment_history\"),\n                    time_context = {\n                        hour = tonumber(os.date(\"%H\")),\n                        day_of_week = os.date(\"%A\")\n                    }\n                }\n\n                -- AI deployment strategy\n                local strategy = ai.decide({\n                    context = factors,\n                    strategies = {\"blue_green\", \"canary\", \"rolling\", \"immediate\"},\n                    risk_tolerance = \"medium\"\n                })\n\n                log.info(\"AI selected deployment strategy: \" .. strategy.choice)\n                log.info(\"Reasoning: \" .. strategy.reasoning)\n\n                -- Execute deployment\n                return exec.run(\"deploy.sh --strategy=\" .. strategy.choice)\n            end)\n            :build()\n    }\n})\n</code></pre>"},{"location":"ai-integration/#ai-powered-infrastructure-management","title":"AI-Powered Infrastructure Management","text":"<pre><code>task(\"ai_infrastructure_optimization\")\n    :description(\"AI optimizes infrastructure based on usage patterns\")\n    :command(function(params, deps)\n        local ai = require(\"ai\")\n        local aws = require(\"aws\")\n\n        -- Gather infrastructure metrics\n        local metrics = {\n            ec2_utilization = aws.ec2.get_utilization_metrics(\"7d\"),\n            rds_performance = aws.rds.get_performance_metrics(\"7d\"),\n            costs = aws.billing.get_costs(\"30d\")\n        }\n\n        -- AI analysis and recommendations\n        local optimization = ai.openai.complete({\n            prompt = \"Analyze these AWS infrastructure metrics and provide optimization recommendations:\\n\" .. \n                     json.encode(metrics),\n            max_tokens = 500\n        })\n\n        -- Parse recommendations and create action plan\n        local recommendations = ai.parse_recommendations(optimization.text)\n\n        for _, rec in ipairs(recommendations) do\n            if rec.type == \"scale_down\" and rec.confidence &gt; 0.8 then\n                log.info(\"AI recommends scaling down: \" .. rec.resource)\n                -- Auto-execute high-confidence recommendations\n                aws.ec2.modify_instance(rec.resource, {instance_type = rec.new_size})\n            end\n        end\n\n        return true, \"Infrastructure optimization completed\", {\n            recommendations = recommendations,\n            estimated_savings = optimization.estimated_savings\n        }\n    end)\n    :build()\n</code></pre>"},{"location":"ai-integration/#security-best-practices","title":"\ud83d\udd12 Security &amp; Best Practices","text":""},{"location":"ai-integration/#api-key-management","title":"API Key Management","text":"<pre><code>-- Secure API key handling\nlocal ai = require(\"ai\")\n\n-- Load from environment (recommended)\nai.configure({\n    api_key = os.getenv(\"OPENAI_API_KEY\"),\n    timeout = 30,\n    retry_attempts = 3\n})\n\n-- Or from encrypted configuration\nai.configure({\n    config_file = \"encrypted-ai-config.yaml\",\n    encryption_key = os.getenv(\"CONFIG_ENCRYPTION_KEY\")\n})\n</code></pre>"},{"location":"ai-integration/#rate-limiting","title":"Rate Limiting","text":"<pre><code>-- Built-in rate limiting\nai.configure({\n    rate_limit = {\n        requests_per_minute = 60,\n        tokens_per_minute = 40000\n    }\n})\n</code></pre>"},{"location":"ai-integration/#data-privacy","title":"Data Privacy","text":"<pre><code>-- Sanitize sensitive data before AI processing\ntask(\"ai_log_analysis\")\n    :command(function(params, deps)\n        local ai = require(\"ai\")\n\n        -- Remove sensitive information\n        local sanitized_logs = ai.sanitize_data(raw_logs, {\n            remove_patterns = {\n                \"password=.*\",\n                \"token=.*\",\n                \"api_key=.*\"\n            }\n        })\n\n        local analysis = ai.openai.complete({\n            prompt = \"Analyze these sanitized logs: \" .. sanitized_logs\n        })\n\n        return true, \"Analysis completed safely\"\n    end)\n    :build()\n</code></pre>"},{"location":"ai-integration/#monitoring-ai-usage","title":"\ud83d\udcca Monitoring AI Usage","text":""},{"location":"ai-integration/#token-usage-tracking","title":"Token Usage Tracking","text":"<pre><code>-- Monitor AI API usage\nlocal usage = ai.get_usage_stats()\nprint(\"Tokens used today: \" .. usage.tokens_today)\nprint(\"API calls made: \" .. usage.calls_today)\nprint(\"Estimated cost: $\" .. usage.estimated_cost)\n</code></pre>"},{"location":"ai-integration/#performance-metrics","title":"Performance Metrics","text":"<pre><code>-- AI response time monitoring\nlocal start_time = os.time()\nlocal result = ai.openai.complete(\"Generate deployment script\")\nlocal duration = os.time() - start_time\n\nstate.set(\"ai_response_time\", duration)\n</code></pre>"},{"location":"ai-integration/#custom-ai-models","title":"\ud83c\udfa8 Custom AI Models","text":""},{"location":"ai-integration/#local-model-integration","title":"Local Model Integration","text":"<pre><code>-- Use local AI models for sensitive data\nai.configure({\n    provider = \"local\",\n    model_path = \"/models/custom-code-model\",\n    device = \"gpu\"  -- or \"cpu\"\n})\n\nlocal result = ai.local.complete(\"Generate Kubernetes deployment\")\n</code></pre>"},{"location":"ai-integration/#custom-fine-tuned-models","title":"Custom Fine-Tuned Models","text":"<pre><code>-- Use organization-specific fine-tuned models\nai.configure({\n    provider = \"openai\",\n    model = \"ft:gpt-3.5-turbo:company:devops-model:abc123\"\n})\n</code></pre>"},{"location":"ai-integration/#future-ai-features","title":"\ud83d\udd2e Future AI Features","text":"<p>The AI integration is continuously evolving with planned features: - Multi-modal AI (text + images + code) - Workflow learning from execution patterns - Predictive failure detection - Auto-healing infrastructure - Natural language workflow creation</p> <p>AI integration transforms Sloth Runner into an intelligent automation platform that doesn't just execute tasks, but thinks about the best way to accomplish your goals! \ud83e\udd16\u2728</p>"},{"location":"core-concepts/","title":"Core Concepts - Modern DSL","text":"<p>This document explains the fundamental concepts of Sloth-Runner using the Modern DSL, helping you understand how tasks are defined and executed with the fluent API.</p>"},{"location":"core-concepts/#modern-dsl-task-definition","title":"Modern DSL Task Definition","text":"<p>Tasks in Sloth-Runner are defined using the Modern DSL fluent API, which provides an intuitive and powerful way to create workflows.</p>"},{"location":"core-concepts/#task-builder-pattern","title":"Task Builder Pattern","text":"<p>Each task is created using the <code>task()</code> function and the fluent API:</p> <pre><code>local my_task = task(\"task_name\")\n    :description(\"Task description\")\n    :command(function(params, deps)\n        -- Task logic here\n        return true, \"Success message\", { output_data = \"value\" }\n    end)\n    :timeout(\"30s\")\n    :retries(3, \"exponential\")\n    :build()\n</code></pre>"},{"location":"core-concepts/#workflow-definition-structure","title":"Workflow Definition Structure","text":"<p>Workflows are defined using <code>workflow.define()</code> with comprehensive configuration:</p> <pre><code>workflow.define(\"workflow_name\", {\n    description = \"Workflow description - Modern DSL\",\n    version = \"2.0.0\",\n\n    metadata = {\n        author = \"Team Name\",\n        tags = {\"tag1\", \"tag2\"},\n        created_at = os.date()\n    },\n\n    tasks = { task1, task2, task3 },\n\n    config = {\n        timeout = \"30m\",\n        retry_policy = \"exponential\",\n        max_parallel_tasks = 4\n    },\n\n    on_start = function()\n        log.info(\"Starting workflow...\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\u2705 Workflow completed successfully!\")\n        else\n            log.error(\"\u274c Workflow failed!\")\n        end\n        return true\n    end\n})\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"Workflow completed successfully!\")\n        end\n        return true\n    end\n})\n</code></pre>"},{"location":"core-concepts/#task-properties-and-methods","title":"Task Properties and Methods","text":"<p>Each task can use the following fluent API methods:</p>"},{"location":"core-concepts/#basic-properties","title":"Basic Properties","text":"<ul> <li><code>:name(string)</code> - Task name (usually set in task() constructor)</li> <li><code>:description(string)</code> - Brief description of what the task does</li> <li><code>:command(function|string)</code> - Task execution logic:<ul> <li><code>function(params, deps)</code> - Lua function with parameters and dependencies</li> <li><code>string</code> - Shell command to execute</li> </ul> </li> </ul>"},{"location":"core-concepts/#execution-control","title":"Execution Control","text":"<ul> <li><code>:timeout(string)</code> - Execution timeout (e.g., \"10s\", \"1m\", \"30m\")</li> <li><code>:retries(number, strategy)</code> - Retry count and strategy (\"exponential\", \"linear\", \"fixed\")</li> <li><code>:async(boolean)</code> - Whether to execute asynchronously</li> <li><code>:depends_on(table)</code> - Array of task names this task depends on</li> </ul>"},{"location":"core-concepts/#conditional-execution","title":"Conditional Execution","text":"<ul> <li><code>:run_if(function|string)</code> - Execute only if condition is true</li> <li><code>:abort_if(function|string)</code> - Abort entire workflow if condition is true</li> <li><code>:condition(function)</code> - Advanced conditional logic</li> </ul>"},{"location":"core-concepts/#lifecycle-hooks","title":"Lifecycle Hooks","text":"<ul> <li><code>:pre_hook(function)</code> - Execute before main command</li> <li><code>:post_hook(function)</code> - Execute after main command  </li> <li><code>:on_success(function)</code> - Execute on successful completion</li> <li><code>:on_failure(function)</code> - Execute on failure</li> <li><code>:on_timeout(function)</code> - Execute on timeout</li> </ul>"},{"location":"core-concepts/#artifact-management","title":"Artifact Management","text":"<ul> <li><code>:artifacts(table)</code> - Files to save as artifacts after execution</li> <li><code>:consumes(table)</code> - Artifacts from other tasks to consume</li> </ul>"},{"location":"core-concepts/#advanced-features","title":"Advanced Features","text":"<ul> <li><code>:circuit_breaker(config)</code> - Circuit breaker configuration</li> <li><code>:performance_monitoring(boolean)</code> - Enable performance tracking</li> <li><code>:environment(table)</code> - Environment variables for task execution</li> </ul>"},{"location":"core-concepts/#artifact-management_1","title":"Artifact Management","text":"<p>Sloth-Runner allows tasks to share files through an artifact mechanism using the Modern DSL. A task can \"produce\" one or more files as artifacts, and subsequent tasks can \"consume\" those artifacts.</p> <p>This is useful for CI/CD pipelines where a build step might generate a binary (artifact) that is then used by a test or deployment step.</p>"},{"location":"core-concepts/#how-it-works","title":"How It Works","text":"<ol> <li> <p>Producing Artifacts: Use the <code>:artifacts()</code> method in your task definition. The value can be a single file pattern (e.g., <code>\"report.txt\"</code>) or a list (e.g., <code>{\"*.log\", \"app.bin\"}</code>). After the task completes successfully, the runner will look for files in the task's workdir that match these patterns and copy them to shared artifact storage.</p> </li> <li> <p>Consuming Artifacts: Use the <code>:consumes()</code> method in another task definition (which typically <code>:depends_on()</code> the producer task). The value should be the artifact file name you want to use (e.g., <code>\"report.txt\"</code>). Before this task executes, the runner will copy the named artifact from shared storage to this task's workdir.</p> </li> </ol>"},{"location":"core-concepts/#modern-dsl-artifact-example","title":"Modern DSL Artifact Example","text":"<pre><code>-- Producer task that creates artifacts\nlocal build_task = task(\"build_app\")\n    :description(\"Build application and create artifacts\")\n    :command(function()\n        -- Build the application\n        local result = exec.run(\"go build -o myapp ./cmd/main.go\")\n        if not result.success then\n            return false, \"Build failed: \" .. result.stderr\n        end\n\n        -- Create a report file\n        fs.write_file(\"build-report.txt\", \"Build completed at \" .. os.date())\n\n        return true, \"Build completed successfully\", {\n            binary_size = fs.size(\"myapp\"),\n            build_time = result.duration\n        }\n    end)\n    :artifacts({\"myapp\", \"build-report.txt\"}) -- These files will be saved as artifacts\n    :timeout(\"5m\")\n    :build()\n\n-- Consumer task that uses artifacts\nlocal test_task = task(\"test_app\")\n    :description(\"Test the built application\")\n    :depends_on({\"build_app\"})\n    :consumes({\"myapp\", \"build-report.txt\"}) -- These artifacts will be available\n    :command(function(params, deps)\n        -- The artifacts are now available in the workdir\n        log.info(\"Testing application: myapp\")\n        log.info(\"Build report: \" .. fs.read_file(\"build-report.txt\"))\n\n        -- Run tests on the binary\n        local result = exec.run(\"./myapp --version\")\n        return result.success, \"Tests completed\", {\n            version_output = result.stdout\n        }\n    end)\n    :build()\n\n-- Deploy task that also uses the binary\nlocal deploy_task = task(\"deploy_app\")\n    :description(\"Deploy the built application\")\n    :depends_on({\"test_app\"})\n    :consumes({\"myapp\"})\n    :command(function()\n        log.info(\"Deploying application...\")\n        -- Copy binary to deployment location\n        local result = exec.run(\"cp myapp /usr/local/bin/\")\n        return result.success, \"Deployment completed\"\n    end)\n    :build()\n\n-- Complete workflow\nworkflow.define(\"ci_cd_pipeline\", {\n    description = \"CI/CD pipeline with artifact management\",\n    version = \"1.0.0\",\n\n    tasks = { build_task, test_task, deploy_task },\n\n    config = {\n        create_workdir_before_run = true,\n        cleanup_artifacts_after = \"7d\"\n    }\n})\n</code></pre>"},{"location":"core-concepts/#key-benefits","title":"Key Benefits","text":"<ul> <li>\ud83d\udd04 Automatic Dependency Resolution: Tasks automatically get the artifacts they need</li> <li>\ud83d\udce6 Efficient Storage: Artifacts are stored in a shared space, reducing duplication</li> <li>\ud83e\uddf9 Automatic Cleanup: Artifacts can be automatically cleaned up after a specified period</li> <li>\ud83d\udcca Rich Metadata: Artifacts include metadata like creation time, size, and source task</li> </ul>"},{"location":"core-concepts/#modern-dsl-vs-legacy-format","title":"Modern DSL vs Legacy Format","text":"<p>The Modern DSL provides several advantages over the legacy Modern DSLs format:</p> Feature Legacy Format Modern DSL Syntax Table-based, procedural Fluent API, chainable Type Safety Runtime discovery Compile-time validation Error Handling Basic Enhanced with context Metadata Limited Rich, structured Retry Logic Manual implementation Built-in strategies Dependencies Simple strings Advanced with conditions Lifecycle Hooks Basic pre/post Rich event handling Testing Manual Integrated framework"},{"location":"core-concepts/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcda Learn More: Check out the Modern DSL Introduction</li> <li>\ud83c\udfaf API Reference: See Task Definition API for complete reference</li> <li>\ud83d\udcdd Examples: Browse Examples for real-world Modern DSL workflows</li> <li>\ud83d\udd27 Migration: Use Migration Guide to convert existing workflows</li> </ul> <p>The Modern DSL represents the future of workflow automation in Sloth Runner - more powerful, intuitive, and maintainable!           })</p> <pre><code>      local spoke_config = values.pulumi.spoke.config\n      spoke_config.hub_network_self_link = hub_outputs.network_self_link -- Use hub output in spoke config\n\n      spoke_stack:select():config_map(spoke_config)\n      local spoke_result = spoke_stack:up({ yes = true })\n      if not spoke_result.success then\n        log.error(\"Spoke stack deployment failed: \" .. spoke_result.stdout)\n        return false, \"Spoke stack deployment failed.\"\n      end\n      log.info(\"Spoke stack deployed successfully.\")\n      local spoke_outputs = spoke_stack:outputs()\n      return true, \"Spoke stack deployed.\", { outputs = spoke_outputs }\n    end\n  },\n  {\n      name = \"final_summary\",\n      depends_on = \"deploy_spoke_stack\", -- Depends on the final deployment task\n      command = function(inputs)\n          log.info(\"GCP Hub and Spoke orchestration completed successfully!\")\n          -- You can access outputs from dependencies like this:\n          -- local hub_outputs = inputs.deploy_hub_stack.outputs\n          -- local spoke_outputs = inputs.deploy_spoke_stack.outputs\n          return true, \"Orchestration successful.\"\n      end\n  }\n}\n</code></pre> <p>} } ``` </p>"},{"location":"core-concepts/#parametros-e-outputs","title":"Par\u00e2metros e Outputs","text":"<ul> <li>Par\u00e2metros (<code>params</code>): Podem ser passados para as tarefas via linha de comando ou definidos na pr\u00f3pria tarefa. A fun\u00e7\u00e3o <code>command</code> e as fun\u00e7\u00f5es <code>run_if</code>/<code>abort_if</code> podem acess\u00e1-los.</li> <li>Outputs (<code>deps</code>): As fun\u00e7\u00f5es Lua de <code>command</code> podem retornar uma tabela de outputs. Tarefas que dependem desta tarefa podem acessar esses outputs atrav\u00e9s do argumento <code>deps</code>. </li> </ul>"},{"location":"core-concepts/#exportando-dados-para-a-cli","title":"Exportando Dados para a CLI","text":"<p>Al\u00e9m dos outputs de tarefas, o <code>sloth-runner</code> fornece uma fun\u00e7\u00e3o global <code>export()</code> que permite passar dados de dentro de um script diretamente para a sa\u00edda da linha de comando. </p>"},{"location":"core-concepts/#exporttabela","title":"<code>export(tabela)</code>","text":"<ul> <li><code>tabela</code>: Uma tabela Lua cujos pares de chave-valor ser\u00e3o exportados.  Quando voc\u00ea executa uma tarefa com a flag <code>--return</code>, os dados passados para a fun\u00e7\u00e3o <code>export()</code> ser\u00e3o mesclados com o output da tarefa final e impressos como um \u00fanico objeto JSON. Se houver chaves duplicadas, o valor da fun\u00e7\u00e3o <code>export()</code> ter\u00e1 preced\u00eancia.  Isso \u00e9 \u00fatil para extrair informa\u00e7\u00f5es importantes de qualquer ponto do seu script, n\u00e3o apenas do valor de retorno da \u00faltima tarefa.  Exemplo: <code>lua command = function(params, deps)   -- L\u00f3gica da tarefa...   local some_data = {     info = \"Este \u00e9 um dado importante\",     timestamp = os.time()   }    -- Exporta a tabela   export(some_data)    -- A tarefa pode continuar e retornar seu pr\u00f3prio output   return true, \"Tarefa conclu\u00edda\", { status = \"ok\" } end</code></li> </ul> <p>Executando com <code>--return</code> resultaria em uma sa\u00edda JSON como: <pre><code>{\n  \"info\": \"Este \u00e9 um dado importante\",\n  \"timestamp\": 1678886400,\n  \"status\": \"ok\"\n}\n</code></pre></p>"},{"location":"core-concepts/#modulos-built-in","title":"M\u00f3dulos Built-in","text":"<p>O Sloth-Runner exp\u00f5e v\u00e1rias funcionalidades Go como m\u00f3dulos Lua, permitindo que suas tarefas interajam com o sistema e servi\u00e7os externos. Al\u00e9m dos m\u00f3dulos b\u00e1sicos (<code>exec</code>, <code>fs</code>, <code>net</code>, <code>data</code>, <code>log</code>, <code>import</code>, <code>parallel</code>), o Sloth-Runner agora inclui m\u00f3dulos avan\u00e7ados para Git, Pulumi e Salt.</p> <p>Esses m\u00f3dulos oferecem uma API fluente e intuitiva para automa\u00e7\u00e3o complexa.</p> <ul> <li><code>exec</code> module: Para executar comandos de shell arbitr\u00e1rios.</li> <li><code>fs</code> module: Para opera\u00e7\u00f5es de sistema de arquivos (leitura, escrita, etc.).</li> <li><code>net</code> module: Para fazer requisi\u00e7\u00f5es HTTP e downloads.</li> <li><code>data</code> module: Para parsear e serializar JSON e YAML.</li> <li><code>log</code> module: Para registrar mensagens no console do Sloth-Runner.</li> <li><code>import</code> function: Para importar outros arquivos Lua e reutilizar tarefas.</li> <li><code>parallel</code> function: Para executar tarefas em paralelo.</li> <li><code>git</code> module: Para interagir com reposit\u00f3rios Git.</li> <li><code>pulumi</code> module: Para orquestrar stacks do Pulumi.</li> <li><code>salt</code> module: Para executar comandos SaltStack.</li> </ul> <p>Para detalhes sobre cada m\u00f3dulo, consulte suas respectivas se\u00e7\u00f5es na documenta\u00e7\u00e3o.</p> <p>Voltar ao \u00cdndice</p>"},{"location":"distributed-agents/","title":"\ud83c\udf10 Distributed Agent System","text":"<p>Sloth Runner provides a powerful distributed execution system with master-agent architecture, enabling you to scale task execution across multiple machines with enterprise-grade reliability and security.</p>"},{"location":"distributed-agents/#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":""},{"location":"distributed-agents/#master-agent-model","title":"Master-Agent Model","text":"<p>The distributed system follows a master-agent architecture where: - Master server coordinates task distribution and agent management - Agent nodes execute tasks and report back to master - gRPC communication ensures fast, reliable messaging - Automatic failover provides high availability</p> <pre><code>graph TB\n    M[Master Server] --&gt; A1[Agent 1]\n    M --&gt; A2[Agent 2] \n    M --&gt; A3[Agent 3]\n    A1 --&gt; T1[Task Execution]\n    A2 --&gt; T2[Task Execution]\n    A3 --&gt; T3[Task Execution]</code></pre>"},{"location":"distributed-agents/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"distributed-agents/#1-start-master-server","title":"1. Start Master Server","text":"<pre><code># Basic master server\nsloth-runner master --port 50053\n\n# Daemon mode with TLS\nsloth-runner master --port 50053 --daemon \\\n  --tls-cert-file /path/to/cert.pem \\\n  --tls-key-file /path/to/key.pem \\\n  --tls-ca-file /path/to/ca.pem\n</code></pre>"},{"location":"distributed-agents/#2-register-agents","title":"2. Register Agents","text":"<pre><code># Start agent and register with master\nsloth-runner agent start \\\n  --name \"build-agent-1\" \\\n  --master \"localhost:50053\" \\\n  --port 50051\n\n# With custom bind address\nsloth-runner agent start \\\n  --name \"deploy-agent-1\" \\\n  --master \"master.company.com:50053\" \\\n  --bind-address \"192.168.1.100\" \\\n  --port 50052\n</code></pre>"},{"location":"distributed-agents/#3-execute-tasks-remotely","title":"3. Execute Tasks Remotely","text":"<pre><code># Run command on specific agent\nsloth-runner agent run build-agent-1 \"docker build -t myapp .\"\n\n# List all registered agents\nsloth-runner agent list --master localhost:50053\n\n# Stop remote agent\nsloth-runner agent stop build-agent-1\n</code></pre>"},{"location":"distributed-agents/#security-features","title":"\ud83d\udd12 Security Features","text":""},{"location":"distributed-agents/#tls-encryption","title":"TLS Encryption","text":"<p>All communication is optionally encrypted with mutual TLS authentication:</p> <pre><code># Master with TLS\nsloth-runner master \\\n  --tls-cert-file server.crt \\\n  --tls-key-file server.key \\\n  --tls-ca-file ca.crt\n\n# Agent with TLS  \nsloth-runner agent start \\\n  --tls-cert-file client.crt \\\n  --tls-key-file client.key \\\n  --tls-ca-file ca.crt\n</code></pre>"},{"location":"distributed-agents/#certificate-management","title":"Certificate Management","text":"<ul> <li>Mutual authentication with client certificates</li> <li>CA verification for trusted connections</li> <li>Automatic certificate rotation support</li> </ul>"},{"location":"distributed-agents/#agent-management","title":"\ud83d\udcca Agent Management","text":""},{"location":"distributed-agents/#registration-process","title":"Registration Process","text":"<ol> <li>Agent starts and connects to master</li> <li>Registration request with agent metadata</li> <li>Heartbeat system maintains connection</li> <li>Automatic cleanup of stale agents</li> </ol>"},{"location":"distributed-agents/#health-monitoring","title":"Health Monitoring","text":"<pre><code># Real-time agent status\nsloth-runner agent list\n\n# Output:\n# AGENT NAME      ADDRESS           STATUS  LAST HEARTBEAT\n# build-agent-1   192.168.1.100:50051  Active  2024-01-15T10:30:45Z\n# deploy-agent-2  192.168.1.101:50052  Active  2024-01-15T10:30:42Z\n</code></pre>"},{"location":"distributed-agents/#load-balancing","title":"Load Balancing","text":"<ul> <li>Intelligent routing based on agent capabilities</li> <li>Resource-aware task distribution</li> <li>Failover handling for unavailable agents</li> </ul>"},{"location":"distributed-agents/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"distributed-agents/#cicd-pipeline-distribution","title":"CI/CD Pipeline Distribution","text":"<pre><code>-- Distribute CI/CD tasks across specialized agents\ntask(\"build\")\n  :agent_selector(\"build-agents\")\n  :command(function()\n    return exec.run(\"docker build -t app:latest .\")\n  end)\n\ntask(\"test\")\n  :agent_selector(\"test-agents\") \n  :depends_on({\"build\"})\n  :command(function()\n    return exec.run(\"pytest tests/\")\n  end)\n\ntask(\"deploy\")\n  :agent_selector(\"deploy-agents\")\n  :depends_on({\"test\"})\n  :command(function()\n    return exec.run(\"kubectl apply -f k8s/\")\n  end)\n</code></pre>"},{"location":"distributed-agents/#multi-environment-deployments","title":"Multi-Environment Deployments","text":"<pre><code># Production deployment agents\nsloth-runner agent start --name \"prod-east-1\" --master prod-master:50053\nsloth-runner agent start --name \"prod-west-1\" --master prod-master:50053\n\n# Staging deployment agents  \nsloth-runner agent start --name \"staging-1\" --master staging-master:50053\n\n# Execute deployment on specific environment\nsloth-runner agent run prod-east-1 \"./deploy.sh production\"\n</code></pre>"},{"location":"distributed-agents/#geographically-distributed-tasks","title":"Geographically Distributed Tasks","text":"<pre><code># Regional agents for global operations\nsloth-runner agent start --name \"us-east-agent\" --master global-master:50053\nsloth-runner agent start --name \"eu-west-agent\" --master global-master:50053\nsloth-runner agent start --name \"asia-southeast-agent\" --master global-master:50053\n\n# Run region-specific tasks\nsloth-runner agent run us-east-agent \"backup-us-data.sh\"\nsloth-runner agent run eu-west-agent \"backup-eu-data.sh\"\n</code></pre>"},{"location":"distributed-agents/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"distributed-agents/#agent-capabilities","title":"Agent Capabilities","text":"<p>Agents can be tagged with capabilities for intelligent task routing:</p> <pre><code># GPU-enabled agent for ML workloads\nsloth-runner agent start \\\n  --name \"ml-gpu-1\" \\\n  --capabilities \"gpu,tensorflow,pytorch\"\n\n# High-memory agent for data processing\nsloth-runner agent start \\\n  --name \"data-proc-1\" \\\n  --capabilities \"high-memory,spark,hadoop\"\n</code></pre>"},{"location":"distributed-agents/#custom-workspaces","title":"Custom Workspaces","text":"<p>Agents support workspace isolation for task execution:</p> <pre><code>task(\"isolated_build\")\n  :workspace(\"/tmp/build-workspace\")\n  :command(function()\n    -- Task runs in isolated workspace\n    return exec.run(\"go build ./...\")\n  end)\n</code></pre>"},{"location":"distributed-agents/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"distributed-agents/#common-issues","title":"Common Issues","text":""},{"location":"distributed-agents/#agent-connection-problems","title":"Agent Connection Problems","text":"<pre><code># Check master connectivity\ntelnet master-server 50053\n\n# Verify TLS certificates\nopenssl verify -CAfile ca.crt client.crt\n</code></pre>"},{"location":"distributed-agents/#agent-registration-failures","title":"Agent Registration Failures","text":"<pre><code># Check agent logs\ntail -f agent.log\n\n# Test master registration endpoint\ngrpcurl -plaintext master-server:50053 list\n</code></pre>"},{"location":"distributed-agents/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable debug logging\nsloth-runner master --debug\nsloth-runner agent start --debug\n</code></pre>"},{"location":"distributed-agents/#performance-optimization","title":"\ud83d\udcc8 Performance Optimization","text":""},{"location":"distributed-agents/#connection-pooling","title":"Connection Pooling","text":"<ul> <li>Persistent connections between master and agents</li> <li>Connection multiplexing for efficiency</li> <li>Automatic reconnection on network issues</li> </ul>"},{"location":"distributed-agents/#task-streaming","title":"Task Streaming","text":"<ul> <li>Real-time streaming of task output</li> <li>Chunked data transfer for large outputs  </li> <li>Buffered I/O for performance</li> </ul>"},{"location":"distributed-agents/#resource-management","title":"Resource Management","text":"<ul> <li>Memory limits per task execution</li> <li>CPU throttling support</li> <li>Disk space monitoring</li> </ul>"},{"location":"distributed-agents/#enterprise-features","title":"\ud83c\udfe2 Enterprise Features","text":""},{"location":"distributed-agents/#high-availability","title":"High Availability","text":"<ul> <li>Master clustering for redundancy</li> <li>Agent failover mechanisms</li> <li>State persistence across restarts</li> </ul>"},{"location":"distributed-agents/#monitoring-integration","title":"Monitoring Integration","text":"<pre><code># Prometheus metrics endpoint\ncurl http://master-server:8080/metrics\n\n# Health check endpoint\ncurl http://master-server:8080/health\n</code></pre>"},{"location":"distributed-agents/#audit-logging","title":"Audit Logging","text":"<ul> <li>Complete audit trail of all operations</li> <li>Agent activity logging</li> <li>Security event tracking</li> </ul>"},{"location":"distributed-agents/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"distributed-agents/#security","title":"Security","text":"<ol> <li>Always use TLS in production environments</li> <li>Rotate certificates regularly  </li> <li>Limit agent access with firewall rules</li> <li>Monitor agent activity continuously</li> </ol>"},{"location":"distributed-agents/#performance","title":"Performance","text":"<ol> <li>Use agent tags for task routing optimization</li> <li>Monitor resource usage on agents</li> <li>Implement proper cleanup of workspaces</li> <li>Use connection pooling for high-throughput scenarios</li> </ol>"},{"location":"distributed-agents/#reliability","title":"Reliability","text":"<ol> <li>Implement health checks for agents</li> <li>Use heartbeat monitoring</li> <li>Plan for agent failures in workflows</li> <li>Backup agent configurations</li> </ol> <p>The distributed agent system makes Sloth Runner a truly scalable solution for enterprise automation needs, enabling teams to execute complex workflows across multiple machines with confidence and reliability! \ud83d\ude80</p>"},{"location":"getting-started/","title":"In\u00edcio R\u00e1pido","text":"<p>Bem-vindo ao Sloth-Runner! Este guia o ajudar\u00e1 a come\u00e7ar a usar a ferramenta rapidamente com as novas funcionalidades de gerenciamento de stacks e output estilo Pulumi.</p> <p>\ud83d\udcdd Nota Importante: A partir da vers\u00e3o atual, os arquivos de workflow do Sloth Runner usam a extens\u00e3o <code>.sloth</code> em vez de <code>.lua</code>. A sintaxe Lua permanece a mesma, apenas a extens\u00e3o do arquivo mudou para melhor identifica\u00e7\u00e3o dos arquivos DSL do Sloth Runner.</p>"},{"location":"getting-started/#instalacao","title":"Instala\u00e7\u00e3o","text":"<p>Para instalar o <code>sloth-runner</code> em seu sistema, voc\u00ea pode usar o script <code>install.sh</code> fornecido. Este script detecta automaticamente seu sistema operacional e arquitetura, baixa a vers\u00e3o mais recente do GitHub e coloca o execut\u00e1vel <code>sloth-runner</code> em <code>/usr/local/bin</code>.</p> <pre><code>bash &lt;(curl -sL https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/install.sh)\n</code></pre> <p>Nota: O script <code>install.sh</code> requer privil\u00e9gios de <code>sudo</code> para mover o execut\u00e1vel para <code>/usr/local/bin</code>.</p>"},{"location":"getting-started/#novo-stack-management-recomendado","title":"\ud83d\uddc2\ufe0f Novo: Stack Management (Recomendado)","text":""},{"location":"getting-started/#execucao-com-stack","title":"Execu\u00e7\u00e3o com Stack","text":"<p>A nova funcionalidade principal do Sloth Runner \u00e9 o Stack Management, similar ao Pulumi:</p> <pre><code># Nova sintaxe - nome do stack como argumento posicional\nsloth-runner run {nome-do-stack} --file workflow.sloth\n\n# Exemplos pr\u00e1ticos\nsloth-runner run production-app -f deploy.sloth --output enhanced\nsloth-runner run dev-environment -f test.sloth -o rich\nsloth-runner run staging-api -f pipeline.sloth\n</code></pre>"},{"location":"getting-started/#gerenciamento-de-stacks","title":"Gerenciamento de Stacks","text":"<pre><code># Listar todos os stacks\nsloth-runner stack list\n\n# Ver detalhes e outputs exportados\nsloth-runner stack show production-app\n\n# Remover stack antigo\nsloth-runner stack delete old-environment\n</code></pre>"},{"location":"getting-started/#listagem-de-tasks-e-grupos-novo","title":"\ud83c\udd94 Listagem de Tasks e Grupos (Novo)","text":"<pre><code># Listar tasks e grupos com IDs \u00fanicos\nsloth-runner list -f workflow.sloth\n\n# Visualizar estrutura completa do workflow\nsloth-runner list -f pipeline.sloth\n\n# Exemplo de sa\u00edda organizada:\n# ## Task Group: deploy_group  \n# ID: e8e77f72-5cf4-4e98-adce-fc839846c24a\n# Tasks:\n# NAME     ID           DESCRIPTION             DEPENDS ON\n# build    a1c4fa46...  Build the application   -\n# test     d8dc4623...  Run tests               build\n# deploy   6253cb19...  Deploy to production    build, test\n</code></pre>"},{"location":"getting-started/#scaffolding-de-projetos","title":"\ud83d\ude80 Scaffolding de Projetos","text":""},{"location":"getting-started/#criar-novo-projeto","title":"Criar Novo Projeto","text":"<pre><code># Criar projeto a partir de template\nsloth-runner workflow init meu-app --template cicd\n\n# Listar templates dispon\u00edveis\nsloth-runner workflow list-templates\n\n# Executar o workflow gerado\ncd meu-app\nsloth-runner run dev-env -f meu-app.sloth --output enhanced\n</code></pre>"},{"location":"getting-started/#templates-disponiveis","title":"Templates Dispon\u00edveis","text":"<ul> <li>basic - Workflow b\u00e1sico com uma task</li> <li>cicd - Pipeline CI/CD completo</li> <li>infrastructure - Deploy de infraestrutura</li> <li>microservices - Deploy de microservi\u00e7os</li> <li>data-pipeline - Pipeline de processamento de dados</li> </ul>"},{"location":"getting-started/#estilos-de-output","title":"\ud83c\udfa8 Estilos de Output","text":""},{"location":"getting-started/#output-configuravel","title":"Output Configur\u00e1vel","text":"<pre><code># Output b\u00e1sico (padr\u00e3o)\nsloth-runner run meu-stack -f workflow.sloth\n\n# Output melhorado estilo Pulumi\nsloth-runner run meu-stack -f workflow.sloth --output enhanced\nsloth-runner run meu-stack -f workflow.sloth -o rich\nsloth-runner run meu-stack -f workflow.sloth --output modern\n</code></pre>"},{"location":"getting-started/#demonstracao-visual","title":"Demonstra\u00e7\u00e3o Visual","text":"<p>Com <code>--output enhanced</code>:</p> <pre><code>\ud83e\udda5 Sloth Runner\n\n     Workflow: production-app     \n\nStarted at: 2025-09-29 19:27:15\n\n\u2713 build (2.1s) completed\n\u2713 test (3.2s) completed  \n\u2713 deploy (1.5s) completed\n\n     Workflow Completed Successfully     \n\n\u2713 production-app\nDuration: 6.8s\nTasks executed: 3\n\n     Outputs     \n\n\u251c\u2500 exports:\n  \u2502 app_url: \"https://myapp.example.com\"\n  \u2502 version: \"1.2.3\"\n  \u2502 environment: \"production\"\n</code></pre>"},{"location":"getting-started/#uso-basico-modo-tradicional","title":"\ud83d\udca1 Uso B\u00e1sico (Modo Tradicional)","text":"<p>Para executar um arquivo de tarefa Lua sem stack:</p> <pre><code># Execu\u00e7\u00e3o simples\nsloth-runner run -f examples/basic_pipeline.sloth\n\n# Com output melhorado\nsloth-runner run -f examples/basic_pipeline.sloth --output enhanced\n</code></pre> <p>Para listar as tarefas em um arquivo:</p> <pre><code>sloth-runner list -f examples/basic_pipeline.sloth\n</code></pre>"},{"location":"getting-started/#exemplos-praticos","title":"\ud83d\udcca Exemplos Pr\u00e1ticos","text":""},{"location":"getting-started/#deploy-multi-ambiente","title":"Deploy Multi-Ambiente","text":"<pre><code># Desenvolvimento\nsloth-runner run dev-app -f deploy.sloth\n\n# Staging\nsloth-runner run staging-app -f deploy.sloth\n\n# Produ\u00e7\u00e3o com output rico\nsloth-runner run prod-app -f deploy.sloth --output enhanced\n\n# Verificar status de produ\u00e7\u00e3o\nsloth-runner stack show prod-app\n</code></pre>"},{"location":"getting-started/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># No pipeline CI/CD\nsloth-runner run ${ENVIRONMENT}-${APP_NAME} -f pipeline.sloth\n\n# Exemplo espec\u00edfico\nsloth-runner run prod-frontend -f frontend-deploy.sloth\n</code></pre>"},{"location":"getting-started/#persistencia-de-estado","title":"\ud83d\uddc3\ufe0f Persist\u00eancia de Estado","text":"<p>Os stacks s\u00e3o automaticamente persistidos em:</p> <pre><code>~/.sloth-runner/stacks.db\n</code></pre> <p>Cada stack mant\u00e9m: - Status atual da execu\u00e7\u00e3o - Outputs exportados da pipeline - Hist\u00f3rico completo de execu\u00e7\u00f5es - Metadados e configura\u00e7\u00f5es</p>"},{"location":"getting-started/#agendador-de-tarefas","title":"\u23f0 Agendador de Tarefas","text":"<p>O Sloth-Runner inclui um poderoso agendador de tarefas que permite automatizar a execu\u00e7\u00e3o de seus fluxos de trabalho em segundo plano usando sintaxe cron. Para mais detalhes sobre como configurar e usar o agendador, consulte a documenta\u00e7\u00e3o completa em Agendador de Tarefas.</p>"},{"location":"getting-started/#proximos-passos","title":"\ud83d\udcda Pr\u00f3ximos Passos","text":"<p>Agora que voc\u00ea tem o Sloth-Runner instalado e funcionando com as novas funcionalidades:</p> <ul> <li>Explore o Stack Management para gerenciamento avan\u00e7ado de estado</li> <li>Veja os Conceitos Essenciais para entender como definir suas tarefas</li> <li>Experimente os M\u00f3dulos Built-in para automa\u00e7\u00e3o avan\u00e7ada</li> <li>Consulte Exemplos Avan\u00e7ados para casos de uso complexos</li> </ul>"},{"location":"implementation-summary/","title":"\ud83d\ude80 Resumo das Implementa\u00e7\u00f5es - Sloth Runner Enhanced","text":""},{"location":"implementation-summary/#funcionalidades-implementadas","title":"\ud83d\udcca Funcionalidades Implementadas","text":""},{"location":"implementation-summary/#1-state-management-e-persistence-implementado","title":"1. \ud83d\udd04 State Management e Persistence \u2705 IMPLEMENTADO","text":"<p>Localiza\u00e7\u00e3o: <code>internal/luainterface/state.go</code> + <code>internal/luainterface/state_helpers.go</code></p> <p>Funcionalidades: - \u2705 Opera\u00e7\u00f5es b\u00e1sicas (set, get, delete, exists, clear) - \u2705 TTL (Time To Live) com expira\u00e7\u00e3o autom\u00e1tica - \u2705 Opera\u00e7\u00f5es at\u00f4micas (increment, decrement, append, compare-and-swap) - \u2705 Gerenciamento de listas (push, pop, length) - \u2705 Locks distribu\u00eddos com se\u00e7\u00f5es cr\u00edticas autom\u00e1ticas - \u2705 Busca por padr\u00f5es com wildcards - \u2705 Estat\u00edsticas e monitoramento - \u2705 Persist\u00eancia SQLite com WAL mode - \u2705 Cleanup autom\u00e1tico de dados expirados</p> <p>API Lua Dispon\u00edvel: <pre><code>-- Opera\u00e7\u00f5es b\u00e1sicas\nstate.set(key, value, ttl?)\nstate.get(key, default?)\nstate.delete(key)\nstate.exists(key)\nstate.clear(pattern?)\n\n-- TTL\nstate.set_ttl(key, seconds)\nstate.get_ttl(key)\n\n-- Opera\u00e7\u00f5es at\u00f4micas\nstate.increment(key, delta?)\nstate.decrement(key, delta?)\nstate.append(key, value)\nstate.compare_swap(key, old_value, new_value)\n\n-- Listas\nstate.list_push(key, item)\nstate.list_pop(key)\nstate.list_length(key)\n\n-- Locks\nstate.try_lock(name, ttl)\nstate.lock(name, timeout?)\nstate.unlock(name)\nstate.with_lock(name, function, timeout?)\n\n-- Utilit\u00e1rios\nstate.keys(pattern?)\nstate.stats()\n</code></pre></p>"},{"location":"implementation-summary/#2-sistema-de-metricas-avancado-implementado","title":"2. \ud83d\udcca Sistema de M\u00e9tricas Avan\u00e7ado \u2705 IMPLEMENTADO","text":"<p>Localiza\u00e7\u00e3o: <code>internal/agent/metrics.go</code> + <code>internal/luainterface/metrics.go</code></p> <p>Funcionalidades: - \u2705 Coleta autom\u00e1tica de m\u00e9tricas do sistema (CPU, mem\u00f3ria, disco, rede) - \u2705 M\u00e9tricas de runtime Go (goroutines, heap, GC) - \u2705 M\u00e9tricas customizadas (gauge, counter, histogram, timer) - \u2705 Health checks autom\u00e1ticos - \u2705 Endpoints HTTP para Prometheus - \u2705 Alertas baseados em thresholds - \u2705 JSON API para integra\u00e7\u00f5es</p> <p>API Lua Dispon\u00edvel: <pre><code>-- M\u00e9tricas do sistema\nmetrics.system_cpu()\nmetrics.system_memory()\nmetrics.system_disk(path?)\nmetrics.runtime_info()\n\n-- M\u00e9tricas customizadas\nmetrics.gauge(name, value, tags?)\nmetrics.counter(name, increment?, tags?)\nmetrics.histogram(name, value, tags?)\nmetrics.timer(name, function, tags?)\n\n-- Health e alertas\nmetrics.health_status()\nmetrics.alert(name, {level, message, threshold, value})\n\n-- Utilit\u00e1rios\nmetrics.get_custom(name)\nmetrics.list_custom()\n</code></pre></p> <p>Endpoints HTTP: - <code>/metrics</code> - Formato Prometheus - <code>/metrics/json</code> - JSON completo - <code>/health</code> - Status de sa\u00fade</p>"},{"location":"implementation-summary/#arquivos-criadosmodificados","title":"\ud83d\udccb Arquivos Criados/Modificados","text":""},{"location":"implementation-summary/#novos-arquivos","title":"Novos Arquivos:","text":"<ol> <li><code>internal/luainterface/state.go</code> - M\u00f3dulo principal de estado</li> <li><code>internal/luainterface/state_helpers.go</code> - Helpers e serializa\u00e7\u00e3o</li> <li><code>internal/agent/metrics.go</code> - Coletor de m\u00e9tricas para agentes</li> <li><code>internal/luainterface/metrics.go</code> - M\u00f3dulo Lua de m\u00e9tricas</li> <li><code>examples/state_management_demo.sloth</code> - Demo completo do state</li> <li><code>examples/simple_state_test.sloth</code> - Teste b\u00e1sico do state</li> <li><code>examples/advanced_agent_demo.sloth</code> - Demo avan\u00e7ado com m\u00e9tricas</li> <li><code>docs/state-module.md</code> - Documenta\u00e7\u00e3o do m\u00f3dulo state</li> <li><code>docs/agent-improvements.md</code> - Proposta de melhorias dos agentes</li> <li><code>docs/implementation-summary.md</code> - Este resumo</li> </ol>"},{"location":"implementation-summary/#arquivos-modificados","title":"Arquivos Modificados:","text":"<ol> <li><code>internal/luainterface/luainterface.go</code> - Registro dos novos m\u00f3dulos</li> <li><code>go.mod</code> - Depend\u00eancias SQLite e gopsutil</li> </ol>"},{"location":"implementation-summary/#dependencias-adicionadas","title":"Depend\u00eancias Adicionadas:","text":"<ul> <li><code>github.com/mattn/go-sqlite3</code> - Driver SQLite</li> <li><code>github.com/shirou/gopsutil/v3</code> - M\u00e9tricas do sistema</li> </ul>"},{"location":"implementation-summary/#testes-realizados","title":"\ud83e\uddea Testes Realizados","text":""},{"location":"implementation-summary/#state-module-tests","title":"\u2705 State Module Tests","text":"<ul> <li>\u2705 Opera\u00e7\u00f5es b\u00e1sicas (set/get/delete)</li> <li>\u2705 Opera\u00e7\u00f5es at\u00f4micas (increment/decrement)</li> <li>\u2705 Gerenciamento de listas</li> <li>\u2705 Locks distribu\u00eddos</li> <li>\u2705 TTL e expira\u00e7\u00e3o</li> <li>\u2705 Compare-and-swap</li> <li>\u2705 Pattern matching</li> <li>\u2705 Estat\u00edsticas</li> </ul>"},{"location":"implementation-summary/#metrics-module-tests","title":"\u2705 Metrics Module Tests","text":"<ul> <li>\u2705 Coleta de m\u00e9tricas do sistema</li> <li>\u2705 M\u00e9tricas de runtime</li> <li>\u2705 M\u00e9tricas customizadas</li> <li>\u2705 Timer de performance</li> <li>\u2705 Health checks</li> <li>\u2705 Alertas</li> </ul>"},{"location":"implementation-summary/#integration-tests","title":"\u2705 Integration Tests","text":"<ul> <li>\u2705 Agentes remotos funcionando</li> <li>\u2705 Streaming em tempo real</li> <li>\u2705 Persist\u00eancia entre execu\u00e7\u00f5es</li> <li>\u2705 Performance adequada</li> </ul>"},{"location":"implementation-summary/#casos-de-uso-implementados","title":"\ud83c\udfaf Casos de Uso Implementados","text":""},{"location":"implementation-summary/#1-controle-de-deploy-com-estado","title":"1. Controle de Deploy com Estado","text":"<pre><code>-- Versionamento e hist\u00f3rico de deploys\nlocal last_version = state.get(\"last_deployed_version\", \"v0.0.0\")\nstate.set(\"deploy_status\", \"in_progress\")\nstate.increment(\"total_deploys\", 1)\n\n-- Se\u00e7\u00e3o cr\u00edtica para deploy\nstate.with_lock(\"deployment_lock\", function()\n    -- Deploy seguro\n    state.set(\"last_deployed_version\", \"v1.2.3\")\n    state.list_push(\"deploy_history\", deployment_info)\nend)\n</code></pre>"},{"location":"implementation-summary/#2-cache-inteligente-com-ttl","title":"2. Cache Inteligente com TTL","text":"<pre><code>-- Cache autom\u00e1tico com expira\u00e7\u00e3o\nfunction get_cached_data(key, fetch_fn, ttl)\n    local cached = state.get(key)\n    if cached then return cached end\n\n    local data = fetch_fn()\n    state.set(key, data, ttl or 300)\n    return data\nend\n</code></pre>"},{"location":"implementation-summary/#3-monitoramento-e-alertas","title":"3. Monitoramento e Alertas","text":"<pre><code>-- Monitoramento em tempo real\nlocal cpu = metrics.system_cpu()\nlocal memory = metrics.system_memory()\n\nif cpu &gt; 80 then\n    metrics.alert(\"high_cpu\", {\n        level = \"warning\",\n        message = \"CPU usage is high: \" .. cpu .. \"%\"\n    })\nend\n\n-- M\u00e9tricas customizadas\nmetrics.gauge(\"deployment_time\", duration)\nmetrics.counter(\"api_requests\", 1)\n</code></pre>"},{"location":"implementation-summary/#4-load-balancing-inteligente","title":"4. Load Balancing Inteligente","text":"<pre><code>-- Distribui\u00e7\u00e3o baseada em m\u00e9tricas\nlocal agent_load = metrics.system_cpu()\nstate.set(\"agent_load_\" .. agent_name, agent_load)\n\n-- Escolher agente menos carregado\nlocal agents = state.keys(\"agent_load_*\")\nlocal best_agent = find_least_loaded_agent(agents)\n</code></pre>"},{"location":"implementation-summary/#performance-e-confiabilidade","title":"\ud83d\udcc8 Performance e Confiabilidade","text":""},{"location":"implementation-summary/#state-management","title":"State Management:","text":"<ul> <li>Storage: SQLite com WAL mode para alta concorr\u00eancia</li> <li>Performance: ~1000 ops/sec para opera\u00e7\u00f5es b\u00e1sicas</li> <li>Reliability: Transa\u00e7\u00f5es ACID, cleanup autom\u00e1tico</li> <li>Scalability: Adequado para datasets pequenos-m\u00e9dios</li> </ul>"},{"location":"implementation-summary/#metrics-collection","title":"Metrics Collection:","text":"<ul> <li>Overhead: &lt;1% CPU para coleta cont\u00ednua</li> <li>Storage: In-memory com snapshots peri\u00f3dicos</li> <li>Latency: &lt;10ms para m\u00e9tricas b\u00e1sicas</li> <li>Integration: Compat\u00edvel com Prometheus/Grafana</li> </ul>"},{"location":"implementation-summary/#proximos-passos-recomendados","title":"\ud83d\udd04 Pr\u00f3ximos Passos Recomendados","text":""},{"location":"implementation-summary/#implementacoes-prioritarias","title":"Implementa\u00e7\u00f5es Priorit\u00e1rias:","text":"<ol> <li>Web Dashboard - Interface gr\u00e1fica para monitoramento</li> <li>Plugin System - Framework de extens\u00f5es</li> <li>Advanced Load Balancing - Distribui\u00e7\u00e3o inteligente de tarefas</li> <li>Security Enhancements - mTLS, RBAC, audit logs</li> <li>AI-Powered Optimization - Machine learning para otimiza\u00e7\u00e3o</li> </ol>"},{"location":"implementation-summary/#melhorias-tecnicas","title":"Melhorias T\u00e9cnicas:","text":"<ol> <li>Distributed State - Sincroniza\u00e7\u00e3o entre agentes</li> <li>Advanced Caching - Cache distribu\u00eddo inteligente</li> <li>Circuit Breakers - Padr\u00f5es de resili\u00eancia</li> <li>Service Discovery - Auto-descoberta de servi\u00e7os</li> <li>Workflow Engine - DAG execution avan\u00e7ada</li> </ol>"},{"location":"implementation-summary/#resultado-final","title":"\ud83c\udfc6 Resultado Final","text":"<p>O sloth-runner foi transformado de um sistema b\u00e1sico de execu\u00e7\u00e3o distribu\u00edda em uma plataforma enterprise-grade com:</p>"},{"location":"implementation-summary/#capacidades-empresariais","title":"Capacidades Empresariais:","text":"<ul> <li>\u2705 Persist\u00eancia Robusta - Estado confi\u00e1vel entre execu\u00e7\u00f5es</li> <li>\u2705 Observabilidade Total - M\u00e9tricas, logs, health checks</li> <li>\u2705 Opera\u00e7\u00f5es At\u00f4micas - Concorr\u00eancia segura</li> <li>\u2705 Monitoramento Proativo - Alertas autom\u00e1ticos</li> <li>\u2705 Performance Tracking - Benchmarks e otimiza\u00e7\u00e3o</li> <li>\u2705 Quality Assurance - Testes automatizados</li> </ul>"},{"location":"implementation-summary/#vantagens-competitivas","title":"Vantagens Competitivas:","text":"<ul> <li>Flexibilidade: Scripting Lua + extensibilidade</li> <li>Performance: Arquitetura otimizada para baixa lat\u00eancia</li> <li>Confiabilidade: Persist\u00eancia + monitoring + recovery</li> <li>Escalabilidade: Design distribu\u00eddo nativo</li> <li>Usabilidade: APIs simples mas poderosas</li> </ul>"},{"location":"implementation-summary/#comparacao-com-ferramentas-similares","title":"Compara\u00e7\u00e3o com Ferramentas Similares:","text":"Ferramenta Scripting Estado Persistente M\u00e9tricas Distribu\u00eddo Flexibilidade Sloth Runner \u2705 Lua \u2705 SQLite \u2705 Completo \u2705 Nativo \u2b50\u2b50\u2b50\u2b50\u2b50 Jenkins \u274c Groovy \u26a0\ufe0f Plugins \u26a0\ufe0f Plugins \u26a0\ufe0f Master/Slave \u2b50\u2b50\u2b50 GitLab CI \u274c YAML \u274c \u26a0\ufe0f B\u00e1sico \u26a0\ufe0f Runners \u2b50\u2b50 GitHub Actions \u274c YAML \u274c \u26a0\ufe0f B\u00e1sico \u2601\ufe0f Cloud \u2b50\u2b50 Airflow \u2705 Python \u2705 Database \u2705 Completo \u2705 Celery \u2b50\u2b50\u2b50\u2b50 <p>O sloth-runner enhanced est\u00e1 agora posicionado como uma alternativa moderna e flex\u00edvel para orquestra\u00e7\u00e3o de tarefas empresariais! \ud83d\ude80</p>"},{"location":"latest-features/","title":"\ud83c\udd95 Latest Features &amp; Improvements","text":"<p>Data de Atualiza\u00e7\u00e3o: 30 de Setembro de 2025 Vers\u00e3o: Sloth Runner dev (latest)</p> <p>Esta p\u00e1gina documenta as mais recentes funcionalidades implementadas no Sloth Runner.</p>"},{"location":"latest-features/#stack-management-completo","title":"\ud83d\uddc2\ufe0f Stack Management Completo","text":""},{"location":"latest-features/#database-location","title":"\ud83d\udccd Database Location","text":"<p>O Sloth Runner agora armazena todos os dados em: <pre><code>/etc/sloth-runner/stacks.db\n</code></pre></p> <p>Benef\u00edcios: - \u2705 Persist\u00eancia entre sess\u00f5es - \u2705 Compartilhamento entre usu\u00e1rios - \u2705 Backup centralizado - \u2705 Performance otimizada</p>"},{"location":"latest-features/#comando-run-melhorado","title":"\ud83d\ude80 Comando <code>run</code> Melhorado","text":"<p>Nova sintaxe posicional para stack names:</p> <pre><code># Sintaxe nova (recomendada)\nsloth-runner run {stack-name} --file workflow.sloth --output enhanced\n\n# Exemplos pr\u00e1ticos\nsloth-runner run production-api -f api-deploy.sloth --output json\nsloth-runner run staging-tests -f test-suite.sloth --output modern\nsloth-runner run dev-environment -f dev-setup.sloth --output enhanced\n</code></pre>"},{"location":"latest-features/#multiplas-opcoes-de-output","title":"\ud83c\udfa8 M\u00faltiplas Op\u00e7\u00f5es de Output","text":""},{"location":"latest-features/#1-basic-output-padrao","title":"1. Basic Output (padr\u00e3o)","text":"<pre><code>sloth-runner run my-stack -f workflow.sloth --output basic\n</code></pre>"},{"location":"latest-features/#2-enhanced-output-estilo-pulumi","title":"2. Enhanced Output (estilo Pulumi)","text":"<p><pre><code>sloth-runner run my-stack -f workflow.sloth --output enhanced\n</code></pre> - Progress bars animados - Status colorido - Resumo detalhado - Outputs exportados</p>"},{"location":"latest-features/#3-modern-output-visual-aprimorado","title":"3. Modern Output (visual aprimorado)","text":"<pre><code>sloth-runner run my-stack -f workflow.sloth --output modern\n</code></pre>"},{"location":"latest-features/#4-json-output-para-cicd","title":"4. JSON Output (para CI/CD)","text":"<pre><code>sloth-runner run my-stack -f workflow.sloth --output json\n</code></pre> <p>Exemplo de output JSON: <pre><code>{\n  \"status\": \"success\",\n  \"duration\": \"2.19075ms\",\n  \"tasks\": {\n    \"setup\": {\n      \"status\": \"Success\",\n      \"duration\": \"193.667\u00b5s\",\n      \"error\": \"\"\n    },\n    \"deploy\": {\n      \"status\": \"Success\", \n      \"duration\": \"420.666\u00b5s\",\n      \"error\": \"\"\n    }\n  },\n  \"outputs\": {\n    \"app_version\": \"1.2.3\",\n    \"deployment_url\": \"https://app.example.com\",\n    \"status\": \"deployed\"\n  },\n  \"stack\": {\n    \"name\": \"my-stack\",\n    \"id\": \"42d60749-7092-4398-ae2d-2702e4a16e0a\"\n  },\n  \"workflow\": \"my-stack\",\n  \"execution_time\": 1759238671\n}\n</code></pre></p>"},{"location":"latest-features/#ids-unicos-para-tasks-e-grupos","title":"\ud83c\udd94 IDs \u00danicos para Tasks e Grupos","text":""},{"location":"latest-features/#funcionalidade","title":"\u2728 Funcionalidade","text":"<p>Cada task e grupo agora possui um UUID \u00fanico para rastreamento granular.</p>"},{"location":"latest-features/#comando-list","title":"\ud83d\udccb Comando <code>list</code>","text":"<pre><code>sloth-runner list -f workflow.sloth\n</code></pre> <p>Exemplo de output: <pre><code>Workflow Tasks and Groups\n\n## Task Group: production-pipeline\nID: 7680eaa4-7b4d-4d71-8bdf-b659f719d75c\nDescription: Production deployment pipeline\n\nTasks:\nNAME      ID              DESCRIPTION              DEPENDS ON\n----      --              -----------              ----------\nsetup     a8cad56b...     Setup environment       -\nbuild     628e29e7...     Build application       setup\ntest      3f07511c...     Run tests               build\ndeploy    9b12345a...     Deploy to production    test\n</code></pre></p>"},{"location":"latest-features/#comandos-de-stack","title":"\ud83d\uddc2\ufe0f Comandos de Stack","text":""},{"location":"latest-features/#sloth-runner-stack-list","title":"<code>sloth-runner stack list</code>","text":"<p>Lista todos os stacks com m\u00e9tricas:</p> <pre><code>$ sloth-runner stack list\n\nWorkflow Stacks\nNAME              STATUS      LAST RUN           DURATION     EXECUTIONS   DESCRIPTION\n----              ------      --------           --------     ----------   -----------\nproduction-app    completed   2024-01-15 14:30   2.5s         15           Production deployment\ndev-environment   completed   2024-01-15 10:15   1.2s         8            Development environment\nstaging-tests     failed      2024-01-14 16:45   45ms         3            Staging test suite\n</code></pre>"},{"location":"latest-features/#sloth-runner-stack-show-name","title":"<code>sloth-runner stack show &lt;name&gt;</code>","text":"<p>Detalhes completos de um stack:</p> <pre><code>$ sloth-runner stack show production-app\n\nStack: production-app\n\nID: 6fcf2daf-ac69-40d0-95ad-ce39d5bd24b8\nDescription: Production deployment pipeline\nVersion: 1.0.0\nStatus: completed\nCreated: 2024-01-15 08:00:00\nUpdated: 2024-01-15 14:30:15\nCompleted: 2024-01-15 14:30:15\nWorkflow File: production-deploy.sloth\nExecutions: 15\nLast Duration: 2.5s\n\nOutputs\napp_version: 1.2.3\ndeployment_url: https://app.example.com\ndatabase_version: 5.7.2\nstatus: deployed\n\nRecent Executions\nSTARTED            STATUS      DURATION   TASKS   SUCCESS   FAILED\n-------            ------      --------   -----   -------   ------\n2024-01-15 14:30   completed   2.5s       5       5         0\n2024-01-15 12:15   completed   2.1s       5       5         0\n2024-01-15 10:30   failed      1.8s       5       3         2\n</code></pre>"},{"location":"latest-features/#sloth-runner-stack-delete-name","title":"<code>sloth-runner stack delete &lt;name&gt;</code>","text":"<p>Remove stack com confirma\u00e7\u00e3o:</p> <pre><code># Com confirma\u00e7\u00e3o interativa\n$ sloth-runner stack delete old-environment\n\u26a0 This will permanently delete stack 'old-environment' and all its execution history.\nAre you sure? (y/N): y\n\u2713 Stack 'old-environment' deleted successfully.\n\n# Sem confirma\u00e7\u00e3o (modo for\u00e7a)\n$ sloth-runner stack delete old-environment --force\n\u2713 Stack 'old-environment' deleted successfully.\n</code></pre>"},{"location":"latest-features/#outputs-exportados","title":"\ud83d\udcca Outputs Exportados","text":""},{"location":"latest-features/#como-exportar","title":"\ud83d\udca1 Como Exportar","text":"<p>No seu workflow Lua, use a vari\u00e1vel global <code>outputs</code>:</p> <pre><code>TaskDefinitions = {\n    deploy_pipeline = {\n        description = \"Production deployment\",\n        tasks = {\n            {\n                name = \"deploy\",\n                description = \"Deploy application\",\n                command = function()\n                    print(\"Deploying application...\")\n\n                    -- Exportar outputs que ser\u00e3o persistidos\n                    outputs = outputs or {}\n                    outputs.app_version = \"1.2.3\"\n                    outputs.deployment_url = \"https://app.example.com\"\n                    outputs.deployment_time = os.time()\n                    outputs.status = \"deployed\"\n\n                    return true\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"latest-features/#visualizacao","title":"\ud83d\udcc8 Visualiza\u00e7\u00e3o","text":"<p>Os outputs s\u00e3o: - Persistidos no stack - Versionados por execu\u00e7\u00e3o - Vis\u00edveis no <code>stack show</code> - Export\u00e1veis em JSON</p>"},{"location":"latest-features/#installation-build","title":"\ud83d\udee0\ufe0f Installation &amp; Build","text":""},{"location":"latest-features/#build-manual","title":"\ud83d\udd28 Build Manual","text":"<pre><code># Clone e build\ngit clone https://github.com/chalkan3/sloth-runner.git\ncd sloth-runner\ngo build -o sloth-runner ./cmd/sloth-runner/\n\n# Instalar no sistema\ncp sloth-runner ~/.local/bin/\n</code></pre>"},{"location":"latest-features/#preparacao-do-sistema","title":"\ud83d\udce6 Prepara\u00e7\u00e3o do Sistema","text":"<pre><code># Criar diret\u00f3rio do database\nsudo mkdir -p /etc/sloth-runner\nsudo chmod 777 /etc/sloth-runner\n</code></pre>"},{"location":"latest-features/#casos-de-uso","title":"\ud83d\ude80 Casos de Uso","text":""},{"location":"latest-features/#1-cicd-pipeline","title":"1. CI/CD Pipeline","text":"<pre><code># Pipeline de produ\u00e7\u00e3o\nsloth-runner run cicd-main -f cicd-pipeline.sloth --output json &gt; deployment-report.json\n\n# Verificar status\nsloth-runner stack show cicd-main\n\n# Deployment para m\u00faltiplos ambientes\nsloth-runner run production -f deploy.sloth --output enhanced\nsloth-runner run staging -f deploy.sloth --output enhanced\nsloth-runner run development -f deploy.sloth --output enhanced\n</code></pre>"},{"location":"latest-features/#2-desenvolvimento-local","title":"2. Desenvolvimento Local","text":"<pre><code># Setup de ambiente\nsloth-runner run dev-setup -f local-env.sloth --output modern\n\n# Testes automatizados\nsloth-runner run test-suite -f tests.sloth --output enhanced\n\n# Monitoramento\nsloth-runner stack list\nsloth-runner stack show test-suite\n</code></pre>"},{"location":"latest-features/#3-analise-e-debugging","title":"3. An\u00e1lise e Debugging","text":"<pre><code># Listar estrutura do workflow\nsloth-runner list -f complex-workflow.sloth\n\n# Output detalhado em JSON para an\u00e1lise\nsloth-runner run debug-session -f debug.sloth --output json | jq .\n\n# Hist\u00f3rico de execu\u00e7\u00f5es\nsloth-runner stack show debug-session\n</code></pre>"},{"location":"latest-features/#proximas-funcionalidades","title":"\ud83d\udd27 Pr\u00f3ximas Funcionalidades","text":"<p>As seguintes funcionalidades est\u00e3o sendo desenvolvidas:</p> <ul> <li>\ud83c\udf10 Remote stacks (shared state)</li> <li>\ud83d\udd04 Stack templates para r\u00e1pida cria\u00e7\u00e3o</li> <li>\ud83d\udcca M\u00e9tricas avan\u00e7adas de performance</li> <li>\ud83d\udd12 RBAC para stacks empresariais</li> <li>\ud83e\uddea Stack testing e valida\u00e7\u00e3o</li> <li>\ud83d\udcc8 Dashboard web para stacks</li> </ul>"},{"location":"latest-features/#dicas-e-truques","title":"\ud83d\udca1 Dicas e Truques","text":""},{"location":"latest-features/#automatizacao-cicd","title":"Automatiza\u00e7\u00e3o CI/CD","text":"<pre><code>#!/bin/bash\n# deploy.sh\nset -e\n\nSTACK_NAME=\"production-$(date +%Y%m%d-%H%M%S)\"\nRESULT=$(sloth-runner run $STACK_NAME -f production.sloth --output json)\nSTATUS=$(echo $RESULT | jq -r '.status')\n\nif [ \"$STATUS\" = \"success\" ]; then\n    echo \"\u2705 Deployment successful!\"\n    echo $RESULT | jq '.outputs'\nelse\n    echo \"\u274c Deployment failed!\"\n    echo $RESULT | jq '.error'\n    exit 1\nfi\n</code></pre>"},{"location":"latest-features/#monitoramento","title":"Monitoramento","text":"<pre><code># Script de monitoramento\n#!/bin/bash\nwhile true; do\n    echo \"=== Stack Status ===\"\n    sloth-runner stack list\n    echo \"\"\n    sleep 30\ndone\n</code></pre>"},{"location":"latest-features/#cleanup-de-stacks-antigos","title":"Cleanup de Stacks Antigos","text":"<pre><code># Limpar stacks antigos\nsloth-runner stack list | grep \"failed\\|old\" | awk '{print $1}' | xargs -I {} sloth-runner stack delete {} --force\n</code></pre> <p>\ud83d\udcda Para mais informa\u00e7\u00f5es: Stack Management Guide | Getting Started | Advanced Features</p>"},{"location":"multi-cloud-excellence/","title":"\u2601\ufe0f Multi-Cloud Excellence","text":"<p>Sloth Runner provides comprehensive cloud provider support with advanced automation capabilities across AWS, GCP, Azure, and DigitalOcean. Built-in modules enable infrastructure management, cost optimization, and security compliance.</p>"},{"location":"multi-cloud-excellence/#supported-cloud-providers","title":"\ud83c\udf1f Supported Cloud Providers","text":""},{"location":"multi-cloud-excellence/#amazon-web-services-aws","title":"\u2601\ufe0f Amazon Web Services (AWS)","text":"<p>Complete AWS ecosystem integration with 200+ services: - EC2 - Virtual machines and auto-scaling - S3 - Object storage and lifecycle management - RDS - Managed databases (MySQL, PostgreSQL, Oracle) - Lambda - Serverless functions - EKS - Kubernetes clusters - CloudFormation - Infrastructure as Code - IAM - Identity and access management - VPC - Virtual private clouds and networking</p>"},{"location":"multi-cloud-excellence/#google-cloud-platform-gcp","title":"\ud83c\udf29\ufe0f Google Cloud Platform (GCP)","text":"<p>Native GCP integration with advanced features: - Compute Engine - Virtual machines and instance groups - Cloud Storage - Object storage with global distribution - Cloud SQL - Managed relational databases - GKE - Google Kubernetes Engine - Cloud Functions - Event-driven serverless - Cloud Deployment Manager - Infrastructure automation - Cloud IAM - Identity and access management - VPC - Virtual private cloud networking</p>"},{"location":"multi-cloud-excellence/#microsoft-azure","title":"\ud83d\udd37 Microsoft Azure","text":"<p>Enterprise-grade Azure support: - Virtual Machines - Compute instances and scale sets - Storage Accounts - Blob, file, and disk storage - Azure SQL Database - Managed SQL services - AKS - Azure Kubernetes Service - Azure Functions - Serverless computing - ARM Templates - Infrastructure deployment - Azure AD - Identity services - Virtual Networks - Software-defined networking</p>"},{"location":"multi-cloud-excellence/#digitalocean","title":"\ud83c\udf0a DigitalOcean","text":"<p>Developer-friendly cloud operations: - Droplets - Virtual private servers - Spaces - Object storage compatible with S3 - Managed Databases - PostgreSQL, MySQL, Redis - Kubernetes - Managed container orchestration - App Platform - Platform-as-a-Service - Load Balancers - Traffic distribution - Firewalls - Network security</p>"},{"location":"multi-cloud-excellence/#aws-advanced-module","title":"\ud83d\ude80 AWS Advanced Module","text":""},{"location":"multi-cloud-excellence/#ec2-management","title":"EC2 Management","text":"<pre><code>local aws = require(\"aws\")\n\ntask(\"manage_ec2_fleet\")\n    :command(function(params, deps)\n        -- List instances with filtering\n        local instances = aws.ec2.list_instances({\n            filters = {\n                [\"instance-state-name\"] = \"running\",\n                [\"tag:Environment\"] = \"production\"\n            }\n        })\n\n        -- Auto-scaling based on metrics\n        for _, instance in ipairs(instances) do\n            local metrics = aws.cloudwatch.get_metrics({\n                instance_id = instance.id,\n                metric_name = \"CPUUtilization\",\n                period = \"5m\"\n            })\n\n            if metrics.average &gt; 80 then\n                log.info(\"High CPU detected, scaling up: \" .. instance.id)\n                aws.autoscaling.scale_out({\n                    auto_scaling_group = instance.asg_name,\n                    desired_capacity = instance.desired_capacity + 1\n                })\n            end\n        end\n\n        return true, \"EC2 fleet management completed\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#s3-advanced-operations","title":"S3 Advanced Operations","text":"<pre><code>task(\"s3_lifecycle_management\")\n    :command(function(params, deps)\n        local aws = require(\"aws\")\n\n        -- Intelligent tiering and cleanup\n        local buckets = aws.s3.list_buckets()\n\n        for _, bucket in ipairs(buckets) do\n            -- Analyze storage classes\n            local analysis = aws.s3.analyze_storage_classes(bucket.name)\n\n            -- Apply cost optimization\n            if analysis.savings_potential &gt; 1000 then  -- $1000 monthly savings\n                aws.s3.apply_lifecycle_policy({\n                    bucket = bucket.name,\n                    rules = {\n                        {\n                            name = \"auto_tiering\",\n                            transitions = {\n                                {days = 30, storage_class = \"STANDARD_IA\"},\n                                {days = 90, storage_class = \"GLACIER\"},\n                                {days = 365, storage_class = \"DEEP_ARCHIVE\"}\n                            }\n                        }\n                    }\n                })\n                log.info(\"Applied lifecycle policy to: \" .. bucket.name)\n            end\n        end\n\n        return true, \"S3 optimization completed\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#lambda-deployment","title":"Lambda Deployment","text":"<pre><code>task(\"deploy_lambda_functions\")\n    :command(function(params, deps)\n        local aws = require(\"aws\")\n\n        -- Deploy multiple functions with dependencies\n        local functions = {\n            {\n                name = \"api-handler\",\n                runtime = \"nodejs18.x\",\n                code = \"build/api-handler.zip\",\n                environment = {\n                    NODE_ENV = \"production\",\n                    DB_CONNECTION = aws.ssm.get_parameter(\"/app/db/connection\")\n                }\n            },\n            {\n                name = \"data-processor\", \n                runtime = \"python3.9\",\n                code = \"build/data-processor.zip\",\n                memory = 512,\n                timeout = 300\n            }\n        }\n\n        for _, func in ipairs(functions) do\n            -- Create or update function\n            local result = aws.lambda.deploy_function(func)\n\n            -- Set up triggers\n            if func.name == \"api-handler\" then\n                aws.apigateway.create_integration({\n                    api_id = params.api_gateway_id,\n                    lambda_function = result.function_arn\n                })\n            end\n\n            log.info(\"Deployed function: \" .. func.name .. \" (ARN: \" .. result.function_arn .. \")\")\n        end\n\n        return true, \"Lambda deployment completed\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#gcp-advanced-module","title":"\ud83c\udf29\ufe0f GCP Advanced Module","text":""},{"location":"multi-cloud-excellence/#compute-engine-automation","title":"Compute Engine Automation","text":"<pre><code>task(\"gcp_compute_management\")\n    :command(function(params, deps)\n        local gcp = require(\"gcp\")\n\n        -- Create managed instance group with auto-scaling\n        local instance_template = gcp.compute.create_instance_template({\n            name = \"web-server-template-v2\",\n            machine_type = \"e2-medium\",\n            source_image = \"projects/ubuntu-os-cloud/global/images/family/ubuntu-2004-lts\",\n            startup_script = [[\n                #!/bin/bash\n                apt-get update\n                apt-get install -y nginx\n                systemctl start nginx\n            ]],\n            tags = {\"web-server\", \"http-server\"},\n            metadata = {\n                [\"startup-script-url\"] = \"gs://my-scripts/startup.sh\"\n            }\n        })\n\n        -- Create managed instance group\n        local mig = gcp.compute.create_managed_instance_group({\n            name = \"web-servers\",\n            base_instance_name = \"web-server\",\n            template = instance_template.self_link,\n            target_size = 3,\n            zone = \"us-central1-a\"\n        })\n\n        -- Configure auto-scaling\n        gcp.compute.create_autoscaler({\n            name = \"web-servers-autoscaler\",\n            target = mig.self_link,\n            autoscaling_policy = {\n                min_replicas = 2,\n                max_replicas = 10,\n                cpu_utilization = {\n                    target = 0.7\n                }\n            }\n        })\n\n        return true, \"GCP compute resources created\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#gke-cluster-management","title":"GKE Cluster Management","text":"<pre><code>task(\"manage_gke_cluster\")\n    :command(function(params, deps)\n        local gcp = require(\"gcp\")\n        local k8s = require(\"kubernetes\")\n\n        -- Create GKE cluster with advanced configuration\n        local cluster = gcp.gke.create_cluster({\n            name = \"production-cluster\",\n            location = \"us-central1\",\n            initial_node_count = 3,\n\n            node_config = {\n                machine_type = \"e2-standard-4\",\n                disk_size_gb = 100,\n                oauth_scopes = {\n                    \"https://www.googleapis.com/auth/devstorage.read_only\",\n                    \"https://www.googleapis.com/auth/logging.write\",\n                    \"https://www.googleapis.com/auth/monitoring\"\n                }\n            },\n\n            addons_config = {\n                horizontal_pod_autoscaling = {disabled = false},\n                http_load_balancing = {disabled = false},\n                network_policy_config = {disabled = false}\n            },\n\n            network_policy = {\n                enabled = true,\n                provider = \"CALICO\"\n            }\n        })\n\n        -- Configure kubectl context\n        gcp.gke.get_credentials({\n            cluster_name = cluster.name,\n            location = cluster.location\n        })\n\n        -- Deploy application\n        k8s.apply_manifest(\"k8s/production/\")\n\n        return true, \"GKE cluster configured and application deployed\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#azure-advanced-module","title":"\ud83d\udd37 Azure Advanced Module","text":""},{"location":"multi-cloud-excellence/#virtual-machine-scale-sets","title":"Virtual Machine Scale Sets","text":"<pre><code>task(\"azure_vmss_management\")\n    :command(function(params, deps)\n        local azure = require(\"azure\")\n\n        -- Create VM Scale Set with custom image\n        local vmss = azure.compute.create_vmss({\n            name = \"web-servers-vmss\",\n            resource_group = \"production-rg\",\n            location = \"East US\",\n\n            sku = {\n                name = \"Standard_B2s\",\n                tier = \"Standard\",\n                capacity = 3\n            },\n\n            virtual_machine_profile = {\n                os_profile = {\n                    computer_name_prefix = \"web\",\n                    admin_username = \"azureuser\",\n                    custom_data = base64.encode([[\n                        #!/bin/bash\n                        apt-get update\n                        apt-get install -y docker.io\n                        docker run -d -p 80:80 nginx\n                    ]])\n                },\n\n                storage_profile = {\n                    image_reference = {\n                        publisher = \"Canonical\",\n                        offer = \"UbuntuServer\",\n                        sku = \"18.04-LTS\",\n                        version = \"latest\"\n                    }\n                },\n\n                network_profile = {\n{% raw %}                    network_interface_configurations = {{\n                        name = \"web-nic\",\n                        primary = true,\n                        ip_configurations = {{\n                            name = \"internal\",\n                            subnet = {\n                                id = \"/subscriptions/.../subnets/web-subnet\"\n                            },\n                            load_balancer_backend_address_pools = {{\n                                id = \"/subscriptions/.../backendAddressPools/web-backend\"\n                            }}\n                        }}{% endraw %}\n                    }}\n                }\n            },\n\n            -- Auto-scaling configuration\n            upgrade_policy = {\n                mode = \"Rolling\",\n                rolling_upgrade_policy = {\n                    max_batch_instance_percent = 20,\n                    max_unhealthy_instance_percent = 20,\n                    max_unhealthy_upgraded_instance_percent = 20,\n                    pause_time_between_batches = \"PT0S\"\n                }\n            }\n        })\n\n        -- Configure auto-scaling rules\n        azure.monitor.create_autoscale_settings({\n            name = \"web-servers-autoscale\",\n            target_resource_id = vmss.id,\n{% raw %}            profiles = {{{% endraw %}\n                name = \"default\",\n                capacity = {\n                    minimum = \"2\",\n                    maximum = \"10\", \n                    default = \"3\"\n                },\n                rules = {\n                    {\n                        metric_trigger = {\n                            metric_name = \"Percentage CPU\",\n                            metric_namespace = \"microsoft.compute/virtualmachinescalesets\",\n                            time_grain = \"PT1M\",\n                            statistic = \"Average\",\n                            time_window = \"PT5M\",\n                            time_aggregation = \"Average\",\n                            operator = \"GreaterThan\",\n                            threshold = 75\n                        },\n                        scale_action = {\n                            direction = \"Increase\",\n                            type = \"ChangeCount\",\n                            value = \"1\",\n                            cooldown = \"PT5M\"\n                        }\n                    }\n                }\n            }}\n        })\n\n        return true, \"Azure VMSS created and configured\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#digitalocean-advanced-module","title":"\ud83c\udf0a DigitalOcean Advanced Module","text":""},{"location":"multi-cloud-excellence/#kubernetes-cluster-with-apps","title":"Kubernetes Cluster with Apps","text":"<pre><code>task(\"do_kubernetes_deployment\")\n    :command(function(params, deps)\n        local do_client = require(\"digitalocean\")\n\n        -- Create Kubernetes cluster\n        local cluster = do_client.kubernetes.create_cluster({\n            name = \"production-k8s\",\n            region = \"nyc1\",\n            version = \"1.25.4-do.0\",\n\n{% raw %}            node_pools = {{{% endraw %}\n                size = \"s-2vcpu-2gb\",\n                count = 3,\n                name = \"worker-pool\",\n                tags = {\"production\", \"web\"},\n                auto_scale = true,\n                min_nodes = 2,\n                max_nodes = 8\n            }},\n\n            maintenance_policy = {\n                start_time = \"00:00\",\n                day = \"sunday\"\n            },\n\n            auto_upgrade = true,\n            surge_upgrade = true,\n            ha = true\n        })\n\n        -- Wait for cluster to be ready\n        do_client.kubernetes.wait_for_cluster(cluster.id, \"running\", 600)\n\n        -- Get kubeconfig\n        local kubeconfig = do_client.kubernetes.get_kubeconfig(cluster.id)\n        fs.write_file(\"~/.kube/do-config\", kubeconfig)\n\n        -- Deploy applications\n        local k8s = require(\"kubernetes\")\n        k8s.set_context(\"do-production\")\n\n        -- Create namespace and deploy app\n        k8s.create_namespace(\"production\")\n        k8s.apply_yaml([[\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\n  namespace: production\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n      - name: web\n        image: nginx:latest\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-service\n  namespace: production\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    app: web-app\n        ]])\n\n        -- Create DigitalOcean Load Balancer\n        local lb = do_client.load_balancers.create({\n            name = \"web-lb\",\n            algorithm = \"round_robin\",\n            status = \"active\",\n\n{% raw %}            forwarding_rules = {{{% endraw %}\n                entry_protocol = \"http\",\n                entry_port = 80,\n                target_protocol = \"http\",\n                target_port = 80,\n                certificate_id = \"\",\n                tls_passthrough = false\n            }},\n\n            health_check = {\n                protocol = \"http\",\n                port = 80,\n                path = \"/health\",\n                check_interval_seconds = 10,\n                response_timeout_seconds = 5,\n                unhealthy_threshold = 3,\n                healthy_threshold = 2\n            },\n\n            sticky_sessions = {\n                type = \"cookies\",\n                cookie_name = \"lb\",\n                cookie_ttl_seconds = 300\n            },\n\n            region = \"nyc1\",\n            tag = \"production\",\n            droplet_ids = {},  -- Will be populated by k8s service\n            redirect_http_to_https = false,\n            enable_proxy_protocol = false\n        })\n\n        return true, \"DigitalOcean Kubernetes cluster deployed\"\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#security-compliance","title":"\ud83d\udd12 Security &amp; Compliance","text":""},{"location":"multi-cloud-excellence/#multi-cloud-security-scanning","title":"Multi-Cloud Security Scanning","text":"<pre><code>task(\"multi_cloud_security_scan\")\n    :command(function(params, deps)\n        local security = require(\"security\")\n        local results = {}\n\n        -- AWS Security Assessment\n        local aws_scan = security.scan_aws({\n            regions = {\"us-east-1\", \"us-west-2\"},\n            services = {\"ec2\", \"s3\", \"rds\", \"iam\"},\n            compliance_frameworks = {\"SOC2\", \"PCI-DSS\"}\n        })\n\n        -- GCP Security Assessment  \n        local gcp_scan = security.scan_gcp({\n            projects = {\"prod-project\", \"staging-project\"},\n            services = {\"compute\", \"storage\", \"iam\"},\n            compliance_frameworks = {\"ISO27001\", \"SOC2\"}\n        })\n\n        -- Azure Security Assessment\n        local azure_scan = security.scan_azure({\n            subscriptions = {\"prod-subscription\"},\n            resource_groups = {\"production-rg\"},\n            compliance_frameworks = {\"HIPAA\", \"SOC2\"}\n        })\n\n        -- Consolidate results\n        results.aws = aws_scan\n        results.gcp = gcp_scan\n        results.azure = azure_scan\n\n        -- Generate compliance report\n        local report = security.generate_compliance_report({\n            scans = results,\n            format = \"pdf\",\n            include_recommendations = true\n        })\n\n        -- Send to security team\n        notifications.email.send({\n            to = [\"security@company.com\"],\n            subject = \"Multi-Cloud Security Assessment Report\",\n            attachments = {report.file_path}\n        })\n\n        return true, \"Security scan completed\", results\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#cost-optimization","title":"\ud83d\udcb0 Cost Optimization","text":""},{"location":"multi-cloud-excellence/#cross-cloud-cost-analysis","title":"Cross-Cloud Cost Analysis","text":"<pre><code>task(\"multi_cloud_cost_optimization\")\n    :command(function(params, deps)\n        local cost_optimizer = require(\"cost_optimizer\")\n\n        -- Gather cost data from all providers\n        local costs = {\n            aws = aws.billing.get_costs({period = \"30d\", breakdown = \"service\"}),\n            gcp = gcp.billing.get_costs({period = \"30d\", breakdown = \"service\"}),\n            azure = azure.billing.get_costs({period = \"30d\", breakdown = \"service\"}),\n            digitalocean = digitalocean.billing.get_costs({period = \"30d\"})\n        }\n\n        -- Analyze usage patterns\n        local analysis = cost_optimizer.analyze_multi_cloud({\n            costs = costs,\n            utilization_threshold = 0.3,  -- 30% utilization minimum\n            savings_threshold = 100       -- $100 minimum savings\n        })\n\n        -- Generate optimization recommendations\n        local recommendations = cost_optimizer.generate_recommendations({\n            analysis = analysis,\n            strategies = {\n                \"rightsizing\",\n                \"reserved_instances\",\n                \"spot_instances\", \n                \"storage_tiering\",\n                \"resource_consolidation\"\n            }\n        })\n\n        -- Auto-apply low-risk optimizations\n        for _, rec in ipairs(recommendations) do\n            if rec.risk_level == \"low\" and rec.estimated_savings &gt; 50 then\n                log.info(\"Auto-applying optimization: \" .. rec.description)\n                cost_optimizer.apply_recommendation(rec)\n            end\n        end\n\n        -- Generate cost report\n        local report = cost_optimizer.generate_report({\n            costs = costs,\n            recommendations = recommendations,\n            format = \"html\"\n        })\n\n        return true, \"Cost optimization completed\", {\n            total_monthly_cost = analysis.total_cost,\n            potential_savings = analysis.potential_savings,\n            optimizations_applied = #recommendations\n        }\n    end)\n    :build()\n</code></pre>"},{"location":"multi-cloud-excellence/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"multi-cloud-excellence/#infrastructure-as-code","title":"Infrastructure as Code","text":"<ol> <li>Use version control for all cloud configurations</li> <li>Implement proper tagging strategies across providers</li> <li>Regular backup and disaster recovery testing</li> <li>Automate security scanning and compliance checks</li> <li>Monitor costs and optimize regularly</li> </ol>"},{"location":"multi-cloud-excellence/#security-guidelines","title":"Security Guidelines","text":"<ol> <li>Enable multi-factor authentication on all cloud accounts</li> <li>Use least privilege access principles</li> <li>Regular security assessments and penetration testing</li> <li>Encrypt data at rest and in transit</li> <li>Implement proper logging and monitoring</li> </ol>"},{"location":"multi-cloud-excellence/#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Right-size resources based on actual usage</li> <li>Use auto-scaling for variable workloads</li> <li>Implement caching strategies appropriately</li> <li>Monitor performance metrics continuously</li> <li>Regular architecture reviews and optimizations</li> </ol> <p>Multi-Cloud Excellence with Sloth Runner enables organizations to leverage the best of each cloud provider while maintaining consistent automation, security, and cost optimization across their entire cloud infrastructure! \u2601\ufe0f\u2728</p>"},{"location":"repl/","title":"Interactive REPL","text":"<p>The <code>sloth-runner repl</code> command drops you into an interactive Read-Eval-Print Loop (REPL) session. This is a powerful tool for debugging, exploration, and quick experimentation with the sloth-runner modules.</p>"},{"location":"repl/#starting-the-repl","title":"Starting the REPL","text":"<p>To start a session, simply run: <pre><code>sloth-runner repl\n</code></pre></p> <p>You can also pre-load a workflow file to have its <code>Modern DSLs</code> and any helper functions available in the session. This is incredibly useful for debugging an existing pipeline.</p> <pre><code>sloth-runner repl -f /path/to/your/pipeline.sloth\n</code></pre>"},{"location":"repl/#features","title":"Features","text":""},{"location":"repl/#live-environment","title":"Live Environment","text":"<p>The REPL provides a live Lua environment where you can execute any Lua code. All the built-in sloth-runner modules (<code>aws</code>, <code>docker</code>, <code>fs</code>, <code>log</code>, etc.) are pre-loaded and ready to use.</p> <pre><code>sloth&gt; log.info(\"Hello from the REPL!\")\nsloth&gt; result = fs.read(\"README.md\")\nsloth&gt; print(string.sub(result, 1, 50))\n</code></pre>"},{"location":"repl/#autocompletion","title":"Autocompletion","text":"<p>The REPL has a sophisticated autocompletion system. - Start typing the name of a global variable or module (e.g., <code>aws</code>) and press <code>Tab</code> to see suggestions. - Type a module name followed by a dot (e.g., <code>docker.</code>) and press <code>Tab</code> to see all the functions available in that module.</p>"},{"location":"repl/#history","title":"History","text":"<p>The REPL keeps a history of your commands. Use the up and down arrow keys to navigate through previous commands.</p>"},{"location":"repl/#example-session","title":"Example Session","text":"<p>Here is an example of using the REPL to debug a Docker command.</p> <pre><code>$ sloth-runner repl\nSloth-Runner Interactive REPL\nType 'exit' or 'quit' to leave.\nsloth&gt; result = docker.exec({\"ps\", \"-a\"})\nsloth&gt; print(result.stdout)\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nsloth&gt; -- Now let's try to build an image\nsloth&gt; build_result = docker.build({tag=\"my-test\", path=\"./examples/docker\"})\nsloth&gt; print(build_result.success)\ntrue\nsloth&gt; exit\nBye!\n</code></pre>"},{"location":"scheduler/","title":"Task Scheduler","text":"<p>The <code>sloth-runner</code> now includes a built-in task scheduler, allowing you to automate the execution of your Lua-defined tasks at specified intervals using cron syntax.</p>"},{"location":"scheduler/#features","title":"Features","text":"<ul> <li>Background Process: The scheduler runs as a persistent background process, independent of your terminal session.</li> <li>Cron-based Scheduling: Define task schedules using flexible cron strings.</li> <li>Persistence: Scheduled tasks are loaded from a configuration file, ensuring they resume after restarts.</li> <li>Integration with Existing Tasks: The scheduler leverages the existing <code>sloth-runner run</code> command to execute your tasks.</li> </ul>"},{"location":"scheduler/#configuration-scheduleryaml","title":"Configuration: <code>scheduler.yaml</code>","text":"<p>Scheduled tasks are defined in a YAML file, typically named <code>scheduler.yaml</code>. This file specifies the tasks to run, their schedule, and the sloth file, group, and task name.</p> <pre><code>scheduled_tasks:\n  - name: \"my_daily_backup\"\n    schedule: \"0 0 * * *\" # Every day at midnight\n    task_file: \"examples/my_workflow.sloth\"\n    task_group: \"backup_group\"\n    task_name: \"perform_backup\"\n  - name: \"hourly_report_generation\"\n    schedule: \"0 * * * *\" # Every hour\n    task_file: \"examples/reporting.sloth\"\n    task_group: \"reports\"\n    task_name: \"generate_report\"\n</code></pre> <p>Fields:</p> <ul> <li><code>name</code> (string, required): A unique name for the scheduled task.</li> <li><code>schedule</code> (string, required): The cron string defining when the task should run. Supports standard cron syntax and some predefined schedules (e.g., <code>@every 1h</code>, <code>@daily</code>). Refer to robfig/cron documentation for details.</li> <li><code>task_file</code> (string, required): The path to the Lua task definition file.</li> <li><code>task_group</code> (string, required): The name of the task group within the sloth file.</li> <li><code>task_name</code> (string, required): The name of the specific task to execute within the task group.</li> </ul>"},{"location":"scheduler/#cli-commands","title":"CLI Commands","text":""},{"location":"scheduler/#sloth-runner-scheduler-enable","title":"<code>sloth-runner scheduler enable</code>","text":"<p>Starts the <code>sloth-runner</code> scheduler as a background process. This command ensures the scheduler is running and ready to process scheduled tasks.</p> <pre><code>sloth-runner scheduler enable --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>--scheduler-config</code> (or <code>-c</code>): Specifies the path to your <code>scheduler.yaml</code> configuration file. Defaults to <code>scheduler.yaml</code> in the current directory.</li> </ul> <p>Upon execution, the command will print the PID of the background scheduler process. The scheduler will continue to run even if your terminal session is closed.</p>"},{"location":"scheduler/#sloth-runner-scheduler-disable","title":"<code>sloth-runner scheduler disable</code>","text":"<p>Stops the running <code>sloth-runner</code> scheduler background process.</p> <pre><code>sloth-runner scheduler disable\n</code></pre> <p>This command will attempt to gracefully terminate the scheduler process. If successful, it will remove the PID file created by the <code>enable</code> command.</p>"},{"location":"scheduler/#sloth-runner-scheduler-list","title":"<code>sloth-runner scheduler list</code>","text":"<p>Lists all scheduled tasks defined in the <code>scheduler.yaml</code> configuration file. This command provides an overview of your configured tasks, their schedules, and associated Lua task details.</p> <pre><code>sloth-runner scheduler list --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>--scheduler-config</code> (or <code>-c</code>): Specifies the path to your <code>scheduler.yaml</code> configuration file. Defaults to <code>scheduler.yaml</code> in the current directory.</li> </ul> <p>Example Output:</p> <pre><code># Configured Scheduled Tasks\n\nNAME                     | SCHEDULE    | FILE                     | GROUP        | TASK\nmy_daily_backup          | 0 0 * * *   | examples/my_workflow.sloth | backup_group | perform_backup\nhourly_report_generation | 0 * * * *   | examples/reporting.sloth   | reports      | generate_report\n</code></pre>"},{"location":"scheduler/#sloth-runner-scheduler-delete-task_name","title":"<code>sloth-runner scheduler delete &lt;task_name&gt;</code>","text":"<p>Deletes a specific scheduled task from the <code>scheduler.yaml</code> configuration file. This command removes the task definition, and the scheduler will no longer execute it.</p> <pre><code>sloth-runner scheduler delete my_daily_backup --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>&lt;task_name&gt;</code> (string, required): The unique name of the scheduled task to delete.</li> <li><code>--scheduler-config</code> (or <code>-c</code>): Specifies the path to your <code>scheduler.yaml</code> configuration file. Defaults to <code>scheduler.yaml</code> in the current directory.</li> </ul> <p>Important: This command modifies your <code>scheduler.yaml</code> file. Ensure you have a backup if necessary. If the scheduler is currently running, you may need to disable and re-enable it for the changes to take effect immediately.</p>"},{"location":"scheduler/#logging-and-error-handling","title":"Logging and Error Handling","text":"<p>The scheduler logs its activities and the execution status of scheduled tasks to standard output and standard error. It's recommended to redirect these outputs to a log file when running in a production environment.</p> <p>If a scheduled task fails, the scheduler will log the error and continue with other scheduled tasks. It will not stop due to individual task failures.</p>"},{"location":"scheduler/#example","title":"Example","text":"<ol> <li> <p>Create a <code>scheduler.yaml</code> file:</p> <pre><code>scheduled_tasks:\n  - name: \"my_test_task\"\n    schedule: \"@every 1m\"\n    task_file: \"examples/basic_pipeline.sloth\"\n    task_group: \"basic_pipeline\"\n    task_name: \"fetch_data\"\n</code></pre> </li> <li> <p>Enable the scheduler:</p> <pre><code>sloth-runner scheduler enable --scheduler-config scheduler.yaml\n</code></pre> </li> <li> <p>Observe the output. Every minute, you should see messages indicating the execution of <code>my_test_task</code>.</p> </li> <li> <p>To stop the scheduler:</p> <pre><code>sloth-runner scheduler disable\n</code></pre> </li> </ol>"},{"location":"stack-management/","title":"\ud83d\uddc2\ufe0f Stack Management","text":"<p>O Sloth Runner oferece um sistema completo de gerenciamento de stacks similar ao Pulumi, permitindo persistir o estado dos workflows e rastrear execu\u00e7\u00f5es ao longo do tempo.</p>"},{"location":"stack-management/#introducao","title":"\ud83d\ude80 Introdu\u00e7\u00e3o","text":"<p>O Stack Management no Sloth Runner permite:</p> <ul> <li>Persistir estado entre execu\u00e7\u00f5es</li> <li>Rastrear outputs exportados da pipeline</li> <li>Hist\u00f3rico completo de execu\u00e7\u00f5es</li> <li>Gest\u00e3o via CLI intuitiva</li> <li>Isolamento por ambiente/projeto</li> <li>Database persistente em <code>/etc/sloth-runner/stacks.db</code></li> <li>IDs \u00fanicos para tasks e grupos</li> <li>Output JSON para integra\u00e7\u00e3o CI/CD</li> <li>Cria\u00e7\u00e3o autom\u00e1tica de stacks</li> <li>Comando de delete com confirma\u00e7\u00e3o</li> </ul>"},{"location":"stack-management/#sintaxe-basica","title":"\ud83d\udcdd Sintaxe B\u00e1sica","text":""},{"location":"stack-management/#executar-com-stack","title":"Executar com Stack","text":"<pre><code># Nova sintaxe - stack name como argumento posicional\nsloth-runner run {stack-name} --file workflow.sloth\n\n# Exemplos pr\u00e1ticos\nsloth-runner run production-app -f deploy.sloth --output enhanced\nsloth-runner run dev-environment -f test.sloth -o json\nsloth-runner run my-cicd -f pipeline.sloth --output modern\n</code></pre>"},{"location":"stack-management/#gerenciar-stacks","title":"Gerenciar Stacks","text":"<pre><code># Listar todos os stacks\nsloth-runner stack list\n\n# Ver detalhes de um stack\nsloth-runner stack show production-app\n\n# Remover stack (com confirma\u00e7\u00e3o)\nsloth-runner stack delete old-environment\n\n# Remover stack (sem confirma\u00e7\u00e3o)\nsloth-runner stack delete old-environment --force\n</code></pre>"},{"location":"stack-management/#exemplo-de-stack-list","title":"Exemplo de <code>stack list</code>:","text":"<pre><code>Workflow Stacks                      \n\nNAME          STATUS      LAST RUN           DURATION     EXECUTIONS   DESCRIPTION\n----          ------      --------           --------     ----------   -----------\nprod-stack    completed   2025-09-30 10:34   926.292\u00b5s    1            Stack for workflow: prod-stack\ndev-env       running     2025-09-30 09:15   2.5ms        3            Development environment\ntest-ci       failed      2025-09-30 08:30   1.2s         5            CI testing stack\n</code></pre>"},{"location":"stack-management/#exemplo-de-stack-show","title":"Exemplo de <code>stack show</code>:","text":"<pre><code>Stack: prod-stack                    \n\nID: 56f1de4f-5e4e-4106-b8a3-333005c16769\nDescription: Stack for workflow: prod-stack\nVersion: 1.0.0\nStatus: completed\nCreated: 2025-09-30 10:34:41\nUpdated: 2025-09-30 10:34:41\nCompleted: 2025-09-30 10:34:41\nWorkflow File: test_working.sloth\nExecutions: 1\nLast Duration: 926.292\u00b5s\n\nOutputs                              \n\napp_url: https://myapp.example.com\nenvironment: production\nstatus: success\ntimestamp: 30 Sep 25 10:34 -03\nversion: 1.2.3\n\nRecent Executions                    \n\nSTARTED            STATUS      DURATION    TASKS   SUCCESS   FAILED\n-------            ------      --------    -----   -------   ------\n2025-09-30 10:34   completed   926.292\u00b5s   1       1         0\n</code></pre>"},{"location":"stack-management/#stack-delete-com-confirmacao","title":"Stack Delete com Confirma\u00e7\u00e3o:","text":"<pre><code>$ sloth-runner stack delete test-stack\n\u26a0 This will permanently delete stack 'test-stack' and all its execution history.\n? Are you sure? (y/N) y\n\u2713 Stack 'test-stack' deleted successfully.\n</code></pre>"},{"location":"stack-management/#listar-tasks-e-grupos","title":"\ud83c\udd94 Listar Tasks e Grupos","text":"<pre><code># Listar todos os grupos e tasks com IDs \u00fanicos\nsloth-runner list -f workflow.sloth\n\n# Exemplo de sa\u00edda:\n# Workflow Tasks and Groups\n# \n# ## Task Group: production-pipeline\n# ID: 7680eaa4-7b4d-4d71-8bdf-b659f719d75c\n# Description: Production deployment pipeline\n# \n# Tasks:\n# NAME      ID              DESCRIPTION              DEPENDS ON\n# ----      --              -----------              ----------\n# setup     a8cad56b...     Setup environment       -\n# build     628e29e7...     Build application       setup\n# test      3f07511c...     Run tests               build\n# deploy    9b12345a...     Deploy to production    test\n</code></pre>"},{"location":"stack-management/#opcoes-de-output","title":"\ud83c\udfa8 Op\u00e7\u00f5es de Output","text":""},{"location":"stack-management/#output-styles-disponiveis","title":"Output Styles Dispon\u00edveis","text":"<pre><code># Output b\u00e1sico (padr\u00e3o)\nsloth-runner run my-stack -f workflow.sloth --output basic\n\n# Output melhorado (estilo Pulumi)\nsloth-runner run my-stack -f workflow.sloth --output enhanced\n\n# Output moderno com cores\nsloth-runner run my-stack -f workflow.sloth --output modern\n\n# Output em JSON estruturado\nsloth-runner run my-stack -f workflow.sloth --output json\n</code></pre>"},{"location":"stack-management/#exemplo-de-output-json","title":"Exemplo de Output JSON","text":"<p>Sucesso: <pre><code>{\n  \"status\": \"success\",\n  \"duration\": \"926.292\u00b5s\",\n  \"execution_time\": 1759239281,\n  \"outputs\": {\n    \"app_url\": \"https://myapp.example.com\",\n    \"environment\": \"production\",\n    \"status\": \"success\",\n    \"timestamp\": \"30 Sep 25 10:34 -03\",\n    \"version\": \"1.2.3\"\n  },\n  \"stack\": {\n    \"id\": \"56f1de4f-5e4e-4106-b8a3-333005c16769\",\n    \"name\": \"prod-stack\"\n  },\n  \"tasks\": {\n    \"hello\": {\n      \"duration\": \"298.458\u00b5s\",\n      \"error\": \"\",\n      \"status\": \"Success\"\n    }\n  },\n  \"workflow\": \"prod-stack\"\n}\n</code></pre></p> <p>Falha: <pre><code>{\n  \"status\": \"failed\",\n  \"duration\": \"2.5935ms\",\n  \"error\": \"one or more task groups failed\",\n  \"execution_time\": 1759239267,\n  \"outputs\": {\n    \"app_url\": \"https://example.com\",\n    \"test_result\": \"success\",\n    \"timestamp\": \"30 Sep 25 10:34 -03\",\n    \"version\": \"1.2.3\"\n  },\n  \"stack\": {\n    \"id\": \"4a9f7561-424b-4087-b8fd-9cdae33885f1\",\n    \"name\": \"test-simple\"\n  },\n  \"tasks\": {\n    \"hello\": {\n      \"duration\": \"548.916\u00b5s\",\n      \"error\": \"\",\n      \"status\": \"Success\"\n    },\n    \"goodbye\": {\n      \"duration\": \"291.917\u00b5s\",\n      \"error\": \"task failed...\",\n      \"status\": \"Failed\"\n    }\n  },\n  \"workflow\": \"test-simple\"\n}\n</code></pre>       \"error\": \"\"     }   },   \"outputs\": {     \"app_version\": \"1.2.3\",     \"deployment_url\": \"https://app.example.com\",     \"status\": \"deployed\"   },   \"stack\": {     \"name\": \"my-stack\",     \"id\": \"42d60749-7092-4398-ae2d-2702e4a16e0a\"   },   \"workflow\": \"my-stack\",   \"execution_time\": 1759238671 } <pre><code>## \ud83d\udcbe Database Storage\n\n### Local de Armazenamento\n\nO Sloth Runner agora armazena todos os dados de stack em:\n</code></pre> /etc/sloth-runner/stacks.db <pre><code>Esta localiza\u00e7\u00e3o permite:\n- **Persist\u00eancia** entre sess\u00f5es\n- **Compartilhamento** entre usu\u00e1rios\n- **Backup** centralizado\n- **Performance** otimizada\n\n### Estrutura do Database\n\n```sql\n-- Tabela principal de stacks\nCREATE TABLE stacks (\n    id TEXT PRIMARY KEY,\n    name TEXT NOT NULL,\n    description TEXT,\n    version TEXT,\n    status TEXT NOT NULL DEFAULT 'created',\n    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n    completed_at DATETIME,\n    workflow_file TEXT,\n    task_results TEXT,\n    outputs TEXT,\n    configuration TEXT,\n    metadata TEXT,\n    execution_count INTEGER DEFAULT 0,\n    last_duration INTEGER DEFAULT 0,\n    last_error TEXT,\n    resource_version TEXT NOT NULL DEFAULT '1'\n);\n\n-- Tabela de execu\u00e7\u00f5es\nCREATE TABLE stack_executions (\n    id TEXT PRIMARY KEY,\n    stack_id TEXT NOT NULL,\n    started_at DATETIME NOT NULL,\n    completed_at DATETIME,\n    duration INTEGER,\n    status TEXT NOT NULL,\n    task_count INTEGER DEFAULT 0,\n    success_count INTEGER DEFAULT 0,\n    failure_count INTEGER DEFAULT 0,\n    outputs TEXT,\n    error_message TEXT,\n    FOREIGN KEY (stack_id) REFERENCES stacks(id)\n);\n</code></pre></p>"},{"location":"stack-management/#comandos-de-stack","title":"\ud83d\udd0d Comandos de Stack","text":""},{"location":"stack-management/#sloth-runner-stack-list","title":"<code>sloth-runner stack list</code>","text":"<p>Lista todos os stacks dispon\u00edveis:</p> <pre><code>$ sloth-runner stack list\n\nWorkflow Stacks\nNAME              STATUS      LAST RUN           DURATION     EXECUTIONS   DESCRIPTION\n----              ------      --------           --------     ----------   -----------\nproduction-app    completed   2024-01-15 14:30   2.5s         15           Production deployment\ndev-environment   completed   2024-01-15 10:15   1.2s         8            Development environment\nstaging-tests     failed      2024-01-14 16:45   45ms         3            Staging test suite\n</code></pre>"},{"location":"stack-management/#sloth-runner-stack-show-name","title":"<code>sloth-runner stack show &lt;name&gt;</code>","text":"<p>Mostra detalhes completos de um stack:</p> <pre><code>$ sloth-runner stack show production-app\n\nStack: production-app\n\nID: 6fcf2daf-ac69-40d0-95ad-ce39d5bd24b8\nDescription: Production deployment pipeline\nVersion: 1.0.0\nStatus: completed\nCreated: 2024-01-15 08:00:00\nUpdated: 2024-01-15 14:30:15\nCompleted: 2024-01-15 14:30:15\nWorkflow File: production-deploy.sloth\nExecutions: 15\nLast Duration: 2.5s\n\nOutputs\napp_version: 1.2.3\ndeployment_url: https://app.example.com\ndatabase_version: 5.7.2\nstatus: deployed\n\nRecent Executions\nSTARTED            STATUS      DURATION   TASKS   SUCCESS   FAILED\n-------            ------      --------   -----   -------   ------\n2024-01-15 14:30   completed   2.5s       5       5         0\n2024-01-15 12:15   completed   2.1s       5       5         0\n2024-01-15 10:30   failed      1.8s       5       3         2\n</code></pre>"},{"location":"stack-management/#sloth-runner-stack-delete-name","title":"<code>sloth-runner stack delete &lt;name&gt;</code>","text":"<p>Remove um stack:</p> <pre><code># Com confirma\u00e7\u00e3o interativa\n$ sloth-runner stack delete old-environment\n\u26a0 This will permanently delete stack 'old-environment' and all its execution history.\nAre you sure? (y/N): y\n\u2713 Stack 'old-environment' deleted successfully.\n\n# Sem confirma\u00e7\u00e3o (modo for\u00e7a)\n$ sloth-runner stack delete old-environment --force\n\u2713 Stack 'old-environment' deleted successfully.\n</code></pre>"},{"location":"stack-management/#casos-de-uso-avancados","title":"\ud83c\udfaf Casos de Uso Avan\u00e7ados","text":""},{"location":"stack-management/#pipeline-cicd","title":"Pipeline CI/CD","text":"<pre><code>-- cicd-pipeline.sloth\nTaskDefinitions = {\n    cicd_pipeline = {\n        description = \"Complete CI/CD pipeline\",\n        tasks = {\n            {\n                name = \"checkout\",\n                description = \"Checkout source code\",\n                command = \"git clone https://github.com/user/repo.git .\"\n            },\n            {\n                name = \"build\",\n                description = \"Build application\",\n                depends_on = {\"checkout\"},\n                command = function()\n                    print(\"Building application...\")\n                    -- Build logic here\n                    outputs = outputs or {}\n                    outputs.build_version = \"1.2.3\"\n                    outputs.build_hash = \"abc123def\"\n                    return true\n                end\n            },\n            {\n                name = \"test\",\n                description = \"Run tests\",\n                depends_on = {\"build\"},\n                command = \"npm test\"\n            },\n            {\n                name = \"deploy\",\n                description = \"Deploy to production\",\n                depends_on = {\"test\"},\n                command = function()\n                    print(\"Deploying to production...\")\n                    outputs = outputs or {}\n                    outputs.deployment_url = \"https://app.example.com\"\n                    outputs.deployment_time = os.time()\n                    return true\n                end\n            }\n        }\n    }\n}\n</code></pre> <pre><code># Executar pipeline\nsloth-runner run cicd-main -f cicd-pipeline.sloth --output enhanced\n\n# Verificar status\nsloth-runner stack show cicd-main\n\n# Ver outputs em JSON\nsloth-runner run cicd-main -f cicd-pipeline.sloth --output json\n</code></pre>"},{"location":"stack-management/#multiplos-ambientes","title":"M\u00faltiplos Ambientes","text":"<pre><code># Diferentes stacks por ambiente\nsloth-runner run production -f deploy.sloth --output enhanced\nsloth-runner run staging -f deploy.sloth --output enhanced\nsloth-runner run development -f deploy.sloth --output enhanced\n\n# Listar todos os ambientes\nsloth-runner stack list\n</code></pre>"},{"location":"stack-management/#monitoramento-e-analytics","title":"\ud83d\udcca Monitoramento e Analytics","text":""},{"location":"stack-management/#historico-de-execucoes","title":"Hist\u00f3rico de Execu\u00e7\u00f5es","text":"<p>Cada stack mant\u00e9m um hist\u00f3rico completo:</p> <ul> <li>Timestamps de in\u00edcio e fim</li> <li>Dura\u00e7\u00e3o de cada execu\u00e7\u00e3o</li> <li>Status (success/failed)</li> <li>Contadores de tasks (total/success/failed)</li> <li>Outputs exportados</li> <li>Mensagens de erro</li> </ul>"},{"location":"stack-management/#outputs-exportados","title":"Outputs Exportados","text":"<p>Os workflows podem exportar dados que s\u00e3o:</p> <ul> <li>Persistidos no stack</li> <li>Versionados por execu\u00e7\u00e3o</li> <li>Acess\u00edveis via CLI</li> <li>Export\u00e1veis em JSON</li> </ul> <pre><code>-- Exportar outputs no workflow\nTaskDefinitions = {\n    export_example = {\n        description = \"Example with exports\",\n        tasks = {\n            {\n                name = \"process\",\n                command = function()\n                    -- Criar/atualizar outputs globais\n                    outputs = outputs or {}\n                    outputs.processed_items = 42\n                    outputs.timestamp = os.time()\n                    outputs.status = \"success\"\n                    outputs.version = \"1.0.0\"\n                    return true\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"stack-management/#configuracao-avancada","title":"\ud83d\udd27 Configura\u00e7\u00e3o Avan\u00e7ada","text":""},{"location":"stack-management/#configuracao-de-database","title":"Configura\u00e7\u00e3o de Database","text":"<p>Por padr\u00e3o, o database \u00e9 criado em <code>/etc/sloth-runner/stacks.db</code>, mas pode ser personalizado:</p> <pre><code># Usando vari\u00e1vel de ambiente\nexport SLOTH_RUNNER_DB_PATH=\"/custom/path/stacks.db\"\nsloth-runner run my-stack -f workflow.sloth\n</code></pre>"},{"location":"stack-management/#backup-e-restore","title":"Backup e Restore","text":"<pre><code># Backup do database\ncp /etc/sloth-runner/stacks.db /backup/location/\n\n# Restore do database\ncp /backup/location/stacks.db /etc/sloth-runner/\n</code></pre>"},{"location":"stack-management/#proximos-passos","title":"\ud83d\ude80 Pr\u00f3ximos Passos","text":"<ol> <li>Experimente diferentes outputs: <code>basic</code>, <code>enhanced</code>, <code>modern</code>, <code>json</code></li> <li>Crie m\u00faltiplos stacks para diferentes projetos</li> <li>Monitore execu\u00e7\u00f5es com <code>stack list</code> e <code>stack show</code></li> <li>Use IDs \u00fanicos para rastreamento granular</li> <li>Implemente pipelines de CI/CD com persist\u00eancia de estado </li> </ol>"},{"location":"stack-management/#task-group-deploy_group","title":"## Task Group: deploy_group","text":""},{"location":"stack-management/#id-e8e77f72-5cf4-4e98-adce-fc839846c24a","title":"ID: e8e77f72-5cf4-4e98-adce-fc839846c24a","text":""},{"location":"stack-management/#description-deployment-tasks-with-ids","title":"Description: Deployment tasks with IDs","text":""},{"location":"stack-management/#_1","title":"\ud83d\uddc2\ufe0f Stack Management","text":""},{"location":"stack-management/#tasks","title":"Tasks:","text":""},{"location":"stack-management/#name-id-description-depends-on","title":"NAME     ID           DESCRIPTION             DEPENDS ON","text":""},{"location":"stack-management/#-","title":"----     --           -----------             ----------","text":""},{"location":"stack-management/#build-a1c4fa46-build-the-application-","title":"build    a1c4fa46...  Build the application   -","text":""},{"location":"stack-management/#test-d8dc4623-run-tests-build","title":"test     d8dc4623...  Run tests               build","text":""},{"location":"stack-management/#deploy-6253cb19-deploy-to-production-build-test","title":"deploy   6253cb19...  Deploy to production    build, test","text":"<p><pre><code>## \ud83c\udfaf Conceitos Fundamentais\n\n### Stack State\n\nCada stack mant\u00e9m:\n\n- **ID \u00fanico** (UUID)\n- **Nome** do stack\n- **Status** atual (created, running, completed, failed)\n- **Outputs exportados** da pipeline\n- **Hist\u00f3rico** de execu\u00e7\u00f5es\n- **Metadados** e configura\u00e7\u00f5es\n\n### \ud83c\udd94 IDs \u00danicos de Tasks e Grupos\n\n**Novidade:** Cada task e task group agora possui **IDs \u00fanicos (UUID)** para rastreabilidade completa:\n\n#### Task IDs\n- **UUID \u00fanico** gerado automaticamente para cada task\n- **Persistente** entre execu\u00e7\u00f5es\n- **Rastre\u00e1vel** durante debugging e logs\n- **Vis\u00edvel** no comando `sloth-runner list`\n\n#### Task Group IDs  \n- **UUID \u00fanico** para cada grupo de tasks\n- **Identifica\u00e7\u00e3o** clara de componentes do workflow\n- **Organiza\u00e7\u00e3o** hier\u00e1rquica com IDs\n- **Debugging** facilitado com identifica\u00e7\u00e3o precisa\n\n#### Benef\u00edcios dos IDs\n- \ud83d\udd0d **Debugging melhorado** com identifica\u00e7\u00e3o precisa\n- \ud83d\udcca **Observabilidade** enhanced para Enterprise\n- \ud83c\udfaf **Execu\u00e7\u00e3o seletiva** por ID (futuro)\n- \ud83d\udcc8 **Rastreabilidade** completa de execu\u00e7\u00f5es\n\n### Ciclo de Vida\n\n1. **Cria\u00e7\u00e3o**: Stack \u00e9 criado automaticamente na primeira execu\u00e7\u00e3o\n2. **Execu\u00e7\u00e3o**: Estado \u00e9 atualizado durante a execu\u00e7\u00e3o\n3. **Persist\u00eancia**: Outputs e resultados s\u00e3o salvos\n4. **Reutiliza\u00e7\u00e3o**: Execu\u00e7\u00f5es subsequentes reutilizam o stack\n\n## \ud83d\udcbe Persist\u00eancia de Estado\n\n### Banco de Dados\n\nO Sloth Runner usa **SQLite** para persistir o estado:\n</code></pre> ~/.sloth-runner/stacks.db <pre><code>### Tabelas\n\n- **stacks**: Informa\u00e7\u00f5es principais dos stacks\n- **stack_executions**: Hist\u00f3rico detalhado de execu\u00e7\u00f5es\n\n## \ud83d\udcca Outputs Exportados\n\n### Captura Autom\u00e1tica\n\nO sistema captura automaticamente:\n\n- **Exports do TaskRunner** (`runner.Exports`)\n- **Vari\u00e1vel global `outputs`** do Lua\n- **Metadados** de execu\u00e7\u00e3o\n\n### Exemplo de Export\n\n```lua\nlocal deploy_task = task(\"deploy\")\n    :command(function(params, deps)\n        -- L\u00f3gica de deploy...\n\n        -- Exportar outputs para o stack\n        runner.Export({\n            app_url = \"https://myapp.example.com\",\n            version = \"1.2.3\",\n            environment = \"production\",\n            deployed_at = os.date()\n        })\n\n        return true, \"Deploy successful\", deploy_info\n    end)\n    :build()\n</code></pre></p>"},{"location":"stack-management/#interface-cli","title":"\ud83d\udda5\ufe0f Interface CLI","text":""},{"location":"stack-management/#lista-de-stacks","title":"Lista de Stacks","text":"<pre><code>$ sloth-runner stack list\n\nWorkflow Stacks     \n\nNAME                  STATUS     LAST RUN           DURATION     EXECUTIONS\n----                  ------     --------           --------     ----------\nproduction-app        completed  2025-09-29 19:27   6.8s         5\ndev-environment       running    2025-09-29 19:25   2.1s         12\nstaging-api           failed     2025-09-29 19:20   4.2s         3\n</code></pre>"},{"location":"stack-management/#detalhes-do-stack","title":"Detalhes do Stack","text":"<pre><code>$ sloth-runner stack show production-app\n\nStack: production-app     \n\nID: abc123-def456-789\nStatus: completed\nCreated: 2025-09-29 15:30:21\nUpdated: 2025-09-29 19:27:15\nExecutions: 5\nLast Duration: 6.8s\n\n     Outputs     \n\napp_url: \"https://myapp.example.com\"\nversion: \"1.2.3\"\nenvironment: \"production\"\ndeployed_at: \"2025-09-29 19:27:15\"\n\n     Recent Executions     \n\nSTARTED            STATUS     DURATION   TASKS   SUCCESS   FAILED\n-------            ------     --------   -----   -------   ------\n2025-09-29 19:27   completed  6.8s       3       3         0\n2025-09-29 18:45   completed  7.2s       3       3         0\n2025-09-29 17:30   failed     4.1s       3       2         1\n</code></pre>"},{"location":"stack-management/#output-styles","title":"\ud83c\udfa8 Output Styles","text":""},{"location":"stack-management/#configuravel-por-execucao","title":"Configur\u00e1vel por Execu\u00e7\u00e3o","text":"<pre><code># Output b\u00e1sico (padr\u00e3o)\nsloth-runner run my-stack -f workflow.sloth\n\n# Output melhorado\nsloth-runner run my-stack -f workflow.sloth --output enhanced\nsloth-runner run my-stack -f workflow.sloth -o rich\nsloth-runner run my-stack -f workflow.sloth --output modern\n</code></pre>"},{"location":"stack-management/#estilo-pulumi","title":"Estilo Pulumi","text":"<p>O output <code>enhanced</code> oferece formata\u00e7\u00e3o rica similar ao Pulumi:</p> <pre><code>\ud83e\udda5 Sloth Runner\n\n     Workflow: production-app     \n\nStarted at: 2025-09-29 19:27:15\n\n\u2713 build (2.1s) completed\n\u2713 test (3.2s) completed  \n\u2713 deploy (1.5s) completed\n\n     Workflow Completed Successfully     \n\n\u2713 production-app\nDuration: 6.8s\nTasks executed: 3\n\n     Outputs     \n\n\u251c\u2500 exports:\n  \u2502 app_url: \"https://myapp.example.com\"\n  \u2502 version: \"1.2.3\"\n  \u2502 environment: \"production\"\n</code></pre>"},{"location":"stack-management/#casos-de-uso","title":"\ud83d\udd27 Casos de Uso","text":""},{"location":"stack-management/#ambientes-separados","title":"Ambientes Separados","text":"<pre><code># Desenvolvimento\nsloth-runner run dev-app -f app.sloth\n\n# Staging  \nsloth-runner run staging-app -f app.sloth\n\n# Produ\u00e7\u00e3o\nsloth-runner run prod-app -f app.sloth --output enhanced\n</code></pre>"},{"location":"stack-management/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># No pipeline CI/CD\nsloth-runner run ${ENVIRONMENT}-${APP_NAME} -f pipeline.sloth\n\n# Exemplos:\nsloth-runner run prod-frontend -f frontend-deploy.sloth\nsloth-runner run staging-api -f api-deploy.sloth\n</code></pre>"},{"location":"stack-management/#monitoramento","title":"Monitoramento","text":"<pre><code># Ver status de todos os ambientes\nsloth-runner stack list\n\n# Verificar \u00faltimo deploy de produ\u00e7\u00e3o\nsloth-runner stack show prod-app\n\n# Limpar ambientes de teste\nsloth-runner stack delete temp-test-env\n</code></pre>"},{"location":"stack-management/#melhores-praticas","title":"\ud83d\udee0\ufe0f Melhores Pr\u00e1ticas","text":""},{"location":"stack-management/#nomeacao-de-stacks","title":"Nomea\u00e7\u00e3o de Stacks","text":"<pre><code># Usar padr\u00e3o: {ambiente}-{aplica\u00e7\u00e3o}\nsloth-runner run prod-frontend -f deploy.sloth\nsloth-runner run staging-api -f deploy.sloth\nsloth-runner run dev-database -f setup.sloth\n</code></pre>"},{"location":"stack-management/#export-de-outputs","title":"Export de Outputs","text":"<pre><code>-- Exportar informa\u00e7\u00f5es relevantes\nrunner.Export({\n    -- URLs importantes\n    app_url = deploy_info.url,\n    admin_url = deploy_info.admin_url,\n\n    -- Informa\u00e7\u00f5es de vers\u00e3o\n    version = build_info.version,\n    commit_hash = build_info.commit,\n\n    -- Configura\u00e7\u00f5es de ambiente\n    environment = config.environment,\n    region = config.region,\n\n    -- Timestamps\n    deployed_at = os.date(),\n    build_time = build_info.timestamp\n})\n</code></pre>"},{"location":"stack-management/#gestao-de-ciclo-de-vida","title":"Gest\u00e3o de Ciclo de Vida","text":"<pre><code># Desenvolvimento ativo\nsloth-runner run dev-app -f app.sloth\n\n# Quando pronto para staging\nsloth-runner run staging-app -f app.sloth\n\n# Deploy para produ\u00e7\u00e3o\nsloth-runner run prod-app -f app.sloth --output enhanced\n\n# Limpeza de ambientes antigos\nsloth-runner stack delete old-test-branch\n</code></pre>"},{"location":"stack-management/#migracao","title":"\ud83d\udd04 Migra\u00e7\u00e3o","text":""},{"location":"stack-management/#comandos-antigos-vs-novos","title":"Comandos Antigos vs Novos","text":"<pre><code># Antes\nsloth-runner run -f workflow.sloth --stack my-stack\n\n# Agora\nsloth-runner run my-stack -f workflow.sloth\n</code></pre>"},{"location":"stack-management/#compatibilidade","title":"Compatibilidade","text":"<ul> <li>Workflows existentes continuam funcionando</li> <li>Stack \u00e9 opcional - pode executar sem especificar</li> <li>Outputs s\u00e3o capturados automaticamente quando stack \u00e9 usado</li> </ul>"},{"location":"stack-management/#proximos-passos_1","title":"\ud83d\udcda Pr\u00f3ximos Passos","text":"<ul> <li>Output Styles - Configura\u00e7\u00e3o de estilos de output</li> <li>Workflow Scaffolding - Cria\u00e7\u00e3o de projetos</li> <li>Examples - Exemplos pr\u00e1ticos</li> </ul>"},{"location":"stack-management/#exportando-outputs","title":"\ud83d\udce4 Exportando Outputs","text":""},{"location":"stack-management/#como-definir-outputs-no-workflow","title":"Como Definir Outputs no Workflow","text":"<p>Os outputs s\u00e3o exportados automaticamente quando voc\u00ea define uma vari\u00e1vel global <code>outputs</code> no seu workflow Lua:</p> <pre><code>-- No final do seu workflow.sloth\noutputs = {\n    app_url = \"https://myapp.example.com\",\n    version = \"1.2.3\",\n    environment = \"production\",\n    status = \"success\",\n    timestamp = os.date(),\n    database_url = \"postgresql://...\",\n    api_key = \"sk-...\",\n    deployment_id = \"dep-12345\"\n}\n</code></pre>"},{"location":"stack-management/#acessando-outputs","title":"Acessando Outputs","text":"<pre><code># Via comando show (outputs persistidos no stack)\nsloth-runner stack show my-stack\n\n# Via output JSON (outputs da execu\u00e7\u00e3o atual)\nsloth-runner run my-stack -f workflow.sloth --output json\n</code></pre>"},{"location":"stack-management/#exemplo-completo-de-workflow-com-outputs","title":"Exemplo Completo de Workflow com Outputs","text":"<p><pre><code>-- Task que gera dados\nlocal deploy_task = task(\"deploy\")\n    :description(\"Deploy application\")\n    :command(function(params)\n        -- Simula deploy e retorna dados\n        local app_url = \"https://app-\" .. os.time() .. \".example.com\"\n        return true, \"echo 'Deployed!'\", { \n            url = app_url,\n            version = \"1.0.0\" \n        }\n    end)\n    :build()\n\n-- Define workflow\nworkflow.define(\"deployment\", {\n    description = \"Deploy application\",\n    tasks = { deploy_task }\n})\n\n-- IMPORTANTE: Outputs globais s\u00e3o capturados automaticamente\noutputs = {\n    app_url = \"https://myapp.example.com\",\n    version = \"1.2.3\",\n    environment = \"production\",\n    timestamp = os.date(),\n    status = \"deployed\"\n}\n</code></pre> - CLI Reference - Refer\u00eancia completa de comandos</p>"},{"location":"state-module/","title":"\ud83d\udd04 State Management Module","text":"<p>O m\u00f3dulo State do sloth-runner fornece funcionalidades avan\u00e7adas de gerenciamento de estado persistente com opera\u00e7\u00f5es at\u00f4micas, locks distribu\u00eddos e TTL (Time To Live). Todos os dados s\u00e3o armazenados localmente usando SQLite com WAL mode para m\u00e1xima performance e confiabilidade.</p>"},{"location":"state-module/#recursos-principais","title":"\ud83d\udce6 Recursos Principais","text":"<ul> <li>Persist\u00eancia SQLite: Armazenamento confi\u00e1vel com WAL mode</li> <li>Opera\u00e7\u00f5es At\u00f4micas: Increment, compare-and-swap, append</li> <li>Locks Distribu\u00eddos: Se\u00e7\u00f5es cr\u00edticas com timeout autom\u00e1tico</li> <li>TTL (Time To Live): Expira\u00e7\u00e3o autom\u00e1tica de chaves</li> <li>Tipos de Dados: String, number, boolean, table, list</li> <li>Pattern Matching: Busca por chaves com wildcards</li> <li>Cleanup Autom\u00e1tico: Limpeza de dados expirados em background</li> <li>Estat\u00edsticas: M\u00e9tricas de uso e performance</li> </ul>"},{"location":"state-module/#como-usar","title":"\ud83d\ude80 Como Usar","text":""},{"location":"state-module/#operacoes-basicas","title":"Opera\u00e7\u00f5es B\u00e1sicas","text":"<pre><code>-- Definir valores\nstate.set(\"app_version\", \"v1.2.3\")\nstate.set(\"user_count\", 1000)\nstate.set(\"config\", {\n    debug = true,\n    max_connections = 100\n})\n\n-- Recuperar valores\nlocal version = state.get(\"app_version\")\nlocal count = state.get(\"user_count\")\nlocal config = state.get(\"config\")\n\n-- Valor padr\u00e3o se chave n\u00e3o existir\nlocal theme = state.get(\"ui_theme\", \"dark\")\n\n-- Verificar exist\u00eancia\nif state.exists(\"app_version\") then\n    log.info(\"Vers\u00e3o da app est\u00e1 configurada\")\nend\n\n-- Deletar chave\nstate.delete(\"old_key\")\n</code></pre>"},{"location":"state-module/#ttl-time-to-live","title":"TTL (Time To Live)","text":"<pre><code>-- Definir com TTL (60 segundos)\nstate.set(\"session_token\", \"abc123\", 60)\n\n-- Definir TTL para chave existente\nstate.set_ttl(\"user_session\", 300) -- 5 minutos\n\n-- Verificar TTL restante\nlocal ttl = state.get_ttl(\"session_token\")\nlog.info(\"Token expira em \" .. ttl .. \" segundos\")\n</code></pre>"},{"location":"state-module/#operacoes-atomicas","title":"Opera\u00e7\u00f5es At\u00f4micas","text":"<pre><code>-- Incremento at\u00f4mico\nlocal counter = state.increment(\"page_views\", 1)\nlocal bulk_counter = state.increment(\"downloads\", 50)\n\n-- Decremento at\u00f4mico  \nlocal remaining = state.decrement(\"inventory\", 5)\n\n-- Append a string\nstate.set(\"log_messages\", \"Iniciando aplica\u00e7\u00e3o\")\nlocal new_length = state.append(\"log_messages\", \" -&gt; Conectando ao banco\")\n\n-- Compare-and-swap at\u00f4mico\nlocal old_version = state.get(\"config_version\")\nlocal success = state.compare_swap(\"config_version\", old_version, old_version + 1)\nif success then\n    log.info(\"Configura\u00e7\u00e3o atualizada com seguran\u00e7a\")\nend\n</code></pre>"},{"location":"state-module/#operacoes-de-lista","title":"Opera\u00e7\u00f5es de Lista","text":"<pre><code>-- Adicionar itens \u00e0 lista\nstate.list_push(\"deployment_queue\", {\n    app = \"frontend\",\n    version = \"v2.1.0\",\n    environment = \"staging\"\n})\n\nstate.list_push(\"deployment_queue\", {\n    app = \"backend\", \n    version = \"v1.8.2\",\n    environment = \"production\"\n})\n\n-- Verificar tamanho da lista\nlocal queue_size = state.list_length(\"deployment_queue\")\nlog.info(\"Itens na fila: \" .. queue_size)\n\n-- Processar lista (pop remove \u00faltimo item)\nwhile state.list_length(\"deployment_queue\") &gt; 0 do\n    local deployment = state.list_pop(\"deployment_queue\")\n    log.info(\"Processando deployment: \" .. deployment.app)\n    -- Processar deployment...\nend\n</code></pre>"},{"location":"state-module/#locks-distribuidos-e-secoes-criticas","title":"Locks Distribu\u00eddos e Se\u00e7\u00f5es Cr\u00edticas","text":"<pre><code>-- Tentar adquirir lock (sem esperar)\nlocal lock_acquired = state.try_lock(\"deployment_lock\", 30) -- 30 segundos TTL\nif lock_acquired then\n    -- Trabalho cr\u00edtico\n    state.unlock(\"deployment_lock\")\nend\n\n-- Lock com espera e timeout\nlocal acquired = state.lock(\"database_migration\", 60) -- espera at\u00e9 60s\nif acquired then\n    -- Executar migra\u00e7\u00e3o\n    state.unlock(\"database_migration\")\nend\n\n-- Se\u00e7\u00e3o cr\u00edtica com gerenciamento autom\u00e1tico de lock\nstate.with_lock(\"critical_section\", function()\n    log.info(\"Executando opera\u00e7\u00e3o cr\u00edtica...\")\n\n    -- Atualizar contador global\n    local counter = state.increment(\"global_counter\", 1)\n\n    -- Atualizar timestamp\n    state.set(\"last_operation\", os.time())\n\n    log.info(\"Opera\u00e7\u00e3o cr\u00edtica conclu\u00edda - contador: \" .. counter)\n\n    -- Lock \u00e9 liberado automaticamente quando fun\u00e7\u00e3o retorna\n    return \"operacao_sucesso\"\nend, 15) -- timeout de 15 segundos\n</code></pre>"},{"location":"state-module/#busca-e-limpeza-por-padroes","title":"Busca e Limpeza por Padr\u00f5es","text":"<pre><code>-- Criar chaves com padr\u00e3o\nstate.set(\"user:1:name\", \"Alice\")\nstate.set(\"user:1:email\", \"alice@example.com\") \nstate.set(\"user:2:name\", \"Bob\")\nstate.set(\"session:abc123\", \"user_1_session\")\nstate.set(\"cache:products:123\", product_data)\n\n-- Buscar chaves por padr\u00e3o\nlocal user_keys = state.keys(\"user:*\")        -- Todas as chaves de usu\u00e1rio\nlocal user1_keys = state.keys(\"user:1:*\")     -- Apenas dados do user 1\nlocal cache_keys = state.keys(\"cache:*\")      -- Todas as chaves de cache\n\n-- Listar todas as chaves\nlocal all_keys = state.keys() -- ou state.keys(\"*\")\n\n-- Limpeza seletiva\nstate.clear(\"cache:*\")        -- Limpa todo o cache\nstate.clear(\"session:*\")      -- Limpa todas as sess\u00f5es\nstate.clear(\"temp_*\")         -- Limpa chaves tempor\u00e1rias\n</code></pre>"},{"location":"state-module/#monitoramento-e-estatisticas","title":"Monitoramento e Estat\u00edsticas","text":"<pre><code>-- Obter estat\u00edsticas do sistema\nlocal stats = state.stats()\nlog.info(\"Estat\u00edsticas do State:\")\nlog.info(\"  Total de chaves: \" .. stats.total_keys)\nlog.info(\"  Chaves expiradas: \" .. stats.expired_keys)  \nlog.info(\"  Locks ativos: \" .. stats.active_locks)\nlog.info(\"  Tamanho do DB: \" .. stats.db_size_bytes .. \" bytes\")\nlog.info(\"  Caminho do DB: \" .. stats.db_path)\n</code></pre>"},{"location":"state-module/#referencia-completa-da-api","title":"\ud83d\udccb Refer\u00eancia Completa da API","text":""},{"location":"state-module/#operacoes-basicas_1","title":"Opera\u00e7\u00f5es B\u00e1sicas","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.set(key, value, ttl?)</code> key: string, value: any, ttl?: number success: boolean Define um valor com TTL opcional <code>state.get(key, default?)</code> key: string, default?: any value: any Recupera um valor ou retorna default <code>state.delete(key)</code> key: string success: boolean Remove uma chave <code>state.exists(key)</code> key: string exists: boolean Verifica se chave existe <code>state.clear(pattern?)</code> pattern?: string success: boolean Remove chaves por padr\u00e3o"},{"location":"state-module/#ttl-operations","title":"TTL Operations","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.set_ttl(key, seconds)</code> key: string, seconds: number success: boolean Define TTL para chave existente <code>state.get_ttl(key)</code> key: string ttl: number Retorna TTL restante (-1 = sem TTL, -2 = n\u00e3o existe)"},{"location":"state-module/#operacoes-atomicas_1","title":"Opera\u00e7\u00f5es At\u00f4micas","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.increment(key, delta?)</code> key: string, delta?: number new_value: number Incrementa valor atomicamente <code>state.decrement(key, delta?)</code> key: string, delta?: number new_value: number Decrementa valor atomicamente <code>state.append(key, value)</code> key: string, value: string new_length: number Anexa string atomicamente <code>state.compare_swap(key, old, new)</code> key: string, old: any, new: any success: boolean Compare-and-swap at\u00f4mico"},{"location":"state-module/#operacoes-de-lista_1","title":"Opera\u00e7\u00f5es de Lista","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.list_push(key, item)</code> key: string, item: any length: number Adiciona item ao final da lista <code>state.list_pop(key)</code> key: string item: any | nil Remove e retorna \u00faltimo item <code>state.list_length(key)</code> key: string length: number Retorna tamanho da lista"},{"location":"state-module/#locks-distribuidos","title":"Locks Distribu\u00eddos","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.try_lock(name, ttl)</code> name: string, ttl: number success: boolean Tenta adquirir lock sem esperar <code>state.lock(name, timeout?)</code> name: string, timeout?: number success: boolean Adquire lock com timeout <code>state.unlock(name)</code> name: string success: boolean Libera lock <code>state.with_lock(name, fn, timeout?)</code> name: string, fn: function, timeout?: number result: any Executa fun\u00e7\u00e3o com lock autom\u00e1tico"},{"location":"state-module/#utilitarios","title":"Utilit\u00e1rios","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.keys(pattern?)</code> pattern?: string keys: table Lista chaves por padr\u00e3o <code>state.stats()</code> - stats: table Estat\u00edsticas do sistema"},{"location":"state-module/#casos-de-uso-praticos","title":"\ud83c\udfd7\ufe0f Casos de Uso Pr\u00e1ticos","text":""},{"location":"state-module/#1-controle-de-versao-de-deploy","title":"1. Controle de Vers\u00e3o de Deploy","text":"<pre><code>Modern DSLs = {\n    deployment_pipeline = {\n        tasks = {\n            prepare_deploy = {\n                command = function()\n                    -- Verificar \u00faltima vers\u00e3o deployada\n                    local last_version = state.get(\"last_deployed_version\", \"v0.0.0\")\n                    local new_version = \"v1.2.3\"\n\n                    -- Verificar se j\u00e1 est\u00e1 deployado\n                    if last_version == new_version then\n                        log.warn(\"Vers\u00e3o \" .. new_version .. \" j\u00e1 deployada\")\n                        return false, \"Version already deployed\"\n                    end\n\n                    -- Registrar in\u00edcio do deploy\n                    state.set(\"deploy_status\", \"in_progress\")\n                    state.set(\"deploy_start_time\", os.time())\n                    state.increment(\"total_deploys\", 1)\n\n                    return true, \"Deploy preparation completed\"\n                end\n            },\n\n            execute_deploy = {\n                depends_on = \"prepare_deploy\",\n                command = function()\n                    -- Se\u00e7\u00e3o cr\u00edtica para deploy\n                    return state.with_lock(\"deployment_lock\", function()\n                        log.info(\"Executando deploy com lock...\")\n\n                        -- Simular deploy\n                        exec.run(\"sleep 5\")\n\n                        -- Atualizar estado\n                        state.set(\"last_deployed_version\", \"v1.2.3\")\n                        state.set(\"deploy_status\", \"completed\")\n                        state.set(\"deploy_end_time\", os.time())\n\n                        -- Registrar hist\u00f3rico\n                        state.list_push(\"deploy_history\", {\n                            version = \"v1.2.3\",\n                            timestamp = os.time(),\n                            duration = state.get(\"deploy_end_time\") - state.get(\"deploy_start_time\")\n                        })\n\n                        return true, \"Deploy completed successfully\"\n                    end, 300) -- 5 minutos timeout\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"state-module/#2-cache-com-ttl-automatico","title":"2. Cache com TTL Autom\u00e1tico","text":"<pre><code>-- Fun\u00e7\u00e3o helper para cache\nfunction get_cached_data(cache_key, fetch_function, ttl)\n    local cached = state.get(cache_key)\n    if cached then\n        log.info(\"Cache hit: \" .. cache_key)\n        return cached\n    end\n\n    log.info(\"Cache miss: \" .. cache_key .. \" - fetching...\")\n    local data = fetch_function()\n    state.set(cache_key, data, ttl or 300) -- 5 minutos default\n    return data\nend\n\n-- Uso em tasks\nModern DSLs = {\n    data_processing = {\n        tasks = {\n            fetch_user_data = {\n                command = function()\n                    local user_data = get_cached_data(\"user:123:profile\", function()\n                        -- Simula\u00e7\u00e3o de busca custosa\n                        return {\n                            name = \"Alice\",\n                            email = \"alice@example.com\",\n                            preferences = {\"dark_mode\", \"notifications\"}\n                        }\n                    end, 600) -- Cache por 10 minutos\n\n                    log.info(\"User data: \" .. data.to_json(user_data))\n                    return true, \"User data retrieved\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"state-module/#3-controle-de-rate-limiting","title":"3. Controle de Rate Limiting","text":"<pre><code>function check_rate_limit(identifier, max_requests, window_seconds)\n    local key = \"rate_limit:\" .. identifier\n    local current_count = state.get(key, 0)\n\n    if current_count &gt;= max_requests then\n        return false, \"Rate limit exceeded\"\n    end\n\n    -- Incrementar contador\n    if current_count == 0 then\n        -- Primeira requisi\u00e7\u00e3o na janela\n        state.set(key, 1, window_seconds)\n    else\n        -- Incrementar contador existente\n        state.increment(key, 1)\n    end\n\n    return true, \"Request allowed\"\nend\n\n-- Uso em tasks\nModern DSLs = {\n    api_tasks = {\n        tasks = {\n            make_api_call = {\n                command = function()\n                    local allowed, msg = check_rate_limit(\"api_calls\", 100, 3600) -- 100 calls/hora\n\n                    if not allowed then\n                        log.error(msg)\n                        return false, msg\n                    end\n\n                    -- Fazer chamada da API\n                    log.info(\"Making API call...\")\n                    return true, \"API call completed\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"state-module/#configuracao-e-personalizacao","title":"\ud83d\udd27 Configura\u00e7\u00e3o e Personaliza\u00e7\u00e3o","text":""},{"location":"state-module/#localizacao-do-banco-de-dados","title":"Localiza\u00e7\u00e3o do Banco de Dados","text":"<p>Por padr\u00e3o, o banco de dados SQLite \u00e9 criado em: - Linux/macOS: <code>~/.sloth-runner/state.db</code> - Windows: <code>%USERPROFILE%\\.sloth-runner\\state.db</code></p>"},{"location":"state-module/#caracteristicas-tecnicas","title":"Caracter\u00edsticas T\u00e9cnicas","text":"<ul> <li>Engine: SQLite 3 com WAL mode</li> <li>Concurrent Access: Suporte a m\u00faltiplas conex\u00f5es simult\u00e2neas</li> <li>Auto-cleanup: Limpeza autom\u00e1tica de dados expirados a cada 5 minutos</li> <li>Lock Timeout: Locks expirados s\u00e3o limpos automaticamente</li> <li>Serializa\u00e7\u00e3o: JSON para objetos complexos, formato nativo para tipos simples</li> </ul>"},{"location":"state-module/#limitacoes","title":"Limita\u00e7\u00f5es","text":"<ul> <li>Escopo Local: Estado \u00e9 persistido apenas na m\u00e1quina local</li> <li>Concorr\u00eancia: Locks s\u00e3o efetivos apenas no processo local</li> <li>Tamanho: Adequado para datasets pequenos a m\u00e9dios (&lt; 1GB)</li> </ul>"},{"location":"state-module/#proximos-passos","title":"\ud83c\udfaf Pr\u00f3ximos Passos","text":"<p>Para evoluir o m\u00f3dulo state, considere implementar:</p> <ol> <li>State Distribu\u00eddo: Sincroniza\u00e7\u00e3o entre m\u00faltiplos agentes</li> <li>Backup/Restore: Funcionalidades de backup autom\u00e1tico</li> <li>Compress\u00e3o: Compress\u00e3o de dados grandes</li> <li>Indices Customizados: \u00cdndices personalizados para queries complexas</li> <li>Webhooks: Notifica\u00e7\u00f5es em mudan\u00e7as de estado</li> <li>M\u00e9tricas Avan\u00e7adas: Histogramas de performance e uso</li> </ol> <p>O m\u00f3dulo State transforma o sloth-runner em uma plataforma ainda mais poderosa para orquestra\u00e7\u00e3o de tarefas complexas com gerenciamento de estado robusto e confi\u00e1vel! \ud83d\ude80</p>"},{"location":"testing/","title":"Testing Workflows","text":"<p>The sloth-runner includes a built-in testing framework that allows you to write unit and integration tests for your task workflows. Writing tests for your automation is crucial for ensuring reliability, preventing regressions, and having confidence when making changes.</p>"},{"location":"testing/#the-test-command","title":"The <code>test</code> Command","text":"<p>You can run a test file using the <code>sloth-runner test</code> command. It requires two main files: the workflow you want to test and the test script itself.</p> <pre><code>sloth-runner test -w &lt;path_to_workflow.sloth&gt; -f &lt;path_to_test_file.sloth&gt;\n</code></pre> <ul> <li><code>-w, --workflow</code>: Specifies the path to the main <code>Modern DSLs</code> file that you want to test.</li> <li><code>-f, --file</code>: Specifies the path to your test file.</li> </ul>"},{"location":"testing/#writing-tests","title":"Writing Tests","text":"<p>Tests are written in Lua and use two new global modules provided by the test runner: <code>test</code> and <code>assert</code>.</p>"},{"location":"testing/#the-test-module","title":"The <code>test</code> Module","text":"<p>The <code>test</code> module is used to structure your tests and to run specific tasks from your workflow.</p> <ul> <li><code>test.describe(suite_name, function)</code>: Groups related tests into a \"suite\". This is for organization.</li> <li><code>test.it(function)</code>: Defines an individual test case. The description of the test should be included in the assertion messages inside this function.</li> <li><code>test.run_task(task_name)</code>: This is the core function of the testing framework. It executes a single task by its name from the loaded workflow file. It returns a <code>result</code> table containing the execution details.</li> </ul> <p>The <code>result</code> table returned by <code>run_task</code> has the following structure:</p> <pre><code>{\n  success = true, -- boolean: true if the task succeeded, false otherwise\n  message = \"Task executed successfully\", -- string: The message returned by the task\n  duration = \"1.23ms\", -- string: The execution duration\n  output = { ... }, -- table: The output table returned by the task\n  error = nil -- string: The error message if the task failed\n}\n</code></pre>"},{"location":"testing/#the-assert-module","title":"The <code>assert</code> Module","text":"<p>The <code>assert</code> module provides functions to check the results of your task executions.</p> <ul> <li><code>assert.is_true(value, message)</code>: Checks if the <code>value</code> is true.</li> <li><code>assert.equals(actual, expected, message)</code>: Checks if the <code>actual</code> value is equal to the <code>expected</code> value.</li> </ul>"},{"location":"testing/#example","title":"Example","text":"<p>Here is a complete example of a test file (<code>examples/basic_pipeline_test.sloth</code>) that tests the <code>examples/basic_pipeline.sloth</code> workflow.</p> <pre><code>-- examples/basic_pipeline_test.sloth\n\ntest.describe(\"Basic Pipeline Tests\", function()\n  test.it(function()\n    local result = test.run_task(\"fetch_data\")\n    assert.is_true(result.success, \"fetch_data should run successfully\")\n  end)\n\n  test.it(function()\n    local result = test.run_task(\"process_data\")\n    assert.is_true(result.success, \"process_data task should succeed\")\n\n    -- Note: This test is simplified. In a real scenario, you might want to\n    -- mock the input from the 'fetch_data' dependency.\n    local expected_output = \"processed_some_data_from_api\"\n    local actual_output = result.output and result.output.final_data\n\n    assert.equals(actual_output, expected_output, \"process_data should produce the correct output\")\n  end)\n\n  test.it(function()\n    assert.equals(\"hello\", \"world\", \"this assertion is designed to fail\")\n  end)\nend)\n</code></pre> <p>When you run this test, you will get a clear report in your terminal indicating which assertions passed and which failed, along with a final summary.</p>"},{"location":"testing/#mocking-modules","title":"Mocking Modules","text":"<p>To test the logic of your pipelines without making real external calls (e.g., to AWS, Docker, or Terraform), the testing framework includes a powerful mocking feature.</p>"},{"location":"testing/#strict-mocking-policy","title":"Strict Mocking Policy","text":"<p>The test runner enforces a strict mocking policy. When running in test mode, any call to a module function (like <code>aws.exec</code> or <code>docker.build</code>) that has not been explicitly mocked will cause the test to fail immediately. This ensures that your tests are fully self-contained, deterministic, and do not have unintended side effects.</p>"},{"location":"testing/#testmockfunction_name-mock_definition","title":"<code>test.mock(function_name, mock_definition)</code>","text":"<p>This function allows you to define a fake return value for any mockable module function.</p> <ul> <li><code>function_name</code> (string): The full name of the function to mock (e.g., <code>\"aws.s3.sync\"</code>, <code>\"docker.build\"</code>).</li> <li><code>mock_definition</code> (table): A table that defines what the mocked function should return. It must contain a <code>returns</code> key, which is a list of the values the function will return.</li> </ul> <p>The <code>returns</code> list is crucial because Lua functions can return multiple values.</p> <p>Example:</p> <pre><code>-- Mock a function that returns a single result table\ntest.mock(\"docker.build\", {\n  returns = {\n    { success = true, stdout = \"Successfully built image\" }\n  }\n})\n\n-- Mock a function that returns two values (e.g., a value and an error)\n-- This simulates a successful call to terraform.output\ntest.mock(\"terraform.output\", {\n  returns = { \"my_file.txt\", nil }\n})\n\n-- This simulates a failed call\ntest.mock(\"terraform.output\", {\n  returns = { nil, \"output not found\" }\n})\n</code></pre>"},{"location":"testing/#complete-mocking-example","title":"Complete Mocking Example","text":"<p>Let's say you have a task that calls <code>aws.exec</code> and has logic that depends on the output.</p> <p>Task in <code>my_workflow.sloth</code>: <pre><code>-- ...\n{\n  name = \"check-account\",\n  command = function()\n    local result = aws.exec({\"sts\", \"get-caller-identity\"})\n    local data = data.parse_json(result.stdout)\n    if data.Account == \"123456789012\" then\n      return true, \"Correct account.\"\n    else\n      return false, \"Wrong account.\"\n    end\n  end\n}\n-- ...\n</code></pre></p> <p>Test in <code>my_test.sloth</code>: <pre><code>test.describe(\"Account Check Logic\", function()\n  test.it(function()\n    -- Mock the return value of aws.exec\n    test.mock(\"aws.exec\", {\n      returns = {\n        {\n          success = true,\n          stdout = '{\"Account\": \"123456789012\"}'\n        }\n      }\n    })\n\n    -- Run the task that uses the mock\n    local result = test.run_task(\"check-account\")\n\n    -- Assert that the task's logic worked correctly with the mocked data\n    assert.is_true(result.success, \"Task should succeed with the correct account ID\")\n    assert.equals(result.message, \"Correct account.\", \"Message should be correct\")\n  end)\nend)\n</code></pre></p>"},{"location":"web-dashboard/","title":"\ud83c\udfa8 Web Dashboard &amp; UI","text":"<p>Sloth Runner provides a comprehensive web-based dashboard for managing workflows, monitoring agents, and visualizing task execution in real-time.</p>"},{"location":"web-dashboard/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"web-dashboard/#starting-the-dashboard","title":"Starting the Dashboard","text":"<pre><code># Basic UI server\nsloth-runner ui --port 8080\n\n# Daemon mode with custom port\nsloth-runner ui --port 3000 --daemon\n\n# With debug logging\nsloth-runner ui --port 8080 --debug\n</code></pre>"},{"location":"web-dashboard/#accessing-the-dashboard","title":"Accessing the Dashboard","text":"<p>Once started, open your browser and navigate to: <pre><code>http://localhost:8080\n</code></pre></p>"},{"location":"web-dashboard/#core-features","title":"\ud83c\udfaf Core Features","text":""},{"location":"web-dashboard/#real-time-monitoring","title":"\ud83d\udcca Real-Time Monitoring","text":"<ul> <li>Live task execution tracking</li> <li>Progress indicators for running workflows</li> <li>Resource utilization metrics</li> <li>Performance graphs and charts</li> </ul>"},{"location":"web-dashboard/#agent-management","title":"\ud83c\udf10 Agent Management","text":"<ul> <li>Visual agent topology display</li> <li>Agent health status monitoring  </li> <li>Real-time heartbeat tracking</li> <li>Agent capability visualization</li> </ul>"},{"location":"web-dashboard/#workflow-dashboard","title":"\ud83d\udcc8 Workflow Dashboard","text":"<ul> <li>Workflow execution history</li> <li>Task dependency graphs</li> <li>Success/failure statistics</li> <li>Duration analytics</li> </ul>"},{"location":"web-dashboard/#log-management","title":"\ud83d\udccb Log Management","text":"<ul> <li>Centralized log aggregation</li> <li>Real-time log streaming</li> <li>Filterable by agent, task, or workflow</li> <li>Searchable log history</li> </ul>"},{"location":"web-dashboard/#dashboard-sections","title":"\ud83c\udfa8 Dashboard Sections","text":""},{"location":"web-dashboard/#1-overview-page","title":"1. Overview Page","text":"<p>Main dashboard with key metrics and status:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Active Workflows  \u2502    Agent Status     \u2502\n\u2502        12           \u2502     \ud83d\udfe2 8 Active     \u2502\n\u2502                     \u2502     \ud83d\udd34 2 Offline    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Tasks Executed    \u2502   Success Rate      \u2502\n\u2502       1,247         \u2502       98.5%         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"web-dashboard/#2-workflow-manager","title":"2. Workflow Manager","text":"<p>Visual workflow builder and manager: - Drag-and-drop task creation - Visual dependency mapping - Workflow templates library - Version control integration</p>"},{"location":"web-dashboard/#3-agent-console","title":"3. Agent Console","text":"<p>Comprehensive agent management interface:</p> <pre><code>Agent Name      Status    Last Seen    Tasks    CPU   Memory\nbuild-agent-1   \ud83d\udfe2 Active  2s ago      3/5      45%   62%\ntest-agent-2    \ud83d\udfe2 Active  1s ago      2/4      32%   48% \ndeploy-agent-3  \ud83d\udd34 Offline 2m ago      0/3      --    --\n</code></pre>"},{"location":"web-dashboard/#4-execution-monitor","title":"4. Execution Monitor","text":"<p>Real-time execution tracking: - Live progress bars for running tasks - Task output streaming - Error highlighting and alerts - Execution timeline visualization</p>"},{"location":"web-dashboard/#5-log-viewer","title":"5. Log Viewer","text":"<p>Advanced log analysis interface: - Multi-level filtering (ERROR, WARN, INFO, DEBUG) - Agent-specific log views - Keyword search across all logs - Export functionality for debugging</p>"},{"location":"web-dashboard/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"web-dashboard/#environment-variables","title":"Environment Variables","text":"<pre><code># UI Configuration\nexport SLOTH_UI_PORT=8080\nexport SLOTH_UI_DEBUG=true\nexport SLOTH_UI_THEME=dark\n\n# Database Connection\nexport SLOTH_DB_PATH=/data/sloth.db\n\n# Security Settings\nexport SLOTH_UI_AUTH_ENABLED=true\nexport SLOTH_UI_SESSION_SECRET=your-secret-key\n</code></pre>"},{"location":"web-dashboard/#configuration-file","title":"Configuration File","text":"<pre><code># ui-config.yaml\nui:\n  port: 8080\n  debug: false\n  theme: \"light\"\n\ndashboard:\n  refresh_interval: 5s\n  max_log_lines: 1000\n  chart_retention: \"24h\"\n\nsecurity:\n  auth_enabled: false\n  session_timeout: \"30m\"\n  csrf_protection: true\n</code></pre>"},{"location":"web-dashboard/#monitoring-features","title":"\ud83d\udcca Monitoring Features","text":""},{"location":"web-dashboard/#real-time-metrics","title":"Real-Time Metrics","text":"<p>The dashboard displays live metrics including:</p>"},{"location":"web-dashboard/#system-metrics","title":"System Metrics","text":"<ul> <li>CPU utilization across all agents</li> <li>Memory usage patterns</li> <li>Network I/O statistics</li> <li>Disk usage monitoring</li> </ul>"},{"location":"web-dashboard/#workflow-metrics","title":"Workflow Metrics","text":"<ul> <li>Tasks per minute execution rate</li> <li>Average task duration</li> <li>Success/failure ratios</li> <li>Queue depth monitoring</li> </ul>"},{"location":"web-dashboard/#agent-metrics","title":"Agent Metrics","text":"<ul> <li>Agent availability percentages</li> <li>Task distribution across agents</li> <li>Agent response times</li> <li>Heartbeat latency</li> </ul>"},{"location":"web-dashboard/#alerting-system","title":"Alerting System","text":"<p>Built-in alerting for critical events:</p> <pre><code>// Alert configuration\n{\n  \"alerts\": [\n    {\n      \"name\": \"Agent Offline\",\n      \"condition\": \"agent.status == 'offline'\",\n      \"duration\": \"30s\",\n      \"action\": \"email\"\n    },\n    {\n      \"name\": \"High Task Failure Rate\", \n      \"condition\": \"task.failure_rate &gt; 0.1\",\n      \"duration\": \"5m\",\n      \"action\": \"slack\"\n    }\n  ]\n}\n</code></pre>"},{"location":"web-dashboard/#themes-customization","title":"\ud83c\udfa8 Themes &amp; Customization","text":""},{"location":"web-dashboard/#built-in-themes","title":"Built-in Themes","text":"<ul> <li>Light theme - Clean, professional appearance</li> <li>Dark theme - Reduced eye strain for long sessions  </li> <li>High contrast - Accessibility focused</li> <li>Custom theme - Company branding support</li> </ul>"},{"location":"web-dashboard/#dashboard-customization","title":"Dashboard Customization","text":"<pre><code>/* Custom CSS styling */\n.dashboard-widget {\n  border-radius: 8px;\n  box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n}\n\n.status-active {\n  color: #28a745;\n}\n\n.status-offline {\n  color: #dc3545;\n}\n</code></pre>"},{"location":"web-dashboard/#security-features","title":"\ud83d\udd12 Security Features","text":""},{"location":"web-dashboard/#authentication","title":"Authentication","text":"<pre><code># Enable authentication\nsloth-runner ui --auth-enabled\n\n# With custom auth provider\nsloth-runner ui --auth-provider ldap --auth-config auth.yaml\n</code></pre>"},{"location":"web-dashboard/#authorization","title":"Authorization","text":"<p>Role-based access control (RBAC): - Admin - Full system access - Operator - Workflow management - Viewer - Read-only access</p>"},{"location":"web-dashboard/#session-management","title":"Session Management","text":"<ul> <li>Secure session cookies</li> <li>Automatic logout after inactivity</li> <li>CSRF protection enabled</li> <li>XSS prevention measures</li> </ul>"},{"location":"web-dashboard/#mobile-responsiveness","title":"\ud83d\udcf1 Mobile Responsiveness","text":"<p>The dashboard is fully responsive and works on: - Desktop computers (optimal experience) - Tablets (touch-friendly interface) - Mobile phones (essential functions)</p>"},{"location":"web-dashboard/#api-integration","title":"\ud83d\udd0c API Integration","text":""},{"location":"web-dashboard/#rest-api-endpoints","title":"REST API Endpoints","text":"<pre><code># Get dashboard data\nGET /api/v1/dashboard/overview\n\n# List workflows\nGET /api/v1/workflows\n\n# Get agent status\nGET /api/v1/agents\n\n# Stream logs\nGET /api/v1/logs/stream?agent=build-agent-1\n</code></pre>"},{"location":"web-dashboard/#websocket-api","title":"WebSocket API","text":"<pre><code>// Real-time updates via WebSocket\nconst ws = new WebSocket('ws://localhost:8080/api/v1/ws');\n\nws.onmessage = function(event) {\n  const update = JSON.parse(event.data);\n  if (update.type === 'agent_status') {\n    updateAgentDisplay(update.data);\n  }\n};\n</code></pre>"},{"location":"web-dashboard/#use-cases","title":"\ud83c\udfaf Use Cases","text":""},{"location":"web-dashboard/#devops-monitoring","title":"DevOps Monitoring","text":"<ul> <li>CI/CD pipeline visualization</li> <li>Deployment status tracking</li> <li>Infrastructure monitoring</li> <li>Performance analytics</li> </ul>"},{"location":"web-dashboard/#team-collaboration","title":"Team Collaboration","text":"<ul> <li>Shared workflow visibility</li> <li>Task assignment tracking</li> <li>Progress reporting</li> <li>Issue identification</li> </ul>"},{"location":"web-dashboard/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Error diagnosis tools</li> <li>Log correlation across agents</li> <li>Performance bottleneck identification</li> <li>System health monitoring</li> </ul>"},{"location":"web-dashboard/#advanced-features","title":"\ud83d\ude80 Advanced Features","text":""},{"location":"web-dashboard/#workflow-builder","title":"Workflow Builder","text":"<p>Visual workflow designer with: - Drag-and-drop task creation - Automatic dependency detection - Template library access - Real-time validation</p>"},{"location":"web-dashboard/#performance-analytics","title":"Performance Analytics","text":"<p>Advanced analytics dashboard: - Historical trends analysis - Capacity planning insights - Optimization recommendations - Custom report generation</p>"},{"location":"web-dashboard/#integration-hub","title":"Integration Hub","text":"<p>External tool integrations: - Slack notifications - Email alerts - Webhook support - Custom plugins</p>"},{"location":"web-dashboard/#troubleshooting_1","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"web-dashboard/#common-issues","title":"Common Issues","text":""},{"location":"web-dashboard/#dashboard-wont-load","title":"Dashboard Won't Load","text":"<pre><code># Check UI server status\nps aux | grep sloth-runner\n\n# Verify port availability\nnetstat -tlnp | grep 8080\n\n# Check logs\ntail -f ui.log\n</code></pre>"},{"location":"web-dashboard/#slow-performance","title":"Slow Performance","text":"<pre><code># Enable debug mode\nsloth-runner ui --debug\n\n# Check database size\nls -lh sloth.db\n\n# Monitor memory usage\ntop -p $(pgrep sloth-runner)\n</code></pre>"},{"location":"web-dashboard/#debug-tools","title":"Debug Tools","text":"<pre><code># Browser developer tools\n# Network tab - Check API response times\n# Console tab - Look for JavaScript errors\n# Performance tab - Analyze rendering bottlenecks\n</code></pre>"},{"location":"web-dashboard/#metrics-collection","title":"\ud83d\udcca Metrics Collection","text":""},{"location":"web-dashboard/#prometheus-integration","title":"Prometheus Integration","text":"<pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'sloth-runner-ui'\n    static_configs:\n      - targets: ['localhost:8080']\n    metrics_path: '/metrics'\n</code></pre>"},{"location":"web-dashboard/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Pre-built Grafana dashboards available for: - System overview metrics - Workflow performance tracking - Agent health monitoring - Error rate analysis</p> <p>The Web Dashboard transforms Sloth Runner into a visual, user-friendly platform that makes complex workflow management accessible to teams of all technical levels! \ud83c\udfa8\u2728</p>"},{"location":"en/","title":"Sloth-Runner Documentation","text":"<p>Welcome to the comprehensive documentation for Sloth-Runner, your flexible tool for task automation and workflow orchestration using Lua scripts.</p> <p>Here you will find detailed guides, API references, and practical examples to help you make the most of Sloth-Runner's power.</p>"},{"location":"en/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Getting Started</li> <li>Core Concepts</li> <li>Distributed Task Execution</li> <li>CLI Commands</li> <li>Interactive REPL</li> <li>Built-in Modules:<ul> <li>AWS Module</li> <li>Azure Module</li> <li>Data Module</li> <li>DigitalOcean Module</li> <li>Docker Module</li> <li>Exec Module</li> <li>FS Module</li> <li>GCP Module</li> <li>Git Module</li> <li>Log Module</li> <li>Net Module</li> <li>Notifications Module</li> <li>Pulumi Module</li> <li>Python Module</li> <li>Salt Module</li> <li>Terraform Module</li> </ul> </li> <li>Advanced Examples</li> </ul> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"en/CLI/","title":"CLI Commands","text":"<p>The <code>sloth-runner</code> command-line interface (CLI) is the primary way to interact with your task pipelines. It provides commands to run, list, validate, and manage your workflows.</p>"},{"location":"en/CLI/#sloth-runner-run","title":"<code>sloth-runner run</code>","text":"<p>Executes tasks defined in a Lua configuration file. This is the most common command you will use.</p> <p>Usage: <pre><code>sloth-runner run [flags]\n</code></pre></p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: (Required) Path to the Lua task configuration file.</li> <li><code>-g, --group string</code>: Run tasks only from a specific task group. If not provided, <code>sloth-runner</code> will run tasks from all groups.</li> <li><code>-t, --tasks string</code>: A comma-separated list of specific tasks to run (e.g., <code>task1,task2</code>). If not provided, all tasks in the specified group (or all groups) will be considered.</li> <li><code>-v, --values string</code>: Path to a YAML file with values to be passed to your Lua scripts. These values are accessible in Lua via the global <code>values</code> table.</li> <li><code>-d, --dry-run</code>: Simulates the execution of tasks. It will print the tasks that would be run and in what order, but will not execute their <code>command</code>.</li> <li><code>--return</code>: Prints the final output of the executed tasks as a JSON object to stdout. This includes both the return value of the last task and any data passed to the global <code>export()</code> function.</li> <li><code>-y, --yes</code>: Bypasses the interactive task selection prompt when no specific tasks are provided with <code>-t</code>.</li> <li><code>--interactive</code>: Enable interactive mode for task execution, prompting for user input before each task.</li> </ul> <p>Examples:</p> <ul> <li>Run all tasks in a specific group:     <pre><code>sloth-runner run -f examples/basic_pipeline.sloth -g my_group\n</code></pre></li> <li>Run a single, specific task:     <pre><code>sloth-runner run -f examples/basic_pipeline.sloth -g my_group -t my_task\n</code></pre></li> <li>Run multiple tasks and get their combined output as JSON:     <pre><code>sloth-runner run -f examples/export_example.sloth -t export-data-task --return\n</code></pre></li> </ul>"},{"location":"en/CLI/#sloth-runner-list","title":"<code>sloth-runner list</code>","text":"<p>Lists all available task groups and tasks defined in a Lua configuration file, along with their descriptions and dependencies.</p> <p>Usage: <pre><code>sloth-runner list [flags]\n</code></pre></p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: (Required) Path to the Lua task configuration file.</li> <li><code>-v, --values string</code>: Path to a YAML values file, in case your task definitions depend on it.</li> </ul>"},{"location":"en/CLI/#sloth-runner-new","title":"<code>sloth-runner new</code>","text":"<p>Generates a new boilerplate Lua task definition file from a template.</p> <p>Usage: <pre><code>sloth-runner new &lt;group-name&gt; [flags]\n</code></pre></p> <p>Arguments:</p> <ul> <li><code>&lt;group-name&gt;</code>: The name of the main task group to be created in the file.</li> </ul> <p>Flags:</p> <ul> <li><code>-t, --template string</code>: The template to use. Default is <code>simple</code>. Run <code>sloth-runner template list</code> to see all available options.</li> <li><code>-o, --output string</code>: The path to the output file. If not provided, the generated content will be printed to stdout.</li> <li><code>--set key=value</code>: Pass key-value pairs to the template for dynamic content generation.</li> </ul> <p>Example: <pre><code>sloth-runner new my-python-pipeline -t python -o my_pipeline.sloth\n</code></pre></p>"},{"location":"en/CLI/#sloth-runner-validate","title":"<code>sloth-runner validate</code>","text":"<p>Validates the syntax and basic structure of a Lua task file without executing any tasks.</p> <p>Usage: <pre><code>sloth-runner validate [flags]\n</code></pre></p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: (Required) Path to the Lua task configuration file to validate.</li> <li><code>-v, --values string</code>: Path to a YAML values file, if needed for validation.</li> </ul>"},{"location":"en/CLI/#sloth-runner-test","title":"<code>sloth-runner test</code>","text":"<p>Executes a Lua-based test file against a workflow file. (This is an advanced feature).</p> <p>Usage: <pre><code>sloth-runner test [flags]\n</code></pre></p> <p>Flags:</p> <ul> <li><code>-w, --workflow string</code>: (Required) Path to the Lua workflow file to be tested.</li> <li><code>-f, --file string</code>: (Required) Path to the Lua test file.</li> </ul>"},{"location":"en/CLI/#sloth-runner-template-list","title":"<code>sloth-runner template list</code>","text":"<p>Lists all available templates that can be used with the <code>sloth-runner new</code> command.</p> <p>Usage: <pre><code>sloth-runner template list\n</code></pre></p>"},{"location":"en/CLI/#sloth-runner-artifacts","title":"<code>sloth-runner artifacts</code>","text":"<p>Manages task artifacts, which are files or directories produced by tasks.</p> <p>Subcommands:</p> <ul> <li><code>sloth-runner artifacts list</code>: Lists all collected artifacts.</li> <li><code>sloth-runner artifacts get &lt;artifact_path&gt;</code>: Downloads a specific artifact.</li> <li><code>sloth-runner artifacts clean</code>: Cleans up old or unwanted artifacts.</li> </ul>"},{"location":"en/CLI/#sloth-runner-version","title":"<code>sloth-runner version</code>","text":"<p>Displays the current version of <code>sloth-runner</code>.</p> <pre><code>sloth-runner version\n</code></pre>"},{"location":"en/CLI/#sloth-runner-scheduler","title":"<code>sloth-runner scheduler</code>","text":"<p>Manages the <code>sloth-runner</code> task scheduler, allowing you to enable, disable, list, and delete scheduled tasks.</p> <p>For detailed information on scheduler commands and configuration, refer to the Task Scheduler documentation.</p> <p>Subcommands:</p> <ul> <li><code>sloth-runner scheduler enable</code>: Starts the scheduler as a background process.</li> <li><code>sloth-runner scheduler disable</code>: Stops the running scheduler process.</li> <li><code>sloth-runner scheduler list</code>: Lists all configured scheduled tasks.</li> <li><code>sloth-runner scheduler delete &lt;task_name&gt;</code>: Deletes a specific scheduled task.</li> </ul>"},{"location":"en/advanced-examples/","title":"Advanced Examples","text":"<p>This section presents more complex examples and use cases that combine multiple Sloth-Runner modules for end-to-end automation.</p>"},{"location":"en/advanced-examples/#full-example-end-to-end-cicd-pipeline","title":"Full Example: End-to-End CI/CD Pipeline","text":"<p>This tutorial demonstrates how to build a complete CI/CD pipeline using the <code>git</code>, <code>pulumi</code>, and <code>salt</code> modules to version code, provision infrastructure, and deploy an application.</p>"},{"location":"en/advanced-examples/#scenario","title":"Scenario","text":"<p>Imagine you have a Pulumi infrastructure project and an application project. You want to automate the following flow:</p> <ol> <li>Clone the infrastructure repository.</li> <li>Update a version file within the repository.</li> <li>Commit and push this change to Git.</li> <li>Execute <code>pulumi up</code> to provision or update the infrastructure (e.g., a staging environment).</li> <li>Use Salt to configure the provisioned servers and deploy the application.</li> </ol>"},{"location":"en/advanced-examples/#lua-script-examplespulumi_git_combined_examplesloth","title":"Lua Script (<code>examples/pulumi_git_combined_example.sloth</code>)","text":"<pre><code>-- examples/pulumi_git_combined_example.sloth\n\ncommand = function(params)\n    log.info(\"Starting combined Pulumi and Git example...\")\n\n    local pulumi_repo_url = \"https://github.com/my-org/my-pulumi-infra.git\" -- Example Pulumi repo\n    local pulumi_repo_path = \"./pulumi-infra-checkout\"\n    local new_infra_version = params.infra_version or \"v1.0.0-infra\"\n    local pulumi_project_workdir = pulumi_repo_path .. \"/my-vpc-project\" -- Subdirectory within the cloned repo\n    local repo\n\n    -- 1. Clone or open the Pulumi repository\n    log.info(\"Step 1: Cloning or opening Pulumi repository...\")\n    if not fs.exists(pulumi_repo_path) then\n        log.info(\"Cloning Pulumi repository: \" .. pulumi_repo_url)\n        local cloned_repo, clone_err = git.clone(pulumi_repo_url, pulumi_repo_path)\n        if clone_err then\n            log.error(\"Failed to clone Pulumi repository: \" .. clone_err)\n            return false, \"Git clone failed.\"\n        end\n        repo = cloned_repo\n    else\n        log.info(\"Pulumi repository already exists, opening local reference.\")\n        local opened_repo, open_err = git.repo(pulumi_repo_path)\n        if open_err then\n            log.error(\"Failed to open Pulumi repository: \" .. open_err)\n            return false, \"Git repo open failed.\"\n        end\n        repo = opened_repo\n    end\n\n    if not repo then\n        return false, \"Failed to get Pulumi repository reference.\"\n    end\n\n    -- 2. Update the repository (pull)\n    log.info(\"Step 2: Pulling latest changes from Pulumi repository...\")\n    repo:checkout(\"main\"):pull(\"origin\", \"main\")\n    local pull_result = repo:result()\n    if not pull_result.success then\n        log.error(\"Failed to pull Pulumi repository: \" .. pull_result.stderr)\n        return false, \"Git pull failed.\"\n    end\n    log.info(\"Pulumi repository updated. Stdout: \" .. pull_result.stdout)\n\n    -- 3. Simulate a change in the Pulumi code (e.g., update a version file)\n    log.info(\"Step 3: Simulating a change in Pulumi code (updating version file)...\")\n    local infra_version_file = pulumi_repo_path .. \"/INFRA_VERSION\"\n    fs.write(infra_version_file, new_infra_version)\n    log.info(\"Updated INFRA_VERSION file to: \" .. new_infra_version)\n\n    -- 4. Commit and push the changes\n    log.info(\"Step 4: Committing and pushing infrastructure version change...\")\n    local commit_message = \"ci: Bump infrastructure version to \" .. new_infra_version\n    repo:add(infra_version_file)\n        :commit(commit_message)\n        :push(\"origin\", \"main\") -- No follow_tags here, just the commit\n\n    local push_result = repo:result()\n    if not push_result.success then\n        log.error(\"Failed to push infrastructure changes: \" .. push_result.stderr)\n        return false, \"Git push failed for infra changes.\"\n    end\n    log.info(\"Infrastructure version change pushed. Stdout: \" .. push_result.stdout)\n\n    -- 5. Execute 'pulumi up' for the project\n    log.info(\"Step 5: Running pulumi up for the infrastructure project...\")\n    local infra_stack = pulumi.stack(\"my-org/my-infra/dev\", {\n        workdir = pulumi_project_workdir -- Use the subdirectory of the Pulumi project\n    })\n\n    local pulumi_up_result = infra_stack:up({ non_interactive = true })\n\n    if not pulumi_up_result.success then\n        log.error(\"Pulumi up failed: \" .. pulumi_up_result.stderr)\n        return false, \"Pulumi up failed.\"\n    end\n    log.info(\"Pulumi up completed successfully. Stdout: \" .. pulumi_up_result.stdout)\n\n    -- 6. Configure and deploy application using Salt (Example)\n    log.info(\"Step 6: Configuring and deploying application using Salt...\")\n    -- Assuming Pulumi up provided the server IP or hostname\n    -- For this example, we'll use a fictitious IP\n    local server_ip = \"192.168.1.100\" -- Replace with actual output from Pulumi, if any\n    local salt_target = salt.target(server_ip)\n\n    log.info(\"Running Salt test.ping on \" .. server_ip .. \"...\")\n    salt_target:ping()\n    local ping_result = salt_target:result()\n    if not ping_result.success then\n        log.error(\"Salt ping failed for \" .. server_ip .. \": \" .. ping_result.stderr)\n        return false, \"Salt ping failed.\"\n    end\n    log.info(\"Salt ping successful. Stdout: \" .. data.to_json(ping_result.stdout)) -- Assuming ping returns JSON\n\n    log.info(\"Applying Salt state 'app.install' on \" .. server_ip .. \"...\")\n    salt_target:cmd('state.apply', 'app.install')\n    local salt_apply_result = salt_target:result()\n    if not salt_apply_result.success then\n        log.error(\"Salt state.apply failed for \" .. server_ip .. \": \" .. salt_apply_result.stderr)\n        return false, \"Salt state.apply failed.\"\n    end\n    log.info(\"Salt state.apply successful. Stdout: \" .. data.to_json(salt_apply_result.stdout))\n\n    log.info(\"Combined Pulumi and Git example finished successfully.\")\n    return true, \"Combined Pulumi and Git example finished.\"\nend\n\nModern DSLs = {\n    pulumi_git_combined_example = {\n        description = \"Demonstrates combined usage of 'pulumi' and 'git' modules for CI/CD pipeline.\",\n        tasks = {\n            {\n                name = \"run_combined_example\",\n                command = command,\n                params = {\n                    infra_version = \"v1.0.0-test-combined\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"en/agent-improvements/","title":"\ud83d\ude80 Agent Improvements &amp; Future Enhancements","text":"<p>This document outlines the comprehensive improvements and new features that transform sloth-runner from a basic distributed execution system into an enterprise-grade orchestration platform.</p>"},{"location":"en/agent-improvements/#current-implementation-status","title":"\ud83d\udcca Current Implementation Status","text":""},{"location":"en/agent-improvements/#implemented-features","title":"\u2705 Implemented Features","text":""},{"location":"en/agent-improvements/#1-state-management-persistence-implemented","title":"1. \ud83d\udd04 State Management &amp; Persistence Implemented","text":"<ul> <li>SQLite-based persistent state with WAL mode</li> <li>47 Lua functions for comprehensive state management</li> <li>Atomic operations (increment, compare-and-swap, append)</li> <li>Distributed locks with automatic timeout handling</li> <li>TTL support with automatic expiration</li> <li>Pattern matching for bulk operations</li> </ul>"},{"location":"en/agent-improvements/#2-advanced-metrics-system-implemented","title":"2. \ud83d\udcca Advanced Metrics System Implemented","text":"<ul> <li>System metrics collection (CPU, memory, disk, network)</li> <li>Custom metrics (gauges, counters, histograms, timers)</li> <li>Automatic health checks with configurable thresholds</li> <li>Prometheus-compatible HTTP endpoints</li> <li>26 Lua functions for monitoring and alerting</li> </ul>"},{"location":"en/agent-improvements/#high-priority-improvements-planned","title":"\ud83c\udfaf High Priority Improvements Planned","text":""},{"location":"en/agent-improvements/#1-web-dashboard-real-time-monitoring","title":"1. \ud83d\udcf1 Web Dashboard &amp; Real-time Monitoring","text":"<pre><code>interface AgentDashboard {\n    realTimeMetrics: LiveMetricsDisplay;\n    taskExecution: TaskMonitor;\n    logStreaming: LogViewer;\n    healthStatus: HealthDashboard;\n    configManager: ConfigEditor;\n    alertCenter: AlertManager;\n}\n</code></pre> <p>Features: - Real-time metrics visualization with interactive charts - Live log streaming with filtering and search - Task execution monitoring with progress tracking - Health status overview with drill-down capabilities - Configuration management with validation - Alert management with notification routing</p> <p>Benefits: - Immediate visibility into system performance - Reduced time to identify and resolve issues - Enhanced user experience for operations teams - Centralized control and monitoring</p>"},{"location":"en/agent-improvements/#2-intelligent-resource-management","title":"2. \ud83c\udf9b\ufe0f Intelligent Resource Management","text":"<pre><code>type ResourceController struct {\n    CPULimits        ResourceLimits    `json:\"cpu_limits\"`\n    MemoryLimits     ResourceLimits    `json:\"memory_limits\"`\n    DiskIOLimits     ResourceLimits    `json:\"disk_limits\"`\n    NetworkLimits    ResourceLimits    `json:\"network_limits\"`\n    QueueManagement  QueueConfig       `json:\"queue_config\"`\n    LoadBalancer     LoadBalancerConfig `json:\"load_balancer\"`\n}\n\ntype ResourceLimits struct {\n    MaxUsagePercent  float64 `json:\"max_usage\"`\n    WarningThreshold float64 `json:\"warning_threshold\"`\n    ActionOnExceed   string  `json:\"action_on_exceed\"`\n    MonitoringWindow string  `json:\"monitoring_window\"`\n}\n</code></pre> <p>Capabilities: - Dynamic resource allocation based on current load - Task prioritization with queue management - Automatic scaling when resource thresholds are exceeded - Resource isolation using cgroups or containers - Predictive scaling using historical data</p>"},{"location":"en/agent-improvements/#3-advanced-load-balancing-task-distribution","title":"3. \ud83d\udd04 Advanced Load Balancing &amp; Task Distribution","text":"<pre><code>-- Intelligent load balancing in Lua\nlocal best_agent = load_balancer.select_agent({\n    strategy = \"weighted_round_robin\",\n    criteria = {\n        cpu_weight = 0.4,\n        memory_weight = 0.3,\n        network_weight = 0.2,\n        queue_weight = 0.1\n    },\n    constraints = {\n        max_cpu_percent = 80,\n        max_memory_percent = 85,\n        max_queue_size = 50\n    },\n    affinity = {\n        tags = {\"gpu\", \"ssd\"},\n        region = \"us-east-1\"\n    }\n})\n</code></pre> <p>Strategies: - Weighted round-robin based on system metrics - Least connections for even distribution - Resource-aware routing based on requirements - Affinity-based assignment for specialized tasks - Failure-aware routing with automatic failover</p>"},{"location":"en/agent-improvements/#4-advanced-health-monitoring","title":"4. \ud83c\udfe5 Advanced Health Monitoring","text":"<pre><code>type HealthChecker struct {\n    SystemChecks     []SystemHealthCheck     `json:\"system_checks\"`\n    ServiceChecks    []ServiceHealthCheck    `json:\"service_checks\"`\n    CustomChecks     []CustomHealthCheck     `json:\"custom_checks\"`\n    AlertRules       []HealthAlertRule       `json:\"alert_rules\"`\n    RecoveryActions  []RecoveryAction        `json:\"recovery_actions\"`\n}\n\ntype HealthCheck struct {\n    Name             string        `json:\"name\"`\n    Type             string        `json:\"type\"`\n    Interval         time.Duration `json:\"interval\"`\n    Timeout          time.Duration `json:\"timeout\"`\n    SuccessThreshold int           `json:\"success_threshold\"`\n    FailureThreshold int           `json:\"failure_threshold\"`\n    Command          string        `json:\"command,omitempty\"`\n    HTTPEndpoint     string        `json:\"http_endpoint,omitempty\"`\n}\n</code></pre> <p>Health Check Types: - System checks: CPU, memory, disk, network connectivity - Service checks: Database connectivity, API endpoints - Custom script checks: Application-specific validations - Dependency checks: External service availability - Performance checks: Response time, throughput</p>"},{"location":"en/agent-improvements/#medium-priority-enhancements-planned","title":"\ud83d\udd27 Medium Priority Enhancements Planned","text":""},{"location":"en/agent-improvements/#5-plugin-architecture-extensibility","title":"5. \ud83d\udd0c Plugin Architecture &amp; Extensibility","text":"<pre><code>type Plugin interface {\n    Name() string\n    Version() string\n    Description() string\n\n    Initialize(config PluginConfig) error\n    Execute(ctx context.Context, params PluginParams) (*PluginResult, error)\n    HealthCheck() (*PluginHealth, error)\n    Cleanup() error\n}\n\ntype PluginManager struct {\n    LoadedPlugins    map[string]Plugin      `json:\"loaded_plugins\"`\n    PluginConfigs    map[string]PluginConfig `json:\"plugin_configs\"`\n    PluginRegistry   PluginRegistry         `json:\"plugin_registry\"`\n    HookManager      HookManager            `json:\"hook_manager\"`\n}\n</code></pre> <p>Plugin Categories: - Infrastructure: Docker, Kubernetes, Terraform, Ansible - Cloud Providers: AWS, GCP, Azure, DigitalOcean enhanced - Databases: PostgreSQL, MySQL, Redis, MongoDB - Monitoring: Prometheus, Grafana, Datadog, New Relic - Notifications: Slack, Email, PagerDuty, Discord - Security: Vault, SOPS, certificate management</p>"},{"location":"en/agent-improvements/#6-enterprise-security-features","title":"6. \ud83d\udd12 Enterprise Security Features","text":"<pre><code>type SecurityConfig struct {\n    Authentication   AuthenticationConfig  `json:\"authentication\"`\n    Authorization    AuthorizationConfig   `json:\"authorization\"`\n    Encryption       EncryptionConfig      `json:\"encryption\"`\n    Audit           AuditConfig           `json:\"audit\"`\n    Compliance      ComplianceConfig      `json:\"compliance\"`\n}\n\ntype AuthenticationConfig struct {\n    Method          string        `json:\"method\"` // \"jwt\", \"oauth2\", \"mtls\", \"ldap\"\n    TokenTTL        time.Duration `json:\"token_ttl\"`\n    RefreshEnabled  bool          `json:\"refresh_enabled\"`\n    MFARequired     bool          `json:\"mfa_required\"`\n    SessionTimeout  time.Duration `json:\"session_timeout\"`\n}\n</code></pre> <p>Security Features: - mTLS authentication with automatic certificate rotation - RBAC (Role-Based Access Control) with fine-grained permissions - Audit logging of all actions with tamper-proof storage - Secret management integration with Vault/SOPS - Network policies and firewall rules - Compliance scanning (SOC2, PCI-DSS, HIPAA)</p>"},{"location":"en/agent-improvements/#7-advanced-caching-data-management","title":"7. \ud83d\udcbe Advanced Caching &amp; Data Management","text":"<pre><code>-- Enhanced caching with multiple backends\ncache.configure({\n    default_backend = \"redis\",\n    backends = {\n        redis = {\n            endpoints = {\"redis:6379\"},\n            cluster_mode = true,\n            password = secret(\"redis-password\")\n        },\n        memory = {\n            max_size_mb = 512,\n            eviction_policy = \"lru\"\n        },\n        disk = {\n            directory = \"/var/cache/sloth-runner\",\n            max_size_gb = 10,\n            compression = true\n        }\n    },\n    policies = {\n        artifacts = {backend = \"disk\", ttl = \"24h\"},\n        config = {backend = \"memory\", ttl = \"5m\"},\n        metrics = {backend = \"redis\", ttl = \"1h\"}\n    }\n})\n</code></pre>"},{"location":"en/agent-improvements/#advanced-features-beta","title":"\ud83c\udfa8 Advanced Features Beta","text":""},{"location":"en/agent-improvements/#8-ai-powered-optimization","title":"8. \ud83e\udd16 AI-Powered Optimization","text":"<pre><code>type AIAssistant struct {\n    PredictiveScaling      bool            `json:\"predictive_scaling\"`\n    AnomalyDetection      bool            `json:\"anomaly_detection\"`\n    PerformanceOptimization bool          `json:\"performance_optimization\"`\n    CapacityPlanning      bool            `json:\"capacity_planning\"`\n    AutoRemediation       bool            `json:\"auto_remediation\"`\n    CostOptimization      bool            `json:\"cost_optimization\"`\n}\n</code></pre> <p>AI Capabilities: - Predictive scaling based on historical patterns - Anomaly detection in metrics and behavior - Performance optimization recommendations - Capacity planning with growth projections - Automated remediation of common issues - Cost optimization suggestions</p>"},{"location":"en/agent-improvements/#9-advanced-workflow-engine","title":"9. \ud83c\udf10 Advanced Workflow Engine","text":"<pre><code>-- Visual workflow definition\nWorkflow = {\n    name = \"advanced_deployment_pipeline\",\n    description = \"Multi-stage deployment with rollback capabilities\",\n\n    stages = {\n        {\n            name = \"build_and_test\",\n            parallel = true,\n            tasks = {\n                {name = \"unit_tests\", timeout = \"10m\"},\n                {name = \"integration_tests\", timeout = \"15m\"},\n                {name = \"security_scan\", timeout = \"20m\"}\n            },\n            on_failure = \"abort\"\n        },\n        {\n            name = \"staging_deployment\",\n            condition = \"previous_stage_success\",\n            tasks = {\n                {name = \"deploy_staging\", agent_selector = \"staging_cluster\"},\n                {name = \"smoke_tests\", depends_on = \"deploy_staging\"}\n            },\n            approval_required = true,\n            approvers = [\"ops-team\", \"qa-team\"]\n        },\n        {\n            name = \"production_deployment\",\n            strategy = \"canary\",\n            rollback_trigger = {\n                error_rate = \"&gt; 5%\",\n                response_time = \"&gt; 1s\"\n            },\n            tasks = {\n                {name = \"deploy_canary\", percentage = 10},\n                {name = \"monitor_canary\", duration = \"10m\"},\n                {name = \"deploy_full\", condition = \"canary_success\"}\n            }\n        }\n    },\n\n    rollback = {\n        strategy = \"automatic\",\n        triggers = [\"error_threshold\", \"manual\"],\n        preserve_data = true\n    }\n}\n</code></pre>"},{"location":"en/agent-improvements/#10-multi-cloud-hybrid-support","title":"10. \ud83c\udf0d Multi-Cloud &amp; Hybrid Support","text":"<pre><code># Multi-cloud configuration\ncloud_providers:\n  aws:\n    regions: [\"us-east-1\", \"us-west-2\", \"eu-west-1\"]\n    services: [\"ecs\", \"fargate\", \"lambda\"]\n    cost_optimization: true\n\n  gcp:\n    regions: [\"us-central1\", \"europe-west1\"]\n    services: [\"gke\", \"cloud-run\", \"cloud-functions\"]\n\n  azure:\n    regions: [\"eastus\", \"westeurope\"]\n    services: [\"aci\", \"functions\"]\n\n  on_premises:\n    datacenters: [\"dc1\", \"dc2\"]\n    kubernetes_clusters: [\"prod\", \"staging\"]\n\ndeployment_strategy:\n  primary_cloud: \"aws\"\n  failover_cloud: \"gcp\"\n  cost_optimization: true\n  data_residency: \"eu-west-1\"\n  disaster_recovery: \"cross-cloud\"\n</code></pre>"},{"location":"en/agent-improvements/#implementation-roadmap","title":"\ud83d\udcca Implementation Roadmap","text":""},{"location":"en/agent-improvements/#phase-1-foundation-q1-2024-completed","title":"Phase 1: Foundation (Q1 2024) Completed","text":"<ul> <li>\u2705 State Management Module</li> <li>\u2705 Advanced Metrics System</li> <li>\u2705 Enhanced Documentation</li> </ul>"},{"location":"en/agent-improvements/#phase-2-core-improvements-q2-2024","title":"Phase 2: Core Improvements (Q2 2024)","text":"<ul> <li>\ud83d\udd04 Web Dashboard Development</li> <li>\ud83d\udd04 Resource Management Implementation</li> <li>\ud83d\udd04 Advanced Health Monitoring</li> </ul>"},{"location":"en/agent-improvements/#phase-3-platform-enhancement-q3-2024","title":"Phase 3: Platform Enhancement (Q3 2024)","text":"<ul> <li>\ud83d\udcc5 Plugin Architecture</li> <li>\ud83d\udcc5 Security Features</li> <li>\ud83d\udcc5 Load Balancing Improvements</li> </ul>"},{"location":"en/agent-improvements/#phase-4-intelligence-scale-q4-2024","title":"Phase 4: Intelligence &amp; Scale (Q4 2024)","text":"<ul> <li>\ud83d\udcc5 AI-Powered Features</li> <li>\ud83d\udcc5 Advanced Workflow Engine</li> <li>\ud83d\udcc5 Multi-Cloud Support</li> </ul>"},{"location":"en/agent-improvements/#expected-benefits","title":"\ud83c\udfaf Expected Benefits","text":""},{"location":"en/agent-improvements/#operational-excellence","title":"Operational Excellence","text":"<ul> <li>99.9% uptime with automatic failover</li> <li>50% reduction in manual operations</li> <li>Real-time visibility into all systems</li> <li>Automated remediation of common issues</li> </ul>"},{"location":"en/agent-improvements/#performance-scalability","title":"Performance &amp; Scalability","text":"<ul> <li>10x better resource utilization</li> <li>Sub-second task scheduling</li> <li>Linear scaling up to 10,000 agents</li> <li>Predictive capacity planning</li> </ul>"},{"location":"en/agent-improvements/#developer-experience","title":"Developer Experience","text":"<ul> <li>Visual workflow designer</li> <li>Integrated debugging tools</li> <li>Comprehensive API documentation</li> <li>Plugin ecosystem</li> </ul>"},{"location":"en/agent-improvements/#enterprise-features","title":"Enterprise Features","text":"<ul> <li>SOC2 compliance ready</li> <li>Multi-tenant isolation</li> <li>Audit trail for all operations</li> <li>Cost optimization recommendations</li> </ul>"},{"location":"en/agent-improvements/#competitive-advantage","title":"\ud83d\udcc8 Competitive Advantage","text":"Feature Sloth Runner Enhanced Jenkins GitLab CI GitHub Actions Airflow Lua Scripting \u2705 Native \u274c \u274c \u274c \u2705 Python State Management \u2705 Built-in \ud83d\udd0c Plugins \u274c \u274c \u2705 Database Real-time Metrics \u2705 Native \ud83d\udd0c Plugins \u26a0\ufe0f Basic \u26a0\ufe0f Basic \u2705 Native Distributed Agents \u2705 Native \u2705 Master/Slave \u2705 Runners \u2601\ufe0f Cloud \u2705 Celery AI Optimization \u2705 Built-in \u274c \u274c \u274c \ud83d\udd0c Plugins Multi-Cloud \u2705 Native \ud83d\udd0c Plugins \ud83d\udd0c Plugins \u2601\ufe0f Limited \ud83d\udd0c Plugins Visual Workflows \u2705 Built-in \ud83d\udd0c Plugins \u2705 Native \u2705 YAML \u2705 Native Enterprise Security \u2705 Built-in \ud83d\udd0c Plugins \u2705 Native \u2705 Native \u26a0\ufe0f Basic"},{"location":"en/agent-improvements/#getting-started-with-improvements","title":"\ud83d\ude80 Getting Started with Improvements","text":""},{"location":"en/agent-improvements/#enable-advanced-features","title":"Enable Advanced Features","text":"<pre><code># Enable metrics collection on agents\nsloth-runner agent start --metrics-port 8080 --health-checks\n\n# Start with enhanced monitoring\nsloth-runner master --dashboard-port 3000 --metrics-enabled\n\n# Configure advanced features\nsloth-runner config set features.ai_optimization=true\nsloth-runner config set features.predictive_scaling=true\n</code></pre>"},{"location":"en/agent-improvements/#monitor-implementation-progress","title":"Monitor Implementation Progress","text":"<pre><code>-- Check feature availability\nlocal features = system.available_features()\nfor feature, status in pairs(features) do\n    log.info(feature .. \": \" .. status)\nend\n\n-- Enable beta features\nsystem.enable_beta_features({\"workflow_engine\", \"ai_assistant\"})\n</code></pre>"},{"location":"en/agent-improvements/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>\ud83d\udcd6 State Management Guide</li> <li>\ud83d\udcca Metrics &amp; Monitoring Guide</li> <li>\ud83d\udd27 Plugin Development Guide</li> <li>\ud83c\udfd7\ufe0f Architecture Deep Dive</li> <li>\ud83d\ude80 Quick Start Tutorial</li> </ul> <p>The transformation of sloth-runner into an enterprise-grade orchestration platform represents a significant leap in capabilities, positioning it as a modern alternative to traditional CI/CD and workflow tools while maintaining the unique advantages of Lua scripting and distributed architecture! \ud83d\ude80</p>"},{"location":"en/ai-features/","title":"\ud83e\udd16 Intelligent Automation &amp; Analytics","text":"<p>Advanced Task Automation with Smart Analytics Sloth Runner provides intelligent automation features including predictive analytics, optimization algorithms, and adaptive workflows for modern infrastructure management.</p>"},{"location":"en/ai-features/#smart-automation-overview","title":"\ud83e\udde0 Smart Automation Overview","text":"<p>The intelligent automation features in Sloth Runner help optimize your workflows through data-driven insights, predictive analytics, and adaptive execution patterns.</p>"},{"location":"en/ai-features/#intelligent-features","title":"\u2728 Intelligent Features","text":""},{"location":"en/ai-features/#predictive-analytics","title":"\ud83d\udcca Predictive Analytics","text":"<ul> <li>Performance Prediction: Analyze historical data to predict system performance</li> <li>Failure Detection: Early warning system for potential task failures</li> <li>Resource Optimization: Predict and optimize resource usage patterns</li> <li>Trend Analysis: Identify patterns in workflow execution and performance</li> </ul>"},{"location":"en/ai-features/#adaptive-optimization","title":"\ud83c\udfaf Adaptive Optimization","text":"<ul> <li>Dynamic Resource Allocation: Automatically adjust resources based on demand</li> <li>Intelligent Retry Strategies: Adaptive retry patterns based on failure types</li> <li>Load Balancing Optimization: Smart distribution of tasks across agents</li> <li>Performance Tuning: Automatic optimization of task execution parameters</li> </ul>"},{"location":"en/ai-features/#self-healing-workflows","title":"\ud83d\udd04 Self-Healing Workflows","text":"<ul> <li>Automatic Recovery: Detect and recover from common failure scenarios</li> <li>Circuit Breaker Patterns: Prevent cascade failures with intelligent circuit breakers</li> <li>Health Monitoring: Continuous monitoring with automatic remediation</li> <li>Rollback Strategies: Intelligent rollback based on health metrics</li> </ul>"},{"location":"en/ai-features/#learning-adaptation","title":"\ud83d\udcc8 Learning &amp; Adaptation","text":"<ul> <li>Execution Pattern Learning: Learn from past executions to improve future runs</li> <li>Anomaly Detection: Identify unusual patterns in workflow execution</li> <li>Performance Baselines: Establish and monitor performance baselines</li> <li>Continuous Improvement: Automatically suggest workflow optimizations</li> </ul>"},{"location":"en/ai-features/#getting-started-with-intelligent-features","title":"\ud83d\ude80 Getting Started with Intelligent Features","text":""},{"location":"en/ai-features/#enable-predictive-analytics","title":"Enable Predictive Analytics","text":"<pre><code>local analytics = require(\"analytics\")\nlocal optimization = require(\"optimization\")\n\n-- Enable predictive analytics for a workflow\nworkflow.define(\"intelligent_deployment\", {\n    analytics_enabled = true,\n    optimization_level = \"aggressive\",\n\n    tasks = {\n        task(\"performance_analysis\")\n            :command(function()\n                -- Analyze historical performance data\n                local prediction = analytics.predict_performance({\n                    metric = \"deployment_time\",\n                    lookback_days = 30,\n                    confidence_threshold = 0.8\n                })\n\n                if prediction.expected_duration &gt; 300 then\n                    log.warn(\"Deployment expected to take \" .. prediction.expected_duration .. \" seconds\")\n                    analytics.alert(\"long_deployment_predicted\", prediction)\n                end\n\n                return prediction\n            end)\n            :build(),\n\n        task(\"optimized_deployment\")\n            :depends_on({\"performance_analysis\"})\n            :command(function(params, deps)\n                local prediction = deps.performance_analysis\n\n                -- Optimize deployment based on predictions\n                local strategy = optimization.recommend_strategy({\n                    predicted_duration = prediction.expected_duration,\n                    available_resources = system.get_resources(),\n                    priority_level = params.priority or \"normal\"\n                })\n\n                return exec.run_optimized(\"kubectl apply -f production.yaml\", strategy)\n            end)\n            :build()\n    }\n})\n</code></pre>"},{"location":"en/ai-features/#adaptive-resource-management","title":"Adaptive Resource Management","text":"<pre><code>local adaptive = require(\"adaptive\")\nlocal monitoring = require(\"monitoring\")\n\n-- Self-adjusting resource allocation\nlocal adaptive_pipeline = task(\"adaptive_processing\")\n    :command(function(params, deps)\n        -- Monitor current system load\n        local system_load = monitoring.get_system_metrics()\n\n        -- Adapt execution strategy based on load\n        local strategy = adaptive.calculate_strategy({\n            cpu_usage = system_load.cpu_percent,\n            memory_usage = system_load.memory_percent,\n            network_load = system_load.network_throughput,\n            historical_data = analytics.get_historical_load(24) -- 24 hours\n        })\n\n        -- Execute with adaptive parameters\n        return exec.run_with_strategy(\"./heavy-processing-task.sh\", {\n            parallelism = strategy.recommended_parallelism,\n            memory_limit = strategy.memory_allocation,\n            timeout = strategy.estimated_timeout,\n            retry_strategy = strategy.retry_config\n        })\n    end)\n    :build()\n</code></pre>"},{"location":"en/ai-features/#intelligent-error-handling","title":"Intelligent Error Handling","text":"<pre><code>local recovery = require(\"recovery\")\nlocal patterns = require(\"patterns\")\n\n-- Self-healing workflow with intelligent recovery\nworkflow.define(\"resilient_pipeline\", {\n    error_recovery = \"intelligent\",\n    learning_enabled = true,\n\n    on_task_failure = function(task_name, error, context)\n        -- Analyze failure pattern\n        local failure_analysis = patterns.analyze_failure({\n            task = task_name,\n            error = error,\n            context = context,\n            historical_failures = analytics.get_failure_history(task_name, 90)\n        })\n\n        -- Determine recovery strategy\n        local recovery_plan = recovery.generate_plan(failure_analysis)\n\n        log.info(\"Failure detected in \" .. task_name .. \": \" .. error.message)\n        log.info(\"Recovery strategy: \" .. recovery_plan.strategy)\n\n        if recovery_plan.auto_recoverable then\n            -- Attempt automatic recovery\n            local recovery_result = recovery.execute_plan(recovery_plan)\n\n            if recovery_result.success then\n                log.info(\"\u2705 Automatic recovery successful\")\n                return \"retry\"\n            else\n                log.error(\"\u274c Automatic recovery failed: \" .. recovery_result.error)\n                return \"fail\"\n            end\n        else\n            -- Manual intervention required\n            recovery.request_manual_intervention({\n                task = task_name,\n                error = error,\n                suggested_actions = recovery_plan.manual_steps\n            })\n            return \"pause\"\n        end\n    end,\n\n    tasks = {\n        task(\"database_migration\")\n            :command(\"./migrate-database.sh\")\n            :retry_strategy(\"intelligent\")\n            :build(),\n\n        task(\"service_deployment\")\n            :command(\"kubectl rollout deployment myapp\")\n            :health_check(function()\n                return monitoring.check_service_health(\"myapp\")\n            end)\n            :rollback_on_failure(true)\n            :build()\n    }\n})\n</code></pre>"},{"location":"en/ai-features/#performance-optimization","title":"Performance Optimization","text":"<pre><code>local optimizer = require(\"optimizer\")\nlocal profiler = require(\"profiler\")\n\n-- Continuous performance optimization\nlocal optimization_task = task(\"performance_optimization\")\n    :command(function(params, deps)\n        -- Profile current performance\n        local profile = profiler.analyze_workflow_performance({\n            workflow_id = params.workflow_id,\n            time_window = \"7d\",\n            metrics = {\"execution_time\", \"resource_usage\", \"error_rate\"}\n        })\n\n        -- Generate optimization recommendations\n        local recommendations = optimizer.analyze_performance(profile)\n\n        log.info(\"Performance Analysis Complete:\")\n        log.info(\"Average execution time: \" .. profile.avg_execution_time .. \"s\")\n        log.info(\"Resource efficiency: \" .. profile.resource_efficiency .. \"%\")\n        log.info(\"Error rate: \" .. profile.error_rate .. \"%\")\n\n        -- Apply optimizations if confidence is high\n        for _, rec in ipairs(recommendations) do\n            if rec.confidence &gt; 0.8 and rec.impact == \"high\" then\n                log.info(\"Applying optimization: \" .. rec.description)\n                optimizer.apply_optimization(rec)\n            else\n                log.info(\"Optimization suggestion: \" .. rec.description .. \" (confidence: \" .. rec.confidence .. \")\")\n            end\n        end\n\n        return {\n            optimizations_applied = #recommendations,\n            expected_improvement = optimizer.calculate_improvement(recommendations)\n        }\n    end)\n    :schedule(\"daily\")\n    :build()\n</code></pre>"},{"location":"en/ai-features/#analytics-dashboard-integration","title":"\ud83d\udcca Analytics Dashboard Integration","text":""},{"location":"en/ai-features/#real-time-analytics","title":"Real-time Analytics","text":"<pre><code>local dashboard = require(\"dashboard\")\nlocal realtime = require(\"realtime\")\n\n-- Real-time analytics dashboard\ndashboard.create_panel(\"workflow_intelligence\", {\n    title = \"Intelligent Workflow Analytics\",\n    refresh_interval = \"30s\",\n\n    widgets = {\n        {\n            type = \"prediction_chart\",\n            title = \"Performance Predictions\",\n            data_source = function()\n                return analytics.get_predictions({\n                    metrics = {\"execution_time\", \"success_rate\", \"resource_usage\"},\n                    forecast_days = 7\n                })\n            end\n        },\n\n        {\n            type = \"optimization_summary\",\n            title = \"Optimization Opportunities\",\n            data_source = function()\n                return optimizer.get_opportunities({\n                    priority = \"high\",\n                    confidence_threshold = 0.7\n                })\n            end\n        },\n\n        {\n            type = \"anomaly_detector\",\n            title = \"Detected Anomalies\",\n            data_source = function()\n                return analytics.detect_anomalies({\n                    time_window = \"24h\",\n                    sensitivity = \"medium\"\n                })\n            end\n        }\n    }\n})\n</code></pre>"},{"location":"en/ai-features/#configuration-options","title":"\ud83d\udd27 Configuration Options","text":""},{"location":"en/ai-features/#analytics-configuration","title":"Analytics Configuration","text":"<pre><code># sloth-runner.yaml\nanalytics:\n  enabled: true\n  data_retention: \"90d\"\n  prediction_models:\n    - execution_time\n    - resource_usage\n    - failure_probability\n\noptimization:\n  enabled: true\n  auto_apply_threshold: 0.8\n  learning_rate: 0.1\n\nmonitoring:\n  anomaly_detection: true\n  baseline_period: \"30d\"\n  alert_thresholds:\n    performance_degradation: 20%\n    error_rate_increase: 5%\n</code></pre>"},{"location":"en/ai-features/#benefits","title":"\ud83d\udcc8 Benefits","text":""},{"location":"en/ai-features/#operational-benefits","title":"Operational Benefits","text":"<ul> <li>Reduced Downtime: Predictive analytics help prevent failures before they occur</li> <li>Improved Performance: Continuous optimization leads to better resource utilization</li> <li>Lower Costs: Efficient resource usage reduces infrastructure costs</li> <li>Better Reliability: Self-healing capabilities improve overall system reliability</li> </ul>"},{"location":"en/ai-features/#developer-benefits","title":"Developer Benefits","text":"<ul> <li>Less Maintenance: Intelligent automation reduces manual intervention</li> <li>Faster Debugging: Anomaly detection helps identify issues quickly</li> <li>Data-Driven Decisions: Analytics provide insights for infrastructure improvements</li> <li>Continuous Learning: System improves over time without manual tuning</li> </ul>"},{"location":"en/ai-features/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<ol> <li>Enable Analytics: Start by enabling basic analytics in your workflows</li> <li>Monitor Patterns: Observe workflow patterns and performance metrics</li> <li>Apply Optimizations: Implement recommended optimizations gradually</li> <li>Expand Coverage: Add analytics to more critical workflows</li> <li>Custom Models: Develop custom prediction models for specific use cases</li> </ol>"},{"location":"en/ai-features/#related-documentation","title":"\ud83d\udcda Related Documentation","text":"<ul> <li>Monitoring &amp; Metrics</li> <li>State Management</li> <li>Performance Tuning</li> <li>Error Handling</li> <li>Advanced Examples</li> </ul>"},{"location":"en/core-concepts/","title":"Core Concepts - Modern DSL","text":"<p>This document explains the fundamental concepts of <code>sloth-runner</code> using the Modern DSL, helping you understand how to define and orchestrate complex workflows with the new fluent API.</p>"},{"location":"en/core-concepts/#modern-dsl-overview","title":"Modern DSL Overview","text":"<p>The Modern DSL replaces the legacy <code>Modern DSLs</code> approach with a more intuitive, fluent API for defining workflows. Instead of large table structures, you now use chainable methods to build tasks and define workflows declaratively.</p> <pre><code>-- my_pipeline.sloth - Modern DSL\nlocal my_task = task(\"task_name\")\n    :description(\"Task description\")\n    :command(function() ... end)\n    :build()\n\nworkflow.define(\"workflow_name\", {\n    description = \"Workflow description - Modern DSL\",\n    tasks = { my_task }\n})\n</code></pre>"},{"location":"en/core-concepts/#task-definition-with-modern-dsl","title":"Task Definition with Modern DSL","text":"<p>Tasks are now defined using the <code>task()</code> function and fluent API methods:</p>"},{"location":"en/core-concepts/#basic-task-structure","title":"Basic Task Structure","text":"<pre><code>local my_task = task(\"task_name\")\n    :description(\"What this task does\")\n    :command(function(params, deps)\n        -- Task logic here\n        return true, \"Success message\", { output_data = \"value\" }\n    end)\n    :timeout(\"5m\")\n    :retries(3, \"exponential\")\n    :build()\n</code></pre>"},{"location":"en/core-concepts/#task-builder-methods","title":"Task Builder Methods","text":"<p>Core Properties: *   <code>:description(string)</code> - Human-readable task description *   <code>:command(function|string)</code> - Task execution logic *   <code>:timeout(string)</code> - Maximum execution time (e.g., \"10s\", \"5m\", \"1h\") *   <code>:retries(number, strategy)</code> - Retry configuration with strategy (\"exponential\", \"linear\", \"fixed\") *   <code>:depends_on(array)</code> - Array of task names this task depends on</p> <p>Advanced Features: *   <code>:async(boolean)</code> - Enable asynchronous execution *   <code>:artifacts(array)</code> - Files to save after successful execution *   <code>:consumes(array)</code> - Artifacts from other tasks to use *   <code>:run_if(function|string)</code> - Conditional execution logic *   <code>:abort_if(function|string)</code> - Condition to abort entire workflow</p> <p>Lifecycle Hooks: *   <code>:on_success(function)</code> - Execute when task succeeds *   <code>:on_failure(function)</code> - Execute when task fails *   <code>:on_timeout(function)</code> - Execute when task times out *   <code>:pre_hook(function)</code> - Execute before main command *   <code>:post_hook(function)</code> - Execute after main command</p> <p>Example: <pre><code>Modern DSLs = {\n  my_group = {\n    description = \"A group that manages its own temporary directory.\",\n    create_workdir_before_run = true,\n    clean_workdir_after_run = function(result)\n      if not result.success then\n        log.warn(\"Group failed. Workdir will be kept for debugging.\")\n      end\n      return result.success -- Only clean up if everything succeeded\n    end,\n    tasks = {\n      -- Tasks go here\n    }\n  }\n}\n</code></pre></p>"},{"location":"en/core-concepts/#individual-tasks","title":"Individual Tasks","text":"<p>A task is a single unit of work. It's defined as a table with several available properties to control its behavior.</p>"},{"location":"en/core-concepts/#basic-properties","title":"Basic Properties","text":"<ul> <li><code>name</code> (string): The unique name of the task within its group.</li> <li><code>description</code> (string): A brief description of what the task does.</li> <li><code>command</code> (string or function): The core action of the task.<ul> <li>As a string: It's executed as a shell command.</li> <li>As a function: The Lua function is executed. It receives two arguments: <code>params</code> (a table of its parameters) and <code>deps</code> (a table containing the outputs of its dependencies). The function must return:<ol> <li><code>boolean</code>: <code>true</code> for success, <code>false</code> for failure.</li> <li><code>string</code>: A message describing the result.</li> <li><code>table</code> (optional): A table of outputs that other tasks can depend on.</li> </ol> </li> </ul> </li> </ul>"},{"location":"en/core-concepts/#dependency-and-execution-flow","title":"Dependency and Execution Flow","text":"<ul> <li><code>depends_on</code> (string or table): A list of task names that must complete successfully before this task can run.</li> <li><code>next_if_fail</code> (string or table): A list of task names to run only if this task fails. This is useful for cleanup or notification tasks.</li> <li><code>async</code> (boolean): If <code>true</code>, the task runs in the background, and the runner does not wait for it to complete before starting the next task in the execution order.</li> </ul>"},{"location":"en/core-concepts/#error-handling-and-robustness","title":"Error Handling and Robustness","text":"<ul> <li><code>retries</code> (number): The number of times to retry a task if it fails. Default is <code>0</code>.</li> <li><code>timeout</code> (string): A duration (e.g., <code>\"10s\"</code>, <code>\"1m\"</code>) after which the task will be terminated if it's still running.</li> </ul>"},{"location":"en/core-concepts/#conditional-execution","title":"Conditional Execution","text":"<ul> <li><code>run_if</code> (string or function): The task will be skipped unless this condition is met.<ul> <li>As a string: A shell command. An exit code of <code>0</code> means the condition is met.</li> <li>As a function: A Lua function that returns <code>true</code> if the task should run.</li> </ul> </li> <li><code>abort_if</code> (string or function): The entire workflow will be aborted if this condition is met.<ul> <li>As a string: A shell command. An exit code of <code>0</code> means abort.</li> <li>As a function: A Lua function that returns <code>true</code> to abort.</li> </ul> </li> </ul>"},{"location":"en/core-concepts/#lifecycle-hooks","title":"Lifecycle Hooks","text":"<ul> <li><code>pre_exec</code> (function): A Lua function that runs before the main <code>command</code>.</li> <li><code>post_exec</code> (function): A Lua function that runs after the main <code>command</code> has completed successfully.</li> </ul>"},{"location":"en/core-concepts/#reusability","title":"Reusability","text":"<ul> <li><code>uses</code> (table): Specifies a pre-defined task from another file (loaded via <code>import</code>) to use as a base. The current task definition can then override properties like <code>params</code> or <code>description</code>.</li> <li><code>params</code> (table): A dictionary of key-value pairs that can be passed to the task's <code>command</code> function.</li> <li><code>artifacts</code> (string or table): A file pattern (glob) or a list of patterns specifying which files from the task's <code>workdir</code> should be saved as artifacts after a successful run.</li> <li><code>consumes</code> (string or table): The name of an artifact (or a list of names) from a previous task that should be copied into this task's <code>workdir</code> before it runs.</li> </ul>"},{"location":"en/core-concepts/#artifact-management","title":"Artifact Management","text":"<p>Sloth-Runner allows tasks to share files with each other through an artifact mechanism. One task can \"produce\" one or more files as artifacts, and subsequent tasks can \"consume\" those artifacts.</p> <p>This is useful for CI/CD pipelines where a build step might generate a binary (the artifact), which is then used by a testing or deployment step.</p>"},{"location":"en/core-concepts/#how-it-works","title":"How It Works","text":"<ol> <li> <p>Producing Artifacts: Add the <code>artifacts</code> key to your task definition. The value can be a single file pattern (e.g., <code>\"report.txt\"</code>) or a list (e.g., <code>{\"*.log\", \"app.bin\"}</code>). After the task runs successfully, the runner will find files in the task's <code>workdir</code> matching these patterns and copy them to a shared artifact storage for the pipeline.</p> </li> <li> <p>Consuming Artifacts: Add the <code>consumes</code> key to another task's definition (which typically <code>depends_on</code> the producer task). The value should be the filename of the artifact you want to use (e.g., <code>\"report.txt\"</code>). Before this task runs, the runner will copy the named artifact from the shared storage into this task's <code>workdir</code>, making it available to the <code>command</code>.</p> </li> </ol>"},{"location":"en/core-concepts/#artifacts-example","title":"Artifacts Example","text":"<pre><code>Modern DSLs = {\n  [\"ci-pipeline\"] = {\n    description = \"Demonstrates the use of artifacts.\",\n    create_workdir_before_run = true,\n    tasks = {\n      {\n        name = \"build\",\n        description = \"Creates a binary and declares it as an artifact.\",\n        command = \"echo 'binary_content' &gt; app.bin\",\n        artifacts = {\"app.bin\"}\n      },\n      {\n        name = \"test\",\n        description = \"Consumes the binary to run tests.\",\n        depends_on = \"build\",\n        consumes = {\"app.bin\"},\n        command = function(params)\n          -- At this point, 'app.bin' exists in this task's workdir\n          local content, err = fs.read(params.workdir .. \"/app.bin\")\n          if content == \"binary_content\" then\n            log.info(\"Successfully consumed artifact!\")\n            return true\n          else\n            return false, \"Artifact content was incorrect!\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/core-concepts/#global-functions","title":"Global Functions","text":"<p><code>sloth-runner</code> provides global functions in the Lua environment to help orchestrate workflows.</p>"},{"location":"en/core-concepts/#importpath","title":"<code>import(path)</code>","text":"<p>Loads another sloth file and returns the value it returns. This is the primary mechanism for creating reusable task modules. The path is relative to the file calling <code>import</code>.</p> <p>Example (<code>reusable_tasks.sloth</code>): <pre><code>-- Import a module that returns a table of task definitions\nlocal docker_tasks = import(\"shared/docker.sloth\")\n\nModern DSLs = {\n  main = {\n    tasks = {\n      {\n        -- Use the 'build' task from the imported module\n        uses = docker_tasks.build,\n        params = { image_name = \"my-app\" }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"en/core-concepts/#paralleltasks","title":"<code>parallel(tasks)</code>","text":"<p>Executes a list of tasks concurrently and waits for all of them to complete.</p> <ul> <li><code>tasks</code> (table): A list of task tables to run in parallel.</li> </ul> <p>Example: <pre><code>command = function()\n  log.info(\"Starting 3 tasks in parallel...\")\n  local results, err = parallel({\n    { name = \"short_task\", command = \"sleep 1\" },\n    { name = \"medium_task\", command = \"sleep 2\" },\n    { name = \"long_task\", command = \"sleep 3\" }\n  })\n  if err then\n    return false, \"Parallel execution failed\"\n  end\n  return true, \"All parallel tasks finished.\"\nend\n</code></pre></p>"},{"location":"en/core-concepts/#exporttable","title":"<code>export(table)</code>","text":"<p>Exports data from any point in a script to the CLI. When the <code>--return</code> flag is used, all exported tables are merged with the final task's output into a single JSON object.</p> <ul> <li><code>table</code>: A Lua table to be exported.</li> </ul> <p>Example: <pre><code>command = function()\n  export({ important_value = \"data from the middle of a task\" })\n  return true, \"Task done\", { final_output = \"some result\" }\nend\n</code></pre> Running with <code>--return</code> would produce: <pre><code>{\n  \"important_value\": \"data from the middle of a task\",\n  \"final_output\": \"some result\"\n}\n</code></pre></p>"},{"location":"en/distributed/","title":"Distributed Task Execution","text":"<p><code>sloth-runner</code> supports distributed task execution, allowing you to run tasks on remote agents. This enables scalable and distributed workflows, where different parts of your pipeline can be executed on different machines.</p>"},{"location":"en/distributed/#how-it-works","title":"How it Works","text":"<p>The distributed execution model in <code>sloth-runner</code> follows a master-agent architecture:</p> <ol> <li>Master: The main <code>sloth-runner</code> instance acts as the master. It parses the workflow definition, identifies tasks configured to run on remote agents, and dispatches them.</li> <li>Agent: A <code>sloth-runner</code> instance running in <code>agent</code> mode on a remote machine. It listens for incoming task execution requests from the master, executes the tasks, and sends back the results.</li> </ol>"},{"location":"en/distributed/#configuring-remote-tasks","title":"Configuring Remote Tasks","text":"<p>To run a task on a remote agent, you need to specify the <code>delegate_to</code> field in either the task group or the individual task definition.</p>"},{"location":"en/distributed/#1-delegate-to-an-agent-at-the-task-group-level","title":"1. Delegate to an Agent at the Task Group Level","text":"<p>You can define the agent directly within your <code>Modern DSLs</code> group using the <code>delegate_to</code> field. All tasks within this group will then be delegated to this agent unless overridden by a task-specific <code>delegate_to</code>.</p> <pre><code>Modern DSLs = {\n  my_distributed_group = {\n    description = \"A task group with distributed tasks.\",\n    delegate_to = { address = \"localhost:50051\" }, -- Define the agent for the entire group\n    tasks = {\n      {\n        name = \"remote_hello\",\n        description = \"Runs a hello world task on a remote agent.\",\n        -- No 'delegate_to' field needed here, it inherits from the group\n        command = function(params)\n          log.info(\"Hello from remote agent!\")\n          return true, \"Remote task executed.\"\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/distributed/#2-delegate-to-an-agent-at-the-task-level","title":"2. Delegate to an Agent at the Task Level","text":"<p>Alternatively, you can specify the <code>delegate_to</code> field directly on an individual task. This will override any group-level delegation or allow for ad-hoc remote execution.</p> <pre><code>Modern DSLs = {\n  my_group = {\n    description = \"A task group with a specific remote task.\",\n    tasks = {\n      {\n        name = \"specific_remote_task\",\n        description = \"Runs this task on a specific remote agent.\",\n        delegate_to = { address = \"192.168.1.100:50051\" }, -- Define agent for this task only\n        command = function(params)\n          log.info(\"Hello from a specific remote agent!\")\n          return true, \"Specific remote task executed.\"\n        end\n      },\n      {\n        name = \"local_task\",\n        description = \"This task runs locally.\",\n        command = \"echo 'Hello from local machine!'\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/distributed/#running-an-agent","title":"Running an Agent","text":"<p>To start a <code>sloth-runner</code> instance in agent mode, use the <code>agent</code> command:</p> <pre><code>sloth-runner agent -p 50051\n</code></pre> <ul> <li><code>-p, --port</code>: Specifies the port the agent should listen on. Defaults to <code>50051</code>.</li> </ul> <p>When an agent starts, it will listen for incoming gRPC requests from the master <code>sloth-runner</code> instance. Upon receiving a task, it will execute it in its local environment and return the result, along with any updated workspace files, back to the master.</p>"},{"location":"en/distributed/#workspace-synchronization","title":"Workspace Synchronization","text":"<p>When a task is dispatched to a remote agent, <code>sloth-runner</code> automatically handles the synchronization of the task's workspace:</p> <ol> <li>Master to Agent: The master creates a tarball of the current task's working directory and sends it to the agent.</li> <li>Agent Execution: The agent extracts the tarball into a temporary directory, executes the task within that directory, and any changes made to the files in the temporary directory are captured.</li> <li>Agent to Master: After task completion, the agent creates a tarball of the modified temporary directory and sends it back to the master. The master then extracts this tarball, updating its local workspace with any changes made by the remote task.</li> </ol> <p>This ensures that remote tasks have access to all necessary files and that any modifications they make are reflected back in the main workflow.</p>"},{"location":"en/enhanced-agent-output/","title":"Enhanced <code>sloth-runner agent run</code> Output","text":""},{"location":"en/enhanced-agent-output/#purpose","title":"Purpose","text":"<p>This feature significantly improves the visual presentation and informational content of the <code>sloth-runner agent run</code> command's output. Previously, the output was a plain text dump, making it difficult to quickly ascertain the status and details of remote command executions. The enhancement aims to provide a more elegant, colorful, and robust user experience by leveraging the <code>pterm</code> library for terminal output.</p> <p>The primary goals of this enhancement are: *   Clarity: Clearly distinguish between successful and failed command executions. *   Readability: Present information in a structured and easy-to-digest format. *   Expressiveness: Utilize colors and visual elements to convey status and highlight important details. *   Completeness: Ensure all relevant information (command, stdout, stderr, error messages) is presented comprehensively.</p>"},{"location":"en/enhanced-agent-output/#usage","title":"Usage","text":"<p>The usage of the <code>sloth-runner agent run</code> command remains the same. You execute it from your local machine (where the master is running) to instruct a registered agent to execute a shell command.</p> <pre><code>go run ./cmd/sloth-runner agent run &lt;agent_name&gt; '&lt;command_to_execute&gt;'\n</code></pre> <ul> <li><code>&lt;agent_name&gt;</code>: The name of the agent registered with the master (e.g., <code>agent1</code>, <code>agent2</code>).</li> <li><code>&lt;command_to_execute&gt;</code>: The shell command you want the agent to execute. Ensure proper quoting to prevent your local shell from interpreting the command before it reaches the agent.</li> </ul>"},{"location":"en/enhanced-agent-output/#output-style","title":"Output Style","text":"<p>The enhanced output now utilizes <code>pterm.DefaultBox</code> to encapsulate the command execution results, providing a clear visual boundary. Different colors and prefixes are used to indicate success or failure, and sections for the command, standard output, and standard error are clearly delineated.</p>"},{"location":"en/enhanced-agent-output/#successful-command-execution","title":"Successful Command Execution","text":"<p>Upon successful execution of a command on a remote agent, the output will be presented within a green-bordered box, with a <code>SUCCESS</code> title. It will clearly state that the command was successful, show the executed command, and display any <code>Stdout</code> content.</p> <p>Example Command: <pre><code>go run ./cmd/sloth-runner agent run agent1 'echo \"Hello from agent1 on $(hostname)\"'\n</code></pre></p> <p>Example Output: <pre><code>\u250c\u2500  SUCCESS  Command Execution Result on agent1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n|  SUCCESS  Command executed successfully!                |\n|  INFO  Command: echo \"Hello from agent1 on $(hostname)\" |\n| # Stdout:                                               |\n| Hello from agent1 on ladyguica                          |\n|                                                         |\n|                                                         |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"en/enhanced-agent-output/#failed-command-execution","title":"Failed Command Execution","text":"<p>In the event of a command failing on a remote agent, the output will be presented within a red-bordered box, with an <code>ERROR</code> title. It will clearly indicate that the command failed, show the executed command, and display any <code>Stdout</code>, <code>Stderr</code>, and the specific <code>Error</code> message returned by the agent.</p> <p>Example Command (Hypothetical Failure): <pre><code>go run ./cmd/sloth-runner agent run agent1 'non_existent_command'\n</code></pre></p> <p>Example Output (Hypothetical): <pre><code>\u250c\u2500  ERROR  Command Execution Result on agent1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n|  ERROR  Command failed on agent1!                     |\n|  INFO  Command: non_existent_command                  |\n| # Stderr:                                             |\n| bash: non_existent_command: command not found         |\n| # Error:                                              |\n| exit status 127                                       |\n|                                                       |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>This enhanced output ensures that users receive immediate, clear, and visually distinct feedback on the status of their remote agent commands, significantly improving the debugging and monitoring experience.</p>"},{"location":"en/enterprise-features/","title":"\ud83c\udfe2 Enterprise Features","text":"<p>Production-Grade Automation Platform Sloth Runner provides enterprise-grade reliability, security, and scalability for mission-critical automation workflows.</p>"},{"location":"en/enterprise-features/#enterprise-grade-foundation","title":"\ud83c\udf1f Enterprise-Grade Foundation","text":""},{"location":"en/enterprise-features/#ai-powered-intelligence-unique-to-sloth-runner","title":"\ud83e\udd16 AI-Powered Intelligence \u2b50 Unique to Sloth Runner","text":"<ul> <li>Predictive Analytics: 90%+ accurate failure prediction</li> <li>Intelligent Optimization: 2-5x performance improvements</li> <li>Adaptive Learning: Gets smarter with every execution</li> <li>Risk Assessment: Automated risk analysis for critical operations</li> </ul>"},{"location":"en/enterprise-features/#gitops-native-industry-first","title":"\ud83d\udd04 GitOps Native \u2b50 Industry First","text":"<ul> <li>Zero-Config GitOps: Works out-of-the-box with any Git repository</li> <li>Intelligent Diff Preview: Visual change analysis before deployment</li> <li>Smart Rollback: Automatic rollback with state restoration</li> <li>Multi-Environment: Coordinated dev/staging/production workflows</li> </ul>"},{"location":"en/enterprise-features/#distributed-architecture","title":"\ud83c\udf10 Distributed Architecture","text":"<ul> <li>Master-Agent Topology: Scalable distributed execution</li> <li>Automatic Failover: High availability with zero downtime</li> <li>Load Balancing: Intelligent workload distribution</li> <li>Real-Time Streaming: Live task execution monitoring</li> </ul>"},{"location":"en/enterprise-features/#enterprise-security","title":"\ud83d\udd12 Enterprise Security","text":"<ul> <li>mTLS Authentication: Mutual TLS for all communications</li> <li>RBAC Authorization: Role-based access control</li> <li>Audit Logging: Comprehensive audit trail</li> <li>Secrets Management: Secure credential storage and rotation</li> </ul>"},{"location":"en/enterprise-features/#advanced-monitoring","title":"\ud83d\udcca Advanced Monitoring","text":"<ul> <li>Real-Time Metrics: Prometheus-compatible metrics</li> <li>Health Checks: Automated system health monitoring</li> <li>Alerting: Intelligent alerting with escalation</li> <li>Observability: Complete system observability</li> </ul>"},{"location":"en/enterprise-features/#enterprise-state-management","title":"\ud83d\udcbe Enterprise State Management","text":"<ul> <li>SQLite Backend: Reliable persistent state storage</li> <li>Atomic Operations: ACID-compliant state operations</li> <li>Distributed Locks: Coordination across multiple agents</li> <li>TTL Support: Automatic state cleanup and lifecycle management</li> </ul>"},{"location":"en/enterprise-features/#distributed-architecture_1","title":"\ud83c\udfd7\ufe0f Distributed Architecture","text":""},{"location":"en/enterprise-features/#master-agent-topology","title":"Master-Agent Topology","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Master Node   \u2502    \u2502   Agent Node    \u2502    \u2502   Agent Node    \u2502\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\n\u2502  \u2022 Task Queue   \u2502\u25c4\u2500\u2500\u25ba\u2502  \u2022 Execution    \u2502    \u2502  \u2022 Execution    \u2502\n\u2502  \u2022 Scheduling   \u2502    \u2502  \u2022 Monitoring   \u2502    \u2502  \u2022 Monitoring   \u2502\n\u2502  \u2022 Monitoring   \u2502    \u2502  \u2022 Health       \u2502    \u2502  \u2022 Health       \u2502\n\u2502  \u2022 Web UI       \u2502    \u2502  \u2022 Streaming    \u2502    \u2502  \u2022 Streaming    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"en/enterprise-features/#scalability-features","title":"Scalability Features","text":"<ul> <li>Horizontal Scaling: Add agents on-demand</li> <li>Auto-Discovery: Automatic agent registration</li> <li>Load Balancing: Intelligent task distribution</li> <li>Resource Optimization: Efficient resource utilization</li> </ul>"},{"location":"en/enterprise-features/#high-availability","title":"High Availability","text":"<ul> <li>Master Redundancy: Multiple master nodes for failover</li> <li>Agent Failover: Automatic task rescheduling on failure</li> <li>Data Replication: State replication across nodes</li> <li>Zero-Downtime Updates: Rolling updates without service interruption</li> </ul>"},{"location":"en/enterprise-features/#security-compliance","title":"\ud83d\udd12 Security &amp; Compliance","text":""},{"location":"en/enterprise-features/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<pre><code>-- RBAC Configuration Example\nsecurity.configure({\n    auth = {\n        type = \"mTLS\",\n        ca_cert = \"/etc/sloth/ca.pem\",\n        server_cert = \"/etc/sloth/server.pem\",\n        server_key = \"/etc/sloth/server.key\"\n    },\n    rbac = {\n        enabled = true,\n        policies = {\n            {\n                role = \"admin\",\n                permissions = [\"*\"],\n                users = [\"admin@company.com\"]\n            },\n            {\n                role = \"developer\", \n                permissions = [\"workflow:read\", \"workflow:execute\"],\n                users = [\"dev-team@company.com\"]\n            },\n            {\n                role = \"viewer\",\n                permissions = [\"workflow:read\", \"metrics:read\"],\n                users = [\"ops-team@company.com\"]\n            }\n        }\n    }\n})\n</code></pre>"},{"location":"en/enterprise-features/#secrets-management","title":"Secrets Management","text":"<pre><code>-- Secure secrets handling\nlocal secrets = require(\"secrets\")\n\nlocal deploy_task = task(\"secure_deploy\")\n    :command(function(params, deps)\n        -- Retrieve secrets securely\n        local api_key = secrets.get(\"api_key\", {\n            vault = \"production\",\n            rotation = true\n        })\n\n        local db_password = secrets.get(\"db_password\", {\n            vault = \"database\",\n            ttl = \"1h\"\n        })\n\n        -- Use secrets in deployment\n        return deploy_with_secrets(api_key, db_password)\n    end)\n    :build()\n</code></pre>"},{"location":"en/enterprise-features/#audit-compliance","title":"Audit &amp; Compliance","text":"<ul> <li>Complete Audit Trail: Every action logged with full context</li> <li>Compliance Reporting: SOC2, HIPAA, PCI-DSS compliance</li> <li>Data Encryption: Encryption at rest and in transit</li> <li>Access Logging: Detailed access and permission logs</li> </ul>"},{"location":"en/enterprise-features/#monitoring-observability","title":"\ud83d\udcca Monitoring &amp; Observability","text":""},{"location":"en/enterprise-features/#prometheus-integration","title":"Prometheus Integration","text":"<pre><code># prometheus.yml\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'sloth-runner'\n    static_configs:\n      - targets: ['sloth-master:8080']\n    metrics_path: '/metrics'\n    scrape_interval: 5s\n</code></pre>"},{"location":"en/enterprise-features/#key-metrics","title":"Key Metrics","text":"<ul> <li>Task Execution Metrics: Duration, success rate, throughput</li> <li>System Metrics: CPU, memory, disk, network utilization</li> <li>AI Metrics: Optimization success rate, prediction accuracy</li> <li>GitOps Metrics: Deployment frequency, rollback rate, sync health</li> </ul>"},{"location":"en/enterprise-features/#alerting-rules","title":"Alerting Rules","text":"<pre><code># alerting_rules.yml\ngroups:\n  - name: sloth-runner\n    rules:\n      - alert: HighTaskFailureRate\n        expr: rate(sloth_task_failures_total[5m]) &gt; 0.1\n        for: 2m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High task failure rate detected\"\n\n      - alert: AIOptimizationDown\n        expr: sloth_ai_optimizations_total == 0\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"AI optimization system is not functioning\"\n</code></pre>"},{"location":"en/enterprise-features/#grafana-dashboards","title":"Grafana Dashboards","text":"<p>Pre-built dashboards for: - System Overview: High-level system health and performance - Task Execution: Task-specific metrics and trends - AI Intelligence: AI optimization and prediction metrics - GitOps Workflows: GitOps deployment and sync status - Agent Performance: Individual agent performance and health</p>"},{"location":"en/enterprise-features/#performance-scalability","title":"\u26a1 Performance &amp; Scalability","text":""},{"location":"en/enterprise-features/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># Add more agents for increased capacity\nsloth-runner agent start \\\n  --master=master.company.com:8080 \\\n  --capacity=100 \\\n  --tags=production,linux\n\n# Scale GitOps workflows\nsloth-runner gitops scale \\\n  --workflows=10 \\\n  --repositories=50 \\\n  --sync-workers=20\n</code></pre>"},{"location":"en/enterprise-features/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Connection Pooling: Efficient resource utilization</li> <li>Caching: Intelligent caching of frequently accessed data</li> <li>Parallel Execution: Concurrent task execution</li> <li>Resource Limits: Configurable resource constraints</li> </ul>"},{"location":"en/enterprise-features/#load-testing","title":"Load Testing","text":"<pre><code>-- Load testing configuration\nlocal load_test = workflow.define(\"load_test\", {\n    description = \"Performance load testing\",\n    config = {\n        parallel_tasks = 100,\n        duration = \"10m\",\n        ramp_up = \"2m\"\n    },\n\n    tasks = {\n        task(\"load_generator\")\n            :replicas(100)\n            :command(function()\n                -- Simulate realistic workload\n                return simulate_production_load()\n            end)\n    }\n})\n</code></pre>"},{"location":"en/enterprise-features/#deployment-options","title":"\ud83d\ude80 Deployment Options","text":""},{"location":"en/enterprise-features/#cloud-deployments","title":"Cloud Deployments","text":""},{"location":"en/enterprise-features/#aws-deployment","title":"AWS Deployment","text":"<pre><code># aws-deployment.yml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sloth-runner-master\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: sloth-runner-master\n  template:\n    metadata:\n      labels:\n        app: sloth-runner-master\n    spec:\n      containers:\n      - name: sloth-runner\n        image: slothrunner/sloth-runner:latest\n        env:\n        - name: MODE\n          value: \"master\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: sloth-secrets\n              key: database-url\n</code></pre>"},{"location":"en/enterprise-features/#kubernetes-helm-chart","title":"Kubernetes Helm Chart","text":"<pre><code># Install with Helm\nhelm repo add sloth-runner https://charts.sloth-runner.dev\nhelm install sloth-runner sloth-runner/sloth-runner \\\n  --set master.replicas=3 \\\n  --set agent.replicas=10 \\\n  --set ai.enabled=true \\\n  --set gitops.enabled=true\n</code></pre>"},{"location":"en/enterprise-features/#on-premises-deployment","title":"On-Premises Deployment","text":"<pre><code># Docker Compose for on-premises\nversion: '3.8'\nservices:\n  sloth-master:\n    image: slothrunner/sloth-runner:latest\n    command: [\"master\", \"start\"]\n    environment:\n      - AI_ENABLED=true\n      - GITOPS_ENABLED=true\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - sloth-data:/data\n\n  sloth-agent:\n    image: slothrunner/sloth-runner:latest\n    command: [\"agent\", \"start\"]\n    environment:\n      - MASTER_URL=http://sloth-master:8080\n    deploy:\n      replicas: 5\n</code></pre>"},{"location":"en/enterprise-features/#hybrid-cloud","title":"Hybrid Cloud","text":"<pre><code>-- Multi-cloud configuration\ninfrastructure.configure({\n    clouds = {\n        {\n            provider = \"aws\",\n            region = \"us-west-2\",\n            agents = 10,\n            capabilities = [\"compute\", \"storage\"]\n        },\n        {\n            provider = \"gcp\", \n            region = \"us-central1\",\n            agents = 5,\n            capabilities = [\"ai\", \"analytics\"]\n        },\n        {\n            provider = \"azure\",\n            region = \"eastus\",\n            agents = 8,\n            capabilities = [\"compliance\", \"security\"]\n        }\n    },\n    load_balancing = \"round_robin\",\n    failover = \"automatic\"\n})\n</code></pre>"},{"location":"en/enterprise-features/#configuration-management","title":"\ud83d\udd27 Configuration Management","text":""},{"location":"en/enterprise-features/#environment-configuration","title":"Environment Configuration","text":"<pre><code># production.yml\nsloth_runner:\n  master:\n    replicas: 3\n    resources:\n      cpu: \"2\"\n      memory: \"4Gi\"\n    database:\n      type: \"postgresql\"\n      url: \"${DATABASE_URL}\"\n      pool_size: 20\n\n  agent:\n    replicas: 20\n    resources:\n      cpu: \"1\"\n      memory: \"2Gi\"\n    capabilities:\n      - \"docker\"\n      - \"kubernetes\" \n      - \"terraform\"\n\n  ai:\n    enabled: true\n    optimization_level: 8\n    learning_mode: \"adaptive\"\n    models:\n      - \"optimization\"\n      - \"prediction\"\n      - \"analytics\"\n\n  gitops:\n    enabled: true\n    repositories: 50\n    sync_workers: 10\n    auto_sync_interval: \"5m\"\n\n  security:\n    auth_type: \"mTLS\"\n    rbac_enabled: true\n    audit_logging: true\n    secrets_backend: \"vault\"\n\n  monitoring:\n    metrics_enabled: true\n    prometheus_endpoint: \"/metrics\"\n    grafana_dashboards: true\n    alerting_enabled: true\n</code></pre>"},{"location":"en/enterprise-features/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>-- Runtime configuration updates\nconfig.update({\n    ai = {\n        optimization_level = 9,  -- Increase optimization\n        learning_mode = \"aggressive\"\n    },\n    gitops = {\n        auto_sync_interval = \"2m\"  -- More frequent sync\n    }\n})\n</code></pre>"},{"location":"en/enterprise-features/#enterprise-integrations","title":"\ud83d\udcc8 Enterprise Integrations","text":""},{"location":"en/enterprise-features/#identity-providers","title":"Identity Providers","text":"<ul> <li>Active Directory: Seamless AD integration</li> <li>LDAP: Standard LDAP authentication</li> <li>SAML 2.0: Single sign-on support</li> <li>OAuth 2.0: Modern OAuth integration</li> <li>OIDC: OpenID Connect support</li> </ul>"},{"location":"en/enterprise-features/#monitoring-systems","title":"Monitoring Systems","text":"<ul> <li>Prometheus: Native Prometheus metrics</li> <li>Grafana: Pre-built dashboards</li> <li>DataDog: DataDog integration</li> <li>New Relic: APM integration</li> <li>Splunk: Log aggregation and analysis</li> </ul>"},{"location":"en/enterprise-features/#notification-systems","title":"Notification Systems","text":"<ul> <li>Slack: Real-time notifications</li> <li>Microsoft Teams: Team collaboration</li> <li>PagerDuty: Incident management</li> <li>Email: Traditional email notifications</li> <li>Webhooks: Custom integrations</li> </ul>"},{"location":"en/enterprise-features/#external-systems","title":"External Systems","text":"<ul> <li>JIRA: Issue tracking integration</li> <li>ServiceNow: ITSM integration</li> <li>HashiCorp Vault: Secrets management</li> <li>Consul: Service discovery</li> <li>Jenkins: CI/CD pipeline integration</li> </ul>"},{"location":"en/enterprise-features/#enterprise-support","title":"\ud83d\udcbc Enterprise Support","text":""},{"location":"en/enterprise-features/#support-tiers","title":"Support Tiers","text":""},{"location":"en/enterprise-features/#professional-support","title":"Professional Support","text":"<ul> <li>8x5 support coverage</li> <li>Email and chat support</li> <li>2-business-day response SLA</li> <li>Knowledge base access</li> </ul>"},{"location":"en/enterprise-features/#enterprise-support_1","title":"Enterprise Support","text":"<ul> <li>24x7 support coverage</li> <li>Phone, email, and chat support</li> <li>4-hour response SLA for critical issues</li> <li>Dedicated customer success manager</li> </ul>"},{"location":"en/enterprise-features/#premium-support","title":"Premium Support","text":"<ul> <li>24x7 priority support</li> <li>1-hour response SLA for critical issues</li> <li>Direct escalation to engineering</li> <li>Custom feature development</li> <li>On-site consulting available</li> </ul>"},{"location":"en/enterprise-features/#professional-services","title":"Professional Services","text":"<ul> <li>Implementation Services: Expert-guided implementation</li> <li>Training Programs: Comprehensive training for teams</li> <li>Custom Development: Tailored features and integrations</li> <li>Performance Optimization: System performance tuning</li> <li>Security Audits: Security assessment and hardening</li> </ul>"},{"location":"en/enterprise-features/#sla-guarantees","title":"SLA &amp; Guarantees","text":"<ul> <li>99.9% Uptime SLA: Guaranteed system availability</li> <li>Performance SLA: Response time guarantees</li> <li>Data Recovery: Backup and disaster recovery</li> <li>Security: Regular security assessments</li> </ul>"},{"location":"en/enterprise-features/#enterprise-documentation","title":"\ud83d\udcda Enterprise Documentation","text":""},{"location":"en/enterprise-features/#administrator-guides","title":"Administrator Guides","text":"<ul> <li>Installation &amp; Setup</li> <li>Security Configuration</li> <li>Monitoring Setup</li> <li>Backup &amp; Recovery</li> </ul>"},{"location":"en/enterprise-features/#operations-guides","title":"Operations Guides","text":"<ul> <li>Day-to-Day Operations</li> <li>Troubleshooting Guide</li> <li>Performance Tuning</li> <li>Scaling Guidelines</li> </ul>"},{"location":"en/enterprise-features/#developer-guides","title":"Developer Guides","text":"<ul> <li>Enterprise API</li> <li>Custom Integrations</li> <li>Plugin Development</li> <li>Advanced Workflows</li> </ul>"},{"location":"en/enterprise-features/#why-choose-sloth-runner-enterprise","title":"\ud83c\udfaf Why Choose Sloth Runner Enterprise?","text":""},{"location":"en/enterprise-features/#competitive-advantages","title":"Competitive Advantages","text":"Feature Sloth Runner Jenkins GitHub Actions GitLab CI AI Intelligence \u2705 Native \u274c None \u274c None \u274c None GitOps Native \u2705 Built-in \u26a0\ufe0f Plugins \u26a0\ufe0f External \u26a0\ufe0f Basic Modern DSL \u2705 Lua \u274c Groovy \u274c YAML \u274c YAML Distributed \u2705 Native \u26a0\ufe0f Complex \u274c Cloud-only \u26a0\ufe0f Limited Real-time UI \u2705 Built-in \u26a0\ufe0f Basic \u274c Limited \u26a0\ufe0f Basic Enterprise Security \u2705 Complete \u26a0\ufe0f Plugins \u26a0\ufe0f Cloud \u2705 Good"},{"location":"en/enterprise-features/#return-on-investment","title":"Return on Investment","text":"<ul> <li>50%+ Faster Deployments: AI optimization and GitOps automation</li> <li>90% Fewer Failures: AI failure prediction and prevention</li> <li>75% Less Maintenance: Self-healing and adaptive systems</li> <li>60% Faster Development: Modern DSL and intelligent workflows</li> </ul>"},{"location":"en/enterprise-features/#enterprise-success-stories","title":"Enterprise Success Stories","text":"<p>\"Sloth Runner's AI capabilities reduced our deployment failures by 85% and cut our release cycle time in half.\" \u2014 Senior DevOps Engineer, Fortune 500 Financial Services</p> <p>\"The GitOps native integration eliminated our need for external tools and reduced complexity by 70%.\" \u2014 Platform Architect, Global Technology Company</p> <p>\"AI-powered optimization improved our build times by 3x and saved us thousands in compute costs.\" \u2014 Engineering Director, Cloud-Native Startup</p>"},{"location":"en/enterprise-features/#get-started-with-enterprise","title":"\ud83d\ude80 Get Started with Enterprise","text":""},{"location":"en/enterprise-features/#contact-sales","title":"Contact Sales","text":"<p>Ready to transform your automation with AI-powered intelligence and GitOps native workflows?</p> <ul> <li>\ud83d\udce7 Email: enterprise@sloth-runner.dev</li> <li>\ud83d\udcde Phone: +1-800-SLOTH-AI</li> <li>\ud83d\udcac Chat: Enterprise Chat</li> <li>\ud83d\udcc5 Demo: Schedule Demo</li> </ul>"},{"location":"en/enterprise-features/#trial-options","title":"Trial Options","text":"<ul> <li>30-Day Free Trial: Full enterprise features</li> <li>Proof of Concept: Custom PoC with your data</li> <li>Pilot Program: Limited production deployment</li> <li>Migration Assistance: Expert-guided migration from existing tools</li> </ul> <p>\ud83c\udfe2 Sloth Runner Enterprise - The future of intelligent automation is here</p> <p>Trusted by Fortune 500 companies worldwide for mission-critical automation workflows.</p>"},{"location":"en/getting-started/","title":"Getting Started","text":"<p>Welcome to Sloth-Runner! This guide will help you get started with the tool quickly.</p> <p>\ud83d\udcdd Important Note: Starting with the current version, Sloth Runner workflow files use the <code>.sloth</code> extension instead of <code>.lua</code>. The Lua syntax remains the same - only the file extension has changed for better identification of Sloth Runner DSL files.</p>"},{"location":"en/getting-started/#installation","title":"Installation","text":"<p>To install <code>sloth-runner</code> on your system, you can use the provided <code>install.sh</code> script. This script automatically detects your operating system and architecture, downloads the latest release from GitHub, and places the <code>sloth-runner</code> executable in <code>/usr/local/bin</code>.</p> <pre><code>bash &lt;(curl -sL https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/install.sh)\n</code></pre> <p>Note: The <code>install.sh</code> script requires <code>sudo</code> privileges to move the executable to <code>/usr/local/bin</code>.</p>"},{"location":"en/getting-started/#basic-usage","title":"Basic Usage","text":"<p>To run a Lua task file:</p> <pre><code>sloth-runner run -f examples/basic_pipeline.sloth\n</code></pre> <p>To list tasks in a file:</p> <pre><code>sloth-runner list -f examples/basic_pipeline.sloth\n</code></pre>"},{"location":"en/getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have Sloth-Runner installed and running, explore the Core Concepts to understand how to define your tasks, or dive directly into the new Built-in Modules for advanced automation with Git, Pulumi, and Salt.</p> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"en/gitops-features/","title":"\ud83d\udd04 GitOps Native Workflows","text":"<p>\ud83c\udf1f World's First Native GitOps Task Runner Sloth Runner revolutionizes deployment automation with built-in GitOps workflows, making infrastructure-as-code truly seamless.</p>"},{"location":"en/gitops-features/#overview","title":"\ud83c\udf0a Overview","text":"<p>GitOps Native brings declarative, Git-driven deployment workflows directly into your task automation. No external tools needed - everything is built-in and ready to use.</p>"},{"location":"en/gitops-features/#key-gitops-features","title":"\u2728 Key GitOps Features","text":""},{"location":"en/gitops-features/#declarative-workflows","title":"\ud83d\udd04 Declarative Workflows","text":"<ul> <li>Zero Configuration: Works out-of-the-box with any Git repository</li> <li>Multi-Repository: Manage multiple repos in a single workflow</li> <li>Branch Strategies: Support for GitFlow, GitHub Flow, and custom strategies</li> </ul>"},{"location":"en/gitops-features/#intelligent-diff-preview","title":"\ud83d\udd0d Intelligent Diff Preview","text":"<ul> <li>Visual Changes: See exactly what will change before deployment</li> <li>Conflict Detection: Automatic detection and resolution of conflicts</li> <li>Impact Analysis: Understand the impact of changes before applying</li> </ul>"},{"location":"en/gitops-features/#smart-rollback","title":"\ud83d\udee1\ufe0f Smart Rollback","text":"<ul> <li>Automatic Rollback: Roll back on failure detection</li> <li>State Backup: Automatic backup before every deployment</li> <li>Multiple Strategies: Rollback to previous commit, timestamp, or state</li> </ul>"},{"location":"en/gitops-features/#multi-environment-support","title":"\ud83c\udfe2 Multi-Environment Support","text":"<ul> <li>Environment Isolation: Separate workflows for dev/staging/production</li> <li>Progressive Deployment: Automatic promotion through environments</li> <li>Approval Gates: Manual approval for production deployments</li> </ul>"},{"location":"en/gitops-features/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"en/gitops-features/#simple-gitops-workflow","title":"Simple GitOps Workflow","text":"<pre><code>local gitops = require(\"gitops\")\n\n-- Create a GitOps workflow with minimal configuration\nlocal workflow = gitops.workflow({\n    repo = \"https://github.com/company/infrastructure\",\n    branch = \"main\",\n    auto_sync = true,\n    diff_preview = true,\n    rollback_on_failure = true\n})\n\n-- That's it! GitOps is now active\nlog.info(\"GitOps workflow created: \" .. workflow.workflow_id)\n</code></pre>"},{"location":"en/gitops-features/#advanced-multi-environment-setup","title":"Advanced Multi-Environment Setup","text":"<pre><code>local gitops = require(\"gitops\")\n\n-- Define environments with different configurations\nlocal environments = {\n    {\n        name = \"development\",\n        repo = \"https://github.com/company/k8s-dev\",\n        branch = \"develop\",\n        auto_sync = true,        -- Auto-deploy in dev\n        sync_interval = \"5m\"\n    },\n    {\n        name = \"staging\",\n        repo = \"https://github.com/company/k8s-staging\", \n        branch = \"staging\",\n        auto_sync = true,        -- Auto-deploy in staging\n        sync_interval = \"10m\"\n    },\n    {\n        name = \"production\",\n        repo = \"https://github.com/company/k8s-prod\",\n        branch = \"main\",\n        auto_sync = false,       -- Manual deploys in production\n        approval_required = true\n    }\n}\n\n-- Create workflows for all environments\nfor _, env in ipairs(environments) do\n    local workflow_id = gitops.create_workflow({\n        name = env.name .. \" Environment\",\n        repository = gitops.register_repository({\n            url = env.repo,\n            branch = env.branch\n        }),\n        auto_sync = env.auto_sync,\n        diff_preview = true,\n        rollback_on_failure = true\n    })\n\n    log.info(\"Created GitOps workflow for \" .. env.name .. \": \" .. workflow_id)\nend\n</code></pre>"},{"location":"en/gitops-features/#diff-preview-change-analysis","title":"\ud83d\udd0d Diff Preview &amp; Change Analysis","text":""},{"location":"en/gitops-features/#preview-changes-before-deployment","title":"Preview Changes Before Deployment","text":"<pre><code>local deploy_task = task(\"preview_and_deploy\")\n    :description(\"Preview changes before deploying\")\n    :command(function(params, deps)\n        local workflow_id = params.workflow_id\n\n        -- Generate comprehensive diff\n        local diff = gitops.generate_diff(workflow_id)\n\n        if not diff then\n            log.info(\"\u2139\ufe0f No changes detected\")\n            return {success = true, message = \"No changes to deploy\"}\n        end\n\n        -- Display change summary\n        log.info(\"\ud83d\udcca Deployment Summary:\")\n        log.info(\"  \ud83d\udcdd Total changes: \" .. diff.summary.total_changes)\n        log.info(\"  \u2728 Created: \" .. diff.summary.created_resources)\n        log.info(\"  \ud83d\udd04 Updated: \" .. diff.summary.updated_resources)\n        log.info(\"  \ud83d\uddd1\ufe0f Deleted: \" .. diff.summary.deleted_resources)\n\n        -- Check for conflicts\n        if diff.summary.conflict_count &gt; 0 then\n            log.warn(\"\u26a0\ufe0f Conflicts detected:\")\n            for _, conflict in ipairs(diff.conflicts) do\n                log.warn(\"  \u274c \" .. conflict.resource .. \": \" .. conflict.description)\n            end\n\n            return {success = false, message = \"Conflicts must be resolved before deployment\"}\n        end\n\n        -- Check for high-impact changes\n        local high_impact_changes = 0\n        for _, change in ipairs(diff.changes) do\n            if change.impact == \"high\" or change.impact == \"critical\" then\n                high_impact_changes = high_impact_changes + 1\n                log.warn(\"\u26a0\ufe0f High-impact change: \" .. change.resource .. \" (\" .. change.type .. \")\")\n            end\n        end\n\n        -- Show warnings\n        if #diff.warnings &gt; 0 then\n            log.warn(\"\u26a0\ufe0f Warnings:\")\n            for _, warning in ipairs(diff.warnings) do\n                log.warn(\"  \u2022 \" .. warning)\n            end\n        end\n\n        -- Require confirmation for high-impact changes\n        if high_impact_changes &gt; 0 then\n            print(\"Proceed with \" .. high_impact_changes .. \" high-impact changes? (y/N)\")\n            local response = io.read()\n            if response:lower() ~= \"y\" then\n                return {success = false, message = \"Deployment cancelled by user\"}\n            end\n        end\n\n        -- Execute deployment\n        log.info(\"\ud83d\ude80 Executing deployment...\")\n        return gitops.sync_workflow(workflow_id)\n    end)\n    :build()\n</code></pre>"},{"location":"en/gitops-features/#sync-strategies","title":"\ud83d\udd04 Sync Strategies","text":""},{"location":"en/gitops-features/#automatic-synchronization","title":"Automatic Synchronization","text":"<pre><code>-- Enable auto-sync for non-production environments\nlocal dev_workflow = gitops.workflow({\n    repo = \"https://github.com/company/dev-config\",\n    auto_sync = true,\n    sync_interval = \"5m\",     -- Check for changes every 5 minutes\n    diff_preview = true,\n    rollback_on_failure = true\n})\n\n-- Start the auto-sync controller\ngitops.start_auto_sync()\nlog.info(\"\ud83d\udd04 Auto-sync controller started\")\n</code></pre>"},{"location":"en/gitops-features/#manual-synchronization-with-validation","title":"Manual Synchronization with Validation","text":"<pre><code>local production_deploy = task(\"production_deploy\")\n    :description(\"Manual production deployment with full validation\")\n    :command(function(params, deps)\n        local workflow_id = params.workflow_id\n\n        -- Step 1: Generate and review diff\n        local diff = gitops.generate_diff(workflow_id)\n\n        -- Step 2: Run pre-deployment validations\n        log.info(\"\ud83d\udd0d Running pre-deployment validations...\")\n\n        -- Check for breaking changes\n        local breaking_changes = false\n        for _, change in ipairs(diff.changes) do\n            if change.type == \"delete\" and change.resource:match(\"PersistentVolume\") then\n                breaking_changes = true\n                log.error(\"\ud83d\udca5 Breaking change detected: Deleting PersistentVolume\")\n            end\n        end\n\n        if breaking_changes then\n            return {success = false, message = \"Breaking changes detected - manual review required\"}\n        end\n\n        -- Step 3: Execute deployment\n        log.info(\"\ud83d\ude80 Executing production deployment...\")\n        local sync_result = gitops.sync_workflow(workflow_id)\n\n        if not sync_result then\n            log.error(\"\ud83d\udca5 Deployment failed!\")\n            return {success = false, message = \"Deployment failed\"}\n        end\n\n        -- Step 4: Verify deployment\n        log.info(\"\ud83d\udd0d Verifying deployment...\")\n        local status = gitops.get_workflow_status(workflow_id)\n\n        if status.status == \"synced\" and status.last_sync_result.status == \"succeeded\" then\n            log.info(\"\u2705 Production deployment successful!\")\n            return {success = true, message = \"Production deployed successfully\"}\n        else\n            log.error(\"\ud83d\udca5 Deployment verification failed!\")\n            return {success = false, message = \"Deployment verification failed\"}\n        end\n    end)\n    :build()\n</code></pre>"},{"location":"en/gitops-features/#rollback-strategies","title":"\ud83d\udee1\ufe0f Rollback Strategies","text":""},{"location":"en/gitops-features/#automatic-rollback-on-failure","title":"Automatic Rollback on Failure","text":"<pre><code>local resilient_deploy = task(\"resilient_deploy\")\n    :description(\"Deploy with automatic rollback on failure\")\n    :command(function(params, deps)\n        local workflow_id = params.workflow_id\n\n        -- Deploy with automatic rollback enabled\n        local sync_result = gitops.sync_workflow(workflow_id)\n\n        if not sync_result then\n            log.warn(\"\ud83d\udd04 Deployment failed, automatic rollback initiated\")\n\n            -- GitOps will automatically rollback due to rollback_on_failure = true\n            -- But we can also trigger manual rollback\n            local rollback_result = gitops.rollback_workflow(workflow_id, \"Deployment failed\")\n\n            if rollback_result then\n                log.info(\"\u2705 Rollback completed successfully\")\n                return {success = false, message = \"Deployment failed but rollback successful\"}\n            else\n                log.error(\"\ud83d\udca5 Rollback failed!\")\n                return {success = false, message = \"Deployment and rollback both failed\"}\n            end\n        end\n\n        return {success = true, message = \"Deployment successful\"}\n    end)\n    :build()\n</code></pre>"},{"location":"en/gitops-features/#manual-rollback","title":"Manual Rollback","text":"<pre><code>local manual_rollback = task(\"manual_rollback\")\n    :description(\"Manual rollback to previous state\")\n    :command(function(params, deps)\n        local workflow_id = params.workflow_id\n        local reason = params.reason or \"Manual rollback requested\"\n\n        log.info(\"\ud83d\udd04 Initiating manual rollback...\")\n        log.info(\"\ud83d\udccb Reason: \" .. reason)\n\n        local rollback_result = gitops.rollback_workflow(workflow_id, reason)\n\n        if rollback_result then\n            log.info(\"\u2705 Manual rollback completed successfully\")\n\n            -- Verify rollback\n            local status = gitops.get_workflow_status(workflow_id)\n            log.info(\"\ud83d\udcca Current status: \" .. status.status)\n\n            return {success = true, message = \"Manual rollback completed\"}\n        else\n            log.error(\"\ud83d\udca5 Manual rollback failed!\")\n            return {success = false, message = \"Manual rollback failed\"}\n        end\n    end)\n    :build()\n</code></pre>"},{"location":"en/gitops-features/#kubernetes-integration","title":"\u2638\ufe0f Kubernetes Integration","text":""},{"location":"en/gitops-features/#native-kubernetes-workflows","title":"Native Kubernetes Workflows","text":"<pre><code>local k8s_gitops = task(\"kubernetes_gitops\")\n    :description(\"GitOps for Kubernetes manifests\")\n    :command(function(params, deps)\n        -- Create GitOps workflow for Kubernetes\n        local k8s_workflow = gitops.workflow({\n            repo = \"https://github.com/company/k8s-manifests\",\n            branch = \"main\",\n            target_path = \"manifests/production\",  -- Focus on specific directory\n            auto_sync = false,\n            diff_preview = true,\n            rollback_on_failure = true\n        })\n\n        -- Preview Kubernetes changes\n        local diff = gitops.generate_diff(k8s_workflow.workflow_id)\n\n        -- Kubernetes-specific validations\n        local k8s_issues = {}\n        for _, change in ipairs(diff.changes) do\n            -- Check for dangerous operations\n            if change.type == \"delete\" and change.resource:match(\"Namespace\") then\n                table.insert(k8s_issues, \"Deleting namespace: \" .. change.resource)\n            end\n\n            if change.type == \"update\" and change.resource:match(\"Deployment\") then\n                -- Check for image changes\n                log.info(\"\ud83d\udce6 Deployment update detected: \" .. change.resource)\n            end\n        end\n\n        if #k8s_issues &gt; 0 then\n            log.warn(\"\u26a0\ufe0f Kubernetes issues detected:\")\n            for _, issue in ipairs(k8s_issues) do\n                log.warn(\"  \u2022 \" .. issue)\n            end\n        end\n\n        -- Deploy to Kubernetes\n        return gitops.sync_workflow(k8s_workflow.workflow_id)\n    end)\n    :build()\n</code></pre>"},{"location":"en/gitops-features/#gitops-api-reference","title":"\ud83d\udcca GitOps API Reference","text":""},{"location":"en/gitops-features/#workflow-management","title":"Workflow Management","text":"<pre><code>-- Create simple workflow\nlocal workflow = gitops.workflow({\n    repo = \"https://github.com/org/repo\",\n    branch = \"main\",\n    auto_sync = true,\n    diff_preview = true,\n    rollback_on_failure = true\n})\n\n-- Create detailed workflow\nlocal workflow_id = gitops.create_workflow({\n    name = \"Production Infrastructure\",\n    repository = repo_id,\n    target_path = \"k8s/production\",\n    auto_sync = false,\n    diff_preview = true,\n    rollback_on_failure = true\n})\n</code></pre>"},{"location":"en/gitops-features/#repository-management","title":"Repository Management","text":"<pre><code>-- Register repository\nlocal repo_id = gitops.register_repository({\n    url = \"https://github.com/company/infrastructure\",\n    branch = \"main\",\n    credentials = {\n        type = \"token\",\n        token = \"ghp_xxxxx\"\n    }\n})\n</code></pre>"},{"location":"en/gitops-features/#sync-operations","title":"Sync Operations","text":"<pre><code>-- Manual sync\nlocal success = gitops.sync_workflow(workflow_id)\n\n-- Get workflow status\nlocal status = gitops.get_workflow_status(workflow_id)\n\n-- List all workflows\nlocal workflows = gitops.list_workflows()\n</code></pre>"},{"location":"en/gitops-features/#diff-and-preview","title":"Diff and Preview","text":"<pre><code>-- Generate diff\nlocal diff = gitops.generate_diff(workflow_id)\n\n-- Alias for diff\nlocal preview = gitops.preview_changes(workflow_id)\n</code></pre>"},{"location":"en/gitops-features/#rollback-operations","title":"Rollback Operations","text":"<pre><code>-- Rollback workflow\nlocal success = gitops.rollback_workflow(workflow_id, \"Reason for rollback\")\n</code></pre>"},{"location":"en/gitops-features/#auto-sync-control","title":"Auto-Sync Control","text":"<pre><code>-- Start auto-sync for all auto_sync=true workflows\ngitops.start_auto_sync()\n\n-- Stop auto-sync\ngitops.stop_auto_sync()\n</code></pre>"},{"location":"en/gitops-features/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"en/gitops-features/#1-environment-strategy","title":"1. Environment Strategy","text":"<pre><code>-- Use different repositories for different environments\nlocal environments = {\n    dev = {repo = \"company/k8s-dev\", auto_sync = true},\n    staging = {repo = \"company/k8s-staging\", auto_sync = true},\n    prod = {repo = \"company/k8s-prod\", auto_sync = false}\n}\n</code></pre>"},{"location":"en/gitops-features/#2-always-preview-in-production","title":"2. Always Preview in Production","text":"<pre><code>-- Never deploy to production without diff preview\nif environment == \"production\" then\n    local diff = gitops.generate_diff(workflow_id)\n    if diff.summary.conflict_count &gt; 0 then\n        error(\"Conflicts detected in production deployment!\")\n    end\nend\n</code></pre>"},{"location":"en/gitops-features/#3-use-descriptive-rollback-reasons","title":"3. Use Descriptive Rollback Reasons","text":"<pre><code>-- Provide clear reasons for rollbacks\ngitops.rollback_workflow(workflow_id, \"Health check failed after 5 minutes\")\n</code></pre>"},{"location":"en/gitops-features/#4-monitor-sync-results","title":"4. Monitor Sync Results","text":"<pre><code>-- Always check sync results\nlocal status = gitops.get_workflow_status(workflow_id)\nif status.last_sync_result.status ~= \"succeeded\" then\n    -- Handle failure\nend\n</code></pre>"},{"location":"en/gitops-features/#advanced-configuration","title":"\ud83d\udd27 Advanced Configuration","text":""},{"location":"en/gitops-features/#multi-repository-workflows","title":"Multi-Repository Workflows","text":"<pre><code>-- Coordinate multiple repositories\nlocal frontend_workflow = gitops.workflow({\n    repo = \"https://github.com/company/frontend-config\"\n})\n\nlocal backend_workflow = gitops.workflow({\n    repo = \"https://github.com/company/backend-config\"\n})\n\nlocal database_workflow = gitops.workflow({\n    repo = \"https://github.com/company/database-config\"\n})\n\n-- Deploy in sequence\ngitops.sync_workflow(database_workflow.workflow_id)\ngitops.sync_workflow(backend_workflow.workflow_id)\ngitops.sync_workflow(frontend_workflow.workflow_id)\n</code></pre>"},{"location":"en/gitops-features/#custom-sync-policies","title":"Custom Sync Policies","text":"<pre><code>local workflow_id = gitops.create_workflow({\n    name = \"Custom Sync Policy\",\n    repository = repo_id,\n    sync_policy = {\n        auto_prune = true,\n        retry = {\n            limit = 5,\n            backoff = \"exponential\"\n        },\n        health_check = {\n            enabled = true,\n            timeout = \"10m\"\n        }\n    }\n})\n</code></pre>"},{"location":"en/gitops-features/#examples","title":"\ud83e\uddea Examples","text":"<p>Explore our comprehensive GitOps Examples directory:</p> <ul> <li>Multi-Environment Deployments: Dev/Staging/Prod workflows</li> <li>Kubernetes GitOps: Native K8s integration</li> <li>Blue-Green Deployments: Zero-downtime deployment strategies</li> <li>Canary Releases: Gradual rollout strategies</li> <li>Disaster Recovery: Backup and restore workflows</li> </ul>"},{"location":"en/gitops-features/#whats-next","title":"\ud83d\ude80 What's Next?","text":"<p>GitOps Native is continuously evolving. Upcoming features include:</p> <ul> <li>\ud83c\udfaf ArgoCD Integration: Seamless integration with ArgoCD</li> <li>\ud83d\udd04 Flux Compatibility: Work with Flux workflows  </li> <li>\ud83d\udcca Advanced Metrics: Deployment success rates and performance metrics</li> <li>\ud83c\udf10 Multi-Cluster: Deploy across multiple Kubernetes clusters</li> <li>\ud83d\udee1\ufe0f Policy Enforcement: OPA/Gatekeeper integration for policy validation</li> </ul> <p>\ud83d\udd04 Ready to revolutionize your deployments? Start with our GitOps Quick Setup Guide or explore the complete API reference.</p>"},{"location":"en/master-agent-architecture/","title":"Sloth-Runner Master-Agent Architecture","text":"<p><code>sloth-runner</code> is designed with a master-agent architecture to facilitate distributed task execution. This allows you to orchestrate and run tasks across multiple remote machines from a central control point.</p>"},{"location":"en/master-agent-architecture/#core-concepts","title":"Core Concepts","text":""},{"location":"en/master-agent-architecture/#master-server","title":"Master Server","text":"<p>The Master Server is the central component of the <code>sloth-runner</code> ecosystem. Its primary responsibilities include:</p> <ul> <li>Agent Registry: Maintains a registry of all connected and available agents.</li> <li>Task Orchestration: Receives task execution requests and dispatches them to the appropriate agents.</li> <li>Communication Hub: Acts as the communication hub between the user (via the CLI) and the agents.</li> </ul>"},{"location":"en/master-agent-architecture/#agent","title":"Agent","text":"<p>An Agent is a lightweight process that runs on a remote machine. Its main functions are:</p> <ul> <li>Registration: Registers itself with the Master Server upon startup, providing its network address and name.</li> <li>Task Execution: Receives commands and tasks from the Master Server and executes them locally.</li> <li>Status Reporting: Reports the status and output of executed tasks back to the Master Server.</li> </ul>"},{"location":"en/master-agent-architecture/#communication-protocol","title":"Communication Protocol","text":"<p>Master and Agents communicate using gRPC, a high-performance, open-source universal RPC framework. This ensures efficient and reliable communication between the distributed components.</p>"},{"location":"en/master-agent-architecture/#installation-and-startup","title":"Installation and Startup","text":""},{"location":"en/master-agent-architecture/#master-server-installation","title":"Master Server Installation","text":"<p>To set up the <code>sloth-runner</code> Master Server, you typically run it on your local machine or a designated control server. The master listens for agent connections on a specified port.</p> <p>Command:</p> <pre><code>go run ./cmd/sloth-runner master -p &lt;port&gt; [--daemon]\n</code></pre> <ul> <li><code>-p, --port &lt;port&gt;</code>: Specifies the port on which the master server will listen for agent connections. The default port is <code>50053</code>.</li> <li><code>--daemon</code>: (Optional) Runs the master server as a background daemon process. This is recommended for continuous operation.</li> </ul> <p>Example:</p> <p>To start the master server on port <code>50053</code> in daemon mode:</p> <pre><code>go run ./cmd/sloth-runner master -p 50053 --daemon\n</code></pre> <p>Upon successful startup, the master will log that it is listening for agent registrations.</p>"},{"location":"en/master-agent-architecture/#agent-installation","title":"Agent Installation","text":"<p>Agents are deployed on the remote machines where you intend to execute tasks. Each agent needs to be configured with a unique name and the address of the Master Server.</p> <p>Command:</p> <pre><code>sloth-runner agent start --name &lt;agent_name&gt; --master &lt;master_ip&gt;:&lt;master_port&gt; --port &lt;agent_port&gt; --bind-address &lt;agent_ip&gt; [--daemon]\n</code></pre> <ul> <li><code>--name &lt;agent_name&gt;</code>: A unique name for this agent (e.g., <code>agent1</code>, <code>web-server-agent</code>). This name is used by the master to identify and address the agent.</li> <li><code>--master &lt;master_ip&gt;:&lt;master_port&gt;</code>: The IP address and port of the running Master Server. Agents will connect to this address to register and receive tasks.</li> <li><code>--port &lt;agent_port&gt;</code>: The port on which the agent itself will listen for direct communication from the master (e.g., for task execution requests). The default port is <code>50051</code>.</li> <li><code>--bind-address &lt;agent_ip&gt;</code>: Crucial for remote agents. This specifies the specific IPv4 address that the agent should bind to and report to the master. This ensures the master can correctly connect to the agent, especially in environments with multiple network interfaces or IPv6 preference. Always set this to the remote machine's accessible IPv4 address.</li> <li><code>--daemon</code>: (Optional) Runs the agent as a background daemon process.</li> </ul> <p>Example:</p> <p>To start an agent named <code>agent1</code> on a machine with IP <code>192.168.1.16</code>, connecting to a master at <code>192.168.1.21:50053</code>, and listening on port <code>50051</code>:</p> <pre><code>sloth-runner agent start --name agent1 --master 192.168.1.21:50053 --port 50051 --bind-address 192.168.1.16 --daemon\n</code></pre>"},{"location":"en/master-agent-architecture/#task-execution-workflow","title":"Task Execution Workflow","text":"<ol> <li>Master Startup: The <code>sloth-runner</code> master server starts and begins listening for agent registrations.</li> <li>Agent Startup &amp; Registration: An agent starts on a remote machine, connects to the configured master, and registers itself, providing its unique name and accessible network address.</li> <li>Agent Listing: The user can list all registered agents using <code>sloth-runner agent list</code> from the master's machine.</li> <li>Task Request: The user initiates a task execution on a specific agent using <code>sloth-runner agent run &lt;agent_name&gt; &lt;command&gt;</code>.</li> <li>Task Dispatch: The master receives the request, looks up the agent's address in its registry, and dispatches the command to the target agent via gRPC.</li> <li>Task Execution: The agent receives the command, executes it locally (e.g., using <code>bash -c &lt;command&gt;</code>), and captures its standard output, standard error, and exit status.</li> <li>Result Reporting: The agent sends the execution results (stdout, stderr, success/failure) back to the master.</li> <li>Output Presentation: The master receives the results and presents them to the user in a clear, formatted, and colored output (as described in the Enhanced <code>sloth-runner agent run</code> Output documentation).</li> </ol> <p>This architecture provides a flexible and scalable way to manage and execute tasks across your infrastructure. </p>"},{"location":"en/quick-start/","title":"\u26a1 Quick Start Guide","text":"<p>Get up and running with Sloth Runner in under 10 minutes! This guide will walk you through installation, basic usage, and your first distributed task execution.</p>"},{"location":"en/quick-start/#installation","title":"\ud83d\ude80 Installation","text":""},{"location":"en/quick-start/#option-1-download-binary","title":"Option 1: Download Binary","text":"<pre><code># Download latest release\ncurl -L https://github.com/chalkan3-sloth/sloth-runner/releases/latest/download/sloth-runner-linux-amd64 -o sloth-runner\nchmod +x sloth-runner\nsudo mv sloth-runner /usr/local/bin/\n</code></pre>"},{"location":"en/quick-start/#option-2-build-from-source","title":"Option 2: Build from Source","text":"<pre><code># Clone repository\ngit clone https://github.com/chalkan3-sloth/sloth-runner.git\ncd sloth-runner\n\n# Build binary\ngo build -o sloth-runner ./cmd/sloth-runner\n\n# Add to PATH\nexport PATH=$PATH:$(pwd)\n</code></pre>"},{"location":"en/quick-start/#option-3-docker","title":"Option 3: Docker","text":"<pre><code># Pull official image\ndocker pull slothrunner/sloth-runner:latest\n\n# Create alias for easy usage\nalias sloth-runner='docker run --rm -v $(pwd):/workspace slothrunner/sloth-runner'\n</code></pre>"},{"location":"en/quick-start/#verify-installation","title":"\ud83d\udccb Verify Installation","text":"<pre><code># Check version\nsloth-runner --version\n\n# View available commands\nsloth-runner --help\n</code></pre> <p>Expected output: <pre><code>Sloth Runner v2.0.0\nA powerful task orchestration platform with Lua scripting\n</code></pre></p>"},{"location":"en/quick-start/#your-first-task","title":"\ud83c\udfaf Your First Task","text":"<p>Create your first Lua task file:</p> <pre><code># Create a simple task file\ncat &gt; hello-world.sloth &lt;&lt; 'EOF'\nModern DSLs = {\n    hello_world = {\n        description = \"My first Sloth Runner task\",\n        tasks = {\n            greet = {\n                name = \"greet\",\n                description = \"Say hello to the world\",\n                command = function()\n                    log.info(\"\ud83c\udf89 Hello from Sloth Runner!\")\n\n                    -- Get system information\n                    local hostname, _ = exec.run(\"hostname\")\n                    local whoami, _ = exec.run(\"whoami\")\n\n                    log.info(\"Running on: \" .. hostname)\n                    log.info(\"User: \" .. whoami)\n\n                    -- Use state management\n                    state.set(\"last_greeting\", os.time())\n                    local count = state.increment(\"greeting_count\", 1)\n\n                    log.info(\"This is greeting #\" .. count)\n\n                    return true, \"Hello World task completed successfully!\"\n                end\n            },\n\n            system_info = {\n                name = \"system_info\", \n                description = \"Display system metrics\",\n                depends_on = \"greet\",\n                command = function()\n                    log.info(\"\ud83d\udcca System Information:\")\n\n                    -- Get system metrics\n                    local cpu = metrics.system_cpu()\n                    local memory = metrics.system_memory()\n                    local disk = metrics.system_disk()\n\n                    log.info(\"CPU Usage: \" .. string.format(\"%.1f%%\", cpu))\n                    log.info(\"Memory: \" .. string.format(\"%.1f%% (%.0f MB used)\", \n                        memory.percent, memory.used_mb))\n                    log.info(\"Disk: \" .. string.format(\"%.1f%% (%.1f GB used)\", \n                        disk.percent, disk.used_gb))\n\n                    -- Record metrics\n                    metrics.gauge(\"quickstart_cpu\", cpu)\n                    metrics.gauge(\"quickstart_memory\", memory.percent)\n\n                    return true, \"System info collected\"\n                end\n            }\n        }\n    }\n}\nEOF\n</code></pre>"},{"location":"en/quick-start/#run-your-first-task","title":"\ud83c\udfc3\u200d\u2642\ufe0f Run Your First Task","text":"<pre><code># Execute the task\nsloth-runner run -f hello-world.sloth\n\n# Or run specific task\nsloth-runner run -f hello-world.sloth -t greet\n</code></pre> <p>Expected output: <pre><code>2024-01-15 10:30:00 INFO \ud83c\udf89 Hello from Sloth Runner!\n2024-01-15 10:30:00 INFO Running on: my-computer\n2024-01-15 10:30:00 INFO User: myuser\n2024-01-15 10:30:00 INFO This is greeting #1\n2024-01-15 10:30:01 INFO \ud83d\udcca System Information:\n2024-01-15 10:30:01 INFO CPU Usage: 15.2%\n2024-01-15 10:30:01 INFO Memory: 45.8% (7520 MB used)\n2024-01-15 10:30:01 INFO Disk: 67.3% (234.5 GB used)\n\u2705 Task 'hello_world' completed successfully!\n</code></pre></p>"},{"location":"en/quick-start/#setting-up-distributed-execution","title":"\ud83c\udf10 Setting Up Distributed Execution","text":""},{"location":"en/quick-start/#step-1-start-master-server","title":"Step 1: Start Master Server","text":"<pre><code># Start master on your main machine (e.g., 192.168.1.100)\nsloth-runner master --port 50053 --bind-address 192.168.1.100\n\n# Or with enhanced features\nsloth-runner master --port 50053 --metrics-port 8080 --dashboard-port 3000\n</code></pre>"},{"location":"en/quick-start/#step-2-deploy-remote-agents","title":"Step 2: Deploy Remote Agents","text":"<p>On remote machine 1 (192.168.1.101): <pre><code># Download sloth-runner binary to remote machine\nscp sloth-runner user@192.168.1.101:/usr/local/bin/\n\n# SSH and start agent\nssh user@192.168.1.101\nsloth-runner agent start \\\n    --name agent-1 \\\n    --master 192.168.1.100:50053 \\\n    --port 50051 \\\n    --bind-address 192.168.1.101\n</code></pre></p> <p>On remote machine 2 (192.168.1.102): <pre><code># SSH and start agent  \nssh user@192.168.1.102\nsloth-runner agent start \\\n    --name agent-2 \\\n    --master 192.168.1.100:50053 \\\n    --port 50051 \\\n    --bind-address 192.168.1.102\n</code></pre></p>"},{"location":"en/quick-start/#step-3-verify-agent-registration","title":"Step 3: Verify Agent Registration","text":"<pre><code># List registered agents\nsloth-runner agent list --master 192.168.1.100:50053\n</code></pre> <p>Expected output: <pre><code>Registered Agents:\n  agent-1    192.168.1.101:50051    Active    2s ago\n  agent-2    192.168.1.102:50051    Active    1s ago\n</code></pre></p>"},{"location":"en/quick-start/#step-4-run-distributed-tasks","title":"Step 4: Run Distributed Tasks","text":"<pre><code># Execute command on specific agent\nsloth-runner agent run agent-1 \"echo 'Hello from Agent 1'\" --master 192.168.1.100:50053\n\n# Execute on all agents\nsloth-runner agent run agent-1 \"uptime\" --master 192.168.1.100:50053 &amp;\nsloth-runner agent run agent-2 \"uptime\" --master 192.168.1.100:50053 &amp;\nwait\n</code></pre>"},{"location":"en/quick-start/#exploring-advanced-features","title":"\ud83d\udcca Exploring Advanced Features","text":""},{"location":"en/quick-start/#state-management-example","title":"State Management Example","text":"<pre><code>-- Create state-demo.sloth\nModern DSLs = {\n    state_demo = {\n        description = \"Demonstrate state management capabilities\",\n        tasks = {\n            setup_state = {\n                name = \"setup_state\",\n                description = \"Initialize application state\", \n                command = function()\n                    -- Initialize configuration\n                    state.set(\"app_config\", {\n                        version = \"1.0.0\",\n                        environment = \"development\",\n                        debug = true\n                    })\n\n                    -- Set TTL for session data (5 minutes)\n                    state.set(\"session_token\", \"abc123xyz\", 300)\n\n                    -- Initialize counters\n                    state.set(\"api_calls\", 0)\n                    state.set(\"errors\", 0)\n\n                    log.info(\"\u2705 Application state initialized\")\n                    return true, \"State setup completed\"\n                end\n            },\n\n            simulate_usage = {\n                name = \"simulate_usage\",\n                description = \"Simulate application usage\",\n                depends_on = \"setup_state\",\n                command = function()\n                    -- Simulate API calls\n                    for i = 1, 10 do\n                        local calls = state.increment(\"api_calls\", 1)\n\n                        -- Simulate occasional error\n                        if math.random(1, 10) &gt; 8 then\n                            state.increment(\"errors\", 1)\n                            log.warn(\"Simulated error occurred\")\n                        end\n\n                        -- Add to processing queue\n                        state.list_push(\"processing_queue\", {\n                            id = \"req_\" .. i,\n                            timestamp = os.time(),\n                            status = \"pending\"\n                        })\n\n                        exec.run(\"sleep 0.1\") -- Small delay\n                    end\n\n                    local total_calls = state.get(\"api_calls\")\n                    local total_errors = state.get(\"errors\")\n                    local queue_size = state.list_length(\"processing_queue\")\n\n                    log.info(\"\ud83d\udcca Usage Summary:\")\n                    log.info(\"  API Calls: \" .. total_calls)\n                    log.info(\"  Errors: \" .. total_errors)\n                    log.info(\"  Queue Size: \" .. queue_size)\n\n                    return true, \"Usage simulation completed\"\n                end\n            },\n\n            process_queue = {\n                name = \"process_queue\",\n                description = \"Process items in queue with locking\",\n                depends_on = \"simulate_usage\",\n                command = function()\n                    -- Process queue with distributed lock\n                    state.with_lock(\"queue_processing\", function()\n                        log.info(\"\ud83d\udd12 Processing queue with exclusive lock...\")\n\n                        local processed = 0\n                        while state.list_length(\"processing_queue\") &gt; 0 do\n                            local item = state.list_pop(\"processing_queue\")\n                            log.info(\"Processing item: \" .. item.id)\n                            processed = processed + 1\n                        end\n\n                        log.info(\"\u2705 Processed \" .. processed .. \" items\")\n                        state.set(\"last_processing_time\", os.time())\n\n                    end, 30) -- 30 second timeout\n\n                    return true, \"Queue processing completed\"\n                end\n            }\n        }\n    }\n}\n</code></pre> <p>Run the state demo: <pre><code>sloth-runner run -f state-demo.sloth\n</code></pre></p>"},{"location":"en/quick-start/#metrics-monitoring-example","title":"Metrics Monitoring Example","text":"<pre><code>-- Create metrics-demo.sloth  \nModern DSLs = {\n    metrics_demo = {\n        description = \"Demonstrate metrics and monitoring\",\n        tasks = {\n            collect_metrics = {\n                name = \"collect_metrics\",\n                description = \"Collect system and custom metrics\",\n                command = function()\n                    log.info(\"\ud83d\udcca Collecting system metrics...\")\n\n                    -- System metrics\n                    local cpu = metrics.system_cpu()\n                    local memory = metrics.system_memory() \n                    local disk = metrics.system_disk()\n\n                    log.info(\"System Status:\")\n                    log.info(\"  CPU: \" .. string.format(\"%.1f%%\", cpu))\n                    log.info(\"  Memory: \" .. string.format(\"%.1f%%\", memory.percent))\n                    log.info(\"  Disk: \" .. string.format(\"%.1f%%\", disk.percent))\n\n                    -- Custom metrics\n                    metrics.gauge(\"demo_cpu_usage\", cpu)\n                    metrics.counter(\"demo_executions\", 1)\n\n                    -- Performance timer\n                    local processing_time = metrics.timer(\"data_processing\", function()\n                        -- Simulate data processing\n                        local sum = 0\n                        for i = 1, 1000000 do\n                            sum = sum + math.sqrt(i)\n                        end\n                        return sum\n                    end)\n\n                    log.info(\"\u23f1\ufe0f Processing took: \" .. string.format(\"%.2f ms\", processing_time))\n\n                    -- Health check\n                    local health = metrics.health_status()\n                    log.info(\"\ud83c\udfe5 Overall health: \" .. health.overall)\n\n                    -- Alert if CPU is high\n                    if cpu &gt; 50 then\n                        metrics.alert(\"high_cpu_demo\", {\n                            level = \"warning\",\n                            message = \"CPU usage is elevated: \" .. string.format(\"%.1f%%\", cpu),\n                            value = cpu\n                        })\n                    end\n\n                    return true, \"Metrics collection completed\"\n                end\n            }\n        }\n    }\n}\n</code></pre> <p>Run the metrics demo: <pre><code>sloth-runner run -f metrics-demo.sloth\n</code></pre></p>"},{"location":"en/quick-start/#access-web-dashboard","title":"\ud83c\udf10 Access Web Dashboard","text":"<p>If you started the master with dashboard support:</p> <pre><code># Open web dashboard\nopen http://192.168.1.100:3000\n\n# View metrics endpoint\ncurl http://192.168.1.100:8080/metrics\n\n# Check health status\ncurl http://192.168.1.100:8080/health\n</code></pre>"},{"location":"en/quick-start/#whats-next","title":"\ud83d\udcda What's Next?","text":""},{"location":"en/quick-start/#explore-core-concepts","title":"Explore Core Concepts","text":"<ul> <li>\ud83d\udcd6 Core Concepts - Understand tasks, workflows, and state</li> <li>\ud83d\udd27 CLI Commands - Master all available commands</li> <li>\ud83c\udf19 Lua API - Deep dive into scripting capabilities</li> </ul>"},{"location":"en/quick-start/#advanced-features","title":"Advanced Features","text":"<ul> <li>\ud83d\udcbe State Management - Persistent state and locks</li> <li>\ud83d\udcca Metrics &amp; Monitoring - Observability and alerting</li> <li>\ud83d\ude80 Agent Improvements - Enterprise features</li> </ul>"},{"location":"en/quick-start/#cloud-integrations","title":"Cloud Integrations","text":"<ul> <li>\u2601\ufe0f AWS Integration - Deploy and manage AWS resources</li> <li>\ud83c\udf29\ufe0f GCP Integration - Google Cloud Platform tasks</li> <li>\ud83d\udd37 Azure Integration - Microsoft Azure automation</li> </ul>"},{"location":"en/quick-start/#infrastructure-as-code","title":"Infrastructure as Code","text":"<ul> <li>\ud83d\udc33 Docker - Container management</li> <li>\ud83c\udfd7\ufe0f Pulumi - Modern infrastructure as code</li> <li>\ud83c\udf0d Terraform - Infrastructure provisioning</li> </ul>"},{"location":"en/quick-start/#getting-help","title":"\ud83c\udd98 Getting Help","text":""},{"location":"en/quick-start/#documentation","title":"Documentation","text":"<ul> <li>\ud83d\udcda Full Documentation</li> <li>\ud83d\udd0d API Reference</li> <li>\ud83d\udca1 Examples</li> </ul>"},{"location":"en/quick-start/#community","title":"Community","text":"<ul> <li>\ud83d\udcac GitHub Discussions</li> <li>\ud83d\udc1b Issue Tracker</li> <li>\ud83d\udce7 Email Support</li> </ul>"},{"location":"en/quick-start/#quick-troubleshooting","title":"Quick Troubleshooting","text":"<p>Agent won't connect to master? <pre><code># Check network connectivity\ntelnet 192.168.1.100 50053\n\n# Verify master is running\nsloth-runner agent list --master 192.168.1.100:50053\n\n# Check firewall settings\nsudo ufw status\n</code></pre></p> <p>Tasks failing with permission errors? <pre><code># Check user permissions\nls -la /usr/local/bin/sloth-runner\n\n# Run with appropriate user\nsudo -u myuser sloth-runner run -f task.sloth\n</code></pre></p> <p>State database issues? <pre><code># Check state database location\nls -la ~/.sloth-runner/\n\n# View state statistics\nsloth-runner state stats\n\n# Clear corrupted state (careful!)\nrm ~/.sloth-runner/state.db*\n</code></pre></p>"},{"location":"en/quick-start/#congratulations","title":"\ud83c\udf89 Congratulations!\ud83d\ude80 Ready for More?","text":"<p>You've successfully: - \u2705 Installed Sloth Runner - \u2705 Executed your first task - \u2705 Set up distributed agents - \u2705 Explored state management - \u2705 Monitored system metrics</p> <p>You're now ready to build powerful, distributed task orchestration workflows with Sloth Runner! \ud83d\ude80</p> <p>Explore advanced features and build production-ready workflows</p> Advanced Features \u2192 More Examples \u2192"},{"location":"en/repl/","title":"Interactive REPL","text":"<p>The <code>sloth-runner repl</code> command drops you into an interactive Read-Eval-Print Loop (REPL) session. This is a powerful tool for debugging, exploration, and quick experimentation with the sloth-runner modules.</p>"},{"location":"en/repl/#starting-the-repl","title":"Starting the REPL","text":"<p>To start a session, simply run: <pre><code>sloth-runner repl\n</code></pre></p> <p>You can also pre-load a workflow file to have its <code>Modern DSLs</code> and any helper functions available in the session. This is incredibly useful for debugging an existing pipeline.</p> <pre><code>sloth-runner repl -f /path/to/your/pipeline.sloth\n</code></pre>"},{"location":"en/repl/#features","title":"Features","text":""},{"location":"en/repl/#live-environment","title":"Live Environment","text":"<p>The REPL provides a live Lua environment where you can execute any Lua code. All the built-in sloth-runner modules (<code>aws</code>, <code>docker</code>, <code>fs</code>, <code>log</code>, etc.) are pre-loaded and ready to use.</p> <pre><code>sloth&gt; log.info(\"Hello from the REPL!\")\nsloth&gt; result = fs.read(\"README.md\")\nsloth&gt; print(string.sub(result, 1, 50))\n</code></pre>"},{"location":"en/repl/#autocompletion","title":"Autocompletion","text":"<p>The REPL has a sophisticated autocompletion system. - Start typing the name of a global variable or module (e.g., <code>aws</code>) and press <code>Tab</code> to see suggestions. - Type a module name followed by a dot (e.g., <code>docker.</code>) and press <code>Tab</code> to see all the functions available in that module.</p>"},{"location":"en/repl/#history","title":"History","text":"<p>The REPL keeps a history of your commands. Use the up and down arrow keys to navigate through previous commands.</p>"},{"location":"en/repl/#example-session","title":"Example Session","text":"<p>Here is an example of using the REPL to debug a Docker command.</p> <pre><code>$ sloth-runner repl\nSloth-Runner Interactive REPL\nType 'exit' or 'quit' to leave.\nsloth&gt; result = docker.exec({\"ps\", \"-a\"})\nsloth&gt; print(result.stdout)\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nsloth&gt; -- Now let's try to build an image\nsloth&gt; build_result = docker.build({tag=\"my-test\", path=\"./examples/docker\"})\nsloth&gt; print(build_result.success)\ntrue\nsloth&gt; exit\nBye!\n</code></pre>"},{"location":"en/stack-management/","title":"\ud83d\uddc2\ufe0f Stack Management","text":"<p>Sloth Runner provides a complete stack management system similar to Pulumi, allowing you to persist workflow state and track executions over time.</p>"},{"location":"en/stack-management/#introduction","title":"\ud83d\ude80 Introduction","text":"<p>Stack Management in Sloth Runner enables:</p> <ul> <li>Persist state between executions</li> <li>Track outputs exported from pipeline</li> <li>Complete history of executions</li> <li>Intuitive CLI management</li> <li>Isolation by environment/project</li> </ul>"},{"location":"en/stack-management/#basic-syntax","title":"\ud83d\udcdd Basic Syntax","text":""},{"location":"en/stack-management/#running-with-stack","title":"Running with Stack","text":"<pre><code># New syntax - stack name as positional argument\nsloth-runner run {stack-name} --file workflow.sloth\n\n# Practical examples\nsloth-runner run production-app -f deploy.sloth --output enhanced\nsloth-runner run dev-environment -f test.sloth -o rich\nsloth-runner run my-cicd -f pipeline.sloth\n</code></pre>"},{"location":"en/stack-management/#managing-stacks","title":"Managing Stacks","text":"<pre><code># List all stacks\nsloth-runner stack list\n\n# Show stack details\nsloth-runner stack show production-app\n\n# Delete stack\nsloth-runner stack delete old-environment\n</code></pre>"},{"location":"en/stack-management/#core-concepts","title":"\ud83c\udfaf Core Concepts","text":""},{"location":"en/stack-management/#stack-state","title":"Stack State","text":"<p>Each stack maintains:</p> <ul> <li>Unique ID (UUID)</li> <li>Stack name</li> <li>Current status (created, running, completed, failed)</li> <li>Exported outputs from pipeline</li> <li>Execution history</li> <li>Metadata and configurations</li> </ul>"},{"location":"en/stack-management/#lifecycle","title":"Lifecycle","text":"<ol> <li>Creation: Stack is automatically created on first execution</li> <li>Execution: State is updated during execution</li> <li>Persistence: Outputs and results are saved</li> <li>Reuse: Subsequent executions reuse the stack</li> </ol>"},{"location":"en/stack-management/#state-persistence","title":"\ud83d\udcbe State Persistence","text":""},{"location":"en/stack-management/#database","title":"Database","text":"<p>Sloth Runner uses SQLite to persist state:</p> <pre><code>~/.sloth-runner/stacks.db\n</code></pre>"},{"location":"en/stack-management/#tables","title":"Tables","text":"<ul> <li>stacks: Main stack information</li> <li>stack_executions: Detailed execution history</li> </ul>"},{"location":"en/stack-management/#exported-outputs","title":"\ud83d\udcca Exported Outputs","text":""},{"location":"en/stack-management/#automatic-capture","title":"Automatic Capture","text":"<p>The system automatically captures:</p> <ul> <li>TaskRunner exports (<code>runner.Exports</code>)</li> <li>Global <code>outputs</code> variable from Lua</li> <li>Execution metadata</li> </ul>"},{"location":"en/stack-management/#export-example","title":"Export Example","text":"<pre><code>local deploy_task = task(\"deploy\")\n    :command(function(params, deps)\n        -- Deploy logic...\n\n        -- Export outputs to stack\n        runner.Export({\n            app_url = \"https://myapp.example.com\",\n            version = \"1.2.3\",\n            environment = \"production\",\n            deployed_at = os.date()\n        })\n\n        return true, \"Deploy successful\", deploy_info\n    end)\n    :build()\n</code></pre>"},{"location":"en/stack-management/#cli-interface","title":"\ud83d\udda5\ufe0f CLI Interface","text":""},{"location":"en/stack-management/#stack-list","title":"Stack List","text":"<pre><code>$ sloth-runner stack list\n\nWorkflow Stacks     \n\nNAME                  STATUS     LAST RUN           DURATION     EXECUTIONS\n----                  ------     --------           --------     ----------\nproduction-app        completed  2025-09-29 19:27   6.8s         5\ndev-environment       running    2025-09-29 19:25   2.1s         12\nstaging-api           failed     2025-09-29 19:20   4.2s         3\n</code></pre>"},{"location":"en/stack-management/#stack-details","title":"Stack Details","text":"<pre><code>$ sloth-runner stack show production-app\n\nStack: production-app     \n\nID: abc123-def456-789\nStatus: completed\nCreated: 2025-09-29 15:30:21\nUpdated: 2025-09-29 19:27:15\nExecutions: 5\nLast Duration: 6.8s\n\n     Outputs     \n\napp_url: \"https://myapp.example.com\"\nversion: \"1.2.3\"\nenvironment: \"production\"\ndeployed_at: \"2025-09-29 19:27:15\"\n\n     Recent Executions     \n\nSTARTED            STATUS     DURATION   TASKS   SUCCESS   FAILED\n-------            ------     --------   -----   -------   ------\n2025-09-29 19:27   completed  6.8s       3       3         0\n2025-09-29 18:45   completed  7.2s       3       3         0\n2025-09-29 17:30   failed     4.1s       3       2         1\n</code></pre>"},{"location":"en/stack-management/#output-styles","title":"\ud83c\udfa8 Output Styles","text":""},{"location":"en/stack-management/#configurable-per-execution","title":"Configurable per Execution","text":"<pre><code># Basic output (default)\nsloth-runner run my-stack -f workflow.sloth\n\n# Enhanced output\nsloth-runner run my-stack -f workflow.sloth --output enhanced\nsloth-runner run my-stack -f workflow.sloth -o rich\nsloth-runner run my-stack -f workflow.sloth --output modern\n</code></pre>"},{"location":"en/stack-management/#pulumi-style","title":"Pulumi Style","text":"<p>The <code>enhanced</code> output provides rich formatting similar to Pulumi:</p> <pre><code>\ud83e\udda5 Sloth Runner\n\n     Workflow: production-app     \n\nStarted at: 2025-09-29 19:27:15\n\n\u2713 build (2.1s) completed\n\u2713 test (3.2s) completed  \n\u2713 deploy (1.5s) completed\n\n     Workflow Completed Successfully     \n\n\u2713 production-app\nDuration: 6.8s\nTasks executed: 3\n\n     Outputs     \n\n\u251c\u2500 exports:\n  \u2502 app_url: \"https://myapp.example.com\"\n  \u2502 version: \"1.2.3\"\n  \u2502 environment: \"production\"\n</code></pre>"},{"location":"en/stack-management/#use-cases","title":"\ud83d\udd27 Use Cases","text":""},{"location":"en/stack-management/#separate-environments","title":"Separate Environments","text":"<pre><code># Development\nsloth-runner run dev-app -f app.sloth\n\n# Staging  \nsloth-runner run staging-app -f app.sloth\n\n# Production\nsloth-runner run prod-app -f app.sloth --output enhanced\n</code></pre>"},{"location":"en/stack-management/#cicd-integration","title":"CI/CD Integration","text":"<pre><code># In CI/CD pipeline\nsloth-runner run ${ENVIRONMENT}-${APP_NAME} -f pipeline.sloth\n\n# Examples:\nsloth-runner run prod-frontend -f frontend-deploy.sloth\nsloth-runner run staging-api -f api-deploy.sloth\n</code></pre>"},{"location":"en/stack-management/#monitoring","title":"Monitoring","text":"<pre><code># View status of all environments\nsloth-runner stack list\n\n# Check last production deployment\nsloth-runner stack show prod-app\n\n# Clean up test environments\nsloth-runner stack delete temp-test-env\n</code></pre>"},{"location":"en/stack-management/#best-practices","title":"\ud83d\udee0\ufe0f Best Practices","text":""},{"location":"en/stack-management/#stack-naming","title":"Stack Naming","text":"<pre><code># Use pattern: {environment}-{application}\nsloth-runner run prod-frontend -f deploy.sloth\nsloth-runner run staging-api -f deploy.sloth\nsloth-runner run dev-database -f setup.sloth\n</code></pre>"},{"location":"en/stack-management/#output-exports","title":"Output Exports","text":"<pre><code>-- Export relevant information\nrunner.Export({\n    -- Important URLs\n    app_url = deploy_info.url,\n    admin_url = deploy_info.admin_url,\n\n    -- Version information\n    version = build_info.version,\n    commit_hash = build_info.commit,\n\n    -- Environment settings\n    environment = config.environment,\n    region = config.region,\n\n    -- Timestamps\n    deployed_at = os.date(),\n    build_time = build_info.timestamp\n})\n</code></pre>"},{"location":"en/stack-management/#lifecycle-management","title":"Lifecycle Management","text":"<pre><code># Active development\nsloth-runner run dev-app -f app.sloth\n\n# When ready for staging\nsloth-runner run staging-app -f app.sloth\n\n# Deploy to production\nsloth-runner run prod-app -f app.sloth --output enhanced\n\n# Clean up old environments\nsloth-runner stack delete old-test-branch\n</code></pre>"},{"location":"en/stack-management/#migration","title":"\ud83d\udd04 Migration","text":""},{"location":"en/stack-management/#old-vs-new-commands","title":"Old vs New Commands","text":"<pre><code># Before\nsloth-runner run -f workflow.sloth --stack my-stack\n\n# Now\nsloth-runner run my-stack -f workflow.sloth\n</code></pre>"},{"location":"en/stack-management/#compatibility","title":"Compatibility","text":"<ul> <li>Existing workflows continue to work</li> <li>Stack is optional - can run without specifying</li> <li>Outputs are captured automatically when stack is used</li> </ul>"},{"location":"en/stack-management/#next-steps","title":"\ud83d\udcda Next Steps","text":"<ul> <li>Output Styles - Output style configuration</li> <li>Workflow Scaffolding - Project creation</li> <li>Examples - Practical examples</li> <li>CLI Reference - Complete command reference</li> </ul>"},{"location":"en/testing/","title":"Testing Workflows","text":"<p>The sloth-runner includes a built-in testing framework that allows you to write unit and integration tests for your task workflows. Writing tests for your automation is crucial for ensuring reliability, preventing regressions, and having confidence when making changes.</p>"},{"location":"en/testing/#the-test-command","title":"The <code>test</code> Command","text":"<p>You can run a test file using the <code>sloth-runner test</code> command. It requires two main files: the workflow you want to test and the test script itself.</p> <pre><code>sloth-runner test -w &lt;path_to_workflow.sloth&gt; -f &lt;path_to_test_file.sloth&gt;\n</code></pre> <ul> <li><code>-w, --workflow</code>: Specifies the path to the main <code>Modern DSLs</code> file that you want to test.</li> <li><code>-f, --file</code>: Specifies the path to your test file.</li> </ul>"},{"location":"en/testing/#writing-tests","title":"Writing Tests","text":"<p>Tests are written in Lua and use two new global modules provided by the test runner: <code>test</code> and <code>assert</code>.</p>"},{"location":"en/testing/#the-test-module","title":"The <code>test</code> Module","text":"<p>The <code>test</code> module is used to structure your tests and to run specific tasks from your workflow.</p> <ul> <li><code>test.describe(suite_name, function)</code>: Groups related tests into a \"suite\". This is for organization.</li> <li><code>test.it(function)</code>: Defines an individual test case. The description of the test should be included in the assertion messages inside this function.</li> <li><code>test.run_task(task_name)</code>: This is the core function of the testing framework. It executes a single task by its name from the loaded workflow file. It returns a <code>result</code> table containing the execution details.</li> </ul> <p>The <code>result</code> table returned by <code>run_task</code> has the following structure:</p> <pre><code>{\n  success = true, -- boolean: true if the task succeeded, false otherwise\n  message = \"Task executed successfully\", -- string: The message returned by the task\n  duration = \"1.23ms\", -- string: The execution duration\n  output = { ... }, -- table: The output table returned by the task\n  error = nil -- string: The error message if the task failed\n}\n</code></pre>"},{"location":"en/testing/#the-assert-module","title":"The <code>assert</code> Module","text":"<p>The <code>assert</code> module provides functions to check the results of your task executions.</p> <ul> <li><code>assert.is_true(value, message)</code>: Checks if the <code>value</code> is true.</li> <li><code>assert.equals(actual, expected, message)</code>: Checks if the <code>actual</code> value is equal to the <code>expected</code> value.</li> </ul>"},{"location":"en/testing/#mocking-modules","title":"Mocking Modules","text":"<p>To test the logic of your pipelines without making real external calls (e.g., to AWS, Docker, or Terraform), the testing framework includes a powerful mocking feature.</p>"},{"location":"en/testing/#strict-mocking-policy","title":"Strict Mocking Policy","text":"<p>The test runner enforces a strict mocking policy. When running in test mode, any call to a module function (like <code>aws.exec</code> or <code>docker.build</code>) that has not been explicitly mocked will cause the test to fail immediately. This ensures that your tests are fully self-contained, deterministic, and do not have unintended side effects.</p>"},{"location":"en/testing/#testmockfunction_name-mock_definition","title":"<code>test.mock(function_name, mock_definition)</code>","text":"<p>This function allows you to define a fake return value for any mockable module function.</p> <ul> <li><code>function_name</code> (string): The full name of the function to mock (e.g., <code>\"aws.s3.sync\"</code>, <code>\"docker.build\"</code>).</li> <li><code>mock_definition</code> (table): A table that defines what the mocked function should return. It must contain a <code>returns</code> key, which is a list of the values the function will return.</li> </ul> <p>The <code>returns</code> list is crucial because Lua functions can return multiple values.</p> <p>Example:</p> <pre><code>-- Mock a function that returns a single result table\ntest.mock(\"docker.build\", {\n  returns = {\n    { success = true, stdout = \"Successfully built image\" }\n  }\n})\n\n-- Mock a function that returns two values (e.g., a value and an error)\n-- This simulates a successful call to terraform.output\ntest.mock(\"terraform.output\", {\n  returns = { \"my_file.txt\", nil }\n})\n\n-- This simulates a failed call\ntest.mock(\"terraform.output\", {\n  returns = { nil, \"output not found\" }\n})\n</code></pre>"},{"location":"en/testing/#complete-mocking-example","title":"Complete Mocking Example","text":"<p>Let's say you have a task that calls <code>aws.exec</code> and has logic that depends on the output.</p> <p>Task in <code>my_workflow.sloth</code>: <pre><code>-- ...\n{\n  name = \"check-account\",\n  command = function()\n    local result = aws.exec({\"sts\", \"get-caller-identity\"})\n    local data = data.parse_json(result.stdout)\n    if data.Account == \"123456789012\" then\n      return true, \"Correct account.\"\n    else\n      return false, \"Wrong account.\"\n    end\n  end\n}\n-- ...\n</code></pre></p> <p>Test in <code>my_test.sloth</code>: <pre><code>test.describe(\"Account Check Logic\", function()\n  test.it(function()\n    -- Mock the return value of aws.exec\n    test.mock(\"aws.exec\", {\n      returns = {\n        {\n          success = true,\n          stdout = '{\"Account\": \"123456789012\"}'\n        }\n      }\n    })\n\n    -- Run the task that uses the mock\n    local result = test.run_task(\"check-account\")\n\n    -- Assert that the task's logic worked correctly with the mocked data\n    assert.is_true(result.success, \"Task should succeed with the correct account ID\")\n    assert.equals(result.message, \"Correct account.\", \"Message should be correct\")\n  end)\nend)\n</code></pre></p>"},{"location":"en/modules/ai/","title":"\ud83e\udd16 AI Module - Complete API Reference","text":"<p>The AI module provides artificial intelligence capabilities for task optimization, failure prediction, and performance analytics.</p>"},{"location":"en/modules/ai/#module-overview","title":"\ud83d\udccb Module Overview","text":"<pre><code>local ai = require(\"ai\")\n</code></pre> <p>The AI module is the core of Sloth Runner's intelligence features, providing:</p> <ul> <li>\ud83d\udd2e Predictive Failure Detection - Predict task failures before they happen</li> <li>\u26a1 Intelligent Optimization - Automatically optimize commands for better performance  </li> <li>\ud83d\udcca Performance Analytics - Analyze execution patterns and trends</li> <li>\ud83e\udde0 Adaptive Learning - Continuous improvement from execution history</li> </ul>"},{"location":"en/modules/ai/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"en/modules/ai/#aiconfigureconfig","title":"<code>ai.configure(config)</code>","text":"<p>Configure AI behavior and capabilities.</p> <pre><code>ai.configure({\n    enabled = true,                    -- Enable/disable AI features\n    learning_mode = \"adaptive\",        -- adaptive | aggressive | conservative\n    optimization_level = 8,            -- 1-10 (higher = more aggressive)\n    failure_prediction = true,         -- Enable failure prediction\n    auto_optimize = true,              -- Automatically apply optimizations\n    confidence_threshold = 0.7         -- Minimum confidence for auto-apply\n})\n</code></pre> <p>Parameters: - <code>enabled</code> (boolean): Enable or disable all AI features - <code>learning_mode</code> (string): Learning aggressiveness level - <code>optimization_level</code> (number): Optimization aggressiveness (1-10) - <code>failure_prediction</code> (boolean): Enable predictive failure detection - <code>auto_optimize</code> (boolean): Automatically apply high-confidence optimizations - <code>confidence_threshold</code> (number): Minimum confidence score for auto-application</p>"},{"location":"en/modules/ai/#aiget_config","title":"<code>ai.get_config()</code>","text":"<p>Get current AI configuration.</p> <pre><code>local config = ai.get_config()\n-- Returns: {enabled: true, learning_mode: \"adaptive\", ...}\n</code></pre>"},{"location":"en/modules/ai/#optimization","title":"\u26a1 Optimization","text":""},{"location":"en/modules/ai/#aioptimize_commandcommand-options","title":"<code>ai.optimize_command(command, options)</code>","text":"<p>Get AI optimization suggestions for a command.</p> <pre><code>local result = ai.optimize_command(\"go build -o app ./cmd/main.go\", {\n    history = ai.get_task_history(\"go build\"),\n    system_resources = {\n        cpu_usage = 45,\n        memory_usage = 60,\n        load_avg = 1.2\n    },\n    similar_tasks = ai.find_similar_tasks(\"go build\", 10),\n    environment = \"production\"\n})\n</code></pre> <p>Parameters: - <code>command</code> (string): Original command to optimize - <code>options</code> (table): Optimization context   - <code>history</code> (array): Historical executions of this command   - <code>system_resources</code> (table): Current system resource usage   - <code>similar_tasks</code> (array): Similar task executions   - <code>environment</code> (string): Execution environment (dev/staging/prod)</p> <p>Returns: <pre><code>{\n    original_command = \"go build -o app ./cmd/main.go\",\n    optimized_command = \"go build -p 4 -ldflags='-s -w' -o app ./cmd/main.go\",\n    confidence_score = 0.85,           -- 0.0-1.0\n    expected_speedup = 2.3,            -- Expected performance multiplier\n    optimizations = {                  -- Applied optimizations\n        {\n            type = \"parallelization\",\n            description = \"Added -p 4 for parallel compilation\",\n            impact = 1.8\n        },\n        {\n            type = \"size_optimization\", \n            description = \"Added -ldflags='-s -w' to reduce binary size\",\n            impact = 0.5\n        }\n    },\n    resource_savings = {\n        estimated_time_saved = \"1.2s\",\n        memory_efficiency = \"+15%\"\n    },\n    rationale = \"Command shows parallelization opportunities based on system CPU count\"\n}\n</code></pre></p>"},{"location":"en/modules/ai/#failure-prediction","title":"\ud83d\udd2e Failure Prediction","text":""},{"location":"en/modules/ai/#aipredict_failuretask_name-command-options","title":"<code>ai.predict_failure(task_name, command, options)</code>","text":"<p>Predict the probability of task failure.</p> <pre><code>local prediction = ai.predict_failure(\"deploy_task\", \"kubectl apply -f deployment.yaml\", {\n    history = ai.get_task_history(\"kubectl apply\"),\n    environment = \"production\",\n    system_state = {\n        disk_usage = 85,\n        network_latency = 120\n    }\n})\n</code></pre> <p>Parameters: - <code>task_name</code> (string): Name of the task being analyzed - <code>command</code> (string): Command to be executed - <code>options</code> (table): Prediction context   - <code>history</code> (array): Historical executions   - <code>environment</code> (string): Execution environment   - <code>system_state</code> (table): Current system state</p> <p>Returns: <pre><code>{\n    failure_probability = 0.23,        -- 0.0-1.0\n    confidence = 0.78,                 -- Confidence in prediction\n    risk_factors = {                   -- Identified risk factors\n        {\n            type = \"resource_contention\",\n            description = \"High disk usage detected (85%)\",\n            impact = 0.6,\n            severity = \"medium\"\n        },\n        {\n            type = \"network_latency\",\n            description = \"Elevated network latency (120ms)\",\n            impact = 0.3,\n            severity = \"low\"\n        }\n    },\n    recommendations = {                -- AI-generated recommendations\n        \"Consider waiting for disk usage to decrease below 80%\",\n        \"Add timeout configuration to handle network latency\",\n        \"Implement retry logic with exponential backoff\"\n    },\n    similar_failures = {               -- Historical similar failures\n        count = 3,\n        common_causes = [\"network_timeout\", \"resource_exhaustion\"]\n    }\n}\n</code></pre></p>"},{"location":"en/modules/ai/#performance-analytics","title":"\ud83d\udcca Performance Analytics","text":""},{"location":"en/modules/ai/#aianalyze_performancecommand-options","title":"<code>ai.analyze_performance(command, options)</code>","text":"<p>Analyze performance patterns for a command or task.</p> <pre><code>local analysis = ai.analyze_performance(\"go build\", {\n    time_range = \"30d\",                -- 1d, 7d, 30d, 90d\n    environment = \"all\",               -- all, dev, staging, prod\n    include_failures = true\n})\n</code></pre> <p>Parameters: - <code>command</code> (string): Command to analyze - <code>options</code> (table): Analysis options   - <code>time_range</code> (string): Time range for analysis   - <code>environment</code> (string): Environment filter   - <code>include_failures</code> (boolean): Include failed executions</p> <p>Returns: <pre><code>{\n    total_executions = 156,\n    success_rate = 0.94,               -- 94% success rate\n    avg_execution_time = \"2.3s\",\n    fastest_execution = \"1.1s\",\n    slowest_execution = \"5.7s\",\n    performance_trend = \"improving\",    -- improving | stable | degrading\n    insights = {                       -- AI-generated insights\n        \"Performance improved 23% over the last 30 days\",\n        \"Failures primarily occur during high system load\",\n        \"Consider caching to improve cold-start performance\"\n    },\n    recommendations = {\n        \"Enable build caching to reduce average execution time\",\n        \"Implement resource monitoring for failure prevention\"\n    },\n    patterns = {                       -- Detected patterns\n        peak_hours = [\"09:00-10:00\", \"14:00-15:00\"],\n        failure_correlation = [\"high_cpu_usage\", \"memory_pressure\"]\n    }\n}\n</code></pre></p>"},{"location":"en/modules/ai/#aiget_task_statstask_name","title":"<code>ai.get_task_stats(task_name)</code>","text":"<p>Get aggregated statistics for a specific task.</p> <pre><code>local stats = ai.get_task_stats(\"build_application\")\n</code></pre> <p>Returns: <pre><code>{\n    task_name = \"build_application\",\n    total_runs = 89,\n    success_count = 84,\n    failure_count = 5,\n    success_rate = 0.944,              -- 94.4%\n    total_time = \"3m 45s\",\n    avg_time = \"2.5s\",\n    fastest_time = \"1.2s\",\n    slowest_time = \"8.1s\",\n    last_execution = \"2024-01-15T10:30:00Z\",\n    trend = \"stable\"\n}\n</code></pre></p>"},{"location":"en/modules/ai/#learning-history","title":"\ud83e\udde0 Learning &amp; History","text":""},{"location":"en/modules/ai/#airecord_executionexecution_data","title":"<code>ai.record_execution(execution_data)</code>","text":"<p>Record task execution for AI learning.</p> <pre><code>ai.record_execution({\n    task_name = \"build_application\",\n    command = \"go build -o app ./cmd/main.go\",\n    success = true,\n    execution_time = \"2.5s\",\n    start_time = os.time(),\n    end_time = os.time() + 2.5,\n    parameters = {\n        environment = \"development\",\n        go_version = \"1.21.0\",\n        parallel = true\n    },\n    system_resources = {\n        cpu_usage = 45,\n        memory_usage = 60,\n        disk_usage = 30\n    },\n    error_message = nil,               -- If success = false\n    optimization_applied = true,\n    ai_confidence = 0.85\n})\n</code></pre> <p>Parameters: - <code>task_name</code> (string): Name of the executed task - <code>command</code> (string): Command that was executed - <code>success</code> (boolean): Whether execution was successful - <code>execution_time</code> (string): Time taken to execute - <code>parameters</code> (table): Execution parameters and context - <code>system_resources</code> (table): System resource state during execution - <code>error_message</code> (string): Error message if failed - <code>optimization_applied</code> (boolean): Whether AI optimization was used - <code>ai_confidence</code> (number): Confidence score if optimization was applied</p>"},{"location":"en/modules/ai/#aiget_task_historycommand-limit","title":"<code>ai.get_task_history(command, limit)</code>","text":"<p>Get execution history for a command.</p> <pre><code>local history = ai.get_task_history(\"go build\", 20)\n-- Returns array of execution records\n</code></pre>"},{"location":"en/modules/ai/#aifind_similar_taskscommand-limit","title":"<code>ai.find_similar_tasks(command, limit)</code>","text":"<p>Find tasks similar to the given command.</p> <pre><code>local similar = ai.find_similar_tasks(\"go build -o app\", 10)\n-- Returns array of similar task executions\n</code></pre>"},{"location":"en/modules/ai/#insights-recommendations","title":"\ud83d\udca1 Insights &amp; Recommendations","text":""},{"location":"en/modules/ai/#aigenerate_insightsoptions","title":"<code>ai.generate_insights(options)</code>","text":"<p>Generate AI-powered insights about task execution patterns.</p> <pre><code>local insights = ai.generate_insights({\n    scope = \"global\",                  -- global | task | command\n    task_name = \"build_application\",   -- if scope = \"task\"\n    time_range = \"7d\"\n})\n</code></pre> <p>Returns: <pre><code>{\n    \"Tasks executed during business hours have 15% lower failure rate\",\n    \"Commands with parallel flags show 40% better performance\", \n    \"Memory-intensive tasks perform better with explicit heap size settings\",\n    \"Network-dependent tasks should include timeout and retry configurations\"\n}\n</code></pre></p>"},{"location":"en/modules/ai/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"en/modules/ai/#1-always-record-executions","title":"1. Always Record Executions","text":"<pre><code>-- Record every execution for AI learning\nworkflow.define(\"my_pipeline\", {\n    on_task_complete = function(task_name, success, output)\n        ai.record_execution({\n            task_name = task_name,\n            command = output.command,\n            success = success,\n            execution_time = output.duration\n        })\n    end\n})\n</code></pre>"},{"location":"en/modules/ai/#2-use-confidence-thresholds","title":"2. Use Confidence Thresholds","text":"<pre><code>-- Only apply high-confidence optimizations\nlocal optimization = ai.optimize_command(command)\nif optimization.confidence_score &gt; 0.8 then\n    command = optimization.optimized_command\n    log.info(\"Applied AI optimization with \" .. (optimization.confidence_score * 100) .. \"% confidence\")\nend\n</code></pre>"},{"location":"en/modules/ai/#3-monitor-predictions","title":"3. Monitor Predictions","text":"<pre><code>-- Always check predictions for critical tasks\nlocal prediction = ai.predict_failure(task_name, command)\nif prediction.failure_probability &gt; 0.3 then\n    log.warn(\"High failure risk detected: \" .. (prediction.failure_probability * 100) .. \"%\")\n    for _, rec in ipairs(prediction.recommendations) do\n        log.info(\"Recommendation: \" .. rec)\n    end\nend\n</code></pre>"},{"location":"en/modules/ai/#4-regular-analysis","title":"4. Regular Analysis","text":"<pre><code>-- Periodic performance analysis\nlocal analysis = ai.analyze_performance(\"critical_task\")\nif analysis.performance_trend == \"degrading\" then\n    log.warn(\"Performance degradation detected for critical_task\")\n    -- Take action\nend\n</code></pre>"},{"location":"en/modules/ai/#advanced-features","title":"\ud83d\udd2c Advanced Features","text":""},{"location":"en/modules/ai/#learning-modes","title":"Learning Modes","text":"<ul> <li>Adaptive: Balanced learning and optimization (recommended)</li> <li>Aggressive: Maximum optimization attempts, higher risk</li> <li>Conservative: Minimal changes, maximum safety</li> </ul>"},{"location":"en/modules/ai/#optimization-strategies","title":"Optimization Strategies","text":"<p>The AI system includes multiple built-in optimization strategies: - Parallelization: Detect parallel execution opportunities - Memory Optimization: Adjust memory settings for optimal performance - Compiler Optimization: Suggest better compiler flags and options - Caching: Implement intelligent caching strategies - Network Optimization: Optimize network operations and timeouts - I/O Optimization: Improve file and disk operations</p>"},{"location":"en/modules/ai/#custom-metrics","title":"Custom Metrics","text":"<p>You can provide custom metrics to improve AI analysis:</p> <pre><code>ai.record_execution({\n    task_name = \"custom_task\",\n    success = true,\n    execution_time = \"1.5s\",\n    custom_metrics = {\n        memory_peak = \"512MB\",\n        cache_hit_rate = 0.85,\n        network_requests = 15,\n        database_queries = 8\n    }\n})\n</code></pre>"},{"location":"en/modules/ai/#integration-examples","title":"\ud83d\ude80 Integration Examples","text":""},{"location":"en/modules/ai/#with-modern-dsl","title":"With Modern DSL","text":"<pre><code>local build_task = task(\"ai_optimized_build\")\n    :description(\"Build with AI optimization\")\n    :command(function(params, deps)\n        local cmd = \"go build -o app ./cmd/main.go\"\n        local optimization = ai.optimize_command(cmd, {\n            history = ai.get_task_history(cmd)\n        })\n\n        if optimization.confidence_score &gt; 0.7 then\n            return exec.run(optimization.optimized_command)\n        else\n            return exec.run(cmd)\n        end\n    end)\n    :on_success(function(params, output)\n        ai.record_execution({\n            task_name = \"ai_optimized_build\",\n            command = output.command,\n            success = true,\n            execution_time = output.duration\n        })\n    end)\n    :build()\n</code></pre>"},{"location":"en/modules/ai/#with-gitops","title":"With GitOps","text":"<pre><code>local gitops_task = task(\"intelligent_deploy\")\n    :command(function(params, deps)\n        local deploy_cmd = \"kubectl apply -f manifests/\"\n\n        -- AI failure prediction\n        local prediction = ai.predict_failure(\"intelligent_deploy\", deploy_cmd)\n        if prediction.failure_probability &gt; 0.25 then\n            log.warn(\"High deployment risk detected\")\n            return {success = false, message = \"Deployment blocked by AI risk assessment\"}\n        end\n\n        -- GitOps deployment\n        return gitops.sync_workflow(params.workflow_id)\n    end)\n    :build()\n</code></pre>"},{"location":"en/modules/ai/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>AI Features Overview</li> <li>Performance Optimization Guide</li> <li>Failure Prediction Guide</li> <li>AI Best Practices</li> </ul>"},{"location":"en/modules/aws/","title":"AWS Module","text":"<p>The <code>aws</code> module provides a comprehensive interface for interacting with Amazon Web Services using the AWS CLI. It is designed to work seamlessly with standard AWS credential chains and also has first-class support for <code>aws-vault</code> for enhanced security.</p>"},{"location":"en/modules/aws/#configuration","title":"Configuration","text":"<p>No specific configuration in <code>values.yaml</code> is required. The module relies on your environment being configured to interact with AWS. This can be achieved through: - IAM roles for EC2 instances or ECS/EKS tasks. - Standard environment variables (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, etc.). - A configured <code>~/.aws/credentials</code> file. - Using <code>aws-vault</code> with a named profile.</p>"},{"location":"en/modules/aws/#generic-executor","title":"Generic Executor","text":""},{"location":"en/modules/aws/#awsexecargs-opts","title":"<code>aws.exec(args, opts)</code>","text":"<p>This is the core function of the module. It executes any AWS CLI command and returns the result.</p> <p>Parameters:</p> <ul> <li><code>args</code> (table): Required. A table of strings representing the command and arguments to pass to the AWS CLI (e.g., <code>{\"s3\", \"ls\", \"--recursive\"}</code>).</li> <li><code>opts</code> (table): Optional. A table of options for the execution.<ul> <li><code>profile</code> (string): If provided, the command will be executed using <code>aws-vault exec &lt;profile&gt; -- aws ...</code>. If omitted, it will run <code>aws ...</code> directly.</li> </ul> </li> </ul> <p>Returns:</p> <p>A table containing the following fields: - <code>stdout</code> (string): The standard output from the command. - <code>stderr</code> (string): The standard error from the command. - <code>exit_code</code> (number): The exit code of the command. <code>0</code> typically indicates success.</p> <p>Example:</p> <pre><code>-- Using default credentials\nlocal result = aws.exec({\"sts\", \"get-caller-identity\"})\nif result.exit_code == 0 then\n  print(result.stdout)\nend\n\n-- Using an aws-vault profile\nlocal result_with_profile = aws.exec({\"ec2\", \"describe-instances\"}, {profile = \"my-prod-profile\"})\n</code></pre>"},{"location":"en/modules/aws/#s3-helpers","title":"S3 Helpers","text":""},{"location":"en/modules/aws/#awss3syncparams","title":"<code>aws.s3.sync(params)</code>","text":"<p>A high-level wrapper for the <code>aws s3 sync</code> command, useful for synchronizing directories with S3.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>source</code> (string): Required. The source directory or S3 path.</li> <li><code>destination</code> (string): Required. The destination directory or S3 path.</li> <li><code>profile</code> (string): Optional. The <code>aws-vault</code> profile to use.</li> <li><code>delete</code> (boolean): Optional. If <code>true</code>, adds the <code>--delete</code> flag to the sync command.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local ok, err = aws.s3.sync({\n  source = \"./build\",\n  destination = \"s3://my-app-bucket/static\",\n  profile = \"deployment-profile\",\n  delete = true\n})\nif not ok then\n  log.error(\"S3 sync failed: \" .. err)\nend\n</code></pre>"},{"location":"en/modules/aws/#secrets-manager-helpers","title":"Secrets Manager Helpers","text":""},{"location":"en/modules/aws/#awssecretsmanagerget_secretparams","title":"<code>aws.secretsmanager.get_secret(params)</code>","text":"<p>Retrieves a secret's value from AWS Secrets Manager. This function simplifies the process by directly returning the <code>SecretString</code>.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>secret_id</code> (string): Required. The name or ARN of the secret to retrieve.</li> <li><code>profile</code> (string): Optional. The <code>aws-vault</code> profile to use.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>secret_string</code> (string) on success.</li> <li><code>nil, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local db_password, err = aws.secretsmanager.get_secret({\n  secret_id = \"production/database/password\",\n  profile = \"my-app-profile\"\n})\n\nif not db_password then\n  log.error(\"Failed to get secret: \" .. err)\n  return false, \"Config failed.\"\nend\n\n-- Now you can use the db_password variable\n</code></pre>"},{"location":"en/modules/azure/","title":"Azure Module","text":"<p>The <code>azure</code> module provides an interface for interacting with Microsoft Azure using the <code>az</code> command-line tool.</p>"},{"location":"en/modules/azure/#configuration","title":"Configuration","text":"<p>This module requires the <code>az</code> CLI to be installed and authenticated. Before running pipelines that use this module, you must log in to your Azure account:</p> <pre><code>az login\n</code></pre> <p>The module will use your logged-in credentials for all commands.</p>"},{"location":"en/modules/azure/#generic-executor","title":"Generic Executor","text":""},{"location":"en/modules/azure/#azureexecargs","title":"<code>azure.exec(args)</code>","text":"<p>Executes any <code>az</code> command. This function automatically adds the <code>--output json</code> flag (if not already present) to ensure that the output is machine-parsable.</p> <p>Parameters:</p> <ul> <li><code>args</code> (table): Required. A table of strings representing the command and arguments to pass to <code>az</code> (e.g., <code>{\"group\", \"list\", \"--location\", \"eastus\"}</code>).</li> </ul> <p>Returns:</p> <p>A table containing the following fields: - <code>stdout</code> (string): The standard output from the command (as a JSON string). - <code>stderr</code> (string): The standard error from the command. - <code>exit_code</code> (number): The exit code of the command. <code>0</code> typically indicates success.</p> <p>Example:</p> <pre><code>local result = azure.exec({\"account\", \"show\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"Logged in as: \" .. account_info.user.name)\n  end\nend\n</code></pre>"},{"location":"en/modules/azure/#resource-group-rg-helpers","title":"Resource Group (RG) Helpers","text":""},{"location":"en/modules/azure/#azurergdeleteparams","title":"<code>azure.rg.delete(params)</code>","text":"<p>Deletes a resource group.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>name</code> (string): Required. The name of the resource group to delete.</li> <li><code>yes</code> (boolean): Optional. If <code>true</code>, adds the <code>--yes</code> flag to bypass the confirmation prompt.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local ok, err = azure.rg.delete({\n  name = \"my-test-rg\",\n  yes = true\n})\nif not ok then\n  log.error(\"Failed to delete resource group: \" .. err)\nend\n</code></pre>"},{"location":"en/modules/azure/#virtual-machine-vm-helpers","title":"Virtual Machine (VM) Helpers","text":""},{"location":"en/modules/azure/#azurevmlistparams","title":"<code>azure.vm.list(params)</code>","text":"<p>Lists virtual machines.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): Optional. A table containing the following fields:<ul> <li><code>resource_group</code> (string): The name of a resource group to scope the list to. If omitted, lists VMs in the entire subscription.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>vms</code> (table) on success, where the table is a parsed JSON array of your VM objects.</li> <li><code>nil, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>-- List all VMs in the subscription\nlocal all_vms, err1 = azure.vm.list()\n\n-- List VMs in a specific resource group\nlocal specific_vms, err2 = azure.vm.list({resource_group = \"my-production-rg\"})\nif specific_vms then\n  for _, vm in ipairs(specific_vms) do\n    print(\"Found VM: \" .. vm.name)\n  end\nend\n</code></pre>"},{"location":"en/modules/data/","title":"Data Module","text":"<p>The <code>data</code> module provides functions for parsing and serializing data between Lua tables and common data formats like JSON and YAML.</p> <p>---\\n</p>"},{"location":"en/modules/data/#dataparse_jsonjson_string","title":"<code>data.parse_json(json_string)</code>","text":"<p>Parses a JSON string into a Lua table.</p> <ul> <li>Parameters:<ul> <li><code>json_string</code> (string): The JSON formatted string to parse.</li> </ul> </li> <li>Returns:<ul> <li><code>table</code>: The resulting Lua table.</li> <li><code>error</code>: An error object if parsing fails.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"en/modules/data/#datato_jsonlua_table","title":"<code>data.to_json(lua_table)</code>","text":"<p>Serializes a Lua table into a JSON string.</p> <ul> <li>Parameters:<ul> <li><code>lua_table</code> (table): The Lua table to serialize.</li> </ul> </li> <li>Returns:<ul> <li><code>string</code>: The resulting JSON string.</li> <li><code>error</code>: An error object if serialization fails.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"en/modules/data/#dataparse_yamlyaml_string","title":"<code>data.parse_yaml(yaml_string)</code>","text":"<p>Parses a YAML string into a Lua table.</p> <ul> <li>Parameters:<ul> <li><code>yaml_string</code> (string): The YAML formatted string to parse.</li> </ul> </li> <li>Returns:<ul> <li><code>table</code>: The resulting Lua table.</li> <li><code>error</code>: An error object if parsing fails.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"en/modules/data/#datato_yamllua_table","title":"<code>data.to_yaml(lua_table)</code>","text":"<p>Serializes a Lua table into a YAML string.</p> <ul> <li>Parameters:<ul> <li><code>lua_table</code> (table): The Lua table to serialize.</li> </ul> </li> <li>Returns:<ul> <li><code>string</code>: The resulting YAML string.</li> <li><code>error</code>: An error object if serialization fails.</li> </ul> </li> </ul>"},{"location":"en/modules/data/#example","title":"Example","text":"<pre><code>command = function()\n  local data = require(\"data\")\n\n  -- JSON Example\n  log.info(\"Testing JSON serialization...\")\n  local my_table = { name = \"sloth-runner\", version = 1.0, features = { \"tasks\", \"lua\" } }\n  local json_str, err = data.to_json(my_table)\n  if err then\n    return false, \"Failed to serialize to JSON: \" .. err\n  end\n  print(\"Serialized JSON: \" .. json_str)\n\n  log.info(\"Testing JSON parsing...\")\n  local parsed_table, err = data.parse_json(json_str)\n  if err then\n    return false, \"Failed to parse JSON: \" .. err\n  end\n  log.info(\"Parsed name from JSON: \" .. parsed_table.name)\n\n  -- YAML Example\n  log.info(\"Testing YAML serialization...\")\n  local yaml_str, err = data.to_yaml(my_table)\n  if err then\n    return false, \"Failed to serialize to YAML: \" .. err\n  end\n  print(\"Serialized YAML:\\n\" .. yaml_str)\n\n  log.info(\"Testing YAML parsing...\")\n  parsed_table, err = data.parse_yaml(yaml_str)\n  if err then\n    return false, \"Failed to parse YAML: \" .. err\n  end\n  log.info(\"Parsed version from YAML: \" .. parsed_table.version)\n\n  return true, \"Data module operations successful.\"\nend\n</code></pre>"},{"location":"en/modules/digitalocean/","title":"DigitalOcean Module","text":"<p>The <code>digitalocean</code> module provides an interface for interacting with your DigitalOcean resources using the <code>doctl</code> command-line tool.</p>"},{"location":"en/modules/digitalocean/#configuration","title":"Configuration","text":"<p>This module requires the <code>doctl</code> CLI to be installed and authenticated. The standard way to do this is to generate a personal access token in your DigitalOcean control panel and set it as the <code>DIGITALOCEAN_ACCESS_TOKEN</code> environment variable.</p> <pre><code>export DIGITALOCEAN_ACCESS_TOKEN=\"your_do_api_token_here\"\n</code></pre> <p>The module will automatically use this token for all commands.</p>"},{"location":"en/modules/digitalocean/#generic-executor","title":"Generic Executor","text":""},{"location":"en/modules/digitalocean/#digitaloceanexecargs","title":"<code>digitalocean.exec(args)</code>","text":"<p>Executes any <code>doctl</code> command. This function automatically adds the <code>--output json</code> flag to ensure that the output is machine-parsable.</p> <p>Parameters:</p> <ul> <li><code>args</code> (table): Required. A table of strings representing the command and arguments to pass to <code>doctl</code> (e.g., <code>{\"compute\", \"droplet\", \"list\"}</code>).</li> </ul> <p>Returns:</p> <p>A table containing the following fields: - <code>stdout</code> (string): The standard output from the command (as a JSON string). - <code>stderr</code> (string): The standard error from the command. - <code>exit_code</code> (number): The exit code of the command. <code>0</code> typically indicates success.</p> <p>Example:</p> <pre><code>local result = digitalocean.exec({\"account\", \"get\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"Account status: \" .. account_info.status)\n  end\nend\n</code></pre>"},{"location":"en/modules/digitalocean/#droplets-helpers","title":"Droplets Helpers","text":""},{"location":"en/modules/digitalocean/#digitaloceandropletslist","title":"<code>digitalocean.droplets.list()</code>","text":"<p>A high-level wrapper to list all Droplets in your account.</p> <p>Returns:</p> <ul> <li><code>droplets</code> (table) on success, where the table is a parsed JSON array of your Droplet objects.</li> <li><code>nil, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local droplets, err = digitalocean.droplets.list()\nif droplets then\n  for _, droplet in ipairs(droplets) do\n    print(\"Found Droplet: \" .. droplet.name)\n  end\nend\n</code></pre>"},{"location":"en/modules/digitalocean/#digitaloceandropletsdeleteparams","title":"<code>digitalocean.droplets.delete(params)</code>","text":"<p>Deletes a specific Droplet by its ID.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>id</code> (string): Required. The ID of the Droplet to delete.</li> <li><code>force</code> (boolean): Optional. If <code>true</code>, adds the <code>--force</code> flag to bypass the confirmation prompt. Defaults to <code>false</code>.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local ok, err = digitalocean.droplets.delete({\n  id = \"123456789\",\n  force = true\n})\nif not ok then\n  log.error(\"Failed to delete droplet: \" .. err)\nend\n</code></pre>"},{"location":"en/modules/docker/","title":"Docker Module","text":"<p>The <code>docker</code> module provides a convenient interface for interacting with the Docker daemon, allowing you to build, run, and push Docker images as part of your pipelines.</p>"},{"location":"en/modules/docker/#configuration","title":"Configuration","text":"<p>This module requires the <code>docker</code> CLI to be installed and the Docker daemon to be running and accessible.</p>"},{"location":"en/modules/docker/#functions","title":"Functions","text":""},{"location":"en/modules/docker/#dockerexecargs","title":"<code>docker.exec(args)</code>","text":"<p>Executes any raw <code>docker</code> command.</p> <ul> <li><code>args</code> (table): Required. A list of arguments to pass to the <code>docker</code> command (e.g., <code>{\"ps\", \"-a\"}</code>).</li> <li>Returns: A result table with <code>success</code>, <code>stdout</code>, <code>stderr</code>, and <code>exit_code</code>.</li> </ul>"},{"location":"en/modules/docker/#dockerbuildparams","title":"<code>docker.build(params)</code>","text":"<p>Builds a Docker image using <code>docker build</code>.</p> <ul> <li><code>params</code> (table):<ul> <li><code>tag</code> (string): Required. The tag for the image (e.g., <code>my-app:latest</code>).</li> <li><code>path</code> (string): Required. The build context path.</li> <li><code>dockerfile</code> (string): Optional. The path to the Dockerfile.</li> <li><code>build_args</code> (table): Optional. A table of build arguments (e.g., <code>{VERSION = \"1.0\"}</code>).</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"en/modules/docker/#dockerpushparams","title":"<code>docker.push(params)</code>","text":"<p>Pushes a Docker image to a registry using <code>docker push</code>.</p> <ul> <li><code>params</code> (table):<ul> <li><code>tag</code> (string): Required. The tag of the image to push.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"en/modules/docker/#dockerrunparams","title":"<code>docker.run(params)</code>","text":"<p>Runs a Docker container using <code>docker run</code>.</p> <ul> <li><code>params</code> (table):<ul> <li><code>image</code> (string): Required. The image to run.</li> <li><code>name</code> (string): Optional. The name for the container.</li> <li><code>detach</code> (boolean): Optional. If <code>true</code>, runs the container in the background (<code>-d</code>).</li> <li><code>ports</code> (table): Optional. A list of port mappings (e.g., <code>{\"8080:80\"}</code>).</li> <li><code>env</code> (table): Optional. A table of environment variables (e.g., <code>{MY_VAR = \"value\"}</code>).</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"en/modules/docker/#example","title":"Example","text":"<pre><code>local image_tag = \"my-test-image:latest\"\n\n-- Task 1: Build\nlocal result_build = docker.build({\n  tag = image_tag,\n  path = \"./app\"\n})\nif not result_build.success then return false, \"Build failed\" end\n\n-- Task 2: Run\nlocal result_run = docker.run({\n  image = image_tag,\n  name = \"my-test-container\",\n  ports = {\"8080:80\"}\n})\nif not result_run.success then return false, \"Run failed\" end\n\n-- Task 3: Push (after successful testing)\nlocal result_push = docker.push({tag = image_tag})\nif not result_push.success then return false, \"Push failed\" end\n</code></pre>"},{"location":"en/modules/exec/","title":"Exec Module","text":"<p>The <code>exec</code> module is one of the most fundamental modules in <code>sloth-runner</code>. It provides a powerful function to execute arbitrary shell commands, giving you full control over the execution environment.</p>"},{"location":"en/modules/exec/#execruncommand-options","title":"<code>exec.run(command, [options])</code>","text":"<p>Executes a shell command using <code>bash -c</code>.</p>"},{"location":"en/modules/exec/#parameters","title":"Parameters","text":"<ul> <li><code>command</code> (string): The shell command to execute.</li> <li><code>options</code> (table, optional): A table of options to control the execution.<ul> <li><code>workdir</code> (string): The working directory where the command should be executed. If not provided, it runs in the task group's temporary directory (if available) or the current directory.</li> <li><code>env</code> (table): A dictionary of environment variables (key-value pairs) to set for the command's execution. These are added to the existing environment.</li> </ul> </li> </ul>"},{"location":"en/modules/exec/#returns","title":"Returns","text":"<p>A table containing the result of the command execution:</p> <ul> <li><code>success</code> (boolean): <code>true</code> if the command exited with a code of <code>0</code>, otherwise <code>false</code>.</li> <li><code>stdout</code> (string): The standard output from the command.</li> <li><code>stderr</code> (string): The standard error output from the command.</li> </ul>"},{"location":"en/modules/exec/#example","title":"Example","text":"<p>This example demonstrates how to use <code>exec.run</code> with a custom working directory and environment variables.</p> <pre><code>-- examples/exec_module_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"A task to demonstrate the exec module.\",\n    tasks = {\n      {\n        name = \"run-with-options\",\n        description = \"Executes a command with a custom workdir and environment.\",\n        command = function()\n          log.info(\"Preparing to run a custom command...\")\n\n          local exec = require(\"exec\")\n\n          -- Create a temporary directory for the example\n          local temp_dir = \"/tmp/sloth-exec-test\"\n          fs.mkdir(temp_dir)\n          fs.write(temp_dir .. \"/test.txt\", \"hello from test file\")\n\n          -- Define options\n          local options = {\n            workdir = temp_dir,\n            env = {\n              MY_VAR = \"SlothRunner\",\n              ANOTHER_VAR = \"is_awesome\"\n            }\n          }\n\n          -- Execute the command\n          local result = exec.run(\"echo 'MY_VAR is $MY_VAR' &amp;&amp; ls -l &amp;&amp; cat test.txt\", options)\n\n          -- Clean up the temporary directory\n          fs.rm_r(temp_dir)\n\n          if result.success then\n            log.info(\"Command executed successfully!\")\n            print(\"--- STDOUT ---\")\n            print(result.stdout)\n            print(\"--------------\")\n            return true, \"Exec command successful.\"\n          else\n            log.error(\"Exec command failed.\")\n            log.error(\"Stderr: \" .. result.stderr)\n            return false, \"Exec command failed.\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/modules/fs/","title":"FS Module","text":"<p>The <code>fs</code> module provides essential functions for interacting with the file system directly from your Lua scripts.</p>"},{"location":"en/modules/fs/#fsreadpath","title":"<code>fs.read(path)</code>","text":"<p>Reads the entire content of a file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the file.</li> </ul> </li> <li>Returns:<ul> <li><code>string</code>: The content of the file.</li> <li><code>error</code>: An error object if the read fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fswritepath-content","title":"<code>fs.write(path, content)</code>","text":"<p>Writes content to a file, overwriting it if it already exists.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the file.</li> <li><code>content</code> (string): The content to write.</li> </ul> </li> <li>Returns:<ul> <li><code>error</code>: An error object if the write fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fsappendpath-content","title":"<code>fs.append(path, content)</code>","text":"<p>Appends content to the end of a file. Creates the file if it doesn't exist.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the file.</li> <li><code>content</code> (string): The content to append.</li> </ul> </li> <li>Returns:<ul> <li><code>error</code>: An error object if the append fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fsexistspath","title":"<code>fs.exists(path)</code>","text":"<p>Checks if a file or directory exists at the given path.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to check.</li> </ul> </li> <li>Returns:<ul> <li><code>boolean</code>: <code>true</code> if the path exists, <code>false</code> otherwise.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fsmkdirpath","title":"<code>fs.mkdir(path)</code>","text":"<p>Creates a directory at the given path, including any necessary parent directories (like <code>mkdir -p</code>).</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The directory path to create.</li> </ul> </li> <li>Returns:<ul> <li><code>error</code>: An error object if the creation fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fsrmpath","title":"<code>fs.rm(path)</code>","text":"<p>Removes a single file.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the file to remove.</li> </ul> </li> <li>Returns:<ul> <li><code>error</code>: An error object if the removal fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fsrm_rpath","title":"<code>fs.rm_r(path)</code>","text":"<p>Removes a file or directory recursively (like <code>rm -rf</code>).</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to remove.</li> </ul> </li> <li>Returns:<ul> <li><code>error</code>: An error object if the removal fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fslspath","title":"<code>fs.ls(path)</code>","text":"<p>Lists the contents of a directory.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the directory.</li> </ul> </li> <li>Returns:<ul> <li><code>table</code>: A table containing the names of files and subdirectories.</li> <li><code>error</code>: An error object if the listing fails.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#fstmpname","title":"<code>fs.tmpname()</code>","text":"<p>Generates a unique temporary directory path. Note: This function only returns the name; it does not create the directory.</p> <ul> <li>Returns:<ul> <li><code>string</code>: A unique path suitable for a temporary directory.</li> <li><code>error</code>: An error object if a name could not be generated.</li> </ul> </li> </ul>"},{"location":"en/modules/fs/#example","title":"Example","text":"<pre><code>command = function()\n  local fs = require(\"fs\")\n\n  local tmp_dir = \"/tmp/fs-example\"\n  log.info(\"Creating directory: \" .. tmp_dir)\n  fs.mkdir(tmp_dir)\n\n  local file_path = tmp_dir .. \"/my_file.txt\"\n  log.info(\"Writing to file: \" .. file_path)\n  fs.write(file_path, \"Hello, Sloth Runner!\\n\")\n\n  log.info(\"Appending to file...\")\n  fs.append(file_path, \"This is a new line.\")\n\n  if fs.exists(file_path) then\n    log.info(\"File content: \" .. fs.read(file_path))\n  end\n\n  log.info(\"Listing contents of \" .. tmp_dir)\n  local contents = fs.ls(tmp_dir)\n  for i, name in ipairs(contents) do\n    print(\"- \" .. name)\n  end\n\n  log.info(\"Cleaning up...\")\n  fs.rm_r(tmp_dir)\n\n  return true, \"FS module operations successful.\"\nend\n</code></pre>"},{"location":"en/modules/gcp/","title":"GCP Module","text":"<p>The <code>gcp</code> module provides a simple interface for executing Google Cloud CLI (<code>gcloud</code>) commands from within a <code>sloth-runner</code> task.</p>"},{"location":"en/modules/gcp/#gcpexecargs","title":"<code>gcp.exec(args)</code>","text":"<p>Executes a <code>gcloud</code> command with the specified arguments.</p>"},{"location":"en/modules/gcp/#parameters","title":"Parameters","text":"<ul> <li><code>args</code> (table): A Lua table (array) of strings representing the arguments to pass to the <code>gcloud</code> command. For example, <code>{\"compute\", \"instances\", \"list\"}</code>.</li> </ul>"},{"location":"en/modules/gcp/#returns","title":"Returns","text":"<p>A table containing the result of the command execution with the following keys:</p> <ul> <li><code>stdout</code> (string): The standard output from the command.</li> <li><code>stderr</code> (string): The standard error output from the command.</li> <li><code>exit_code</code> (number): The exit code of the command. An exit code of <code>0</code> typically indicates success.</li> </ul>"},{"location":"en/modules/gcp/#example","title":"Example","text":"<p>This example defines a task that lists all Compute Engine instances in the <code>us-central1</code> region for a specific project.</p> <pre><code>-- examples/gcp_cli_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"A task to list GCP compute instances.\",\n    tasks = {\n      {\n        name = \"list-instances\",\n        description = \"Lists GCE instances in us-central1.\",\n        command = function()\n          log.info(\"Listing GCP instances...\")\n\n          -- require the gcp module to make it available\n          local gcp = require(\"gcp\")\n\n          -- Execute the gcloud command\n          local result = gcp.exec({\n            \"compute\", \n            \"instances\", \n            \"list\", \n            \"--project\", \"my-gcp-project-id\",\n            \"--zones\", \"us-central1-a,us-central1-b\"\n          })\n\n          -- Check the result\n          if result and result.exit_code == 0 then\n            log.info(\"Successfully listed instances.\")\n            print(\"--- INSTANCE LIST ---\")\n            print(result.stdout)\n            print(\"---------------------\")\n            return true, \"GCP command successful.\"\n          else\n            log.error(\"Failed to list GCP instances.\")\n            if result then\n              log.error(\"Stderr: \" .. result.stderr)\n            end\n            return false, \"GCP command failed.\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"en/modules/git/","title":"Git Module","text":"<p>The <code>git</code> module provides a fluent API to interact with Git repositories, allowing you to automate common version control operations like cloning, committing, and pushing.</p>"},{"location":"en/modules/git/#gitcloneurl-path","title":"<code>git.clone(url, path)</code>","text":"<p>Clones a Git repository to a local path.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL of the repository to clone.</li> <li><code>path</code> (string): The local directory to clone into.</li> </ul> </li> <li>Returns:<ul> <li><code>repo</code> (object): A <code>GitRepo</code> object on success.</li> <li><code>error</code>: An error object if the clone fails.</li> </ul> </li> </ul>"},{"location":"en/modules/git/#gitrepopath","title":"<code>git.repo(path)</code>","text":"<p>Opens an existing local Git repository.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The path to the existing local repository.</li> </ul> </li> <li>Returns:<ul> <li><code>repo</code> (object): A <code>GitRepo</code> object on success.</li> <li><code>error</code>: An error object if the path is not a valid Git repository.</li> </ul> </li> </ul>"},{"location":"en/modules/git/#the-gitrepo-object","title":"The <code>GitRepo</code> Object","text":"<p>This object represents a local repository and provides chainable methods for performing Git operations.</p>"},{"location":"en/modules/git/#repocheckoutref","title":"<code>repo:checkout(ref)</code>","text":"<p>Checks out a specific branch, tag, or commit.</p> <ul> <li>Parameters: <code>ref</code> (string).</li> </ul>"},{"location":"en/modules/git/#repopullremote-branch","title":"<code>repo:pull(remote, branch)</code>","text":"<p>Pulls changes from a remote.</p> <ul> <li>Parameters: <code>remote</code> (string), <code>branch</code> (string).</li> </ul>"},{"location":"en/modules/git/#repoaddpattern","title":"<code>repo:add(pattern)</code>","text":"<p>Stages files for a commit.</p> <ul> <li>Parameters: <code>pattern</code> (string), e.g., <code>\".\"</code> or <code>\"path/to/file.txt\"</code>.</li> </ul>"},{"location":"en/modules/git/#repocommitmessage","title":"<code>repo:commit(message)</code>","text":"<p>Creates a commit.</p> <ul> <li>Parameters: <code>message</code> (string).</li> </ul>"},{"location":"en/modules/git/#repotagname-message","title":"<code>repo:tag(name, [message])</code>","text":"<p>Creates a new tag.</p> <ul> <li>Parameters: <code>name</code> (string), <code>message</code> (string, optional).</li> </ul>"},{"location":"en/modules/git/#repopushremote-branch-options","title":"<code>repo:push(remote, branch, [options])</code>","text":"<p>Pushes commits to a remote.</p> <ul> <li>Parameters:<ul> <li><code>remote</code> (string).</li> <li><code>branch</code> (string).</li> <li><code>options</code> (table, optional): e.g., <code>{ follow_tags = true }</code>.</li> </ul> </li> </ul>"},{"location":"en/modules/git/#reporesult","title":"<code>repo:result()</code>","text":"<p>This method is called at the end of a chain to get the result of the last operation.</p> <ul> <li>Returns:<ul> <li><code>result</code> (table): A table containing <code>success</code> (boolean), <code>stdout</code> (string), and <code>stderr</code> (string).</li> </ul> </li> </ul>"},{"location":"en/modules/git/#example","title":"Example","text":"<p>This example demonstrates a full CI/CD-like workflow: clone, create a version file, add, commit, tag, and push.</p> <pre><code>command = function()\n  local git = require(\"git\")\n  local repo_path = \"/tmp/git-example-repo\"\n\n  -- Clean up previous runs\n  fs.rm_r(repo_path)\n\n  -- 1. Clone the repository\n  log.info(\"Cloning repository...\")\n  local repo, err = git.clone(\"https://github.com/chalkan3-sloth/sloth-runner.git\", repo_path)\n  if err then\n    return false, \"Failed to clone: \" .. err\n  end\n\n  -- 2. Create and write a version file\n  fs.write(repo_path .. \"/VERSION\", \"1.2.3\")\n\n  -- 3. Chain Git commands: add -&gt; commit -&gt; tag -&gt; push\n  log.info(\"Adding, committing, tagging, and pushing...\")\n  repo:add(\".\"):commit(\"ci: Bump version to 1.2.3\"):tag(\"v1.2.3\"):push(\"origin\", \"main\", { follow_tags = true })\n\n  -- 4. Get the result of the final operation (push)\n  local result = repo:result()\n\n  if not result.success then\n    log.error(\"Git push failed: \" .. result.stderr)\n    return false, \"Git push failed.\"\n  end\n\n  log.info(\"Successfully pushed new version tag.\")\n  return true, \"Git operations successful.\"\nend\n</code></pre>"},{"location":"en/modules/gitops/","title":"\ud83d\udd04 GitOps Module - Complete API Reference","text":"<p>The GitOps module provides native Git-driven deployment workflows with intelligent diff preview, automatic rollback, and multi-environment support.</p>"},{"location":"en/modules/gitops/#module-overview","title":"\ud83d\udccb Module Overview","text":"<pre><code>local gitops = require(\"gitops\")\n</code></pre> <p>The GitOps module enables:</p> <ul> <li>\ud83c\udf0a Declarative Workflows - Git-driven deployment automation</li> <li>\ud83d\udd0d Intelligent Diff Preview - Visual change analysis before deployment</li> <li>\ud83d\udee1\ufe0f Smart Rollback - Automatic rollback on failure with state backup</li> <li>\ud83c\udfe2 Multi-Environment - Separate workflows for dev/staging/production</li> <li>\u2638\ufe0f Kubernetes Native - First-class Kubernetes integration</li> </ul>"},{"location":"en/modules/gitops/#quick-setup","title":"\ud83d\ude80 Quick Setup","text":""},{"location":"en/modules/gitops/#gitopsworkflowconfig","title":"<code>gitops.workflow(config)</code>","text":"<p>Create a simple GitOps workflow with minimal configuration.</p> <pre><code>local workflow = gitops.workflow({\n    repo = \"https://github.com/company/infrastructure\",\n    branch = \"main\",\n    auto_sync = true,\n    diff_preview = true,\n    rollback_on_failure = true\n})\n\n-- Returns: {workflow_id: \"workflow-123\", repository_id: \"repo-123\", status: \"created\"}\n</code></pre> <p>Parameters: - <code>repo</code> (string): Git repository URL - <code>branch</code> (string): Git branch to track (default: \"main\") - <code>auto_sync</code> (boolean): Enable automatic synchronization - <code>diff_preview</code> (boolean): Enable diff preview before sync - <code>rollback_on_failure</code> (boolean): Enable automatic rollback on failure</p> <p>Returns: <pre><code>{\n    workflow_id = \"workflow-1234567890\",\n    repository_id = \"repo-1234567890\", \n    status = \"created\",\n    auto_sync = true,\n    diff_preview = true,\n    rollback_on_failure = true\n}\n</code></pre></p>"},{"location":"en/modules/gitops/#repository-management","title":"\ud83c\udfd7\ufe0f Repository Management","text":""},{"location":"en/modules/gitops/#gitopsregister_repositoryconfig","title":"<code>gitops.register_repository(config)</code>","text":"<p>Register a Git repository for GitOps workflows.</p> <pre><code>local repo_id = gitops.register_repository({\n    id = \"production-repo\",           -- Optional custom ID\n    url = \"https://github.com/company/k8s-manifests\",\n    branch = \"main\",\n    credentials = {                   -- Optional authentication\n        type = \"token\",\n        token = \"ghp_xxxxxxxxxxxx\"\n    },\n    poll_interval = \"30s\"            -- How often to check for changes\n})\n</code></pre> <p>Parameters: - <code>id</code> (string): Custom repository ID (auto-generated if not provided) - <code>url</code> (string): Git repository URL - <code>branch</code> (string): Git branch to track - <code>credentials</code> (table): Authentication credentials   - <code>type</code> (string): \"token\", \"ssh\", or \"userpass\"   - <code>token</code> (string): Personal access token (for type=\"token\")   - <code>username</code> (string): Username (for type=\"userpass\")   - <code>password</code> (string): Password (for type=\"userpass\")   - <code>ssh_key</code> (string): SSH private key (for type=\"ssh\") - <code>poll_interval</code> (string): Polling interval for auto-sync</p>"},{"location":"en/modules/gitops/#workflow-management","title":"\ud83d\udd27 Workflow Management","text":""},{"location":"en/modules/gitops/#gitopscreate_workflowconfig","title":"<code>gitops.create_workflow(config)</code>","text":"<p>Create a detailed GitOps workflow with advanced configuration.</p> <pre><code>local workflow_id = gitops.create_workflow({\n    id = \"production-workflow\",       -- Optional custom ID\n    name = \"Production Infrastructure\",\n    repository = \"production-repo\",   -- Repository ID\n    target_path = \"k8s/production\",   -- Path within repository\n    auto_sync = false,                -- Manual sync for production\n    diff_preview = true,\n    rollback_on_failure = true,\n    sync_policy = {                   -- Advanced sync configuration\n        auto_prune = true,            -- Remove orphaned resources\n        retry = {\n            limit = 3,\n            backoff = \"exponential\"\n        },\n        health_check = {\n            enabled = true,\n            timeout = \"10m\"\n        }\n    }\n})\n</code></pre> <p>Parameters: - <code>id</code> (string): Custom workflow ID - <code>name</code> (string): Human-readable workflow name - <code>repository</code> (string): Repository ID to use - <code>target_path</code> (string): Path within repository to sync - <code>auto_sync</code> (boolean): Enable automatic synchronization - <code>diff_preview</code> (boolean): Enable diff preview - <code>rollback_on_failure</code> (boolean): Enable automatic rollback - <code>sync_policy</code> (table): Advanced synchronization policies</p>"},{"location":"en/modules/gitops/#gitopsget_workflow_statusworkflow_id","title":"<code>gitops.get_workflow_status(workflow_id)</code>","text":"<p>Get the current status of a GitOps workflow.</p> <pre><code>local status = gitops.get_workflow_status(\"workflow-123\")\n</code></pre> <p>Returns: <pre><code>{\n    id = \"workflow-123\",\n    name = \"Production Infrastructure\",\n    status = \"synced\",                -- active | syncing | synced | failed | degraded\n    auto_sync = false,\n    repository = \"production-repo\",\n    last_sync_result = {              -- Last synchronization result\n        id = \"sync-1234567890\",\n        status = \"succeeded\",         -- running | succeeded | failed\n        start_time = \"2024-01-15T10:30:00Z\",\n        commit_hash = \"abc123def456\",\n        message = \"Sync completed successfully\",\n        metrics = {\n            duration = \"45.2s\",\n            resources_processed = 15,\n            resources_applied = 8,\n            resources_skipped = 7,\n            conflicts_resolved = 0\n        }\n    }\n}\n</code></pre></p>"},{"location":"en/modules/gitops/#gitopslist_workflows","title":"<code>gitops.list_workflows()</code>","text":"<p>List all registered GitOps workflows.</p> <pre><code>local workflows = gitops.list_workflows()\n-- Returns array of workflow objects\n</code></pre>"},{"location":"en/modules/gitops/#synchronization","title":"\ud83d\udd04 Synchronization","text":""},{"location":"en/modules/gitops/#gitopssync_workflowworkflow_id","title":"<code>gitops.sync_workflow(workflow_id)</code>","text":"<p>Manually trigger synchronization for a workflow.</p> <pre><code>local success = gitops.sync_workflow(\"workflow-123\")\n-- Returns: true on success, false on failure\n</code></pre>"},{"location":"en/modules/gitops/#gitopsstart_auto_sync","title":"<code>gitops.start_auto_sync()</code>","text":"<p>Start the auto-sync controller for all workflows with <code>auto_sync = true</code>.</p> <pre><code>gitops.start_auto_sync()\n-- Starts background polling for all auto-sync enabled workflows\n</code></pre>"},{"location":"en/modules/gitops/#gitopsstop_auto_sync","title":"<code>gitops.stop_auto_sync()</code>","text":"<p>Stop the auto-sync controller.</p> <pre><code>gitops.stop_auto_sync()\n-- Stops all background synchronization\n</code></pre>"},{"location":"en/modules/gitops/#diff-preview","title":"\ud83d\udd0d Diff &amp; Preview","text":""},{"location":"en/modules/gitops/#gitopsgenerate_diffworkflow_id","title":"<code>gitops.generate_diff(workflow_id)</code>","text":"<p>Generate a comprehensive diff preview for pending changes.</p> <pre><code>local diff = gitops.generate_diff(\"workflow-123\")\n</code></pre> <p>Returns: <pre><code>{\n    workflow_id = \"workflow-123\",\n    generated_at = \"2024-01-15T10:30:00Z\",\n    summary = {                       -- High-level summary\n        total_changes = 5,\n        created_resources = 2,\n        updated_resources = 2,\n        deleted_resources = 1,\n        conflict_count = 0,\n        warning_count = 1\n    },\n    changes = {                       -- Detailed changes\n        {\n            type = \"create\",          -- create | update | delete\n            resource = \"Deployment/web-app\",\n            desired_state = {...},    -- New resource definition\n            diff = \"+ Creating Deployment/web-app with 3 replicas\",\n            impact = \"medium\"         -- low | medium | high | critical\n        },\n        {\n            type = \"update\", \n            resource = \"Service/web-svc\",\n            current_state = {...},    -- Current resource state\n            desired_state = {...},    -- Desired resource state\n            diff = \"~ Updating Service/web-svc:\\n  port: 80 -&gt; 8080\",\n            impact = \"low\"\n        }\n    },\n    conflicts = {                     -- Detected conflicts\n        {\n            resource = \"ConfigMap/app-config\",\n            type = \"validation\",      -- resource_exists | out_of_sync | validation\n            description = \"Resource modified outside of GitOps\",\n            current_state = {...},\n            desired_state = {...},\n            suggestions = [\n                \"Review manual changes before proceeding\",\n                \"Consider updating the Git repository\"\n            ]\n        }\n    },\n    warnings = [                      -- Warnings and recommendations\n        \"High-impact change detected: Deployment/critical-app\"\n    ]\n}\n</code></pre></p>"},{"location":"en/modules/gitops/#gitopspreview_changesworkflow_id","title":"<code>gitops.preview_changes(workflow_id)</code>","text":"<p>Alias for <code>gitops.generate_diff()</code> for better readability.</p> <pre><code>local preview = gitops.preview_changes(\"workflow-123\")\n-- Same as gitops.generate_diff()\n</code></pre>"},{"location":"en/modules/gitops/#rollback","title":"\ud83d\udee1\ufe0f Rollback","text":""},{"location":"en/modules/gitops/#gitopsrollback_workflowworkflow_id-reason","title":"<code>gitops.rollback_workflow(workflow_id, reason)</code>","text":"<p>Rollback a workflow to its previous state.</p> <pre><code>local success = gitops.rollback_workflow(\"workflow-123\", \"Health check failed\")\n-- Returns: true on success, false on failure\n</code></pre> <p>Parameters: - <code>workflow_id</code> (string): Workflow to rollback - <code>reason</code> (string): Reason for rollback (for audit logging)</p>"},{"location":"en/modules/gitops/#complete-examples","title":"\ud83c\udfaf Complete Examples","text":""},{"location":"en/modules/gitops/#multi-environment-setup","title":"Multi-Environment Setup","text":"<pre><code>local gitops = require(\"gitops\")\nlocal log = require(\"log\")\n\n-- Define environments\nlocal environments = {\n    {\n        name = \"development\",\n        repo = \"https://github.com/company/k8s-dev\",\n        branch = \"develop\",\n        auto_sync = true,\n        sync_interval = \"5m\"\n    },\n    {\n        name = \"staging\",\n        repo = \"https://github.com/company/k8s-staging\",\n        branch = \"staging\", \n        auto_sync = true,\n        sync_interval = \"10m\"\n    },\n    {\n        name = \"production\",\n        repo = \"https://github.com/company/k8s-prod\",\n        branch = \"main\",\n        auto_sync = false,      -- Manual deployments in production\n        approval_required = true\n    }\n}\n\n-- Create workflows for all environments\nlocal workflows = {}\nfor _, env in ipairs(environments) do\n    -- Register repository\n    local repo_id = gitops.register_repository({\n        id = env.name .. \"-repo\",\n        url = env.repo,\n        branch = env.branch\n    })\n\n    -- Create workflow\n    local workflow_id = gitops.create_workflow({\n        id = env.name .. \"-workflow\",\n        name = env.name .. \" Environment\", \n        repository = repo_id,\n        target_path = \"manifests\",\n        auto_sync = env.auto_sync,\n        diff_preview = true,\n        rollback_on_failure = true\n    })\n\n    workflows[env.name] = workflow_id\n    log.info(\"Created GitOps workflow for \" .. env.name .. \": \" .. workflow_id)\nend\n\n-- Start auto-sync controller\ngitops.start_auto_sync()\n</code></pre>"},{"location":"en/modules/gitops/#production-deployment-with-validation","title":"Production Deployment with Validation","text":"<pre><code>local production_deploy = task(\"production_deploy\")\n    :description(\"Production deployment with full GitOps validation\")\n    :command(function(params, deps)\n        local workflow_id = workflows.production\n\n        -- Step 1: Generate diff and validate\n        log.info(\"\ud83d\udd0d Analyzing changes for production deployment...\")\n        local diff = gitops.generate_diff(workflow_id)\n\n        if not diff then\n            log.info(\"\u2139\ufe0f No changes detected\")\n            return {success = true, message = \"No changes to deploy\"}\n        end\n\n        -- Step 2: Display change summary\n        log.info(\"\ud83d\udcca Production Deployment Summary:\")\n        log.info(\"  \ud83d\udcdd Total changes: \" .. diff.summary.total_changes)\n        log.info(\"  \u2728 Created: \" .. diff.summary.created_resources)\n        log.info(\"  \ud83d\udd04 Updated: \" .. diff.summary.updated_resources)\n        log.info(\"  \ud83d\uddd1\ufe0f Deleted: \" .. diff.summary.deleted_resources)\n\n        -- Step 3: Check for conflicts and high-impact changes\n        if diff.summary.conflict_count &gt; 0 then\n            log.error(\"\ud83d\udca5 Conflicts detected - manual resolution required\")\n            return {success = false, message = \"Conflicts must be resolved\"}\n        end\n\n        local high_impact_changes = 0\n        for _, change in ipairs(diff.changes) do\n            if change.impact == \"high\" or change.impact == \"critical\" then\n                high_impact_changes = high_impact_changes + 1\n                log.warn(\"\u26a0\ufe0f High-impact: \" .. change.resource .. \" (\" .. change.type .. \")\")\n            end\n        end\n\n        -- Step 4: Show warnings\n        if #diff.warnings &gt; 0 then\n            log.warn(\"\u26a0\ufe0f Warnings:\")\n            for _, warning in ipairs(diff.warnings) do\n                log.warn(\"  \u2022 \" .. warning)\n            end\n        end\n\n        -- Step 5: Require approval for production\n        if high_impact_changes &gt; 0 then\n            print(\"\ud83d\udd12 High-impact changes detected. Proceed? (y/N)\")\n            local response = io.read()\n            if response:lower() ~= \"y\" then\n                return {success = false, message = \"Deployment cancelled\"}\n            end\n        end\n\n        -- Step 6: Execute deployment\n        log.info(\"\ud83d\ude80 Executing production deployment...\")\n        local sync_success = gitops.sync_workflow(workflow_id)\n\n        if not sync_success then\n            log.error(\"\ud83d\udca5 Production deployment failed!\")\n            return {success = false, message = \"Deployment failed\"}\n        end\n\n        -- Step 7: Verify deployment\n        log.info(\"\ud83d\udd0d Verifying deployment...\")\n        local status = gitops.get_workflow_status(workflow_id)\n\n        if status.status == \"synced\" and status.last_sync_result.status == \"succeeded\" then\n            log.info(\"\u2705 Production deployment successful!\")\n            log.info(\"\ud83d\udcca Applied \" .. status.last_sync_result.metrics.resources_applied .. \" resources\")\n            log.info(\"\u23f1\ufe0f Completed in \" .. status.last_sync_result.metrics.duration)\n            return {success = true, message = \"Production deployed successfully\"}\n        else\n            log.error(\"\ud83d\udca5 Deployment verification failed!\")\n\n            -- Automatic rollback\n            log.warn(\"\ud83d\udd04 Initiating automatic rollback...\")\n            local rollback_success = gitops.rollback_workflow(workflow_id, \"Deployment verification failed\")\n\n            if rollback_success then\n                log.info(\"\u2705 Automatic rollback completed\")\n                return {success = false, message = \"Deployment failed, rollback successful\"}\n            else\n                log.error(\"\ud83d\udca5 Rollback also failed!\")\n                return {success = false, message = \"Deployment and rollback both failed\"}\n            end\n        end\n    end)\n    :build()\n</code></pre>"},{"location":"en/modules/gitops/#kubernetes-specific-gitops","title":"Kubernetes-Specific GitOps","text":"<pre><code>local k8s_deploy = task(\"kubernetes_gitops_deploy\")\n    :description(\"Kubernetes-native GitOps deployment\")\n    :command(function(params, deps)\n        local workflow_id = params.workflow_id\n\n        -- Generate diff with Kubernetes-specific analysis\n        local diff = gitops.generate_diff(workflow_id)\n\n        -- Kubernetes-specific validations\n        local k8s_issues = {}\n        for _, change in ipairs(diff.changes) do\n            -- Check for dangerous Kubernetes operations\n            if change.type == \"delete\" then\n                if change.resource:match(\"Namespace\") then\n                    table.insert(k8s_issues, \"\ud83d\udea8 CRITICAL: Deleting namespace \" .. change.resource)\n                elseif change.resource:match(\"PersistentVolume\") then\n                    table.insert(k8s_issues, \"\u26a0\ufe0f WARNING: Deleting PersistentVolume \" .. change.resource)\n                end\n            end\n\n            if change.type == \"update\" and change.resource:match(\"Deployment\") then\n                log.info(\"\ud83d\udce6 Deployment update: \" .. change.resource)\n                -- Could add image change detection here\n            end\n        end\n\n        if #k8s_issues &gt; 0 then\n            log.warn(\"\ud83d\udea8 Kubernetes-specific issues detected:\")\n            for _, issue in ipairs(k8s_issues) do\n                log.warn(\"  \" .. issue)\n            end\n\n            print(\"Proceed despite Kubernetes warnings? (y/N)\")\n            local response = io.read()\n            if response:lower() ~= \"y\" then\n                return {success = false, message = \"Deployment cancelled due to K8s issues\"}\n            end\n        end\n\n        -- Execute Kubernetes deployment\n        local sync_success = gitops.sync_workflow(workflow_id)\n\n        if sync_success then\n            -- Kubernetes-specific post-deployment checks\n            log.info(\"\ud83d\udd0d Running Kubernetes health checks...\")\n\n            -- Could add kubectl-based health checks here\n            -- kubectl get pods --all-namespaces\n            -- kubectl get services\n            -- kubectl get ingress\n\n            return {success = true, message = \"Kubernetes deployment successful\"}\n        else\n            return {success = false, message = \"Kubernetes deployment failed\"}\n        end\n    end)\n    :build()\n</code></pre>"},{"location":"en/modules/gitops/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"en/modules/gitops/#1-environment-separation","title":"1. Environment Separation","text":"<pre><code>-- Use different repositories for different environments\nlocal env_repos = {\n    dev = \"company/k8s-dev\",\n    staging = \"company/k8s-staging\", \n    prod = \"company/k8s-prod\"\n}\n</code></pre>"},{"location":"en/modules/gitops/#2-always-preview-in-production","title":"2. Always Preview in Production","text":"<pre><code>-- Never deploy to production without reviewing changes\nif environment == \"production\" then\n    local diff = gitops.generate_diff(workflow_id)\n    if diff.summary.conflict_count &gt; 0 or has_high_impact_changes(diff) then\n        -- Require manual approval\n    end\nend\n</code></pre>"},{"location":"en/modules/gitops/#3-descriptive-rollback-reasons","title":"3. Descriptive Rollback Reasons","text":"<pre><code>-- Provide clear audit trail\ngitops.rollback_workflow(workflow_id, \"Health check failed after 5 minutes - CPU usage &gt; 90%\")\n</code></pre>"},{"location":"en/modules/gitops/#4-monitor-sync-results","title":"4. Monitor Sync Results","text":"<pre><code>-- Always verify deployment success\nlocal status = gitops.get_workflow_status(workflow_id)\nif status.last_sync_result.status ~= \"succeeded\" then\n    -- Handle failure appropriately\nend\n</code></pre>"},{"location":"en/modules/gitops/#5-use-auto-sync-judiciously","title":"5. Use Auto-Sync Judiciously","text":"<pre><code>-- Auto-sync for dev/staging, manual for production\nlocal auto_sync = environment ~= \"production\"\n</code></pre>"},{"location":"en/modules/gitops/#advanced-features","title":"\ud83d\udd27 Advanced Features","text":""},{"location":"en/modules/gitops/#custom-sync-policies","title":"Custom Sync Policies","text":"<pre><code>local workflow_id = gitops.create_workflow({\n    name = \"Advanced Sync Policy\",\n    repository = repo_id,\n    sync_policy = {\n        auto_prune = true,            -- Remove resources not in Git\n        retry = {\n            limit = 5,\n            backoff = \"exponential\",  -- exponential | linear | fixed\n            max_duration = \"10m\"\n        },\n        health_check = {\n            enabled = true,\n            timeout = \"10m\",\n            failure_mode = \"rollback\"  -- ignore | fail | rollback\n        },\n        pre_sync_hooks = [            -- Commands to run before sync\n            \"kubectl cluster-info\",\n            \"helm repo update\"\n        ],\n        post_sync_hooks = [           -- Commands to run after sync\n            \"kubectl rollout status deployment/app\",\n            \"curl -f http://app/health\"\n        ]\n    }\n})\n</code></pre>"},{"location":"en/modules/gitops/#multi-repository-coordination","title":"Multi-Repository Coordination","text":"<pre><code>-- Coordinate deployments across multiple repositories\nlocal repos = {\n    frontend = gitops.workflow({repo = \"company/frontend-config\"}),\n    backend = gitops.workflow({repo = \"company/backend-config\"}),\n    database = gitops.workflow({repo = \"company/database-config\"})\n}\n\n-- Deploy in dependency order\ngitops.sync_workflow(repos.database.workflow_id)\ngitops.sync_workflow(repos.backend.workflow_id) \ngitops.sync_workflow(repos.frontend.workflow_id)\n</code></pre>"},{"location":"en/modules/gitops/#integration-examples","title":"\ud83d\ude80 Integration Examples","text":""},{"location":"en/modules/gitops/#with-ai-module","title":"With AI Module","text":"<pre><code>local ai = require(\"ai\")\nlocal gitops = require(\"gitops\")\n\nlocal intelligent_deploy = task(\"ai_gitops_deploy\")\n    :command(function(params, deps)\n        local deploy_cmd = \"kubectl apply -f manifests/\"\n\n        -- AI failure prediction before GitOps deployment\n        local prediction = ai.predict_failure(\"ai_gitops_deploy\", deploy_cmd)\n\n        if prediction.failure_probability &gt; 0.25 then\n            log.warn(\"\ud83e\udd16 AI detected high deployment risk: \" .. \n                    string.format(\"%.1f%%\", prediction.failure_probability * 100))\n\n            for _, rec in ipairs(prediction.recommendations) do\n                log.info(\"\ud83d\udca1 AI Recommendation: \" .. rec)\n            end\n        end\n\n        -- GitOps deployment with AI insights\n        local workflow_id = params.gitops_workflow_id\n        local success = gitops.sync_workflow(workflow_id)\n\n        -- Record execution for AI learning\n        ai.record_execution({\n            task_name = \"ai_gitops_deploy\",\n            command = deploy_cmd,\n            success = success,\n            execution_time = \"30s\",\n            ai_prediction_used = true,\n            predicted_failure_probability = prediction.failure_probability\n        })\n\n        return {success = success}\n    end)\n    :build()\n</code></pre>"},{"location":"en/modules/gitops/#with-modern-dsl-workflows","title":"With Modern DSL Workflows","text":"<pre><code>workflow.define(\"gitops_pipeline\", {\n    description = \"Complete GitOps deployment pipeline\",\n    version = \"2.0.0\",\n\n    metadata = {\n        author = \"DevOps Team\",\n        tags = {\"gitops\", \"kubernetes\", \"production\"}\n    },\n\n    tasks = {\n        production_deploy,\n        k8s_deploy\n    },\n\n    on_task_start = function(task_name)\n        log.info(\"\ud83d\ude80 Starting GitOps task: \" .. task_name)\n    end,\n\n    on_task_complete = function(task_name, success, output)\n        if success then\n            log.info(\"\u2705 GitOps task completed: \" .. task_name)\n        else\n            log.error(\"\u274c GitOps task failed: \" .. task_name)\n\n            -- Could trigger emergency rollback here\n            if task_name == \"production_deploy\" then\n                log.warn(\"\ud83d\udd04 Triggering emergency rollback...\")\n                gitops.rollback_workflow(production_workflow_id, \"Emergency rollback due to task failure\")\n            end\n        end\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\ud83c\udf89 GitOps pipeline completed successfully!\")\n        else\n            log.error(\"\ud83d\udca5 GitOps pipeline failed - check logs for details\")\n        end\n    end\n})\n</code></pre>"},{"location":"en/modules/gitops/#see-also","title":"\ud83d\udcda See Also","text":"<ul> <li>GitOps Features Overview</li> <li>GitOps Quick Setup</li> <li>Multi-Environment GitOps</li> <li>Kubernetes Integration</li> <li>Rollback Strategies</li> </ul>"},{"location":"en/modules/log/","title":"Log Module","text":"<p>The <code>log</code> module provides a simple and essential interface for logging messages from within your Lua scripts to the <code>sloth-runner</code> console. Using this module is the standard way to provide feedback and debug information during a task's execution.</p>"},{"location":"en/modules/log/#loginfomessage","title":"<code>log.info(message)</code>","text":"<p>Logs a message at the INFO level. This is the standard level for general, informative messages.</p> <ul> <li>Parameters:<ul> <li><code>message</code> (string): The message to log.</li> </ul> </li> </ul>"},{"location":"en/modules/log/#logwarnmessage","title":"<code>log.warn(message)</code>","text":"<p>Logs a message at the WARN level. This is suitable for non-critical issues that should be brought to the user's attention.</p> <ul> <li>Parameters:<ul> <li><code>message</code> (string): The message to log.</li> </ul> </li> </ul>"},{"location":"en/modules/log/#logerrormessage","title":"<code>log.error(message)</code>","text":"<p>Logs a message at the ERROR level. This should be used for significant errors that might cause a task to fail.</p> <ul> <li>Parameters:<ul> <li><code>message</code> (string): The message to log.</li> </ul> </li> </ul>"},{"location":"en/modules/log/#logdebugmessage","title":"<code>log.debug(message)</code>","text":"<p>Logs a message at the DEBUG level. These messages are typically hidden unless the runner is in a verbose or debug mode. They are useful for detailed diagnostic information.</p> <ul> <li>Parameters:<ul> <li><code>message</code> (string): The message to log.</li> </ul> </li> </ul>"},{"location":"en/modules/log/#example","title":"Example","text":"<pre><code>command = function()\n  -- The log module is globally available and does not need to be required.\n\n  log.info(\"Starting the logging example task.\")\n\n  local user_name = \"Sloth\"\n  log.debug(\"Current user is: \" .. user_name)\n\n  if user_name ~= \"Sloth\" then\n    log.warn(\"The user is not the expected one.\")\n  end\n\n  log.info(\"Task is performing its main action...\")\n\n  local success = true -- Simulate a successful operation\n  if not success then\n    log.error(\"The main action failed unexpectedly!\")\n    return false, \"Main action failed\"\n  end\n\n  log.info(\"Logging example task finished successfully.\")\n  return true, \"Logging demonstrated.\"\nend\n</code></pre>"},{"location":"en/modules/metrics/","title":"\ud83d\udcca Metrics &amp; Monitoring Module","text":"<p>The Metrics &amp; Monitoring module provides comprehensive system monitoring, custom metrics collection, and health checking capabilities. It enables real-time observability of both system resources and application performance.</p>"},{"location":"en/modules/metrics/#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>System Metrics: Automatic collection of CPU, memory, disk, and network metrics</li> <li>Runtime Metrics: Go runtime information (goroutines, heap, GC)</li> <li>Custom Metrics: Gauges, counters, histograms, and timers</li> <li>Health Checks: Automatic system health monitoring</li> <li>HTTP Endpoints: Prometheus-compatible metrics export</li> <li>Alerting: Threshold-based alerts</li> <li>JSON API: Complete metrics data for integrations</li> </ul>"},{"location":"en/modules/metrics/#system-metrics","title":"\ud83d\udcca System Metrics","text":""},{"location":"en/modules/metrics/#cpu-memory-and-disk-monitoring","title":"CPU, Memory, and Disk Monitoring","text":"<pre><code>-- Get current CPU usage\nlocal cpu_usage = metrics.system_cpu()\nlog.info(\"CPU Usage: \" .. string.format(\"%.1f%%\", cpu_usage))\n\n-- Get memory information\nlocal memory_info = metrics.system_memory()\nlog.info(\"Memory: \" .. string.format(\"%.1f%% (%.0f/%.0f MB)\", \n    memory_info.percent, memory_info.used_mb, memory_info.total_mb))\n\n-- Get disk usage\nlocal disk_info = metrics.system_disk(\"/\")\nlog.info(\"Disk: \" .. string.format(\"%.1f%% (%.1f/%.1f GB)\", \n    disk_info.percent, disk_info.used_gb, disk_info.total_gb))\n\n-- Check specific disk path\nlocal var_disk = metrics.system_disk(\"/var\")\nlog.info(\"Var disk usage: \" .. string.format(\"%.1f%%\", var_disk.percent))\n</code></pre>"},{"location":"en/modules/metrics/#runtime-information","title":"Runtime Information","text":"<pre><code>-- Get Go runtime metrics\nlocal runtime = metrics.runtime_info()\nlog.info(\"Runtime Information:\")\nlog.info(\"  Goroutines: \" .. runtime.goroutines)\nlog.info(\"  CPU cores: \" .. runtime.num_cpu)\nlog.info(\"  Heap allocated: \" .. string.format(\"%.1f MB\", runtime.heap_alloc_mb))\nlog.info(\"  Heap system: \" .. string.format(\"%.1f MB\", runtime.heap_sys_mb))\nlog.info(\"  GC cycles: \" .. runtime.num_gc)\nlog.info(\"  Go version: \" .. runtime.go_version)\n</code></pre>"},{"location":"en/modules/metrics/#custom-metrics","title":"\ud83d\udcc8 Custom Metrics","text":""},{"location":"en/modules/metrics/#gauge-metrics-current-values","title":"Gauge Metrics (Current Values)","text":"<pre><code>-- Set simple gauge values\nmetrics.gauge(\"cpu_temperature\", 65.4)\nmetrics.gauge(\"active_connections\", 142)\nmetrics.gauge(\"queue_size\", 23)\n\n-- Set gauge with tags\nmetrics.gauge(\"memory_usage\", memory_percent, {\n    server = \"web-01\",\n    environment = \"production\",\n    region = \"us-east-1\"\n})\n\n-- Update deployment status\nmetrics.gauge(\"deployment_progress\", 75.5, {\n    app = \"frontend\",\n    version = \"v2.1.0\"\n})\n</code></pre>"},{"location":"en/modules/metrics/#counter-metrics-incremental-values","title":"Counter Metrics (Incremental Values)","text":"<pre><code>-- Increment counters\nlocal total_requests = metrics.counter(\"http_requests_total\", 1)\nlocal error_count = metrics.counter(\"http_errors_total\", 1, {\n    status_code = \"500\",\n    endpoint = \"/api/users\"\n})\n\n-- Bulk increment\nlocal processed = metrics.counter(\"messages_processed\", 50, {\n    queue = \"user_notifications\",\n    priority = \"high\"\n})\n\nlog.info(\"Total requests processed: \" .. total_requests)\n</code></pre>"},{"location":"en/modules/metrics/#histogram-metrics-value-distributions","title":"Histogram Metrics (Value Distributions)","text":"<pre><code>-- Record response times\nmetrics.histogram(\"response_time_ms\", 245.6, {\n    endpoint = \"/api/users\",\n    method = \"GET\"\n})\n\n-- Record payload sizes\nmetrics.histogram(\"payload_size_bytes\", 1024, {\n    content_type = \"application/json\"\n})\n\n-- Record batch sizes\nmetrics.histogram(\"batch_size\", 150, {\n    operation = \"bulk_insert\",\n    table = \"user_events\"\n})\n</code></pre>"},{"location":"en/modules/metrics/#timer-metrics-function-execution-time","title":"Timer Metrics (Function Execution Time)","text":"<pre><code>-- Time function execution automatically\nlocal duration = metrics.timer(\"database_query\", function()\n    -- Simulate database query\n    local result = exec.run(\"sleep 0.1\")\n    return result\nend, {\n    query_type = \"select\",\n    table = \"users\"\n})\n\nlog.info(\"Database query took: \" .. string.format(\"%.2f ms\", duration))\n\n-- Time complex operations\nlocal processing_time = metrics.timer(\"data_processing\", function()\n    -- Process large dataset\n    local data = {}\n    for i = 1, 100000 do\n        data[i] = math.sqrt(i) * 2.5\n    end\n    return #data\nend, {\n    operation = \"mathematical_computation\",\n    size = \"large\"\n})\n\nlog.info(\"Data processing completed in: \" .. string.format(\"%.2f ms\", processing_time))\n</code></pre>"},{"location":"en/modules/metrics/#health-monitoring","title":"\ud83c\udfe5 Health Monitoring","text":""},{"location":"en/modules/metrics/#automatic-health-status","title":"Automatic Health Status","text":"<pre><code>-- Get comprehensive health status\nlocal health = metrics.health_status()\nlog.info(\"Overall Health Status: \" .. health.overall)\n\n-- Check individual components\nlocal components = {\"cpu\", \"memory\", \"disk\"}\nfor _, component in ipairs(components) do\n    local comp_info = health[component]\n    if comp_info then\n        local status_icon = \"\u2705\"\n        if comp_info.status == \"warning\" then\n            status_icon = \"\u26a0\ufe0f\"\n        elseif comp_info.status == \"critical\" then\n            status_icon = \"\u274c\"\n        end\n\n        log.info(string.format(\"  %s %s: %.1f%% (%s)\", \n            status_icon, component:upper(), comp_info.usage, comp_info.status))\n    end\nend\n</code></pre>"},{"location":"en/modules/metrics/#custom-health-checks","title":"Custom Health Checks","text":"<pre><code>-- Create health check function\nfunction check_application_health()\n    local health_score = 100\n    local issues = {}\n\n    -- Check database connectivity\n    local db_result = exec.run(\"pg_isready -h localhost -p 5432\")\n    if db_result ~= \"\" then\n        health_score = health_score - 20\n        table.insert(issues, \"Database connection failed\")\n    end\n\n    -- Check disk space\n    local disk = metrics.system_disk(\"/\")\n    if disk.percent &gt; 90 then\n        health_score = health_score - 30\n        table.insert(issues, \"Disk space critical: \" .. string.format(\"%.1f%%\", disk.percent))\n    end\n\n    -- Check memory usage\n    local memory = metrics.system_memory()\n    if memory.percent &gt; 85 then\n        health_score = health_score - 25\n        table.insert(issues, \"Memory usage high: \" .. string.format(\"%.1f%%\", memory.percent))\n    end\n\n    -- Record health score\n    metrics.gauge(\"application_health_score\", health_score)\n\n    if health_score &lt; 70 then\n        metrics.alert(\"application_health\", {\n            level = \"warning\",\n            message = \"Application health degraded: \" .. table.concat(issues, \", \"),\n            score = health_score\n        })\n    end\n\n    return health_score &gt;= 70\nend\n\n-- Use in tasks\nModern DSLs = {\n    health_monitoring = {\n        tasks = {\n            health_check = {\n                command = function()\n                    local healthy = check_application_health()\n                    return healthy, healthy and \"System healthy\" or \"System health issues detected\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"en/modules/metrics/#alerting-system","title":"\ud83d\udea8 Alerting System","text":""},{"location":"en/modules/metrics/#creating-alerts","title":"Creating Alerts","text":"<pre><code>-- Simple threshold alert\nlocal cpu = metrics.system_cpu()\nif cpu &gt; 80 then\n    metrics.alert(\"high_cpu_usage\", {\n        level = \"warning\",\n        message = \"CPU usage is high: \" .. string.format(\"%.1f%%\", cpu),\n        threshold = 80,\n        value = cpu,\n        severity = \"medium\"\n    })\nend\n\n-- Complex alert with multiple conditions\nlocal memory = metrics.system_memory()\nlocal disk = metrics.system_disk()\n\nif memory.percent &gt; 90 and disk.percent &gt; 85 then\n    metrics.alert(\"resource_exhaustion\", {\n        level = \"critical\",\n        message = string.format(\"Critical resource usage - Memory: %.1f%%, Disk: %.1f%%\", \n            memory.percent, disk.percent),\n        memory_usage = memory.percent,\n        disk_usage = disk.percent,\n        recommended_action = \"Scale up resources immediately\"\n    })\nend\n\n-- Application-specific alerts\nlocal queue_size = state.get(\"task_queue_size\", 0)\nif queue_size &gt; 1000 then\n    metrics.alert(\"queue_backlog\", {\n        level = \"warning\", \n        message = \"Task queue backlog detected: \" .. queue_size .. \" items\",\n        queue_size = queue_size,\n        estimated_processing_time = queue_size * 2 .. \" seconds\"\n    })\nend\n</code></pre>"},{"location":"en/modules/metrics/#metrics-management","title":"\ud83d\udd0d Metrics Management","text":""},{"location":"en/modules/metrics/#retrieving-custom-metrics","title":"Retrieving Custom Metrics","text":"<pre><code>-- Get specific custom metric\nlocal cpu_metric = metrics.get_custom(\"cpu_temperature\")\nif cpu_metric then\n    log.info(\"CPU Temperature metric: \" .. data.to_json(cpu_metric))\nend\n\n-- List all custom metrics\nlocal all_metrics = metrics.list_custom()\nlog.info(\"Total custom metrics: \" .. #all_metrics)\nfor i, metric_name in ipairs(all_metrics) do\n    log.info(\"  \" .. i .. \". \" .. metric_name)\nend\n</code></pre>"},{"location":"en/modules/metrics/#performance-monitoring-example","title":"Performance Monitoring Example","text":"<pre><code>Modern DSLs = {\n    performance_monitoring = {\n        tasks = {\n            monitor_api_performance = {\n                command = function()\n                    -- Start monitoring session\n                    log.info(\"Starting API performance monitoring...\")\n\n                    -- Simulate API calls and measure performance\n                    for i = 1, 10 do\n                        local api_time = metrics.timer(\"api_call_\" .. i, function()\n                            -- Simulate API call\n                            exec.run(\"curl -s -o /dev/null -w '%{time_total}' https://api.example.com/health\")\n                        end, {\n                            endpoint = \"health\",\n                            call_number = tostring(i)\n                        })\n\n                        -- Record response time\n                        metrics.histogram(\"api_response_time\", api_time, {\n                            endpoint = \"health\"\n                        })\n\n                        -- Check if response time is acceptable\n                        if api_time &gt; 1000 then -- 1 second\n                            metrics.counter(\"slow_api_calls\", 1, {\n                                endpoint = \"health\"\n                            })\n\n                            metrics.alert(\"slow_api_response\", {\n                                level = \"warning\",\n                                message = string.format(\"Slow API response: %.2f ms\", api_time),\n                                response_time = api_time,\n                                threshold = 1000\n                            })\n                        end\n\n                        -- Brief delay between calls\n                        exec.run(\"sleep 0.1\")\n                    end\n\n                    -- Get summary statistics\n                    local system_health = metrics.health_status()\n                    log.info(\"System health after API tests: \" .. system_health.overall)\n\n                    return true, \"API performance monitoring completed\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"en/modules/metrics/#http-endpoints","title":"\ud83c\udf10 HTTP Endpoints","text":"<p>The metrics module automatically exposes HTTP endpoints for external monitoring systems:</p>"},{"location":"en/modules/metrics/#prometheus-format-metrics","title":"Prometheus Format (<code>/metrics</code>)","text":"<pre><code># Access Prometheus-compatible metrics\ncurl http://agent:8080/metrics\n\n# Example output:\n# sloth_agent_cpu_usage_percent 15.4\n# sloth_agent_memory_usage_mb 2048.5\n# sloth_agent_disk_usage_percent 67.2\n# sloth_agent_tasks_total 142\n</code></pre>"},{"location":"en/modules/metrics/#json-format-metricsjson","title":"JSON Format (<code>/metrics/json</code>)","text":"<pre><code># Get complete metrics in JSON format\ncurl http://agent:8080/metrics/json\n\n# Example response:\n{\n  \"agent_name\": \"myagent1\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"system\": {\n    \"cpu_usage_percent\": 15.4,\n    \"memory_usage_mb\": 2048.5,\n    \"disk_usage_percent\": 67.2\n  },\n  \"runtime\": {\n    \"num_goroutines\": 25,\n    \"heap_alloc_mb\": 45.2\n  },\n  \"custom\": {\n    \"api_response_time\": {...},\n    \"deployment_progress\": 85.5\n  }\n}\n</code></pre>"},{"location":"en/modules/metrics/#health-check-health","title":"Health Check (<code>/health</code>)","text":"<pre><code># Check agent health status\ncurl http://agent:8080/health\n\n# Example response:\n{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"checks\": {\n    \"cpu\": {\"usage\": 15.4, \"status\": \"healthy\"},\n    \"memory\": {\"usage\": 45.8, \"status\": \"healthy\"},\n    \"disk\": {\"usage\": 67.2, \"status\": \"healthy\"}\n  }\n}\n</code></pre>"},{"location":"en/modules/metrics/#api-reference","title":"\ud83d\udccb API Reference","text":""},{"location":"en/modules/metrics/#system-metrics_1","title":"System Metrics","text":"Function Parameters Return Description <code>metrics.system_cpu()</code> - usage: number Get current CPU usage percentage <code>metrics.system_memory()</code> - info: table Get memory usage information <code>metrics.system_disk(path?)</code> path?: string info: table Get disk usage for path (default: \"/\") <code>metrics.runtime_info()</code> - info: table Get Go runtime information"},{"location":"en/modules/metrics/#custom-metrics_1","title":"Custom Metrics","text":"Function Parameters Return Description <code>metrics.gauge(name, value, tags?)</code> name: string, value: number, tags?: table success: boolean Set gauge metric <code>metrics.counter(name, increment?, tags?)</code> name: string, increment?: number, tags?: table new_value: number Increment counter <code>metrics.histogram(name, value, tags?)</code> name: string, value: number, tags?: table success: boolean Record histogram value <code>metrics.timer(name, function, tags?)</code> name: string, func: function, tags?: table duration: number Time function execution"},{"location":"en/modules/metrics/#health-and-monitoring","title":"Health and Monitoring","text":"Function Parameters Return Description <code>metrics.health_status()</code> - status: table Get comprehensive health status <code>metrics.alert(name, data)</code> name: string, data: table success: boolean Create alert"},{"location":"en/modules/metrics/#utilities","title":"Utilities","text":"Function Parameters Return Description <code>metrics.get_custom(name)</code> name: string metric: table | nil Get custom metric by name <code>metrics.list_custom()</code> - names: table List all custom metric names"},{"location":"en/modules/metrics/#best-practices","title":"\ud83c\udfaf Best Practices","text":"<ol> <li>Use appropriate metric types - gauges for current values, counters for totals, histograms for distributions</li> <li>Add meaningful tags to categorize and filter metrics</li> <li>Set reasonable alert thresholds to avoid alert fatigue</li> <li>Monitor performance impact of extensive metrics collection</li> <li>Use timers for performance-critical operations to identify bottlenecks</li> <li>Implement health checks for all critical system components</li> <li>Export metrics to external systems like Prometheus for long-term storage</li> </ol> <p>The Metrics &amp; Monitoring module provides comprehensive observability for your distributed sloth-runner environment! \ud83d\udcca\ud83d\ude80</p>"},{"location":"en/modules/net/","title":"Net Module","text":"<p>The <code>net</code> module provides functions for making HTTP requests and downloading files, allowing your tasks to interact with web services and remote resources.</p>"},{"location":"en/modules/net/#nethttp_geturl","title":"<code>net.http_get(url)</code>","text":"<p>Performs an HTTP GET request to the specified URL.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL to send the GET request to.</li> </ul> </li> <li>Returns:<ul> <li><code>body</code> (string): The response body as a string.</li> <li><code>status_code</code> (number): The HTTP status code of the response.</li> <li><code>headers</code> (table): A table containing the response headers.</li> <li><code>error</code> (string): An error message if the request failed.</li> </ul> </li> </ul>"},{"location":"en/modules/net/#nethttp_posturl-body-headers","title":"<code>net.http_post(url, body, [headers])</code>","text":"<p>Performs an HTTP POST request to the specified URL.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL to send the POST request to.</li> <li><code>body</code> (string): The request body to send.</li> <li><code>headers</code> (table, optional): A table of request headers to set.</li> </ul> </li> <li>Returns:<ul> <li><code>body</code> (string): The response body as a string.</li> <li><code>status_code</code> (number): The HTTP status code of the response.</li> <li><code>headers</code> (table): A table containing the response headers.</li> <li><code>error</code> (string): An error message if the request failed.</li> </ul> </li> </ul>"},{"location":"en/modules/net/#netdownloadurl-destination_path","title":"<code>net.download(url, destination_path)</code>","text":"<p>Downloads a file from a URL and saves it to a local path.</p> <ul> <li>Parameters:<ul> <li><code>url</code> (string): The URL of the file to download.</li> <li><code>destination_path</code> (string): The local file path to save the downloaded content.</li> </ul> </li> <li>Returns:<ul> <li><code>error</code>: An error object if the download fails.</li> </ul> </li> </ul>"},{"location":"en/modules/net/#example","title":"Example","text":"<pre><code>command = function()\n  local net = require(\"net\")\n\n  -- Example GET request\n  log.info(\"Performing GET request to httpbin.org...\")\n  local body, status, headers, err = net.http_get(\"https://httpbin.org/get\")\n  if err then\n    log.error(\"GET request failed: \" .. err)\n    return false, \"GET request failed\"\n  end\n  log.info(\"GET request successful! Status: \" .. status)\n  -- print(\"Response Body: \" .. body)\n\n  -- Example POST request\n  log.info(\"Performing POST request to httpbin.org...\")\n  local post_body = '{\"name\": \"sloth-runner\", \"awesome\": true}'\n  local post_headers = { [\"Content-Type\"] = \"application/json\" }\n  body, status, headers, err = net.http_post(\"https://httpbin.org/post\", post_body, post_headers)\n  if err then\n    log.error(\"POST request failed: \" .. err)\n    return false, \"POST request failed\"\n  end\n  log.info(\"POST request successful! Status: \" .. status)\n  -- print(\"Response Body: \" .. body)\n\n  -- Example Download\n  local download_path = \"/tmp/sloth-runner-logo.svg\"\n  log.info(\"Downloading file to \" .. download_path)\n  local err = net.download(\"https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/assets/sloth-runner-logo.svg\", download_path)\n  if err then\n    log.error(\"Download failed: \" .. err)\n    return false, \"Download failed\"\n  end\n  log.info(\"File downloaded successfully.\")\n  fs.rm(download_path) -- Clean up\n\n  return true, \"Net module operations successful.\"\nend\n</code></pre>"},{"location":"en/modules/notifications/","title":"Notifications Module","text":"<p>The <code>notifications</code> module provides a simple way to send messages to various notification services from your pipelines. This is particularly useful for reporting the success or failure of a CI/CD workflow.</p> <p>Currently, the following services are supported: - Slack - ntfy</p>"},{"location":"en/modules/notifications/#configuration","title":"Configuration","text":"<p>Before using the module, you need to add the required credentials or URLs to your <code>configs/values.yaml</code> file. The module will read these values at runtime.</p> <pre><code># configs/values.yaml\n\nnotifications:\n  slack:\n    # Your Slack Incoming Webhook URL\n    webhook_url: \"https://hooks.slack.com/services/...\"\n  ntfy:\n    # The ntfy server to use. Can be the public one or self-hosted.\n    server: \"https://ntfy.sh\"\n    # The topic to publish the notification to.\n    topic: \"your-sloth-runner-topic\"\n</code></pre>"},{"location":"en/modules/notifications/#slack","title":"Slack","text":""},{"location":"en/modules/notifications/#notificationsslacksendparams","title":"<code>notifications.slack.send(params)</code>","text":"<p>Sends a message to a Slack channel via an Incoming Webhook.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>webhook_url</code> (string): Required. The Slack Incoming Webhook URL. It's recommended to get this from the <code>values</code> module.</li> <li><code>message</code> (string): Required. The main text of the message.</li> <li><code>pipeline</code> (string): Optional. The name of the pipeline, which will be displayed in the message attachment for context.</li> <li><code>error_details</code> (string): Optional. Any error details to include in the message attachment. This is useful for failure notifications.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local values = require(\"values\")\n\nlocal slack_webhook = values.get(\"notifications.slack.webhook_url\")\n\nif slack_webhook and slack_webhook ~= \"\" then\n  -- On success\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u2705 Pipeline executed successfully!\",\n    pipeline = \"my-awesome-pipeline\"\n  })\n\n  -- On failure\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u274c Pipeline execution failed!\",\n    pipeline = \"my-awesome-pipeline\",\n    error_details = \"Could not connect to database.\"\n  })\nend\n</code></pre>"},{"location":"en/modules/notifications/#ntfy","title":"ntfy","text":""},{"location":"en/modules/notifications/#notificationsntfysendparams","title":"<code>notifications.ntfy.send(params)</code>","text":"<p>Sends a message to an ntfy.sh topic.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>server</code> (string): Required. The ntfy server URL.</li> <li><code>topic</code> (string): Required. The topic to send the message to.</li> <li><code>message</code> (string): Required. The body of the notification.</li> <li><code>title</code> (string): Optional. The title of the notification.</li> <li><code>priority</code> (string): Optional. Notification priority (e.g., <code>high</code>, <code>default</code>, <code>low</code>).</li> <li><code>tags</code> (table): Optional. A list of tags (emojis) to add to the notification.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local values = require(\"values\")\n\nlocal ntfy_server = values.get(\"notifications.ntfy.server\")\nlocal ntfy_topic = values.get(\"notifications.ntfy.topic\")\n\nif ntfy_topic and ntfy_topic ~= \"\" then\n  -- On success\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"Pipeline Success\",\n    message = \"The pipeline finished without errors.\",\n    priority = \"default\",\n    tags = {\"tada\"}\n  })\n\n  -- On failure\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"Pipeline Failed!\",\n    message = \"The pipeline failed with an error.\",\n    priority = \"high\",\n    tags = {\"skull\", \"warning\"}\n  })\nend\n</code></pre>"},{"location":"en/modules/pkg/","title":"<code>pkg</code> Module","text":"<p>The <code>pkg</code> module provides functions for managing system packages. It automatically detects the package manager (<code>apt</code>, <code>yum</code>, <code>brew</code>) and uses <code>sudo</code> when necessary.</p>"},{"location":"en/modules/pkg/#pkginstallpackages","title":"<code>pkg.install(packages)</code>","text":"<p>Installs one or more packages.</p> <ul> <li><code>packages</code>: A string representing a single package, or a Lua table of strings representing multiple packages to install.</li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success, <code>false</code> on failure.</li> <li>The command's output (stdout and stderr).</li> </ul> <p>Examples:</p> <pre><code>-- Install a single package\nlocal success, output = pkg.install(\"htop\")\nif not success then\n  log.error(\"Failed to install htop: \" .. output)\nend\n\n-- Install multiple packages\nlocal success, output = pkg.install({\"htop\", \"git\"})\nif not success then\n  log.error(\"Failed to install htop and git: \" .. output)\nend\n</code></pre>"},{"location":"en/modules/pkg/#pkgremovepackages","title":"<code>pkg.remove(packages)</code>","text":"<p>Removes one or more packages.</p> <ul> <li><code>packages</code>: A string representing a single package, or a Lua table of strings representing multiple packages to remove.</li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success, <code>false</code> on failure.</li> <li>The command's output (stdout and stderr).</li> </ul> <p>Examples:</p> <pre><code>-- Remove a single package\nlocal success, output = pkg.remove(\"htop\")\nif not success then\n  log.error(\"Failed to remove htop: \" .. output)\nend\n\n-- Remove multiple packages\nlocal success, output = pkg.remove({\"htop\", \"git\"})\nif not success then\n  log.error(\"Failed to remove htop and git: \" .. output)\nend\n</code></pre>"},{"location":"en/modules/pkg/#pkgupdate","title":"<code>pkg.update()</code>","text":"<p>Updates the package list.</p> <p>Returns:</p> <ul> <li><code>true</code> on success, <code>false</code> on failure.</li> <li>The command's output (stdout and stderr).</li> </ul> <p>Example:</p> <pre><code>local success, output = pkg.update()\nif not success then\n  log.error(\"Failed to update package list: \" .. output)\nend\n</code></pre>"},{"location":"en/modules/pulumi/","title":"Pulumi Module","text":"<p>The <code>pulumi</code> module provides a fluent API to orchestrate Pulumi stacks, enabling you to manage your Infrastructure as Code (IaC) workflows directly from <code>sloth-runner</code>.</p>"},{"location":"en/modules/pulumi/#pulumistackname-options","title":"<code>pulumi.stack(name, options)</code>","text":"<p>Creates a Pulumi stack object.</p> <ul> <li>Parameters:<ul> <li><code>name</code> (string): The full name of the stack (e.g., <code>\"my-org/my-project/dev\"</code>).</li> <li><code>options</code> (table): A table of options.<ul> <li><code>workdir</code> (string): Required. The path to the Pulumi project directory.</li> </ul> </li> </ul> </li> <li>Returns:<ul> <li><code>stack</code> (object): A <code>PulumiStack</code> object.</li> <li><code>error</code>: An error object if the stack cannot be initialized.</li> </ul> </li> </ul>"},{"location":"en/modules/pulumi/#the-pulumistack-object","title":"The <code>PulumiStack</code> Object","text":"<p>This object represents a specific Pulumi stack and provides methods for interaction.</p>"},{"location":"en/modules/pulumi/#stackupoptions","title":"<code>stack:up([options])</code>","text":"<p>Creates or updates the stack's resources by running <code>pulumi up</code>.</p> <ul> <li>Parameters:<ul> <li><code>options</code> (table, optional):<ul> <li><code>yes</code> (boolean): If <code>true</code>, passes <code>--yes</code> to approve the update automatically.</li> <li><code>config</code> (table): A dictionary of configuration values to pass to the stack.</li> <li><code>args</code> (table): A list of additional string arguments to pass to the command.</li> </ul> </li> </ul> </li> <li>Returns:<ul> <li><code>result</code> (table): A table containing <code>success</code> (boolean), <code>stdout</code> (string), and <code>stderr</code> (string).</li> </ul> </li> </ul>"},{"location":"en/modules/pulumi/#stackpreviewoptions","title":"<code>stack:preview([options])</code>","text":"<p>Previews the changes that would be made by an update by running <code>pulumi preview</code>.</p> <ul> <li>Parameters: Same as <code>stack:up</code>.</li> <li>Returns: Same as <code>stack:up</code>.</li> </ul>"},{"location":"en/modules/pulumi/#stackrefreshoptions","title":"<code>stack:refresh([options])</code>","text":"<p>Refreshes the stack's state by running <code>pulumi refresh</code>.</p> <ul> <li>Parameters: Same as <code>stack:up</code>.</li> <li>Returns: Same as <code>stack:up</code>.</li> </ul>"},{"location":"en/modules/pulumi/#stackdestroyoptions","title":"<code>stack:destroy([options])</code>","text":"<p>Destroys all resources in the stack by running <code>pulumi destroy</code>.</p> <ul> <li>Parameters: Same as <code>stack:up</code>.</li> <li>Returns: Same as <code>stack:up</code>.</li> </ul>"},{"location":"en/modules/pulumi/#stackoutputs","title":"<code>stack:outputs()</code>","text":"<p>Retrieves the outputs of a deployed stack.</p> <ul> <li>Returns:<ul> <li><code>outputs</code> (table): A Lua table of the stack's outputs.</li> <li><code>error</code>: An error object if fetching outputs fails.</li> </ul> </li> </ul>"},{"location":"en/modules/pulumi/#example","title":"Example","text":"<p>This example shows a common pattern: deploying a networking stack (VPC) and then using its output (<code>vpcId</code>) to configure and deploy an application stack.</p> <pre><code>command = function()\n  local pulumi = require(\"pulumi\")\n\n  -- 1. Define the VPC stack\n  local vpc_stack = pulumi.stack(\"my-org/vpc/prod\", { workdir = \"./pulumi/vpc\" })\n\n  -- 2. Deploy the VPC\n  log.info(\"Deploying VPC stack...\")\n  local vpc_result = vpc_stack:up({ yes = true })\n  if not vpc_result.success then\n    return false, \"VPC deployment failed: \" .. vpc_result.stderr\n  end\n\n  -- 3. Get the VPC ID from its outputs\n  log.info(\"Fetching VPC outputs...\")\n  local vpc_outputs, err = vpc_stack:outputs()\n  if err then\n    return false, \"Failed to get VPC outputs: \" .. err\n  end\n  local vpc_id = vpc_outputs.vpcId\n\n  -- 4. Define the App stack\n  local app_stack = pulumi.stack(\"my-org/app/prod\", { workdir = \"./pulumi/app\" })\n\n  -- 5. Deploy the App, passing the vpcId as configuration\n  log.info(\"Deploying App stack into VPC: \" .. vpc_id)\n  local app_result = app_stack:up({\n    yes = true,\n    config = { [\"my-app:vpcId\"] = vpc_id }\n  })\n  if not app_result.success then\n    return false, \"App deployment failed: \" .. app_result.stderr\n  end\n\n  log.info(\"All stacks deployed successfully.\")\n  return true, \"Pulumi orchestration complete.\"\nend\n</code></pre>"},{"location":"en/modules/python/","title":"Python Module","text":"<p>The <code>python</code> module provides a convenient way to manage Python virtual environments (<code>venv</code>) and execute scripts from within your <code>sloth-runner</code> tasks. This is particularly useful for workflows that involve Python-based tools or scripts.</p>"},{"location":"en/modules/python/#pythonvenvpath","title":"<code>python.venv(path)</code>","text":"<p>Creates a Python virtual environment object. Note that this only creates the object in Lua; the environment itself is not created on the file system until you call <code>:create()</code>.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (string): The file system path where the virtual environment should be created (e.g., <code>./.venv</code>).</li> </ul> </li> <li>Returns:<ul> <li><code>venv</code> (object): A virtual environment object with methods to interact with it.</li> </ul> </li> </ul>"},{"location":"en/modules/python/#venvcreate","title":"<code>venv:create()</code>","text":"<p>Creates the virtual environment on the file system at the specified path.</p> <ul> <li>Returns:<ul> <li><code>error</code>: An error object if the creation fails.</li> </ul> </li> </ul>"},{"location":"en/modules/python/#venvpipcommand","title":"<code>venv:pip(command)</code>","text":"<p>Executes a <code>pip</code> command within the context of the virtual environment.</p> <ul> <li>Parameters:<ul> <li><code>command</code> (string): The arguments to pass to <code>pip</code> (e.g., <code>install -r requirements.txt</code>).</li> </ul> </li> <li>Returns:<ul> <li><code>result</code> (table): A table containing the <code>stdout</code>, <code>stderr</code>, and <code>exit_code</code> of the <code>pip</code> command.</li> </ul> </li> </ul>"},{"location":"en/modules/python/#venvexecscript_path","title":"<code>venv:exec(script_path)</code>","text":"<p>Executes a Python script using the Python interpreter from the virtual environment.</p> <ul> <li>Parameters:<ul> <li><code>script_path</code> (string): The path to the Python script to execute.</li> </ul> </li> <li>Returns:<ul> <li><code>result</code> (table): A table containing the <code>stdout</code>, <code>stderr</code>, and <code>exit_code</code> of the script execution.</li> </ul> </li> </ul>"},{"location":"en/modules/python/#example","title":"Example","text":"<p>This example demonstrates a complete lifecycle: creating a virtual environment, installing dependencies from a <code>requirements.txt</code> file, and running a Python script.</p> <pre><code>-- examples/python_venv_lifecycle_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"A task to demonstrate the Python venv lifecycle.\",\n    create_workdir_before_run = true, -- Use a temporary workdir\n    tasks = {\n      {\n        name = \"run-python-script\",\n        description = \"Creates a venv, installs dependencies, and runs a script.\",\n        command = function(params)\n          local python = require(\"python\")\n          local workdir = params.workdir -- Get the temp workdir from the group\n\n          -- 1. Write our Python script and dependencies to the workdir\n          fs.write(workdir .. \"/requirements.txt\", \"requests==2.28.1\")\n          fs.write(workdir .. \"/main.py\", \"import requests\\nprint(f'Hello from Python! Using requests version: {requests.__version__}')\")\n\n          -- 2. Create a venv object\n          local venv_path = workdir .. \"/.venv\"\n          log.info(\"Setting up virtual environment at: \" .. venv_path)\n          local venv = python.venv(venv_path)\n\n          -- 3. Create the venv on the filesystem\n          venv:create()\n\n          -- 4. Install dependencies using pip\n          log.info(\"Installing dependencies from requirements.txt...\")\n          local pip_result = venv:pip(\"install -r \" .. workdir .. \"/requirements.txt\")\n          if pip_result.exit_code ~= 0 then\n            log.error(\"Pip install failed: \" .. pip_result.stderr)\n            return false, \"Failed to install Python dependencies.\"\n          end\n\n          -- 5. Execute the script\n          log.info(\"Running the Python script...\")\n          local exec_result = venv:exec(workdir .. \"/main.py\")\n          if exec_result.exit_code ~= 0 then\n            log.error(\"Python script failed: \" .. exec_result.stderr)\n            return false, \"Python script execution failed.\"\n          end\n\n          log.info(\"Python script executed successfully.\")\n          print(\"---\\n--- Python Script Output ---\")\n          print(exec_result.stdout)\n          print(\"----------------------------\")\n\n          return true, \"Python venv lifecycle complete.\"\n        end\n      }\n    }\n  }\n}\n</code></pre> <p>```</p>"},{"location":"en/modules/reliability/","title":"\ud83d\udee1\ufe0f Reliability Module","text":"<p>The Reliability module provides enterprise-grade reliability patterns including circuit breakers, retry logic with exponential backoff, and failure handling strategies. These patterns help build resilient systems that can gracefully handle failures and recover automatically.</p>"},{"location":"en/modules/reliability/#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>Circuit Breaker Pattern: Prevents cascading failures by stopping calls to failing services</li> <li>Retry Logic: Configurable retry strategies with backoff algorithms</li> <li>Failure Tracking: Persistent failure state across task executions</li> <li>Multiple Strategies: Fixed delay, exponential backoff, linear backoff, custom</li> <li>Jitter Support: Randomization to prevent thundering herd problems</li> <li>State Integration: Uses state module for persistent failure tracking</li> <li>Callback Support: Custom callbacks for retry and state change events</li> </ul>"},{"location":"en/modules/reliability/#basic-usage","title":"\ud83d\udccb Basic Usage","text":""},{"location":"en/modules/reliability/#simple-retry","title":"Simple Retry","text":"<pre><code>-- Retry a function up to 3 times with 1 second initial delay\nlocal result = reliability.retry(3, 1, function()\n    -- Your potentially failing code here\n    if math.random() &gt; 0.7 then\n        return \"Success!\"\n    else\n        return nil, \"Random failure\"\n    end\nend)\n\nif result then\n    log.info(\"Operation succeeded: \" .. result)\nelse \n    log.error(\"All retries failed\")\nend\n</code></pre>"},{"location":"en/modules/reliability/#advanced-retry-configuration","title":"Advanced Retry Configuration","text":"<pre><code>local config = {\n    max_attempts = 5,\n    initial_delay = 0.5,  -- 500ms\n    max_delay = 10,       -- 10 seconds max\n    strategy = reliability.strategy.EXPONENTIAL_BACKOFF,\n    multiplier = 2.0,\n    jitter = true,\n    on_retry = function(attempt, delay, error)\n        log.warn(\"Retry attempt \" .. attempt .. \" in \" .. delay .. \"s: \" .. error)\n    end\n}\n\nlocal result = reliability.retry_with_config(config, function()\n    -- Your code here\n    return call_external_service()\nend)\n</code></pre>"},{"location":"en/modules/reliability/#circuit-breaker","title":"Circuit Breaker","text":"<pre><code>local cb_config = {\n    max_failures = 3,     -- Open after 3 failures\n    timeout = 30,         -- Wait 30 seconds before trying half-open\n    success_threshold = 2, -- Need 2 successes to close circuit\n    on_state_change = function(from_state, to_state)\n        log.info(\"Circuit breaker: \" .. from_state .. \" -&gt; \" .. to_state)\n    end\n}\n\nlocal result = reliability.circuit_breaker(\"external_api\", cb_config, function()\n    -- Call that might fail\n    return http.get(\"https://api.example.com/data\")\nend)\n</code></pre>"},{"location":"en/modules/reliability/#retry-strategies","title":"\ud83d\udd04 Retry Strategies","text":""},{"location":"en/modules/reliability/#available-strategy-types","title":"Available Strategy Types","text":"<pre><code>-- Fixed delay between retries\nreliability.strategy.FIXED_DELAY\n\n-- Exponential backoff (delay doubles each time)\nreliability.strategy.EXPONENTIAL_BACKOFF  \n\n-- Linear backoff (delay increases linearly)\nreliability.strategy.LINEAR_BACKOFF\n\n-- Custom delay function\nreliability.strategy.CUSTOM_BACKOFF\n</code></pre>"},{"location":"en/modules/reliability/#custom-delay-function","title":"Custom Delay Function","text":"<pre><code>local config = {\n    max_attempts = 5,\n    strategy = reliability.strategy.CUSTOM_BACKOFF,\n    custom_delay = function(attempt)\n        -- Custom fibonacci-like delays\n        if attempt == 1 then return 1 end\n        if attempt == 2 then return 1 end\n        return (attempt - 1) + (attempt - 2)\n    end\n}\n</code></pre>"},{"location":"en/modules/reliability/#circuit-breaker-states","title":"\u26a1 Circuit Breaker States","text":""},{"location":"en/modules/reliability/#state-transitions","title":"State Transitions","text":"<ul> <li>Closed \u2192 Open: After max_failures consecutive failures</li> <li>Open \u2192 Half-Open: After timeout period expires  </li> <li>Half-Open \u2192 Closed: After success_threshold successes</li> <li>Half-Open \u2192 Open: After any failure</li> </ul>"},{"location":"en/modules/reliability/#monitoring-circuit-state","title":"Monitoring Circuit State","text":"<pre><code>-- Get current statistics\nlocal stats = reliability.get_circuit_stats(\"my_service\")\nif stats then\n    log.info(\"Circuit state: \" .. stats.state)\n    log.info(\"Total requests: \" .. stats.requests)\n    log.info(\"Success rate: \" .. (stats.total_success / stats.requests * 100) .. \"%\")\nend\n\n-- List all circuit breakers\nlocal circuits = reliability.list_circuits()\nfor _, name in ipairs(circuits) do\n    log.info(\"Circuit: \" .. name)\nend\n\n-- Reset circuit breaker\nreliability.reset_circuit(\"my_service\")\n</code></pre>"},{"location":"en/modules/reliability/#integration-with-state-module","title":"\ud83d\udd17 Integration with State Module","text":""},{"location":"en/modules/reliability/#persistent-failure-tracking","title":"Persistent Failure Tracking","text":"<pre><code>-- Track failures across task executions\nlocal service_name = \"payment_service\"\nlocal failure_key = \"failures:\" .. service_name\n\nlocal function make_payment_call()\n    local success = make_api_call()\n\n    if success then\n        -- Reset failure count on success\n        state.set(failure_key, \"0\")\n        return true\n    else\n        -- Increment failure counter\n        local failures = state.increment(failure_key, 1)\n\n        -- Circuit break if too many failures\n        if failures &gt;= 5 then\n            return nil, \"Service circuit opened - too many failures\"\n        end\n\n        return nil, \"Temporary service failure\"\n    end\nend\n\n-- Use with retry\nlocal result = reliability.retry(3, 2, make_payment_call)\n</code></pre>"},{"location":"en/modules/reliability/#distributed-lock-with-retry","title":"Distributed Lock with Retry","text":"<pre><code>-- Combine distributed locking with retry logic\nlocal retry_config = {\n    max_attempts = 5,\n    initial_delay = 0.5,\n    strategy = reliability.strategy.LINEAR_BACKOFF\n}\n\nlocal result = reliability.retry_with_config(retry_config, function()\n    -- Try to acquire distributed lock\n    if not state.try_lock(\"critical_resource\", 10) then\n        return nil, \"Could not acquire lock\"\n    end\n\n    -- Do critical work\n    local work_result = perform_critical_operation()\n\n    -- Release lock\n    state.unlock(\"critical_resource\")\n\n    return work_result\nend)\n</code></pre>"},{"location":"en/modules/reliability/#advanced-patterns","title":"\ud83d\udcca Advanced Patterns","text":""},{"location":"en/modules/reliability/#combine-multiple-patterns","title":"Combine Multiple Patterns","text":"<pre><code>-- Deployment with circuit breaker, retry, and state tracking\nlocal deployment_steps = {\"validate\", \"backup\", \"deploy\", \"verify\"}\n\nfor _, step in ipairs(deployment_steps) do\n    local step_result = reliability.retry_with_config({\n        max_attempts = 3,\n        initial_delay = 1,\n        strategy = reliability.strategy.EXPONENTIAL_BACKOFF,\n        on_retry = function(attempt, delay, error)\n            state.append(\"deployment_log\", \n                step .. \" retry \" .. attempt .. \": \" .. error, \"\\n\")\n        end\n    }, function()\n        return reliability.circuit_breaker(\"deployment_service\", {\n            max_failures = 2,\n            timeout = 30,\n            on_state_change = function(from, to)\n                state.set(\"deployment_cb_state\", to)\n            end\n        }, function()\n            return execute_deployment_step(step)\n        end)\n    end)\n\n    if not step_result then\n        state.set(\"deployment_status\", \"failed_at_\" .. step)\n        return false, \"Deployment failed at: \" .. step\n    end\n\n    -- Update progress\n    local progress = math.floor((step_index / #deployment_steps) * 100)\n    state.set(\"deployment_progress\", progress)\nend\n\nstate.set(\"deployment_status\", \"completed\")\n</code></pre>"},{"location":"en/modules/reliability/#health-check-with-backoff","title":"Health Check with Backoff","text":"<pre><code>-- Health check with exponential backoff\nlocal health_config = {\n    max_attempts = 10,\n    initial_delay = 1,\n    max_delay = 60,\n    strategy = reliability.strategy.EXPONENTIAL_BACKOFF,\n    multiplier = 1.5,\n    jitter = true\n}\n\nlocal health_status = reliability.retry_with_config(health_config, function()\n    local response = http.get(\"http://localhost:8080/health\")\n\n    if response.status == 200 then\n        return response.body\n    else\n        return nil, \"Health check failed: \" .. response.status\n    end\nend)\n</code></pre>"},{"location":"en/modules/reliability/#configuration-reference","title":"\ud83c\udf9b\ufe0f Configuration Reference","text":""},{"location":"en/modules/reliability/#retry-configuration","title":"Retry Configuration","text":"<pre><code>{\n    max_attempts = 3,           -- Maximum retry attempts\n    initial_delay = 1,          -- Initial delay in seconds\n    max_delay = 30,             -- Maximum delay in seconds  \n    strategy = \"exponential\",   -- Retry strategy\n    multiplier = 2.0,           -- Backoff multiplier\n    jitter = true,              -- Add random jitter\n    on_retry = function(attempt, delay, error)\n        -- Retry callback\n    end\n}\n</code></pre>"},{"location":"en/modules/reliability/#circuit-breaker-configuration","title":"Circuit Breaker Configuration","text":"<pre><code>{\n    max_failures = 5,           -- Failures before opening\n    timeout = 60,               -- Seconds before half-open\n    success_threshold = 1,      -- Successes needed to close\n    on_state_change = function(from, to)\n        -- State change callback  \n    end\n}\n</code></pre>"},{"location":"en/modules/reliability/#error-handling","title":"\ud83d\udea8 Error Handling","text":""},{"location":"en/modules/reliability/#custom-error-predicates","title":"Custom Error Predicates","text":"<pre><code>-- Retry only on specific errors\nlocal config = {\n    max_attempts = 3,\n    should_retry = function(error)\n        -- Only retry on network errors\n        return string.find(error, \"network\") or string.find(error, \"timeout\")\n    end\n}\n</code></pre>"},{"location":"en/modules/reliability/#error-types","title":"Error Types","text":"<ul> <li>RetryableError: Explicitly marked as retryable</li> <li>NonRetryableError: Should not be retried</li> <li>CircuitBreakerError: Circuit is open, don't retry immediately</li> </ul>"},{"location":"en/modules/reliability/#monitoring-and-observability","title":"\ud83d\udcc8 Monitoring and Observability","text":""},{"location":"en/modules/reliability/#metrics-collection","title":"Metrics Collection","text":"<pre><code>-- Circuit breaker metrics\nlocal cb_stats = reliability.get_circuit_stats(\"service_name\")\n-- Returns: requests, total_success, total_failures, consecutive_success, \n--          consecutive_failures, state, last_success_time, last_failure_time\n\n-- State-based metrics\nlocal failure_count = tonumber(state.get(\"service_failures\", \"0\"))\nlocal success_rate = calculate_success_rate()\n\n-- Log metrics\nlog.info(\"Service metrics\", {\n    circuit_state = cb_stats.state,\n    failure_count = failure_count,\n    success_rate = success_rate\n})\n</code></pre> <p>The reliability module provides the foundation for building resilient, fault-tolerant automation workflows that can handle failures gracefully and recover automatically.</p>"},{"location":"en/modules/salt/","title":"Salt Module","text":"<p>The <code>salt</code> module provides a fluent API to interact with SaltStack, allowing you to run remote execution commands and manage configurations from your <code>sloth-runner</code> workflows.</p>"},{"location":"en/modules/salt/#saltclientoptions","title":"<code>salt.client([options])</code>","text":"<p>Creates a Salt client object.</p> <ul> <li>Parameters:<ul> <li><code>options</code> (table, optional): A table of options.<ul> <li><code>config_path</code> (string): Path to the Salt master configuration file.</li> </ul> </li> </ul> </li> <li>Returns:<ul> <li><code>client</code> (object): A <code>SaltClient</code> object.</li> </ul> </li> </ul>"},{"location":"en/modules/salt/#the-saltclient-object","title":"The <code>SaltClient</code> Object","text":"<p>This object represents a client for a Salt master and provides methods for targeting minions.</p>"},{"location":"en/modules/salt/#clienttargettarget_string-expr_form","title":"<code>client:target(target_string, [expr_form])</code>","text":"<p>Specifies the minion(s) to target for a command.</p> <ul> <li>Parameters:<ul> <li><code>target_string</code> (string): The target expression (e.g., <code>\"*\"</code> for all minions, <code>\"web-server-1\"</code>, or a grain value).</li> <li><code>expr_form</code> (string, optional): The type of targeting to use (e.g., <code>\"glob\"</code>, <code>\"grain\"</code>, <code>\"list\"</code>). Defaults to glob.</li> </ul> </li> <li>Returns:<ul> <li><code>target</code> (object): A <code>SaltTarget</code> object.</li> </ul> </li> </ul>"},{"location":"en/modules/salt/#the-salttarget-object","title":"The <code>SaltTarget</code> Object","text":"<p>This object represents a specific target and provides chainable methods for executing Salt functions.</p>"},{"location":"en/modules/salt/#targetcmdfunction-arg1-arg2","title":"<code>target:cmd(function, [arg1, arg2, ...])</code>","text":"<p>Executes a Salt execution module function on the target.</p> <ul> <li>Parameters:<ul> <li><code>function</code> (string): The name of the function to run (e.g., <code>\"test.ping\"</code>, <code>\"state.apply\"</code>, <code>\"cmd.run\"</code>).</li> <li><code>arg1</code>, <code>arg2</code>, ... (any): Additional arguments to pass to the Salt function.</li> </ul> </li> <li>Returns:<ul> <li><code>result</code> (table): A table containing <code>success</code> (boolean), <code>stdout</code> (string or table), and <code>stderr</code> (string). If the Salt command returns JSON, <code>stdout</code> will be a parsed Lua table.</li> </ul> </li> </ul>"},{"location":"en/modules/salt/#example","title":"Example","text":"<p>This example demonstrates targeting minions to ping them and apply a Salt state.</p> <pre><code>command = function()\n  local salt = require(\"salt\")\n\n  -- 1. Create a Salt client\n  local client = salt.client()\n\n  -- 2. Target all minions and ping them\n  log.info(\"Pinging all minions...\")\n  local ping_result = client:target(\"*\"):cmd(\"test.ping\")\n  if not ping_result.success then\n    return false, \"Failed to ping minions: \" .. ping_result.stderr\n  end\n  print(\"Ping Results:\")\n  print(data.to_yaml(ping_result.stdout)) -- stdout is a table\n\n  -- 3. Target a specific web server and apply a state\n  log.info(\"Applying 'nginx' state to web-server-1...\")\n  local apply_result = client:target(\"web-server-1\", \"glob\"):cmd(\"state.apply\", \"nginx\")\n  if not apply_result.success then\n    return false, \"Failed to apply state: \" .. apply_result.stderr\n  end\n\n  log.info(\"State applied successfully.\")\n  return true, \"Salt operations complete.\"\nend\n</code></pre>"},{"location":"en/modules/state/","title":"\ud83d\udcbe State Management Module","text":"<p>The State Management module provides powerful persistent state capabilities with atomic operations, distributed locks, and TTL (Time To Live) functionality. All data is stored locally using SQLite with WAL mode for maximum performance and reliability.</p>"},{"location":"en/modules/state/#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>SQLite Persistence: Reliable storage with WAL mode</li> <li>Atomic Operations: Thread-safe increment, compare-and-swap, append</li> <li>Distributed Locks: Critical sections with automatic timeout</li> <li>TTL (Time To Live): Automatic key expiration</li> <li>Data Types: String, number, boolean, table, list</li> <li>Pattern Matching: Wildcard key searches</li> <li>Auto Cleanup: Background cleanup of expired data</li> <li>Statistics: Usage and performance metrics</li> </ul>"},{"location":"en/modules/state/#basic-usage","title":"\ud83d\udccb Basic Usage","text":""},{"location":"en/modules/state/#setting-and-getting-values","title":"Setting and Getting Values","text":"<pre><code>-- Set values\nstate.set(\"app_version\", \"v1.2.3\")\nstate.set(\"user_count\", 1000)\nstate.set(\"config\", {\n    debug = true,\n    max_connections = 100\n})\n\n-- Get values\nlocal version = state.get(\"app_version\")\nlocal count = state.get(\"user_count\")\nlocal config = state.get(\"config\")\n\n-- Get with default value\nlocal theme = state.get(\"ui_theme\", \"dark\")\n\n-- Check existence\nif state.exists(\"app_version\") then\n    log.info(\"App version is configured\")\nend\n\n-- Delete key\nstate.delete(\"old_key\")\n</code></pre>"},{"location":"en/modules/state/#ttl-time-to-live","title":"TTL (Time To Live)","text":"<pre><code>-- Set with TTL (60 seconds)\nstate.set(\"session_token\", \"abc123\", 60)\n\n-- Set TTL for existing key\nstate.set_ttl(\"user_session\", 300) -- 5 minutes\n\n-- Check remaining TTL\nlocal ttl = state.get_ttl(\"session_token\")\nlog.info(\"Token expires in \" .. ttl .. \" seconds\")\n</code></pre>"},{"location":"en/modules/state/#atomic-operations","title":"Atomic Operations","text":"<pre><code>-- Atomic increment\nlocal counter = state.increment(\"page_views\", 1)\nlocal bulk_counter = state.increment(\"downloads\", 50)\n\n-- Atomic decrement  \nlocal remaining = state.decrement(\"inventory\", 5)\n\n-- String append\nstate.set(\"log_messages\", \"Starting application\")\nlocal new_length = state.append(\"log_messages\", \" -&gt; Connecting to database\")\n\n-- Atomic compare-and-swap\nlocal old_version = state.get(\"config_version\")\nlocal success = state.compare_swap(\"config_version\", old_version, old_version + 1)\nif success then\n    log.info(\"Configuration updated safely\")\nend\n</code></pre>"},{"location":"en/modules/state/#list-operations","title":"List Operations","text":"<pre><code>-- Add items to list\nstate.list_push(\"deployment_queue\", {\n    app = \"frontend\",\n    version = \"v2.1.0\",\n    environment = \"staging\"\n})\n\n-- Check list size\nlocal queue_size = state.list_length(\"deployment_queue\")\nlog.info(\"Items in queue: \" .. queue_size)\n\n-- Process list (pop removes last item)\nwhile state.list_length(\"deployment_queue\") &gt; 0 do\n    local deployment = state.list_pop(\"deployment_queue\")\n    log.info(\"Processing deployment: \" .. deployment.app)\n    -- Process deployment...\nend\n</code></pre>"},{"location":"en/modules/state/#distributed-locks-and-critical-sections","title":"Distributed Locks and Critical Sections","text":"<pre><code>-- Try to acquire lock (no waiting)\nlocal lock_acquired = state.try_lock(\"deployment_lock\", 30) -- 30 seconds TTL\nif lock_acquired then\n    -- Critical work\n    state.unlock(\"deployment_lock\")\nend\n\n-- Lock with wait and timeout\nlocal acquired = state.lock(\"database_migration\", 60) -- wait up to 60s\nif acquired then\n    -- Execute migration\n    state.unlock(\"database_migration\")\nend\n\n-- Critical section with automatic lock management\nstate.with_lock(\"critical_section\", function()\n    log.info(\"Executing critical operation...\")\n\n    -- Update global counter\n    local counter = state.increment(\"global_counter\", 1)\n\n    -- Update timestamp\n    state.set(\"last_operation\", os.time())\n\n    log.info(\"Critical operation completed - counter: \" .. counter)\n\n    -- Lock is automatically released when function returns\n    return \"operation_success\"\nend, 15) -- 15 second timeout\n</code></pre>"},{"location":"en/modules/state/#api-reference","title":"\ud83d\udd0d API Reference","text":""},{"location":"en/modules/state/#basic-operations","title":"Basic Operations","text":"Function Parameters Return Description <code>state.set(key, value, ttl?)</code> key: string, value: any, ttl?: number success: boolean Set a value with optional TTL <code>state.get(key, default?)</code> key: string, default?: any value: any Get a value or return default <code>state.delete(key)</code> key: string success: boolean Remove a key <code>state.exists(key)</code> key: string exists: boolean Check if key exists <code>state.clear(pattern?)</code> pattern?: string success: boolean Remove keys by pattern"},{"location":"en/modules/state/#ttl-operations","title":"TTL Operations","text":"Function Parameters Return Description <code>state.set_ttl(key, seconds)</code> key: string, seconds: number success: boolean Set TTL for existing key <code>state.get_ttl(key)</code> key: string ttl: number Get remaining TTL (-1 = no TTL, -2 = not exists)"},{"location":"en/modules/state/#atomic-operations_1","title":"Atomic Operations","text":"Function Parameters Return Description <code>state.increment(key, delta?)</code> key: string, delta?: number new_value: number Atomically increment value <code>state.decrement(key, delta?)</code> key: string, delta?: number new_value: number Atomically decrement value <code>state.append(key, value)</code> key: string, value: string new_length: number Atomically append string <code>state.compare_swap(key, old, new)</code> key: string, old: any, new: any success: boolean Atomic compare-and-swap"},{"location":"en/modules/state/#list-operations_1","title":"List Operations","text":"Function Parameters Return Description <code>state.list_push(key, item)</code> key: string, item: any length: number Add item to end of list <code>state.list_pop(key)</code> key: string item: any | nil Remove and return last item <code>state.list_length(key)</code> key: string length: number Get list length"},{"location":"en/modules/state/#distributed-locks","title":"Distributed Locks","text":"Function Parameters Return Description <code>state.try_lock(name, ttl)</code> name: string, ttl: number success: boolean Try to acquire lock without waiting <code>state.lock(name, timeout?)</code> name: string, timeout?: number success: boolean Acquire lock with timeout <code>state.unlock(name)</code> name: string success: boolean Release lock <code>state.with_lock(name, fn, timeout?)</code> name: string, fn: function, timeout?: number result: any Execute function with automatic lock"},{"location":"en/modules/state/#utilities","title":"Utilities","text":"Function Parameters Return Description <code>state.keys(pattern?)</code> pattern?: string keys: table List keys by pattern <code>state.stats()</code> - stats: table Get system statistics"},{"location":"en/modules/state/#practical-use-cases","title":"\ud83d\udca1 Practical Use Cases","text":""},{"location":"en/modules/state/#1-deployment-version-control","title":"1. Deployment Version Control","text":"<pre><code>Modern DSLs = {\n    deployment_pipeline = {\n        tasks = {\n            prepare_deploy = {\n                command = function()\n                    -- Check last deployed version\n                    local last_version = state.get(\"last_deployed_version\", \"v0.0.0\")\n                    local new_version = \"v1.2.3\"\n\n                    -- Check if already deployed\n                    if last_version == new_version then\n                        log.warn(\"Version \" .. new_version .. \" already deployed\")\n                        return false, \"Version already deployed\"\n                    end\n\n                    -- Register deployment start\n                    state.set(\"deploy_status\", \"in_progress\")\n                    state.set(\"deploy_start_time\", os.time())\n                    state.increment(\"total_deploys\", 1)\n\n                    return true, \"Deploy preparation completed\"\n                end\n            },\n\n            execute_deploy = {\n                depends_on = \"prepare_deploy\",\n                command = function()\n                    -- Critical section for deployment\n                    return state.with_lock(\"deployment_lock\", function()\n                        log.info(\"Executing deployment with lock...\")\n\n                        -- Simulate deployment\n                        exec.run(\"sleep 5\")\n\n                        -- Update state\n                        state.set(\"last_deployed_version\", \"v1.2.3\")\n                        state.set(\"deploy_status\", \"completed\")\n                        state.set(\"deploy_end_time\", os.time())\n\n                        -- Record history\n                        state.list_push(\"deploy_history\", {\n                            version = \"v1.2.3\",\n                            timestamp = os.time(),\n                            duration = state.get(\"deploy_end_time\") - state.get(\"deploy_start_time\")\n                        })\n\n                        return true, \"Deploy completed successfully\"\n                    end, 300) -- 5 minutes timeout\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"en/modules/state/#2-intelligent-caching-with-ttl","title":"2. Intelligent Caching with TTL","text":"<pre><code>-- Helper function for caching\nfunction get_cached_data(cache_key, fetch_function, ttl)\n    local cached = state.get(cache_key)\n    if cached then\n        log.info(\"Cache hit: \" .. cache_key)\n        return cached\n    end\n\n    log.info(\"Cache miss: \" .. cache_key .. \" - fetching...\")\n    local data = fetch_function()\n    state.set(cache_key, data, ttl or 300) -- 5 minutes default\n    return data\nend\n\n-- Usage in tasks\nModern DSLs = {\n    data_processing = {\n        tasks = {\n            fetch_user_data = {\n                command = function()\n                    local user_data = get_cached_data(\"user:123:profile\", function()\n                        -- Simulate expensive fetch\n                        return {\n                            name = \"Alice\",\n                            email = \"alice@example.com\",\n                            preferences = {\"dark_mode\", \"notifications\"}\n                        }\n                    end, 600) -- Cache for 10 minutes\n\n                    log.info(\"User data: \" .. data.to_json(user_data))\n                    return true, \"User data retrieved\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"en/modules/state/#3-rate-limiting","title":"3. Rate Limiting","text":"<pre><code>function check_rate_limit(identifier, max_requests, window_seconds)\n    local key = \"rate_limit:\" .. identifier\n    local current_count = state.get(key, 0)\n\n    if current_count &gt;= max_requests then\n        return false, \"Rate limit exceeded\"\n    end\n\n    -- Increment counter\n    if current_count == 0 then\n        -- First request in window\n        state.set(key, 1, window_seconds)\n    else\n        -- Increment existing counter\n        state.increment(key, 1)\n    end\n\n    return true, \"Request allowed\"\nend\n\n-- Usage in tasks\nModern DSLs = {\n    api_tasks = {\n        tasks = {\n            make_api_call = {\n                command = function()\n                    local allowed, msg = check_rate_limit(\"api_calls\", 100, 3600) -- 100 calls/hour\n\n                    if not allowed then\n                        log.error(msg)\n                        return false, msg\n                    end\n\n                    -- Make API call\n                    log.info(\"Making API call...\")\n                    return true, \"API call completed\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"en/modules/state/#configuration-and-storage","title":"\u2699\ufe0f Configuration and Storage","text":""},{"location":"en/modules/state/#database-location","title":"Database Location","text":"<p>By default, the SQLite database is created at: - Linux/macOS: <code>~/.sloth-runner/state.db</code> - Windows: <code>%USERPROFILE%\\.sloth-runner\\state.db</code></p>"},{"location":"en/modules/state/#technical-characteristics","title":"Technical Characteristics","text":"<ul> <li>Engine: SQLite 3 with WAL mode</li> <li>Concurrent Access: Support for multiple simultaneous connections</li> <li>Auto-cleanup: Automatic cleanup of expired data every 5 minutes</li> <li>Lock Timeout: Expired locks are cleaned automatically</li> <li>Serialization: JSON for complex objects, native format for simple types</li> </ul>"},{"location":"en/modules/state/#limitations","title":"Limitations","text":"<ul> <li>Local Scope: State is persisted only on local machine</li> <li>Concurrency: Locks are effective only within local process</li> <li>Size: Suitable for small to medium datasets (&lt; 1GB)</li> </ul>"},{"location":"en/modules/state/#best-practices","title":"\ud83d\udd04 Best Practices","text":"<ol> <li>Use TTL for temporary data to prevent storage bloat</li> <li>Use locks for critical sections to avoid race conditions  </li> <li>Use patterns for bulk operations to manage related keys</li> <li>Monitor storage size using <code>state.stats()</code> </li> <li>Use atomic operations instead of read-modify-write patterns</li> <li>Clean up expired keys regularly with <code>state.clear(pattern)</code></li> </ol> <p>The State Management module transforms sloth-runner into a stateful, reliable platform for complex task orchestration! \ud83d\ude80</p>"},{"location":"en/modules/terraform/","title":"Terraform Module","text":"<p>The <code>terraform</code> module provides a high-level interface for orchestrating <code>terraform</code> CLI commands, allowing you to manage your infrastructure lifecycle directly from within a Sloth-Runner pipeline.</p>"},{"location":"en/modules/terraform/#configuration","title":"Configuration","text":"<p>This module requires the <code>terraform</code> CLI to be installed and available in the system's PATH. All commands must be executed within a specific <code>workdir</code> where your <code>.tf</code> files are located.</p>"},{"location":"en/modules/terraform/#functions","title":"Functions","text":""},{"location":"en/modules/terraform/#terraforminitparams","title":"<code>terraform.init(params)</code>","text":"<p>Initializes a Terraform working directory.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory containing the Terraform files.</li> </ul> </li> <li>Returns: A result table with <code>success</code>, <code>stdout</code>, <code>stderr</code>, and <code>exit_code</code>.</li> </ul>"},{"location":"en/modules/terraform/#terraformplanparams","title":"<code>terraform.plan(params)</code>","text":"<p>Creates a Terraform execution plan.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>out</code> (string): Optional. The filename to save the generated plan to.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"en/modules/terraform/#terraformapplyparams","title":"<code>terraform.apply(params)</code>","text":"<p>Applies a Terraform plan.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>plan</code> (string): Optional. The path to a plan file to apply.</li> <li><code>auto_approve</code> (boolean): Optional. If <code>true</code>, applies changes without interactive approval.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"en/modules/terraform/#terraformdestroyparams","title":"<code>terraform.destroy(params)</code>","text":"<p>Destroys Terraform-managed infrastructure.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>auto_approve</code> (boolean): Optional. If <code>true</code>, destroys resources without interactive approval.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"en/modules/terraform/#terraformoutputparams","title":"<code>terraform.output(params)</code>","text":"<p>Reads an output variable from a Terraform state file.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>name</code> (string): Optional. The name of a specific output to read. If omitted, all outputs are returned as a table.</li> </ul> </li> <li>Returns:<ul> <li>On success: The parsed JSON value of the output (can be a string, table, etc.).</li> <li>On failure: <code>nil, error_message</code>.</li> </ul> </li> </ul>"},{"location":"en/modules/terraform/#full-lifecycle-example","title":"Full Lifecycle Example","text":"<pre><code>local tf_workdir = \"./examples/terraform\"\n\n-- Task 1: Init\nlocal result_init = terraform.init({workdir = tf_workdir})\nif not result_init.success then return false, \"Init failed\" end\n\n-- Task 2: Plan\nlocal result_plan = terraform.plan({workdir = tf_workdir})\nif not result_plan.success then return false, \"Plan failed\" end\n\n-- Task 3: Apply\nlocal result_apply = terraform.apply({workdir = tf_workdir, auto_approve = true})\nif not result_apply.success then return false, \"Apply failed\" end\n\n-- Task 4: Get Output\nlocal filename, err = terraform.output({workdir = tf_workdir, name = \"report_filename\"})\nif not filename then return false, \"Output failed: \" .. err end\nlog.info(\"Terraform created file: \" .. filename)\n\n-- Task 5: Destroy\nlocal result_destroy = terraform.destroy({workdir = tf_workdir, auto_approve = true})\nif not result_destroy.success then return false, \"Destroy failed\" end\n</code></pre>"},{"location":"modern-dsl/best-practices/","title":"\ud83d\udcdd Modern DSL Best Practices","text":"<p>This guide provides best practices, patterns, and recommendations for writing effective workflows using the Modern DSL.</p>"},{"location":"modern-dsl/best-practices/#general-principles","title":"\ud83c\udfaf General Principles","text":""},{"location":"modern-dsl/best-practices/#1-clear-and-descriptive-naming","title":"1. Clear and Descriptive Naming","text":"<pre><code>-- \u274c Poor naming\nlocal t1 = task(\"t1\"):command(\"npm run build\"):build()\nlocal t2 = task(\"t2\"):command(\"npm test\"):build()\n\n-- \u2705 Good naming\nlocal build_frontend = task(\"build_frontend\")\n    :description(\"Build React frontend application\")\n    :command(\"npm run build:frontend\")\n    :build()\n\nlocal run_unit_tests = task(\"run_unit_tests\")\n    :description(\"Execute Jest unit test suite\")\n    :command(\"npm run test:unit\")\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#2-comprehensive-documentation","title":"2. Comprehensive Documentation","text":"<pre><code>local deploy_to_production = task(\"deploy_to_production\")\n    :description(\"Deploy application to production Kubernetes cluster with health checks\")\n    :command(function(params, deps)\n        -- Deploy using helm with production values\n        local result = exec.run(\"helm upgrade --install myapp ./charts/myapp -f values.prod.yaml\")\n\n        if not result.success then\n            return false, \"Helm deployment failed: \" .. result.stderr\n        end\n\n        -- Verify deployment health\n        local health_check = k8s.wait_for_pods(\"app=myapp\", \"5m\")\n        if not health_check.ready then\n            return false, \"Pods not ready within timeout\"\n        end\n\n        return true, \"Production deployment successful\", {\n            release_name = \"myapp\",\n            pods_ready = health_check.count,\n            deployment_time = os.time()\n        }\n    end)\n    :metadata({\n        owner = \"platform-team\",\n        runbook = \"https://runbooks.company.com/production-deploy\",\n        escalation = \"platform-oncall@company.com\"\n    })\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#3-consistent-error-handling","title":"3. Consistent Error Handling","text":"<pre><code>local process_data_task = task(\"process_data\")\n    :description(\"Process incoming data with comprehensive error handling\")\n    :command(function(params, deps)\n        local input_data = deps.fetch_data.result\n\n        -- Validate input\n        if not input_data or #input_data == 0 then\n            return false, \"No input data received from fetch_data task\"\n        end\n\n        -- Process with error handling\n        local success, result, error = pcall(function()\n            return data_processor.process(input_data, {\n                format = params.output_format or \"json\",\n                validation = true,\n                sanitize = true\n            })\n        end)\n\n        if not success then\n            return false, \"Data processing failed: \" .. (error or \"unknown error\")\n        end\n\n        -- Validate output\n        if not result or not result.processed_count then\n            return false, \"Processing completed but output validation failed\"\n        end\n\n        log.info(\"Successfully processed \" .. result.processed_count .. \" records\")\n\n        return true, \"Data processing completed\", {\n            processed_count = result.processed_count,\n            output_file = result.output_file,\n            processing_time = result.duration\n        }\n    end)\n    :timeout(\"30m\")\n    :retries(2, \"exponential\")\n    :on_failure(function(params, error)\n        log.error(\"Data processing failed: \" .. error)\n\n        -- Send detailed failure notification\n        notifications.send(\"slack\", {\n            channel = \"#data-alerts\",\n            message = \"\ud83d\udea8 Data processing pipeline failed\\n\" ..\n                     \"Error: \" .. error .. \"\\n\" ..\n                     \"Input size: \" .. (params.input_size or \"unknown\") .. \"\\n\" ..\n                     \"Runbook: https://runbooks.company.com/data-processing\"\n        })\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#task-design-patterns","title":"\ud83c\udfd7\ufe0f Task Design Patterns","text":""},{"location":"modern-dsl/best-practices/#pattern-1-idempotent-tasks","title":"Pattern 1: Idempotent Tasks","text":"<p>Design tasks that can be safely re-run:</p> <pre><code>local setup_database = task(\"setup_database\")\n    :description(\"Idempotent database setup with migration support\")\n    :command(function(params)\n        -- Check if database exists\n        local db_exists = database.exists(params.database_name)\n\n        if not db_exists then\n            log.info(\"Creating database: \" .. params.database_name)\n            local create_result = database.create(params.database_name)\n            if not create_result.success then\n                return false, \"Failed to create database: \" .. create_result.error\n            end\n        else\n            log.info(\"Database already exists: \" .. params.database_name)\n        end\n\n        -- Run migrations (idempotent)\n        log.info(\"Running database migrations...\")\n        local migrate_result = database.migrate(params.database_name, {\n            migrations_path = \"./migrations\",\n            target_version = params.target_version\n        })\n\n        if not migrate_result.success then\n            return false, \"Migration failed: \" .. migrate_result.error\n        end\n\n        return true, \"Database setup completed\", {\n            database_name = params.database_name,\n            current_version = migrate_result.current_version,\n            migrations_applied = migrate_result.applied_count\n        }\n    end)\n    :retries(3, \"exponential\")\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#pattern-2-circuit-breaker-for-external-services","title":"Pattern 2: Circuit Breaker for External Services","text":"<pre><code>local call_external_api = task(\"call_external_api\")\n    :description(\"Call external API with circuit breaker protection\")\n    :command(function(params)\n        -- Use circuit breaker for external API calls\n        local api_result = circuit.protect(\"payment_api\", function()\n            return net.http_post(\"https://api.payment.com/process\", {\n                headers = {\n                    [\"Authorization\"] = \"Bearer \" .. utils.secret(\"payment_api_token\"),\n                    [\"Content-Type\"] = \"application/json\"\n                },\n                body = data.to_json(params.payment_data),\n                timeout = \"10s\"\n            })\n        end, {\n            failure_threshold = 5,\n            recovery_timeout = \"30s\",\n            half_open_max_calls = 3\n        })\n\n        if not api_result.success then\n            -- Circuit might be open\n            if api_result.circuit_open then\n                return false, \"Payment API circuit breaker is open - service unavailable\"\n            else\n                return false, \"Payment API call failed: \" .. api_result.error\n            end\n        end\n\n        -- Validate API response\n        if api_result.status_code ~= 200 then\n            return false, \"Payment API returned error: \" .. api_result.status_code\n        end\n\n        local response_data = data.parse_json(api_result.body)\n        if not response_data.transaction_id then\n            return false, \"Invalid response from payment API - missing transaction_id\"\n        end\n\n        return true, \"Payment processed successfully\", {\n            transaction_id = response_data.transaction_id,\n            amount = response_data.amount,\n            status = response_data.status\n        }\n    end)\n    :timeout(\"30s\")\n    :retries(3, \"exponential\")\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#pattern-3-parallel-processing-with-aggregation","title":"Pattern 3: Parallel Processing with Aggregation","text":"<pre><code>local parallel_data_processing = task(\"parallel_data_processing\")\n    :description(\"Process data in parallel and aggregate results\")\n    :command(function(params, deps)\n        local input_files = deps.prepare_data.file_list\n\n        log.info(\"Processing \" .. #input_files .. \" files in parallel...\")\n\n        -- Process files in parallel\n        local results = async.parallel(\n            table.map(input_files, function(file)\n                return function()\n                    return data_processor.process_file(file, {\n                        format = params.output_format,\n                        validation = true\n                    })\n                end\n            end),\n            {\n                max_workers = params.max_workers or 4,\n                timeout = \"20m\",\n                fail_fast = false  -- Process all files even if some fail\n            }\n        )\n\n        -- Aggregate results\n        local successful_files = {}\n        local failed_files = {}\n        local total_records = 0\n\n        for i, result in ipairs(results) do\n            if result.success then\n                table.insert(successful_files, {\n                    file = input_files[i],\n                    records = result.record_count\n                })\n                total_records = total_records + result.record_count\n            else\n                table.insert(failed_files, {\n                    file = input_files[i],\n                    error = result.error\n                })\n            end\n        end\n\n        -- Report results\n        log.info(\"Processing completed:\")\n        log.info(\"  Successful files: \" .. #successful_files)\n        log.info(\"  Failed files: \" .. #failed_files)\n        log.info(\"  Total records processed: \" .. total_records)\n\n        if #failed_files &gt; 0 then\n            log.warn(\"Some files failed to process:\")\n            for _, failed in ipairs(failed_files) do\n                log.warn(\"  \" .. failed.file .. \": \" .. failed.error)\n            end\n        end\n\n        -- Decide if task should succeed or fail\n        local success_rate = #successful_files / #input_files\n        if success_rate &lt; (params.min_success_rate or 0.8) then\n            return false, \"Processing failed - success rate \" .. \n                   string.format(\"%.1f%%\", success_rate * 100) .. \n                   \" below threshold\"\n        end\n\n        return true, \"Parallel processing completed\", {\n            total_files = #input_files,\n            successful_files = #successful_files,\n            failed_files = #failed_files,\n            total_records = total_records,\n            success_rate = success_rate\n        }\n    end)\n    :timeout(\"30m\")\n    :depends_on({\"prepare_data\"})\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#workflow-design-patterns","title":"\ud83d\udd04 Workflow Design Patterns","text":""},{"location":"modern-dsl/best-practices/#pattern-1-multi-environment-deployment","title":"Pattern 1: Multi-Environment Deployment","text":"<pre><code>local deploy_to_environment = function(environment)\n    return task(\"deploy_to_\" .. environment)\n        :description(\"Deploy application to \" .. environment .. \" environment\")\n        :command(function(params, deps)\n            local build_info = deps.build_application\n\n            log.info(\"Deploying to \" .. environment .. \" environment...\")\n\n            -- Environment-specific configuration\n            local env_config = {\n                staging = {\n                    replicas = 2,\n                    resources = {cpu = \"100m\", memory = \"256Mi\"},\n                    ingress = \"staging.example.com\"\n                },\n                production = {\n                    replicas = 5,\n                    resources = {cpu = \"500m\", memory = \"1Gi\"},\n                    ingress = \"api.example.com\"\n                }\n            }\n\n            local config = env_config[environment]\n            if not config then\n                return false, \"Unknown environment: \" .. environment\n            end\n\n            -- Deploy with environment-specific settings\n            local deploy_result = k8s.deploy({\n                image = build_info.image_tag,\n                namespace = environment,\n                replicas = config.replicas,\n                resources = config.resources,\n                ingress_host = config.ingress\n            })\n\n            if not deploy_result.success then\n                return false, \"Deployment to \" .. environment .. \" failed: \" .. deploy_result.error\n            end\n\n            -- Environment-specific health checks\n            local health_timeout = environment == \"production\" and \"10m\" or \"5m\"\n            local health_check = k8s.wait_for_rollout({\n                deployment = \"myapp\",\n                namespace = environment,\n                timeout = health_timeout\n            })\n\n            if not health_check.ready then\n                return false, \"Health check failed for \" .. environment .. \" deployment\"\n            end\n\n            return true, \"Successfully deployed to \" .. environment, {\n                environment = environment,\n                replicas_ready = health_check.ready_replicas,\n                deployment_time = os.time(),\n                endpoint = \"https://\" .. config.ingress\n            }\n        end)\n        :condition(when(\"params.deploy_\" .. environment .. \" == true\"))\n        :timeout(environment == \"production\" and \"20m\" or \"10m\")\n        :retries(environment == \"production\" and 1 or 2)\n        :build()\nend\n\n-- Define environment-specific workflows\nworkflow.define(\"deploy_pipeline\", {\n    description = \"Multi-environment deployment pipeline\",\n    version = \"2.0.0\",\n\n    tasks = {\n        build_application,\n        run_tests,\n        deploy_to_environment(\"staging\"),\n        deploy_to_environment(\"production\")\n    },\n\n    config = {\n        timeout = \"1h\",\n        max_parallel_tasks = 2\n    }\n})\n</code></pre>"},{"location":"modern-dsl/best-practices/#pattern-2-blue-green-deployment","title":"Pattern 2: Blue-Green Deployment","text":"<pre><code>local blue_green_deployment = task(\"blue_green_deploy\")\n    :description(\"Blue-green deployment with automatic rollback\")\n    :command(function(params, deps)\n        local build_info = deps.build_application\n        local current_env = k8s.get_active_environment(\"myapp\")\n        local target_env = current_env == \"blue\" and \"green\" or \"blue\"\n\n        log.info(\"Current active environment: \" .. current_env)\n        log.info(\"Deploying to target environment: \" .. target_env)\n\n        -- Deploy to target environment\n        local deploy_result = k8s.deploy({\n            image = build_info.image_tag,\n            environment = target_env,\n            namespace = \"production\",\n            replicas = 3\n        })\n\n        if not deploy_result.success then\n            return false, \"Deployment to \" .. target_env .. \" failed: \" .. deploy_result.error\n        end\n\n        -- Wait for deployment to be ready\n        local health_check = k8s.wait_for_rollout({\n            deployment = \"myapp-\" .. target_env,\n            namespace = \"production\",\n            timeout = \"10m\"\n        })\n\n        if not health_check.ready then\n            return false, \"Target environment \" .. target_env .. \" not ready\"\n        end\n\n        -- Run smoke tests against target environment\n        local smoke_tests = testing.run_smoke_tests({\n            endpoint = \"http://myapp-\" .. target_env .. \":8080\",\n            timeout = \"5m\"\n        })\n\n        if not smoke_tests.passed then\n            log.error(\"Smoke tests failed, keeping current environment active\")\n            return false, \"Smoke tests failed: \" .. smoke_tests.error\n        end\n\n        -- Switch traffic to new environment\n        log.info(\"Switching traffic from \" .. current_env .. \" to \" .. target_env)\n        local switch_result = k8s.switch_traffic({\n            service = \"myapp\",\n            from_env = current_env,\n            to_env = target_env\n        })\n\n        if not switch_result.success then\n            return false, \"Traffic switch failed: \" .. switch_result.error\n        end\n\n        -- Wait and verify new environment is stable\n        sleep(30)  -- Allow some traffic to flow\n\n        local stability_check = monitoring.check_stability({\n            service = \"myapp\",\n            environment = target_env,\n            duration = \"2m\",\n            error_rate_threshold = 0.01\n        })\n\n        if not stability_check.stable then\n            log.error(\"New environment unstable, rolling back...\")\n\n            -- Rollback traffic\n            k8s.switch_traffic({\n                service = \"myapp\",\n                from_env = target_env,\n                to_env = current_env\n            })\n\n            return false, \"Deployment unstable, rolled back: \" .. stability_check.reason\n        end\n\n        -- Success - clean up old environment\n        log.info(\"Deployment successful, cleaning up old environment\")\n        k8s.scale_down({\n            deployment = \"myapp-\" .. current_env,\n            replicas = 0\n        })\n\n        return true, \"Blue-green deployment completed successfully\", {\n            previous_env = current_env,\n            current_env = target_env,\n            deployment_time = os.time(),\n            image_deployed = build_info.image_tag\n        }\n    end)\n    :depends_on({\"build_application\", \"run_tests\"})\n    :timeout(\"30m\")\n    :on_failure(function(params, error)\n        log.error(\"Blue-green deployment failed: \" .. error)\n\n        -- Send critical alert\n        alerts.send(\"pagerduty\", {\n            severity = \"critical\",\n            summary = \"Blue-green deployment failed\",\n            details = error,\n            runbook = \"https://runbooks.company.com/blue-green-rollback\"\n        })\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#monitoring-and-observability-best-practices","title":"\ud83d\udcca Monitoring and Observability Best Practices","text":""},{"location":"modern-dsl/best-practices/#1-comprehensive-metrics-collection","title":"1. Comprehensive Metrics Collection","text":"<pre><code>workflow.define(\"monitored_pipeline\", {\n    description = \"Pipeline with comprehensive monitoring\",\n    version = \"2.0.0\",\n\n    tasks = { build_task, test_task, deploy_task },\n\n    config = {\n        monitoring = {\n            metrics = {\n                enabled = true,\n                custom_metrics = {\n                    \"pipeline_duration_seconds\",\n                    \"build_size_bytes\", \n                    \"test_coverage_percentage\",\n                    \"deployment_success_rate\"\n                }\n            },\n\n            alerts = {\n                enabled = true,\n                rules = {\n                    {\n                        name = \"pipeline_duration_high\",\n                        condition = \"pipeline_duration_seconds &gt; 1800\",  -- 30 minutes\n                        severity = \"warning\",\n                        message = \"Pipeline taking longer than expected\"\n                    },\n                    {\n                        name = \"deployment_failure_rate_high\",\n                        condition = \"deployment_success_rate &lt; 0.95\",\n                        severity = \"critical\",\n                        message = \"Deployment success rate below 95%\"\n                    }\n                }\n            }\n        }\n    },\n\n    on_start = function()\n        metrics.start_timer(\"pipeline_duration\")\n        metrics.increment(\"pipeline_starts_total\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        local duration = metrics.stop_timer(\"pipeline_duration\")\n\n        metrics.record_gauge(\"pipeline_duration_seconds\", duration)\n\n        if success then\n            metrics.increment(\"pipeline_success_total\")\n        else\n            metrics.increment(\"pipeline_failure_total\")\n        end\n\n        return true\n    end\n})\n</code></pre>"},{"location":"modern-dsl/best-practices/#2-structured-logging","title":"2. Structured Logging","text":"<pre><code>local structured_logging_task = task(\"process_with_logging\")\n    :description(\"Task with comprehensive structured logging\")\n    :command(function(params)\n        local correlation_id = utils.uuid()\n\n        log.info(\"Starting data processing\", {\n            correlation_id = correlation_id,\n            input_size = params.input_size,\n            processing_mode = params.mode,\n            timestamp = os.time()\n        })\n\n        -- Processing with progress logging\n        local total_items = params.input_size\n        local processed_items = 0\n\n        for i = 1, total_items do\n            -- Process item\n            local item_result = process_item(i)\n            processed_items = processed_items + 1\n\n            -- Log progress every 1000 items\n            if i % 1000 == 0 then\n                log.info(\"Processing progress\", {\n                    correlation_id = correlation_id,\n                    processed_items = processed_items,\n                    total_items = total_items,\n                    progress_percentage = math.floor((processed_items / total_items) * 100),\n                    items_per_second = calculate_rate(processed_items)\n                })\n            end\n\n            if not item_result.success then\n                log.error(\"Item processing failed\", {\n                    correlation_id = correlation_id,\n                    item_id = i,\n                    error = item_result.error,\n                    retry_count = item_result.retry_count\n                })\n            end\n        end\n\n        log.info(\"Data processing completed\", {\n            correlation_id = correlation_id,\n            total_items = total_items,\n            processed_items = processed_items,\n            success_rate = processed_items / total_items,\n            duration_seconds = calculate_duration()\n        })\n\n        return true, \"Processing completed\", {\n            correlation_id = correlation_id,\n            processed_items = processed_items,\n            success_rate = processed_items / total_items\n        }\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#security-best-practices","title":"\ud83d\udd10 Security Best Practices","text":""},{"location":"modern-dsl/best-practices/#1-secret-management","title":"1. Secret Management","text":"<pre><code>local secure_deployment = task(\"secure_deploy\")\n    :description(\"Deployment with proper secret management\")\n    :command(function(params)\n        -- Retrieve secrets securely\n        local db_password = utils.secret(\"database_password\")\n        local api_key = utils.secret(\"external_api_key\")\n        local ssl_cert = utils.secret(\"ssl_certificate\")\n\n        if not db_password or not api_key or not ssl_cert then\n            return false, \"Required secrets not available\"\n        end\n\n        -- Use secrets in deployment without logging them\n        local deploy_result = k8s.deploy({\n            image = params.image_tag,\n            secrets = {\n                DATABASE_PASSWORD = db_password,\n                API_KEY = api_key,\n                SSL_CERT = ssl_cert\n            },\n            security_context = {\n                run_as_non_root = true,\n                read_only_root_filesystem = true,\n                capabilities = {\n                    drop = {\"ALL\"}\n                }\n            }\n        })\n\n        -- Clear secrets from memory\n        db_password = nil\n        api_key = nil\n        ssl_cert = nil\n\n        if not deploy_result.success then\n            return false, \"Secure deployment failed: \" .. deploy_result.error\n        end\n\n        return true, \"Secure deployment completed\", {\n            deployment_id = deploy_result.deployment_id,\n            security_scan_passed = true\n        }\n    end)\n    :security({\n        secrets_required = {\"database_password\", \"external_api_key\", \"ssl_certificate\"},\n        rbac_role = \"secure-deployer\",\n        audit_logging = true\n    })\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#2-input-validation","title":"2. Input Validation","text":"<pre><code>local validated_task = task(\"process_user_input\")\n    :description(\"Process user input with comprehensive validation\")\n    :command(function(params)\n        -- Validate required parameters\n        validate.required(params.user_id, \"user_id\")\n        validate.required(params.action, \"action\")\n\n        -- Validate parameter types and formats\n        validate.type(params.user_id, \"number\", \"user_id\")\n        validate.pattern(params.action, \"^[a-zA-Z0-9_]+$\", \"action\")\n\n        -- Validate parameter ranges\n        validate.range(params.user_id, 1, 1000000, \"user_id\")\n        validate.enum(params.action, {\"create\", \"update\", \"delete\"}, \"action\")\n\n        -- Sanitize input\n        local sanitized_input = utils.sanitize({\n            user_id = params.user_id,\n            action = params.action,\n            data = params.data and utils.escape_html(params.data) or nil\n        })\n\n        -- Process with validated and sanitized input\n        local result = user_processor.process(sanitized_input)\n\n        if not result.success then\n            return false, \"Processing failed: \" .. result.error\n        end\n\n        return true, \"User input processed successfully\", {\n            user_id = sanitized_input.user_id,\n            action = sanitized_input.action,\n            result_id = result.id\n        }\n    end)\n    :validation(function(params)\n        -- Pre-execution validation\n        if not params.user_id or not params.action then\n            return false, \"Missing required parameters\"\n        end\n        return true\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#performance-optimization-best-practices","title":"\ud83c\udfaf Performance Optimization Best Practices","text":""},{"location":"modern-dsl/best-practices/#1-efficient-resource-usage","title":"1. Efficient Resource Usage","text":"<pre><code>local optimized_task = task(\"resource_optimized_processing\")\n    :description(\"Processing task optimized for resource usage\")\n    :command(function(params)\n        -- Set resource limits\n        process.set_memory_limit(\"2GB\")\n        process.set_cpu_limit(\"2 cores\")\n\n        -- Use streaming for large datasets\n        local input_stream = data.open_stream(params.input_file)\n        local output_stream = data.create_stream(params.output_file)\n\n        local processed_count = 0\n        local batch_size = 1000\n\n        while true do\n            local batch = input_stream:read_batch(batch_size)\n            if not batch or #batch == 0 then\n                break\n            end\n\n            -- Process batch efficiently\n            local processed_batch = data_processor.process_batch(batch, {\n                parallel_workers = 4,\n                memory_efficient = true\n            })\n\n            -- Write results\n            output_stream:write_batch(processed_batch)\n            processed_count = processed_count + #processed_batch\n\n            -- Memory cleanup\n            batch = nil\n            processed_batch = nil\n\n            -- Yield control periodically\n            if processed_count % 10000 == 0 then\n                log.info(\"Processed \" .. processed_count .. \" records...\")\n                coroutine.yield()\n            end\n        end\n\n        input_stream:close()\n        output_stream:close()\n\n        return true, \"Processing completed efficiently\", {\n            processed_count = processed_count,\n            memory_usage = process.get_memory_usage(),\n            cpu_usage = process.get_cpu_usage()\n        }\n    end)\n    :resources({\n        cpu = \"2 cores\",\n        memory = \"2GB\",\n        disk = \"10GB\"\n    })\n    :build()\n</code></pre>"},{"location":"modern-dsl/best-practices/#2-caching-strategies","title":"2. Caching Strategies","text":"<pre><code>local cached_computation = task(\"cached_expensive_computation\")\n    :description(\"Expensive computation with intelligent caching\")\n    :command(function(params)\n        local cache_key = \"computation_\" .. params.dataset_id .. \"_\" .. params.algorithm_version\n\n        -- Check cache first\n        local cached_result = cache.get(cache_key)\n        if cached_result then\n            log.info(\"Using cached result for \" .. cache_key)\n            return true, \"Computation completed (cached)\", cached_result\n        end\n\n        log.info(\"Cache miss, performing computation...\")\n\n        -- Perform expensive computation\n        local start_time = os.time()\n        local computation_result = expensive_algorithm.compute({\n            dataset_id = params.dataset_id,\n            algorithm_version = params.algorithm_version,\n            parameters = params.computation_params\n        })\n        local computation_time = os.time() - start_time\n\n        if not computation_result.success then\n            return false, \"Computation failed: \" .. computation_result.error\n        end\n\n        -- Cache result with TTL\n        local cache_ttl = computation_time &gt; 300 and \"1h\" or \"30m\"  -- Longer cache for expensive computations\n        cache.set(cache_key, computation_result.data, cache_ttl)\n\n        log.info(\"Computation completed in \" .. computation_time .. \"s, cached with TTL \" .. cache_ttl)\n\n        return true, \"Computation completed\", {\n            result = computation_result.data,\n            computation_time = computation_time,\n            cache_key = cache_key,\n            cached = false\n        }\n    end)\n    :build()\n</code></pre> <p>Following these best practices will help you build robust, maintainable, and efficient workflows using the Modern DSL. Remember to adapt these patterns to your specific use cases and requirements!</p>"},{"location":"modern-dsl/introduction/","title":"\ud83c\udfaf Modern DSL Introduction","text":"<p>Welcome to the Modern DSL (Domain Specific Language) for Sloth Runner - a powerful approach to defining workflows that combines the flexibility of Lua with an intuitive, fluent API.</p>"},{"location":"modern-dsl/introduction/#what-is-modern-dsl","title":"\ud83d\ude80 What is Modern DSL?","text":"<p>The Modern DSL is the syntax for Sloth Runner that provides:</p> <ul> <li>\ud83c\udfaf Fluent API: Chainable, intuitive method calls</li> <li>\ud83d\udccb Declarative Workflows: Configuration-driven workflow definitions  </li> <li>\ud83d\udd04 Enhanced Features: Built-in retry strategies, circuit breakers, and resilience patterns</li> <li>\ud83d\udee1\ufe0f Type Safety: Better validation and error detection</li> <li>\ud83d\udcca Rich Metadata: Comprehensive workflow and task information</li> <li>\u26a1 Modern Patterns: Async operations, performance monitoring, and observability</li> </ul>"},{"location":"modern-dsl/introduction/#modern-dsl-syntax","title":"\ud83c\udfa8 Modern DSL Syntax","text":""},{"location":"modern-dsl/introduction/#task-definition","title":"Task Definition","text":"<pre><code>-- Define tasks with fluent API\nlocal build_task = task(\"build_app\")\n    :description(\"Build application with modern features\")\n    :command(function(params, deps)\n        log.info(\"Building application...\")\n        local result = exec.run(\"go build -o app ./cmd/main.go\")\n\n        if not result.success then\n            return false, \"Build failed: \" .. result.stderr\n        end\n\n        return true, \"Build completed\", {\n            artifact = \"app\",\n            size = fs.size(\"app\"),\n            build_time = result.duration\n        }\n    end)\n    :timeout(\"5m\")\n    :retries(3, \"exponential\")\n    :depends_on({\"setup\"})\n    :artifacts({\"app\"})\n    :on_success(function(params, output)\n        log.info(\"Build completed! Artifact size: \" .. output.size .. \" bytes\")\n    end)\n    :build()\n\nlocal test_task = task(\"run_tests\")\n    :description(\"Run comprehensive test suite\")\n    :command(\"go test ./...\")\n    :depends_on({\"build_app\"})\n    :timeout(\"10m\")\n    :condition(when(\"params.skip_tests != true\"))\n    :build()\n\n-- Define workflow with rich configuration\nworkflow.define(\"my_pipeline\", {\n    description = \"Modern CI/CD Pipeline\",\n    version = \"2.0.0\",\n\n    metadata = {\n        author = \"DevOps Team\",\n        tags = {\"ci\", \"golang\", \"build\"},\n        created_at = os.date(),\n        repository = \"github.com/company/project\"\n    },\n\n    tasks = { build_task, test_task },\n\n    config = {\n        timeout = \"30m\",\n        retry_policy = \"exponential\",\n        max_parallel_tasks = 4,\n        cleanup_on_failure = true\n    },\n\n    on_start = function()\n        log.info(\"\ud83d\ude80 Starting modern CI/CD pipeline...\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        if success then\n            log.info(\"\u2705 Pipeline completed successfully!\")\n            -- Send notification, update status, etc.\n        else\n            log.error(\"\u274c Pipeline failed!\")\n        end\n        return true\n    end\n})\n</code></pre>"},{"location":"modern-dsl/introduction/#key-benefits","title":"\ud83c\udfaf Key Benefits","text":""},{"location":"modern-dsl/introduction/#1-enhanced-readability","title":"1. Enhanced Readability","text":"<p>The fluent API makes workflows self-documenting and easier to understand:</p> <pre><code>-- Clear, expressive syntax\nlocal deploy_task = task(\"deploy_to_production\")\n    :description(\"Deploy application to production environment\")\n    :command(function(params, deps)\n        -- Business logic is clear and well-structured\n        return deploy_application(deps.build_app.artifact)\n    end)\n    :condition(when(\"env.ENVIRONMENT == 'production'\"))\n    :retries(2, \"exponential\")\n    :timeout(\"15m\")\n    :on_failure(function(params, error)\n        alert.send(\"deployment_failed\", {\n            environment = \"production\",\n            error = error\n        })\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/introduction/#2-built-in-resilience-patterns","title":"2. Built-in Resilience Patterns","text":"<p>Modern DSL includes enterprise-grade resilience patterns out of the box:</p> <pre><code>-- Circuit breaker for external dependencies\nlocal api_task = task(\"call_external_api\")\n    :command(function()\n        return circuit.protect(\"payment_api\", function()\n            return net.http_post(\"https://api.payment.com/charge\", data)\n        end)\n    end)\n    :retries(3, \"exponential\")\n    :build()\n\n-- Saga pattern for distributed transactions\nlocal payment_saga = saga.define(\"payment_process\")\n    :step(\"validate_payment\", validate_task)\n    :step(\"charge_card\", charge_task)\n    :step(\"update_inventory\", inventory_task)\n    :compensate(\"charge_card\", refund_task)\n    :compensate(\"update_inventory\", restore_inventory_task)\n    :build()\n</code></pre>"},{"location":"modern-dsl/introduction/#3-advanced-async-operations","title":"3. Advanced Async Operations","text":"<p>Modern patterns for parallel and asynchronous execution:</p> <pre><code>local parallel_build = task(\"parallel_build\")\n    :command(function()\n        -- Modern async patterns\n        local results = async.parallel({\n            frontend = function()\n                return exec.run(\"npm run build:frontend\")\n            end,\n            backend = function() \n                return exec.run(\"go build ./cmd/server\")\n            end,\n            docs = function()\n                return exec.run(\"mkdocs build\")\n            end\n        }, {\n            max_workers = 3,\n            timeout = \"10m\",\n            fail_fast = false\n        })\n\n        return true, \"All builds completed\", results\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/introduction/#4-rich-metadata-and-observability","title":"4. Rich Metadata and Observability","text":"<p>Comprehensive tracking and monitoring capabilities:</p> <pre><code>workflow.define(\"data_pipeline\", {\n    description = \"ETL Data Processing Pipeline\",\n    version = \"3.1.0\",\n\n    metadata = {\n        author = \"Data Team\",\n        tags = {\"etl\", \"data\", \"analytics\"},\n        sla = \"4h\",\n        cost_center = \"analytics\",\n        compliance = [\"GDPR\", \"SOX\"]\n    },\n\n    config = {\n        monitoring = {\n            metrics = true,\n            alerts = true,\n            dashboard = \"grafana://data-pipeline\"\n        },\n        performance = {\n            expected_duration = \"2h\",\n            memory_limit = \"4GB\",\n            cpu_limit = \"2 cores\"\n        }\n    }\n})\n</code></pre>"},{"location":"modern-dsl/introduction/#learning-path","title":"\ud83c\udf93 Learning Path","text":""},{"location":"modern-dsl/introduction/#beginner","title":"Beginner","text":"<ol> <li>Start with simple task definitions</li> <li>Learn the fluent API basics</li> <li>Explore basic workflow configuration</li> </ol>"},{"location":"modern-dsl/introduction/#intermediate","title":"Intermediate","text":"<ol> <li>Add error handling and retries</li> <li>Use conditional execution</li> <li>Implement parallel tasks</li> </ol>"},{"location":"modern-dsl/introduction/#advanced","title":"Advanced","text":"<ol> <li>Master circuit breaker patterns</li> <li>Implement saga patterns</li> <li>Build enterprise-grade pipelines</li> </ol>"},{"location":"modern-dsl/introduction/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>Ready to start with Modern DSL? Check out these resources:</p> <ul> <li>Task Definition API - Complete task builder reference</li> <li>Workflow Definition - Workflow configuration guide</li> <li>Migration Guide - Convert existing workflows</li> <li>Best Practices - Modern DSL patterns and guidelines</li> <li>Examples - Browse modernized examples</li> </ul>"},{"location":"modern-dsl/introduction/#community","title":"\ud83e\udd1d Community","text":"<p>The Modern DSL is designed with community feedback in mind:</p> <ul> <li>\ud83d\udc1b Issues: Report bugs and request features</li> <li>\ud83d\udca1 Ideas: Propose new DSL features</li> <li>\ud83d\udcda Documentation: Help improve guides and examples</li> <li>\ud83d\udd27 Tools: Build migration and validation tools</li> </ul> <p>\ud83c\udfaf The Modern DSL represents the future of workflow automation - more powerful, more intuitive, and more maintainable than ever before!</p>"},{"location":"modern-dsl/reference-guide/","title":"\ud83d\udcda Modern DSL Reference Guide","text":"<p>This guide provides comprehensive examples and patterns for using the Modern DSL syntax in Sloth Runner.</p>"},{"location":"modern-dsl/reference-guide/#modern-dsl-overview","title":"\ud83c\udfaf Modern DSL Overview","text":"<p>The Modern DSL is the primary syntax for defining workflows in Sloth Runner, providing a powerful fluent API for task orchestration.</p>"},{"location":"modern-dsl/reference-guide/#modern-dsl-structure","title":"Modern DSL Structure","text":"<pre><code>-- Define tasks with fluent API\nlocal my_task = task(\"task_name\")\n    :description(\"Task description\")\n    :command(\"shell command or function\")\n    :depends_on({\"other_task\"})\n    :timeout(\"5m\")\n    :retries(3, \"exponential\")\n    :build()\n\n-- Define workflow\nworkflow.define(\"workflow_name\", {\n    description = \"Workflow description\",\n    version = \"2.0.0\",\n    tasks = { my_task }\n})\n</code></pre>"},{"location":"modern-dsl/reference-guide/#essential-modern-dsl-patterns","title":"\ud83d\ude80 Essential Modern DSL Patterns","text":""},{"location":"modern-dsl/reference-guide/#basic-task-definition","title":"Basic Task Definition","text":"<pre><code>local build_task = task(\"build_app\")\n    :description(\"Build the application\")\n    :command(\"npm run build\")\n    :timeout(\"10m\")\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#task-with-dependencies","title":"Task with Dependencies","text":"<pre><code>local deploy_task = task(\"deploy_app\")\n    :command(\"kubectl apply -f deployment.yaml\")\n    :depends_on({\"build_app\"})  -- Always use array format\n    :build()\n\nlocal notify_task = task(\"notify_team\")\n    :command(\"slack-notify.sh\")\n    :depends_on({\"test_app\", \"security_scan\"})  -- Multiple dependencies\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#function-commands-with-error-handling","title":"Function Commands with Error Handling","text":"<pre><code>local process_task = task(\"process_data\")\n    :command(function(params, deps)  -- 'deps' parameter for dependency outputs\n        local data = deps.fetch_data.result\n        log.info(\"Processing: \" .. data)\n\n        if not data then\n            return false, \"No data to process\"\n        end\n\n        return true, \"Processed\", {processed = data}\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#advanced-task-with-hooks","title":"Advanced Task with Hooks","text":"<pre><code>local deploy_task = task(\"deploy\")\n    :command(\"deploy.sh\")\n    :pre_hook(function(params, deps)  -- pre_hook for setup\n        log.info(\"Preparing deployment...\")\n        return true, \"Ready\"\n    end)\n    :post_hook(function(params, output)  -- post_hook for cleanup\n        log.info(\"Deployment completed\")\n        return true, \"Done\"\n    end)\n    :on_success(function(params, output)  -- Success-specific hook\n        notifications.send(\"slack\", \"Deployment successful!\")\n    end)\n    :on_failure(function(params, error)  -- Failure-specific hook\n        alerts.send(\"pagerduty\", \"Deployment failed: \" .. error)\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#enhanced-modern-dsl-features","title":"\ud83d\udd27 Enhanced Modern DSL Features","text":""},{"location":"modern-dsl/reference-guide/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<pre><code>local api_task = task(\"call_external_api\")\n    :command(function()\n        return circuit.protect(\"payment_api\", function()\n            return net.http_post(\"https://api.payment.com/charge\", data)\n        end)\n    end)\n    :retries(3, \"exponential\")\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#conditional-execution","title":"Conditional Execution","text":"<pre><code>local enhanced_task = task(\"enhanced_deploy\")\n    :description(\"Deploy with modern features\")\n    :command(\"deploy.sh\")\n    :depends_on({\"build\", \"test\"})\n    :timeout(\"15m\")\n    :retries(3, \"exponential\")  -- Enhanced retry with strategy\n    :condition(when(\"env.ENVIRONMENT == 'production'\"))  -- Conditional execution\n    :artifacts({\"deployment.yaml\", \"logs/\"})  -- Artifact management\n    :metadata({  -- Rich metadata\n        owner = \"platform-team\",\n        cost_center = \"engineering\"\n    })\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#parallel-task-execution","title":"Parallel Task Execution","text":"<pre><code>local parallel_build = task(\"parallel_build\")\n    :command(function()\n        -- Modern async patterns\n        local results = async.parallel({\n            frontend = function()\n                return exec.run(\"npm run build:frontend\")\n            end,\n            backend = function() \n                return exec.run(\"go build ./cmd/server\")\n            end,\n            docs = function()\n                return exec.run(\"mkdocs build\")\n            end\n        }, {\n            max_workers = 3,\n            timeout = \"10m\",\n            fail_fast = false\n        })\n\n        return true, \"All builds completed\", results\n    end)\n    :build()\n</code></pre>"},{"location":"modern-dsl/reference-guide/#complete-workflow-examples","title":"\ud83c\udf1f Complete Workflow Examples","text":""},{"location":"modern-dsl/reference-guide/#simple-workflow","title":"Simple Workflow","text":"<pre><code>-- Simple build and test workflow\nlocal build_task = task(\"build\")\n    :description(\"Build application\")\n    :command(\"go build -o app ./cmd/main.go\")\n    :timeout(\"5m\")\n    :artifacts({\"app\"})\n    :build()\n\nlocal test_task = task(\"test\")\n    :description(\"Run tests\")\n    :command(\"go test ./...\")\n    :depends_on({\"build\"})\n    :timeout(\"10m\")\n    :build()\n\nworkflow.define(\"ci_pipeline\", {\n    description = \"Simple CI Pipeline\",\n    version = \"2.0.0\",\n    tasks = { build_task, test_task },\n\n    config = {\n        timeout = \"30m\",\n        retry_policy = \"exponential\"\n    }\n})\n</code></pre>"},{"location":"modern-dsl/reference-guide/#enterprise-workflow-with-monitoring","title":"Enterprise Workflow with Monitoring","text":"<pre><code>workflow.define(\"enterprise_deployment\", {\n    description = \"Enterprise deployment pipeline\",\n    version = \"3.0.0\",\n\n    metadata = {\n        author = \"Platform Team\",\n        team = \"infrastructure\",\n        tags = {\"deployment\", \"production\", \"enterprise\"},\n        cost_center = \"engineering\",\n        criticality = \"high\"\n    },\n\n    tasks = { build_task, test_task, security_task, deploy_task },\n\n    config = {\n        timeout = \"2h\",\n        max_parallel_tasks = 4,\n        retry_policy = \"exponential\",\n        cleanup_on_failure = true,\n\n        monitoring = {\n            metrics = true,\n            alerts = true,\n            dashboard = \"grafana://deployment-pipeline\"\n        },\n\n        security = {\n            required_secrets = [\"k8s_token\", \"registry_password\"],\n            rbac_role = \"deployment-executor\"\n        }\n    },\n\n    pre_conditions = {\n        cluster_available = function()\n            local result = exec.run(\"kubectl cluster-info\")\n            return result.success, \"Kubernetes cluster not available\"\n        end\n    },\n\n    on_start = function()\n        log.info(\"\ud83d\ude80 Starting enterprise deployment...\")\n        metrics.increment(\"deployment_starts_total\")\n        return true\n    end,\n\n    on_complete = function(success, results)\n        local duration = metrics.stop_timer(\"deployment_duration\")\n\n        if success then\n            log.info(\"\u2705 Deployment completed successfully!\")\n            metrics.increment(\"deployment_success_total\")\n        else\n            log.error(\"\u274c Deployment failed!\")\n            metrics.increment(\"deployment_failure_total\")\n        end\n\n        return true\n    end\n})\n</code></pre>"},{"location":"modern-dsl/reference-guide/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"modern-dsl/reference-guide/#task-definition","title":"Task Definition","text":"<ol> <li>Always use descriptive names for tasks and workflows</li> <li>Set appropriate timeouts for all tasks</li> <li>Use exponential backoff for retry strategies</li> <li>Add metadata for tracking and documentation</li> <li>Implement proper error handling in function commands</li> </ol>"},{"location":"modern-dsl/reference-guide/#workflow-organization","title":"Workflow Organization","text":"<ol> <li>Group related tasks logically</li> <li>Use meaningful version numbers for workflows</li> <li>Add comprehensive metadata for maintainability</li> <li>Set resource limits for performance</li> <li>Enable monitoring for production workflows</li> </ol>"},{"location":"modern-dsl/reference-guide/#error-handling","title":"Error Handling","text":"<ol> <li>Use circuit breakers for external dependencies</li> <li>Implement compensation logic for critical operations</li> <li>Add proper logging at all levels</li> <li>Set up alerts for failures</li> <li>Plan rollback strategies for deployments</li> </ol> <p>\ud83c\udfaf The Modern DSL provides powerful capabilities for building robust, maintainable workflows. Use these patterns as building blocks for your automation needs!</p>"},{"location":"modules/aws/","title":"AWS Module","text":"<p>The <code>aws</code> module provides a comprehensive interface for interacting with Amazon Web Services using the AWS CLI. It is designed to work seamlessly with standard AWS credential chains and also has first-class support for <code>aws-vault</code> for enhanced security.</p>"},{"location":"modules/aws/#configuration","title":"Configuration","text":"<p>No specific configuration in <code>values.yaml</code> is required. The module relies on your environment being configured to interact with AWS. This can be achieved through: - IAM roles for EC2 instances or ECS/EKS tasks. - Standard environment variables (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, etc.). - A configured <code>~/.aws/credentials</code> file. - Using <code>aws-vault</code> with a named profile.</p>"},{"location":"modules/aws/#generic-executor","title":"Generic Executor","text":""},{"location":"modules/aws/#awsexecargs-opts","title":"<code>aws.exec(args, opts)</code>","text":"<p>This is the core function of the module. It executes any AWS CLI command and returns the result.</p> <p>Parameters:</p> <ul> <li><code>args</code> (table): Required. A table of strings representing the command and arguments to pass to the AWS CLI (e.g., <code>{\"s3\", \"ls\", \"--recursive\"}</code>).</li> <li><code>opts</code> (table): Optional. A table of options for the execution.<ul> <li><code>profile</code> (string): If provided, the command will be executed using <code>aws-vault exec &lt;profile&gt; -- aws ...</code>. If omitted, it will run <code>aws ...</code> directly.</li> </ul> </li> </ul> <p>Returns:</p> <p>A table containing the following fields: - <code>stdout</code> (string): The standard output from the command. - <code>stderr</code> (string): The standard error from the command. - <code>exit_code</code> (number): The exit code of the command. <code>0</code> typically indicates success.</p> <p>Example:</p> <pre><code>-- Using default credentials\nlocal result = aws.exec({\"sts\", \"get-caller-identity\"})\nif result.exit_code == 0 then\n  print(result.stdout)\nend\n\n-- Using an aws-vault profile\nlocal result_with_profile = aws.exec({\"ec2\", \"describe-instances\"}, {profile = \"my-prod-profile\"})\n</code></pre>"},{"location":"modules/aws/#s3-helpers","title":"S3 Helpers","text":""},{"location":"modules/aws/#awss3syncparams","title":"<code>aws.s3.sync(params)</code>","text":"<p>A high-level wrapper for the <code>aws s3 sync</code> command, useful for synchronizing directories with S3.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>source</code> (string): Required. The source directory or S3 path.</li> <li><code>destination</code> (string): Required. The destination directory or S3 path.</li> <li><code>profile</code> (string): Optional. The <code>aws-vault</code> profile to use.</li> <li><code>delete</code> (boolean): Optional. If <code>true</code>, adds the <code>--delete</code> flag to the sync command.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local ok, err = aws.s3.sync({\n  source = \"./build\",\n  destination = \"s3://my-app-bucket/static\",\n  profile = \"deployment-profile\",\n  delete = true\n})\nif not ok then\n  log.error(\"S3 sync failed: \" .. err)\nend\n</code></pre>"},{"location":"modules/aws/#secrets-manager-helpers","title":"Secrets Manager Helpers","text":""},{"location":"modules/aws/#awssecretsmanagerget_secretparams","title":"<code>aws.secretsmanager.get_secret(params)</code>","text":"<p>Retrieves a secret's value from AWS Secrets Manager. This function simplifies the process by directly returning the <code>SecretString</code>.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>secret_id</code> (string): Required. The name or ARN of the secret to retrieve.</li> <li><code>profile</code> (string): Optional. The <code>aws-vault</code> profile to use.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>secret_string</code> (string) on success.</li> <li><code>nil, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local db_password, err = aws.secretsmanager.get_secret({\n  secret_id = \"production/database/password\",\n  profile = \"my-app-profile\"\n})\n\nif not db_password then\n  log.error(\"Failed to get secret: \" .. err)\n  return false, \"Config failed.\"\nend\n\n-- Now you can use the db_password variable\n</code></pre>"},{"location":"modules/azure/","title":"Azure Module","text":"<p>The <code>azure</code> module provides an interface for interacting with Microsoft Azure using the <code>az</code> command-line tool.</p>"},{"location":"modules/azure/#configuration","title":"Configuration","text":"<p>This module requires the <code>az</code> CLI to be installed and authenticated. Before running pipelines that use this module, you must log in to your Azure account:</p> <pre><code>az login\n</code></pre> <p>The module will use your logged-in credentials for all commands.</p>"},{"location":"modules/azure/#generic-executor","title":"Generic Executor","text":""},{"location":"modules/azure/#azureexecargs","title":"<code>azure.exec(args)</code>","text":"<p>Executes any <code>az</code> command. This function automatically adds the <code>--output json</code> flag (if not already present) to ensure that the output is machine-parsable.</p> <p>Parameters:</p> <ul> <li><code>args</code> (table): Required. A table of strings representing the command and arguments to pass to <code>az</code> (e.g., <code>{\"group\", \"list\", \"--location\", \"eastus\"}</code>).</li> </ul> <p>Returns:</p> <p>A table containing the following fields: - <code>stdout</code> (string): The standard output from the command (as a JSON string). - <code>stderr</code> (string): The standard error from the command. - <code>exit_code</code> (number): The exit code of the command. <code>0</code> typically indicates success.</p> <p>Example:</p> <pre><code>local result = azure.exec({\"account\", \"show\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"Logged in as: \" .. account_info.user.name)\n  end\nend\n</code></pre>"},{"location":"modules/azure/#resource-group-rg-helpers","title":"Resource Group (RG) Helpers","text":""},{"location":"modules/azure/#azurergdeleteparams","title":"<code>azure.rg.delete(params)</code>","text":"<p>Deletes a resource group.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>name</code> (string): Required. The name of the resource group to delete.</li> <li><code>yes</code> (boolean): Optional. If <code>true</code>, adds the <code>--yes</code> flag to bypass the confirmation prompt.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local ok, err = azure.rg.delete({\n  name = \"my-test-rg\",\n  yes = true\n})\nif not ok then\n  log.error(\"Failed to delete resource group: \" .. err)\nend\n</code></pre>"},{"location":"modules/azure/#virtual-machine-vm-helpers","title":"Virtual Machine (VM) Helpers","text":""},{"location":"modules/azure/#azurevmlistparams","title":"<code>azure.vm.list(params)</code>","text":"<p>Lists virtual machines.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): Optional. A table containing the following fields:<ul> <li><code>resource_group</code> (string): The name of a resource group to scope the list to. If omitted, lists VMs in the entire subscription.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>vms</code> (table) on success, where the table is a parsed JSON array of your VM objects.</li> <li><code>nil, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>-- List all VMs in the subscription\nlocal all_vms, err1 = azure.vm.list()\n\n-- List VMs in a specific resource group\nlocal specific_vms, err2 = azure.vm.list({resource_group = \"my-production-rg\"})\nif specific_vms then\n  for _, vm in ipairs(specific_vms) do\n    print(\"Found VM: \" .. vm.name)\n  end\nend\n</code></pre>"},{"location":"modules/digitalocean/","title":"DigitalOcean Module","text":"<p>The <code>digitalocean</code> module provides an interface for interacting with your DigitalOcean resources using the <code>doctl</code> command-line tool.</p>"},{"location":"modules/digitalocean/#configuration","title":"Configuration","text":"<p>This module requires the <code>doctl</code> CLI to be installed and authenticated. The standard way to do this is to generate a personal access token in your DigitalOcean control panel and set it as the <code>DIGITALOCEAN_ACCESS_TOKEN</code> environment variable.</p> <pre><code>export DIGITALOCEAN_ACCESS_TOKEN=\"your_do_api_token_here\"\n</code></pre> <p>The module will automatically use this token for all commands.</p>"},{"location":"modules/digitalocean/#generic-executor","title":"Generic Executor","text":""},{"location":"modules/digitalocean/#digitaloceanexecargs","title":"<code>digitalocean.exec(args)</code>","text":"<p>Executes any <code>doctl</code> command. This function automatically adds the <code>--output json</code> flag to ensure that the output is machine-parsable.</p> <p>Parameters:</p> <ul> <li><code>args</code> (table): Required. A table of strings representing the command and arguments to pass to <code>doctl</code> (e.g., <code>{\"compute\", \"droplet\", \"list\"}</code>).</li> </ul> <p>Returns:</p> <p>A table containing the following fields: - <code>stdout</code> (string): The standard output from the command (as a JSON string). - <code>stderr</code> (string): The standard error from the command. - <code>exit_code</code> (number): The exit code of the command. <code>0</code> typically indicates success.</p> <p>Example:</p> <pre><code>local result = digitalocean.exec({\"account\", \"get\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"Account status: \" .. account_info.status)\n  end\nend\n</code></pre>"},{"location":"modules/digitalocean/#droplets-helpers","title":"Droplets Helpers","text":""},{"location":"modules/digitalocean/#digitaloceandropletslist","title":"<code>digitalocean.droplets.list()</code>","text":"<p>A high-level wrapper to list all Droplets in your account.</p> <p>Returns:</p> <ul> <li><code>droplets</code> (table) on success, where the table is a parsed JSON array of your Droplet objects.</li> <li><code>nil, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local droplets, err = digitalocean.droplets.list()\nif droplets then\n  for _, droplet in ipairs(droplets) do\n    print(\"Found Droplet: \" .. droplet.name)\n  end\nend\n</code></pre>"},{"location":"modules/digitalocean/#digitaloceandropletsdeleteparams","title":"<code>digitalocean.droplets.delete(params)</code>","text":"<p>Deletes a specific Droplet by its ID.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>id</code> (string): Required. The ID of the Droplet to delete.</li> <li><code>force</code> (boolean): Optional. If <code>true</code>, adds the <code>--force</code> flag to bypass the confirmation prompt. Defaults to <code>false</code>.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local ok, err = digitalocean.droplets.delete({\n  id = \"123456789\",\n  force = true\n})\nif not ok then\n  log.error(\"Failed to delete droplet: \" .. err)\nend\n</code></pre>"},{"location":"modules/docker/","title":"Docker Module","text":"<p>The <code>docker</code> module provides a convenient interface for interacting with the Docker daemon, allowing you to build, run, and push Docker images as part of your pipelines.</p>"},{"location":"modules/docker/#configuration","title":"Configuration","text":"<p>This module requires the <code>docker</code> CLI to be installed and the Docker daemon to be running and accessible.</p>"},{"location":"modules/docker/#functions","title":"Functions","text":""},{"location":"modules/docker/#dockerexecargs","title":"<code>docker.exec(args)</code>","text":"<p>Executes any raw <code>docker</code> command.</p> <ul> <li><code>args</code> (table): Required. A list of arguments to pass to the <code>docker</code> command (e.g., <code>{\"ps\", \"-a\"}</code>).</li> <li>Returns: A result table with <code>success</code>, <code>stdout</code>, <code>stderr</code>, and <code>exit_code</code>.</li> </ul>"},{"location":"modules/docker/#dockerbuildparams","title":"<code>docker.build(params)</code>","text":"<p>Builds a Docker image using <code>docker build</code>.</p> <ul> <li><code>params</code> (table):<ul> <li><code>tag</code> (string): Required. The tag for the image (e.g., <code>my-app:latest</code>).</li> <li><code>path</code> (string): Required. The build context path.</li> <li><code>dockerfile</code> (string): Optional. The path to the Dockerfile.</li> <li><code>build_args</code> (table): Optional. A table of build arguments (e.g., <code>{VERSION = \"1.0\"}</code>).</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"modules/docker/#dockerpushparams","title":"<code>docker.push(params)</code>","text":"<p>Pushes a Docker image to a registry using <code>docker push</code>.</p> <ul> <li><code>params</code> (table):<ul> <li><code>tag</code> (string): Required. The tag of the image to push.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"modules/docker/#dockerrunparams","title":"<code>docker.run(params)</code>","text":"<p>Runs a Docker container using <code>docker run</code>.</p> <ul> <li><code>params</code> (table):<ul> <li><code>image</code> (string): Required. The image to run.</li> <li><code>name</code> (string): Optional. The name for the container.</li> <li><code>detach</code> (boolean): Optional. If <code>true</code>, runs the container in the background (<code>-d</code>).</li> <li><code>ports</code> (table): Optional. A list of port mappings (e.g., <code>{\"8080:80\"}</code>).</li> <li><code>env</code> (table): Optional. A table of environment variables (e.g., <code>{MY_VAR = \"value\"}</code>).</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"modules/docker/#example","title":"Example","text":"<pre><code>local image_tag = \"my-test-image:latest\"\n\n-- Task 1: Build\nlocal result_build = docker.build({\n  tag = image_tag,\n  path = \"./app\"\n})\nif not result_build.success then return false, \"Build failed\" end\n\n-- Task 2: Run\nlocal result_run = docker.run({\n  image = image_tag,\n  name = \"my-test-container\",\n  ports = {\"8080:80\"}\n})\nif not result_run.success then return false, \"Run failed\" end\n\n-- Task 3: Push (after successful testing)\nlocal result_push = docker.push({tag = image_tag})\nif not result_push.success then return false, \"Push failed\" end\n</code></pre>"},{"location":"modules/gcp/","title":"GCP Module","text":"<p>The <code>gcp</code> module provides a simple interface for executing Google Cloud CLI (<code>gcloud</code>) commands from within a <code>sloth-runner</code> task.</p>"},{"location":"modules/gcp/#gcpexecargs","title":"<code>gcp.exec(args)</code>","text":"<p>Executes a <code>gcloud</code> command with the specified arguments.</p>"},{"location":"modules/gcp/#parameters","title":"Parameters","text":"<ul> <li><code>args</code> (table): A Lua table (array) of strings representing the arguments to pass to the <code>gcloud</code> command. For example, <code>{\"compute\", \"instances\", \"list\"}</code>.</li> </ul>"},{"location":"modules/gcp/#returns","title":"Returns","text":"<p>A table containing the result of the command execution with the following keys:</p> <ul> <li><code>stdout</code> (string): The standard output from the command.</li> <li><code>stderr</code> (string): The standard error output from the command.</li> <li><code>exit_code</code> (number): The exit code of the command. An exit code of <code>0</code> typically indicates success.</li> </ul>"},{"location":"modules/gcp/#example","title":"Example","text":"<p>This example defines a task that lists all Compute Engine instances in the <code>us-central1</code> region for a specific project.</p> <pre><code>-- examples/gcp_cli_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"A task to list GCP compute instances.\",\n    tasks = {\n      {\n        name = \"list-instances\",\n        description = \"Lists GCE instances in us-central1.\",\n        command = function()\n          log.info(\"Listing GCP instances...\")\n\n          -- require the gcp module to make it available\n          local gcp = require(\"gcp\")\n\n          -- Execute the gcloud command\n          local result = gcp.exec({\n            \"compute\", \n            \"instances\", \n            \"list\", \n            \"--project\", \"my-gcp-project-id\",\n            \"--zones\", \"us-central1-a,us-central1-b\"\n          })\n\n          -- Check the result\n          if result and result.exit_code == 0 then\n            log.info(\"Successfully listed instances.\")\n            print(\"--- INSTANCE LIST ---\")\n            print(result.stdout)\n            print(\"---------------------\")\n            return true, \"GCP command successful.\"\n          else\n            log.error(\"Failed to list GCP instances.\")\n            if result then\n              log.error(\"Stderr: \" .. result.stderr)\n            end\n            return false, \"GCP command failed.\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"modules/git/","title":"M\u00f3dulo Git","text":"<p>O m\u00f3dulo <code>git</code> do Sloth-Runner fornece uma API fluente e de alto n\u00edvel para interagir com reposit\u00f3rios Git diretamente de seus scripts Lua. Isso permite automatizar opera\u00e7\u00f5es comuns do Git, como clonagem, pull, adi\u00e7\u00e3o, commit, tag e push, facilitando fluxos de trabalho de CI/CD e automa\u00e7\u00e3o de versionamento.</p>"},{"location":"modules/git/#casos-de-uso-comuns","title":"Casos de Uso Comuns","text":"<ul> <li>Automa\u00e7\u00e3o de CI/CD: Clonar reposit\u00f3rios, atualizar c\u00f3digo, commitar altera\u00e7\u00f5es geradas por scripts e empurrar para o controle de vers\u00e3o.</li> <li>Gerenciamento de Configura\u00e7\u00e3o: Puxar as \u00faltimas configura\u00e7\u00f5es de um reposit\u00f3rio Git antes de aplicar mudan\u00e7as.</li> <li>Versionamento Autom\u00e1tico: Criar tags e commits para novas vers\u00f5es de software.</li> </ul>"},{"location":"modules/git/#referencia-da-api","title":"Refer\u00eancia da API","text":""},{"location":"modules/git/#gitcloneurl-path","title":"<code>git.clone(url, path)</code>","text":"<p>Clona um reposit\u00f3rio Git de uma URL para um caminho local. Se o caminho j\u00e1 contiver um reposit\u00f3rio Git, a fun\u00e7\u00e3o retornar\u00e1 <code>nil</code> e uma mensagem de erro.</p> <ul> <li><code>url</code> (string): A URL do reposit\u00f3rio Git a ser clonado.</li> <li><code>path</code> (string): O caminho local onde o reposit\u00f3rio ser\u00e1 clonado.</li> </ul> <p>Retorna: *   <code>GitRepo</code> (userdata): Uma inst\u00e2ncia do objeto <code>GitRepo</code> se o clone for bem-sucedido. *   <code>error</code> (string): Uma mensagem de erro se o clone falhar ou o caminho j\u00e1 for um reposit\u00f3rio.</p>"},{"location":"modules/git/#gitrepopath","title":"<code>git.repo(path)</code>","text":"<p>Obriga uma refer\u00eancia a um reposit\u00f3rio Git local existente.</p> <ul> <li><code>path</code> (string): O caminho local para o diret\u00f3rio raiz do reposit\u00f3rio Git.</li> </ul> <p>Retorna: *   <code>GitRepo</code> (userdata): Uma inst\u00e2ncia do objeto <code>GitRepo</code> se o caminho for um reposit\u00f3rio Git v\u00e1lido. *   <code>error</code> (string): Uma mensagem de erro se o caminho n\u00e3o for um reposit\u00f3rio Git.</p>"},{"location":"modules/git/#metodos-do-objeto-gitrepo-encadeaveis","title":"M\u00e9todos do Objeto <code>GitRepo</code> (Encade\u00e1veis)","text":"<p>Todos os m\u00e9todos abaixo s\u00e3o chamados na inst\u00e2ncia do <code>GitRepo</code> (ex: <code>repo:checkout(...)</code>) e retornam a pr\u00f3pria inst\u00e2ncia do <code>GitRepo</code> para permitir o encadeamento de chamadas. Para obter o resultado da \u00faltima opera\u00e7\u00e3o, use o m\u00e9todo <code>:result()</code>.</p>"},{"location":"modules/git/#repocheckoutref","title":"<code>repo:checkout(ref)</code>","text":"<p>Muda o branch ou commit atual do reposit\u00f3rio.</p> <ul> <li><code>ref</code> (string): O branch, tag ou hash do commit para o qual fazer o checkout.</li> </ul>"},{"location":"modules/git/#repopullremote-branch","title":"<code>repo:pull(remote, branch)</code>","text":"<p>Puxa as \u00faltimas altera\u00e7\u00f5es de um reposit\u00f3rio remoto.</p> <ul> <li><code>remote</code> (string): O nome do remoto (ex: \"origin\").</li> <li><code>branch</code> (string): O nome do branch a ser puxado.</li> </ul>"},{"location":"modules/git/#repoaddpattern","title":"<code>repo:add(pattern)</code>","text":"<p>Adiciona arquivos ao \u00edndice (staging area) do Git.</p> <ul> <li><code>pattern</code> (string): O padr\u00e3o de arquivo a ser adicionado (ex: \".\", \"path/to/file.txt\").</li> </ul>"},{"location":"modules/git/#repocommitmessage","title":"<code>repo:commit(message)</code>","text":"<p>Cria um novo commit com as altera\u00e7\u00f5es no \u00edndice.</p> <ul> <li><code>message</code> (string): A mensagem do commit.</li> </ul>"},{"location":"modules/git/#repotagname-message","title":"<code>repo:tag(name, message)</code>","text":"<p>Cria uma nova tag no reposit\u00f3rio.</p> <ul> <li><code>name</code> (string): O nome da tag (ex: \"v1.0.0\").</li> <li><code>message</code> (string, opcional): Uma mensagem opcional para a tag.</li> </ul>"},{"location":"modules/git/#repopushremote-branch-options","title":"<code>repo:push(remote, branch, options)</code>","text":"<p>Empurra commits e tags para um reposit\u00f3rio remoto.</p> <ul> <li><code>remote</code> (string): O nome do remoto (ex: \"origin\").</li> <li><code>branch</code> (string): O nome do branch a ser empurrado.</li> <li><code>options</code> (tabela Lua, opcional): Uma tabela de op\u00e7\u00f5es para flags adicionais:<ul> <li><code>follow_tags</code> (booleano): Se <code>true</code>, adiciona a flag <code>--follow-tags</code> ao comando <code>git push</code>.</li> </ul> </li> </ul>"},{"location":"modules/git/#reporesult","title":"<code>repo:result()</code>","text":"<p>Retorna o resultado da \u00faltima opera\u00e7\u00e3o Git executada na inst\u00e2ncia do <code>GitRepo</code>.</p> <p>Retorna: *   <code>result</code> (tabela Lua): Uma tabela contendo:     *   <code>success</code> (booleano): <code>true</code> se a opera\u00e7\u00e3o foi bem-sucedida, <code>false</code> caso contr\u00e1rio.     *   <code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando Git.     *   <code>stderr</code> (string): A sa\u00edda de erro padr\u00e3o do comando Git.     *   <code>error</code> (string ou <code>nil</code>): Uma mensagem de erro Go se a execu\u00e7\u00e3o do comando falhou.</p>"},{"location":"modules/git/#exemplos-de-uso","title":"Exemplos de Uso","text":""},{"location":"modules/git/#exemplo-basico-de-automacao-git","title":"Exemplo B\u00e1sico de Automa\u00e7\u00e3o Git","text":"<p>Este exemplo demonstra como clonar um reposit\u00f3rio, fazer um pull, simular uma altera\u00e7\u00e3o, commitar e empurrar as mudan\u00e7as.</p> <pre><code>-- examples/git_example.sloth\n\ncommand = function(params)\n    log.info(\"Iniciando exemplo de automa\u00e7\u00e3o Git...\")\n\n    local repo_url = \"https://github.com/chalkan3-sloth/sloth-runner.git\" -- Usando o pr\u00f3prio sloth-runner para exemplo\n    local repo_path = \"./sloth-runner-checkout\"\n    local new_version = params.version or \"v1.0.0-test\" -- Vers\u00e3o de exemplo\n    local repo\n\n    -- Clona o reposit\u00f3rio se ele ainda n\u00e3o existir no disco\n    if not fs.exists(repo_path) then\n        log.info(\"Cloning repository: \" .. repo_url .. \" into \" .. repo_path)\n        local cloned_repo, clone_err = git.clone(repo_url, repo_path)\n        if clone_err then\n            log.error(\"Failed to clone repository: \" .. clone_err)\n            return false, \"Git clone failed.\"\n        end\n        repo = cloned_repo\n    else\n        log.info(\"Repository already exists, opening local reference: \" .. repo_path)\n        local opened_repo, open_err = git.repo(repo_path) -- Apenas obt\u00e9m o objeto para o repo local\n        if open_err then\n            log.error(\"Failed to open repository: \" .. open_err)\n            return false, \"Git repo open failed.\"\n        end\n        repo = opened_repo\n    end\n\n    if not repo then\n        return false, \"Failed to clone or open repository.\"\n    end\n\n    log.info(\"Starting git operations on \" .. repo.RepoPath .. \"...\")\n\n    -- Executa uma sequ\u00eancia de comandos de forma fluente e encadeada\n    -- Nota: Cada opera\u00e7\u00e3o retorna o objeto 'repo' para encadeamento.\n    -- Para verificar o sucesso de cada passo, voc\u00ea deve chamar :result() ap\u00f3s cada um,\n    -- ou no final da cadeia para o \u00faltimo comando.\n\n    log.info(\"Checking out main branch and pulling latest changes...\")\n    repo:checkout(\"main\"):pull(\"origin\", \"main\")\n    local pull_result = repo:result() -- Obt\u00e9m o resultado do \u00faltimo comando (pull)\n    if not pull_result.success then\n        log.error(\"Failed to checkout or pull: \" .. pull_result.stderr)\n        return false, \"Git checkout/pull failed.\"\n    end\n    log.info(\"Checkout and pull successful. Stdout: \" .. pull_result.stdout)\n\n    -- Simula uma altera\u00e7\u00e3o no reposit\u00f3rio\n    local version_file_path = repo_path .. \"/VERSION_EXAMPLE\" -- Usar um nome diferente para n\u00e3o conflitar\n    fs.write(version_file_path, new_version)\n    log.info(\"Updated VERSION_EXAMPLE file to: \" .. new_version)\n\n    -- Adiciona, commita, tagueia e empurra as mudan\u00e7as de forma encadeada\n    local commit_message = \"ci: Example bump version to \" .. new_version\n    log.info(\"Adding, committing, tagging, and pushing changes...\")\n\n    -- Encadeamento: add -&gt; commit -&gt; tag -&gt; push\n    repo:add(version_file_path)\n        :commit(commit_message)\n        :tag(new_version, \"Release \" .. new_version)\n        :push(\"origin\", \"main\", { follow_tags = true })\n\n    local final_push_result = repo:result() -- Obt\u00e9m o resultado do \u00faltimo comando (push)\n\n    -- Verifica o resultado da \u00faltima opera\u00e7\u00e3o na cadeia\n    if not final_push_result.success then\n        log.error(\"Failed to push changes: \" .. final_push_result.stderr)\n        return false, \"Git push failed.\"\n    end\n\n    log.info(\"Successfully pushed version \" .. new_version .. \" to origin. Stdout: \" .. final_push_result.stdout)\n    log.info(\"Exemplo de automa\u00e7\u00e3o Git conclu\u00eddo com sucesso.\")\n    return true, \"Git automation example finished.\"\nend\n\nModern DSLs = {\n    git_automation_example = {\n        description = \"Demonstrates using the 'git' module for repository automation.\",\n        tasks = {\n            {\n                name = \"run_git_automation\",\n                command = command,\n                params = {\n                    version = \"v1.0.0-test\" -- Par\u00e2metro de exemplo\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Voltar aos M\u00f3dulos | Voltar ao \u00cdndice</p>"},{"location":"modules/notifications/","title":"Notifications Module","text":"<p>The <code>notifications</code> module provides a simple way to send messages to various notification services from your pipelines. This is particularly useful for reporting the success or failure of a CI/CD workflow.</p> <p>Currently, the following services are supported: - Slack - ntfy</p>"},{"location":"modules/notifications/#configuration","title":"Configuration","text":"<p>Before using the module, you need to add the required credentials or URLs to your <code>configs/values.yaml</code> file. The module will read these values at runtime.</p> <pre><code># configs/values.yaml\n\nnotifications:\n  slack:\n    # Your Slack Incoming Webhook URL\n    webhook_url: \"https://hooks.slack.com/services/...\"\n  ntfy:\n    # The ntfy server to use. Can be the public one or self-hosted.\n    server: \"https://ntfy.sh\"\n    # The topic to publish the notification to.\n    topic: \"your-sloth-runner-topic\"\n</code></pre>"},{"location":"modules/notifications/#slack","title":"Slack","text":""},{"location":"modules/notifications/#notificationsslacksendparams","title":"<code>notifications.slack.send(params)</code>","text":"<p>Sends a message to a Slack channel via an Incoming Webhook.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>webhook_url</code> (string): Required. The Slack Incoming Webhook URL. It's recommended to get this from the <code>values</code> module.</li> <li><code>message</code> (string): Required. The main text of the message.</li> <li><code>pipeline</code> (string): Optional. The name of the pipeline, which will be displayed in the message attachment for context.</li> <li><code>error_details</code> (string): Optional. Any error details to include in the message attachment. This is useful for failure notifications.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local values = require(\"values\")\n\nlocal slack_webhook = values.get(\"notifications.slack.webhook_url\")\n\nif slack_webhook and slack_webhook ~= \"\" then\n  -- On success\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u2705 Pipeline executed successfully!\",\n    pipeline = \"my-awesome-pipeline\"\n  })\n\n  -- On failure\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u274c Pipeline execution failed!\",\n    pipeline = \"my-awesome-pipeline\",\n    error_details = \"Could not connect to database.\"\n  })\nend\n</code></pre>"},{"location":"modules/notifications/#ntfy","title":"ntfy","text":""},{"location":"modules/notifications/#notificationsntfysendparams","title":"<code>notifications.ntfy.send(params)</code>","text":"<p>Sends a message to an ntfy.sh topic.</p> <p>Parameters:</p> <ul> <li><code>params</code> (table): A table containing the following fields:<ul> <li><code>server</code> (string): Required. The ntfy server URL.</li> <li><code>topic</code> (string): Required. The topic to send the message to.</li> <li><code>message</code> (string): Required. The body of the notification.</li> <li><code>title</code> (string): Optional. The title of the notification.</li> <li><code>priority</code> (string): Optional. Notification priority (e.g., <code>high</code>, <code>default</code>, <code>low</code>).</li> <li><code>tags</code> (table): Optional. A list of tags (emojis) to add to the notification.</li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>true</code> on success.</li> <li><code>false, error_message</code> on failure.</li> </ul> <p>Example:</p> <pre><code>local values = require(\"values\")\n\nlocal ntfy_server = values.get(\"notifications.ntfy.server\")\nlocal ntfy_topic = values.get(\"notifications.ntfy.topic\")\n\nif ntfy_topic and ntfy_topic ~= \"\" then\n  -- On success\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"Pipeline Success\",\n    message = \"The pipeline finished without errors.\",\n    priority = \"default\",\n    tags = {\"tada\"}\n  })\n\n  -- On failure\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"Pipeline Failed!\",\n    message = \"The pipeline failed with an error.\",\n    priority = \"high\",\n    tags = {\"skull\", \"warning\"}\n  })\nend\n</code></pre>"},{"location":"modules/pulumi/","title":"M\u00f3dulo Pulumi","text":"<p>O m\u00f3dulo <code>pulumi</code> do Sloth-Runner permite que voc\u00ea orquestre suas stacks do Pulumi diretamente de seus scripts Lua. Isso \u00e9 ideal para fluxos de trabalho de Infraestrutura como C\u00f3digo (IaC) onde voc\u00ea precisa provisionar, atualizar ou destruir recursos de nuvem como parte de uma pipeline de automa\u00e7\u00e3o maior.</p>"},{"location":"modules/pulumi/#casos-de-uso-comuns","title":"Casos de Uso Comuns","text":"<ul> <li>Provisionamento Din\u00e2mico: Criar ambientes de staging ou teste sob demanda.</li> <li>Atualiza\u00e7\u00f5es de Infraestrutura: Automatizar o deploy de novas vers\u00f5es da sua infraestrutura.</li> <li>Gerenciamento de Ambientes: Destruir ambientes ap\u00f3s o uso para economizar custos.</li> <li>Integra\u00e7\u00e3o CI/CD: Executar <code>pulumi up</code> ou <code>preview</code> como parte de um pipeline de CI/CD.</li> </ul>"},{"location":"modules/pulumi/#referencia-da-api","title":"Refer\u00eancia da API","text":""},{"location":"modules/pulumi/#pulumistackname-options_table","title":"<code>pulumi.stack(name, options_table)</code>","text":"<p>Cria uma nova inst\u00e2ncia de uma stack Pulumi, permitindo que voc\u00ea interaja com ela.</p> <ul> <li><code>name</code> (string): O nome completo da stack Pulumi (ex: \"my-org/my-project/dev\").</li> <li><code>options_table</code> (tabela Lua): Uma tabela de op\u00e7\u00f5es para configurar a stack:<ul> <li><code>workdir</code> (string): Obrigat\u00f3rio. O caminho para o diret\u00f3rio raiz do projeto Pulumi associado a esta stack.</li> </ul> </li> </ul> <p>Retorna: *   <code>PulumiStack</code> (userdata): Uma inst\u00e2ncia do objeto <code>PulumiStack</code> para a stack especificada.</p>"},{"location":"modules/pulumi/#metodos-do-objeto-pulumistack","title":"M\u00e9todos do Objeto <code>PulumiStack</code>","text":"<p>Todos os m\u00e9todos abaixo s\u00e3o chamados na inst\u00e2ncia do <code>PulumiStack</code> (ex: <code>my_stack:up(...)</code>).</p>"},{"location":"modules/pulumi/#stackupoptions","title":"<code>stack:up(options)</code>","text":"<p>Executa o comando <code>pulumi up</code> para criar ou atualizar os recursos da stack.</p> <ul> <li><code>options</code> (tabela Lua, opcional): Uma tabela de op\u00e7\u00f5es para o comando <code>up</code>:<ul> <li><code>non_interactive</code> (booleano): Se <code>true</code>, adiciona as flags <code>--non-interactive</code> e <code>--yes</code> ao comando <code>pulumi up</code>.</li> <li><code>config</code> (tabela Lua): Uma tabela de pares chave-valor para passar configura\u00e7\u00f5es para a stack (ex: <code>[\"my-app:vpcId\"] = vpc_id</code>).</li> <li><code>args</code> (tabela Lua de strings): Uma lista de argumentos adicionais a serem passados diretamente para o comando <code>pulumi up</code>.</li> </ul> </li> </ul> <p>Retorna: *   <code>result</code> (tabela Lua): Uma tabela contendo:     *   <code>success</code> (booleano): <code>true</code> se a opera\u00e7\u00e3o foi bem-sucedida, <code>false</code> caso contr\u00e1rio.     *   <code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando Pulumi.     *   <code>stderr</code> (string): A sa\u00edda de erro padr\u00e3o do comando Pulumi.     *   <code>error</code> (string ou <code>nil</code>): Uma mensagem de erro Go se a execu\u00e7\u00e3o do comando falhou.</p>"},{"location":"modules/pulumi/#stackpreviewoptions","title":"<code>stack:preview(options)</code>","text":"<p>Executa o comando <code>pulumi preview</code> para mostrar uma pr\u00e9via das altera\u00e7\u00f5es que seriam aplicadas.</p> <ul> <li><code>options</code> (tabela Lua, opcional): As mesmas op\u00e7\u00f5es que para <code>stack:up()</code>.</li> </ul> <p>Retorna: *   <code>result</code> (tabela Lua): O mesmo formato de retorno que <code>stack:up()</code>.</p>"},{"location":"modules/pulumi/#stackrefreshoptions","title":"<code>stack:refresh(options)</code>","text":"<p>Executa o comando <code>pulumi refresh</code> para atualizar o estado da stack com os recursos reais na nuvem.</p> <ul> <li><code>options</code> (tabela Lua, opcional): As mesmas op\u00e7\u00f5es que para <code>stack:up()</code>.</li> </ul> <p>Retorna: *   <code>result</code> (tabela Lua): O mesmo formato de retorno que <code>stack:up()</code>.</p>"},{"location":"modules/pulumi/#stackdestroyoptions","title":"<code>stack:destroy(options)</code>","text":"<p>Executa o comando <code>pulumi destroy</code> para destruir todos os recursos da stack.</p> <ul> <li><code>options</code> (tabela Lua, opcional): As mesmas op\u00e7\u00f5es que para <code>stack:up()</code>.</li> </ul> <p>Retorna: *   <code>result</code> (tabela Lua): O mesmo formato de retorno que <code>stack:up()</code>.</p>"},{"location":"modules/pulumi/#stackoutputs","title":"<code>stack:outputs()</code>","text":"<p>Obt\u00e9m os outputs da stack Pulumi.</p> <p>Retorna: *   <code>outputs</code> (tabela Lua): Uma tabela Lua onde as chaves s\u00e3o os nomes dos outputs e os valores s\u00e3o os respectivos outputs da stack. *   <code>error</code> (string ou <code>nil</code>): Uma mensagem de erro se a opera\u00e7\u00e3o falhar.</p>"},{"location":"modules/pulumi/#exemplos-de-uso","title":"Exemplos de Uso","text":""},{"location":"modules/pulumi/#exemplo-basico-de-orquestracao-pulumi","title":"Exemplo B\u00e1sico de Orquestra\u00e7\u00e3o Pulumi","text":"<p>Este exemplo demonstra como fazer o deploy de duas stacks Pulumi, passando um output da primeira como input para a segunda.</p> <pre><code>-- examples/pulumi_example.sloth\n\ncommand = function()\n    log.info(\"Iniciando exemplo de orquestra\u00e7\u00e3o Pulumi...\")\n\n    -- Exemplo 1: Deploy de uma stack base (e.g., VPC)\n    log.info(\"Deploying the base infrastructure stack (VPC)...\")\n    local vpc_stack = pulumi.stack(\"my-org/vpc-network/prod\", {\n        workdir = \"./pulumi/vpc\" -- Assumindo que o diret\u00f3rio do projeto Pulumi est\u00e1 aqui\n    })\n\n    -- Executa 'pulumi up' de forma n\u00e3o-interativa\n    local vpc_result = vpc_stack:up({ non_interactive = true })\n\n    -- Verifica o resultado do deploy da VPC\n    if not vpc_result.success then\n        log.error(\"VPC stack deployment failed: \" .. vpc_result.stderr)\n        return false, \"VPC deployment failed.\"\n    end\n    log.info(\"VPC stack deployed successfully. Stdout: \" .. vpc_result.stdout)\n\n    -- Obt\u00e9m os outputs da stack da VPC\n    local vpc_outputs, outputs_err = vpc_stack:outputs()\n    if outputs_err then\n        log.error(\"Failed to get VPC stack outputs: \" .. outputs_err)\n        return false, \"Failed to get VPC outputs.\"\n    end\n\n    local vpc_id = vpc_outputs.vpcId -- Assumindo que a stack exporta 'vpcId'\n    if not vpc_id then\n        log.warn(\"VPC stack did not export 'vpcId'. Continuing without it.\")\n        vpc_id = \"unknown-vpc-id\"\n    end\n    log.info(\"Obtained VPC ID from outputs: \" .. vpc_id)\n\n    -- Exemplo 2: Deploy de uma stack de aplica\u00e7\u00e3o, usando outputs da stack anterior como config\n    log.info(\"Deploying the application stack into VPC: \" .. vpc_id)\n    local app_stack = pulumi.stack(\"my-org/app-server/prod\", {\n        workdir = \"./pulumi/app\" -- Assumindo que o diret\u00f3rio do projeto Pulumi da app est\u00e1 aqui\n    })\n\n    -- Executa 'pulumi up' passando outputs da stack anterior como configura\u00e7\u00e3o\n    local app_result = app_stack:up({\n        non_interactive = true,\n        config = {\n            [\"my-app:vpcId\"] = vpc_id,\n            [\"aws:region\"] = \"us-east-1\"\n        }\n    })\n\n    -- Verifica o resultado do deploy da aplica\u00e7\u00e3o\n    if not app_result.success then\n        log.error(\"Application stack deployment failed: \" .. app_result.stderr)\n        return false, \"Application deployment failed.\"\n    end\n    log.info(\"Application stack deployed successfully. Stdout: \" .. app_result.stdout)\n\n    log.info(\"Exemplo de orquestra\u00e7\u00e3o Pulumi conclu\u00eddo com sucesso.\")\n    return true, \"Pulumi orchestration example finished.\"\nend\n\nModern DSLs = {\n    pulumi_orchestration_example = {\n        description = \"Demonstrates using the 'pulumi' module to orchestrate infrastructure stacks.\",\n        tasks = {\n            {\n                name = \"run_pulumi_orchestration\",\n                command = command\n            }\n        }\n    }\n}\n</code></pre> <p>Voltar aos M\u00f3dulos | Voltar ao \u00cdndice</p>"},{"location":"modules/salt/","title":"M\u00f3dulo Salt","text":"<p>O m\u00f3dulo <code>salt</code> do Sloth-Runner fornece uma API fluente para interagir com o SaltStack diretamente de seus scripts Lua. Isso permite automatizar a orquestra\u00e7\u00e3o e configura\u00e7\u00e3o de servidores, integrando o poder do Salt em seus fluxos de trabalho do Sloth-Runner.</p>"},{"location":"modules/salt/#casos-de-uso-comuns","title":"Casos de Uso Comuns","text":"<ul> <li>Automa\u00e7\u00e3o de Configura\u00e7\u00e3o: Aplicar estados Salt (<code>state.apply</code>) em minions espec\u00edficos.</li> <li>Verifica\u00e7\u00e3o de Status: Realizar pings (<code>test.ping</code>) para verificar a conectividade com minions.</li> <li>Execu\u00e7\u00e3o Remota de Comandos: Executar comandos arbitr\u00e1rios (<code>cmd.run</code>) em um ou mais minions.</li> <li>Orquestra\u00e7\u00e3o de Deployments: Coordenar a implanta\u00e7\u00e3o de aplica\u00e7\u00f5es usando fun\u00e7\u00f5es Salt.</li> </ul>"},{"location":"modules/salt/#referencia-da-api","title":"Refer\u00eancia da API","text":""},{"location":"modules/salt/#salttargettarget_string","title":"<code>salt.target(target_string)</code>","text":"<p>Define o alvo (minion ou grupo de minions) para as opera\u00e7\u00f5es Salt subsequentes.</p> <ul> <li><code>target_string</code> (string): O ID do minion, glob, lista, ou outro tipo de alvo suportado pelo Salt.</li> </ul> <p>Retorna: *   <code>SaltTargeter</code> (userdata): Uma inst\u00e2ncia do objeto <code>SaltTargeter</code> para o alvo especificado.</p>"},{"location":"modules/salt/#metodos-do-objeto-salttargeter-encadeaveis","title":"M\u00e9todos do Objeto <code>SaltTargeter</code> (Encade\u00e1veis)","text":"<p>Todos os m\u00e9todos abaixo s\u00e3o chamados na inst\u00e2ncia do <code>SaltTargeter</code> (ex: <code>minion:ping()</code>) e retornam a pr\u00f3pria inst\u00e2ncia do <code>SaltTargeter</code> para permitir o encadeamento de chamadas. Para obter o resultado da \u00faltima opera\u00e7\u00e3o, use o m\u00e9todo <code>:result()</code>.</p>"},{"location":"modules/salt/#targetping","title":"<code>target:ping()</code>","text":"<p>Executa o comando <code>test.ping</code> no alvo definido.</p>"},{"location":"modules/salt/#targetcmdfunction-args","title":"<code>target:cmd(function, ...args)</code>","text":"<p>Executa uma fun\u00e7\u00e3o Salt arbitr\u00e1ria no alvo.</p> <ul> <li><code>function</code> (string): O nome da fun\u00e7\u00e3o Salt a ser executada (ex: \"state.apply\", \"cmd.run\", \"pkg.upgrade\").</li> <li><code>...args</code> (variadic): Argumentos adicionais a serem passados para a fun\u00e7\u00e3o Salt.</li> </ul>"},{"location":"modules/salt/#targetresult","title":"<code>target:result()</code>","text":"<p>Retorna o resultado da \u00faltima opera\u00e7\u00e3o Salt executada na inst\u00e2ncia do <code>SaltTargeter</code>.</p> <p>Retorna: *   <code>result</code> (tabela Lua): Uma tabela contendo:     *   <code>success</code> (booleano): <code>true</code> se a opera\u00e7\u00e3o foi bem-sucedida, <code>false</code> caso contr\u00e1rio.     *   <code>stdout</code> (string ou tabela Lua): A sa\u00edda padr\u00e3o do comando Salt. Se o Salt retornar JSON v\u00e1lido, ser\u00e1 uma tabela Lua.     *   <code>stderr</code> (string): A sa\u00edda de erro padr\u00e3o do comando Salt.     *   <code>error</code> (string ou <code>nil</code>): Uma mensagem de erro Go se a execu\u00e7\u00e3o do comando falhou.</p>"},{"location":"modules/salt/#exemplos-de-uso","title":"Exemplos de Uso","text":""},{"location":"modules/salt/#exemplo-basico-de-orquestracao-salt","title":"Exemplo B\u00e1sico de Orquestra\u00e7\u00e3o Salt","text":"<p>Este exemplo demonstra como usar a API fluente do Salt para realizar pings e executar comandos em minions.</p> <pre><code>-- examples/fluent_salt_api_test.sloth\n\ncommand = function()\n    log.info(\"Iniciando teste da API fluente do Salt...\")\n\n    -- Teste 1: Executando comandos no minion 'keiteguica'\n    log.info(\"Testando alvo \u00fanico: keiteguica\")\n    -- Encadeia o comando ping() para o alvo 'keiteguica'\n    salt.target('keiteguica'):ping()\n\n    log.info(\"--------------------------------------------------\")\n\n    -- Teste 2: Executando comandos em m\u00faltiplos minions usando globbing\n    log.info(\"Testando alvo com glob: vm-gcp-squid-proxy*\")\n    -- Encadeia os comandos ping() e cmd() para alvos que correspondem ao padr\u00e3o\n    salt.target('vm-gcp-squid-proxy*'):ping():cmd('pkg.upgrade')\n\n    log.info(\"Teste da API fluente do Salt conclu\u00eddo.\")\n\n    log.info(\"Executando 'ls -la' via Salt e tratando a sa\u00edda...\")\n    local result_stdout, result_stderr, result_err = salt.target('keiteguica'):cmd('cmd.run', 'ls -la'):result()\n\n    if result_err ~= nil then\n        log.error(\"Erro ao executar 'ls -la' via Salt: \" .. result_err)\n        log.error(\"Stderr: \" .. result_stderr)\n    else\n        log.info(\"Sa\u00edda de 'ls -la' via Salt:\")\n        -- Se a sa\u00edda for uma tabela (JSON), voc\u00ea pode iterar sobre ela ou convert\u00ea-la para string\n        if type(result_stdout) == \"table\" then\n            log.info(\"Sa\u00edda JSON (tabela): \" .. data.to_json(result_stdout))\n        else\n            log.info(result_stdout)\n        end\n    end\n    log.info(\"Tratamento da sa\u00edda de 'ls -la' via Salt conclu\u00eddo.\")\n\n    return true, \"Comandos da API fluente do Salt e 'ls -la' executados com sucesso.\"\nend\n\nModern DSLs = {\n    test_fluent_salt = {\n        description = \"Demonstrates using the 'salt' module for SaltStack orchestration.\",\n        tasks = {\n            {\n                name = \"run_salt_orchestration\",\n                command = command\n            }\n        }\n    }\n}\n</code></pre> <p>Voltar aos M\u00f3dulos | Voltar ao \u00cdndice</p>"},{"location":"modules/terraform/","title":"Terraform Module","text":"<p>The <code>terraform</code> module provides a high-level interface for orchestrating <code>terraform</code> CLI commands, allowing you to manage your infrastructure lifecycle directly from within a Sloth-Runner pipeline.</p>"},{"location":"modules/terraform/#configuration","title":"Configuration","text":"<p>This module requires the <code>terraform</code> CLI to be installed and available in the system's PATH. All commands must be executed within a specific <code>workdir</code> where your <code>.tf</code> files are located.</p>"},{"location":"modules/terraform/#functions","title":"Functions","text":""},{"location":"modules/terraform/#terraforminitparams","title":"<code>terraform.init(params)</code>","text":"<p>Initializes a Terraform working directory.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory containing the Terraform files.</li> </ul> </li> <li>Returns: A result table with <code>success</code>, <code>stdout</code>, <code>stderr</code>, and <code>exit_code</code>.</li> </ul>"},{"location":"modules/terraform/#terraformplanparams","title":"<code>terraform.plan(params)</code>","text":"<p>Creates a Terraform execution plan.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>out</code> (string): Optional. The filename to save the generated plan to.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"modules/terraform/#terraformapplyparams","title":"<code>terraform.apply(params)</code>","text":"<p>Applies a Terraform plan.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>plan</code> (string): Optional. The path to a plan file to apply.</li> <li><code>auto_approve</code> (boolean): Optional. If <code>true</code>, applies changes without interactive approval.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"modules/terraform/#terraformdestroyparams","title":"<code>terraform.destroy(params)</code>","text":"<p>Destroys Terraform-managed infrastructure.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>auto_approve</code> (boolean): Optional. If <code>true</code>, destroys resources without interactive approval.</li> </ul> </li> <li>Returns: A result table.</li> </ul>"},{"location":"modules/terraform/#terraformoutputparams","title":"<code>terraform.output(params)</code>","text":"<p>Reads an output variable from a Terraform state file.</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): Required. The path to the directory.</li> <li><code>name</code> (string): Optional. The name of a specific output to read. If omitted, all outputs are returned as a table.</li> </ul> </li> <li>Returns:<ul> <li>On success: The parsed JSON value of the output (can be a string, table, etc.).</li> <li>On failure: <code>nil, error_message</code>.</li> </ul> </li> </ul>"},{"location":"modules/terraform/#full-lifecycle-example","title":"Full Lifecycle Example","text":"<pre><code>local tf_workdir = \"./examples/terraform\"\n\n-- Task 1: Init\nlocal result_init = terraform.init({workdir = tf_workdir})\nif not result_init.success then return false, \"Init failed\" end\n\n-- Task 2: Plan\nlocal result_plan = terraform.plan({workdir = tf_workdir})\nif not result_plan.success then return false, \"Plan failed\" end\n\n-- Task 3: Apply\nlocal result_apply = terraform.apply({workdir = tf_workdir, auto_approve = true})\nif not result_apply.success then return false, \"Apply failed\" end\n\n-- Task 4: Get Output\nlocal filename, err = terraform.output({workdir = tf_workdir, name = \"report_filename\"})\nif not filename then return false, \"Output failed: \" .. err end\nlog.info(\"Terraform created file: \" .. filename)\n\n-- Task 5: Destroy\nlocal result_destroy = terraform.destroy({workdir = tf_workdir, auto_approve = true})\nif not result_destroy.success then return false, \"Destroy failed\" end\n</code></pre>"},{"location":"pt/","title":"Documenta\u00e7\u00e3o do Sloth-Runner","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o completa do Sloth-Runner, sua ferramenta flex\u00edvel para automa\u00e7\u00e3o de tarefas e orquestra\u00e7\u00e3o de fluxos de trabalho usando scripts Lua.</p> <p>Aqui voc\u00ea encontrar\u00e1 guias detalhados, refer\u00eancias de API e exemplos pr\u00e1ticos para aproveitar ao m\u00e1ximo o poder do Sloth-Runner.</p>"},{"location":"pt/#indice","title":"\u00cdndice","text":"<ul> <li>Agendador de Tarefas</li> <li>In\u00edcio R\u00e1pido</li> <li>Conceitos Essenciais</li> <li>Exemplos Pr\u00e1ticos</li> <li>Funcionalidades Avan\u00e7adas</li> <li>REPL Interativo</li> <li>M\u00f3dulos Built-in:<ul> <li>M\u00f3dulo AWS</li> <li>M\u00f3dulo Azure</li> <li>M\u00f3dulo DigitalOcean</li> <li>M\u00f3dulo Docker</li> <li>M\u00f3dulo Git</li> <li>M\u00f3dulo Pulumi</li> <li>M\u00f3dulo Salt</li> <li>M\u00f3dulo Terraform</li> </ul> </li> <li>Exemplos Avan\u00e7ados</li> </ul>"},{"location":"pt/CLI/","title":"Comandos da CLI","text":"<p>A interface de linha de comando (CLI) do <code>sloth-runner</code> \u00e9 a principal forma de interagir com seus pipelines de tarefas. Ela fornece comandos para executar, listar, validar e gerenciar seus fluxos de trabalho.</p>"},{"location":"pt/CLI/#sloth-runner-run","title":"<code>sloth-runner run</code>","text":"<p>Executa tarefas definidas em um arquivo de configura\u00e7\u00e3o Lua.</p> <p>Uso: <code>sloth-runner run [flags]</code></p> <p>Descri\u00e7\u00e3o: O comando <code>run</code> executa tarefas definidas em um arquivo de modelo Lua. Voc\u00ea pode especificar o arquivo, vari\u00e1veis de ambiente e direcionar tarefas ou grupos espec\u00edficos.</p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: Caminho para o arquivo de configura\u00e7\u00e3o de tarefas Lua (padr\u00e3o: \"examples/basic_pipeline.sloth\")</li> <li><code>-e, --env string</code>: Ambiente para as tarefas (ex: Development, Production) (padr\u00e3o: \"Development\")</li> <li><code>-p, --prod</code>: Definir como verdadeiro para ambiente de produ\u00e7\u00e3o (padr\u00e3o: false)</li> <li><code>--shards string</code>: Lista de n\u00fameros de shard separados por v\u00edrgula (ex: 1,2,3) (padr\u00e3o: \"1,2,3\")</li> <li><code>-t, --tasks string</code>: Lista de tarefas espec\u00edficas a serem executadas, separadas por v\u00edrgula (ex: tarefa1,tarefa2)</li> <li><code>-g, --group string</code>: Executa tarefas apenas de um grupo de tarefas espec\u00edfico</li> <li><code>-v, --values string</code>: Caminho para um arquivo YAML com valores a serem passados para as tarefas Lua</li> <li><code>-d, --dry-run</code>: Simula a execu\u00e7\u00e3o das tarefas sem realmente execut\u00e1-las (padr\u00e3o: false)</li> <li><code>--return</code>: Retorna a sa\u00edda das tarefas de destino como JSON (padr\u00e3o: false)</li> <li><code>-y, --yes</code>: Ignora a sele\u00e7\u00e3o interativa de tarefas e executa todas as tarefas (padr\u00e3o: false)</li> <li><code>--interactive</code>: Habilita o modo interativo para execu\u00e7\u00e3o de tarefas, solicitando a entrada do usu\u00e1rio antes de cada tarefa.</li> </ul>"},{"location":"pt/CLI/#sloth-runner-list","title":"<code>sloth-runner list</code>","text":"<p>Lista todos os grupos de tarefas e tarefas dispon\u00edveis.</p> <p>Uso: <code>sloth-runner list [flags]</code></p> <p>Descri\u00e7\u00e3o: O comando <code>list</code> exibe todos os grupos de tarefas e suas respectivas tarefas, juntamente com suas descri\u00e7\u00f5es e depend\u00eancias.</p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: Caminho para o arquivo de configura\u00e7\u00e3o de tarefas Lua (padr\u00e3o: \"examples/basic_pipeline.sloth\")</li> <li><code>-e, --env string</code>: Ambiente para as tarefas (ex: Development, Production) (padr\u00e3o: \"Development\")</li> <li><code>-p, --prod</code>: Definir como verdadeiro para ambiente de produ\u00e7\u00e3o (padr\u00e3o: false)</li> <li><code>--shards string</code>: Lista de n\u00fameros de shard separados por v\u00edrgula (ex: 1,2,3) (padr\u00e3o: \"1,2,3\")</li> <li><code>-v, --values string</code>: Caminho para um arquivo YAML com valores a serem passados para as tarefas Lua</li> </ul>"},{"location":"pt/CLI/#sloth-runner-validate","title":"<code>sloth-runner validate</code>","text":"<p>Valida a sintaxe e a estrutura de um arquivo de tarefas Lua.</p> <p>Uso: <code>sloth-runner validate [flags]</code></p> <p>Descri\u00e7\u00e3o: O comando <code>validate</code> verifica um arquivo de tarefas Lua quanto a erros de sintaxe e garante que a tabela <code>Modern DSLs</code> esteja corretamente estruturada.</p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: Caminho para o arquivo de configura\u00e7\u00e3o de tarefas Lua (padr\u00e3o: \"examples/basic_pipeline.sloth\")</li> <li><code>-e, --env string</code>: Ambiente para as tarefas (ex: Development, Production) (padr\u00e3o: \"Development\")</li> <li><code>-p, --prod</code>: Definir como verdadeiro para ambiente de produ\u00e7\u00e3o (padr\u00e3o: false)</li> <li><code>--shards string</code>: Lista de n\u00fameros de shard separados por v\u00edrgula (ex: 1,2,3) (padr\u00e3o: \"1,2,3\")</li> <li><code>-v, --values string</code>: Caminho para um arquivo YAML com valores a serem passados para as tarefas Lua</li> </ul>"},{"location":"pt/CLI/#sloth-runner-test","title":"<code>sloth-runner test</code>","text":"<p>Executa um arquivo de teste Lua para um fluxo de trabalho de tarefas.</p> <p>Uso: <code>sloth-runner test -w &lt;workflow-file&gt; -f &lt;test-file&gt;</code></p> <p>Descri\u00e7\u00e3o: O comando <code>test</code> executa um arquivo de teste Lua especificado contra um fluxo de trabalho. Dentro do arquivo de teste, voc\u00ea pode usar os m\u00f3dulos 'test' e 'assert' para validar os comportamentos das tarefas.</p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: Caminho para o arquivo de teste Lua (obrigat\u00f3rio)</li> <li><code>-w, --workflow string</code>: Caminho para o arquivo de fluxo de trabalho Lua a ser testado (obrigat\u00f3rio)</li> </ul>"},{"location":"pt/CLI/#sloth-runner-repl","title":"<code>sloth-runner repl</code>","text":"<p>Inicia uma sess\u00e3o REPL interativa.</p> <p>Uso: <code>sloth-runner repl [flags]</code></p> <p>Descri\u00e7\u00e3o: O comando <code>repl</code> inicia um Loop de Leitura-Avalia\u00e7\u00e3o-Impress\u00e3o interativo que permite executar c\u00f3digo Lua e interagir com todos os m\u00f3dulos sloth-runner integrados. Voc\u00ea pode opcionalmente carregar um arquivo de fluxo de trabalho para ter seu contexto dispon\u00edvel.</p> <p>Flags:</p> <ul> <li><code>-f, --file string</code>: Caminho para um arquivo de fluxo de trabalho Lua a ser carregado na sess\u00e3o REPL</li> </ul>"},{"location":"pt/CLI/#sloth-runner-version","title":"<code>sloth-runner version</code>","text":"<p>Imprime o n\u00famero da vers\u00e3o do sloth-runner.</p> <p>Uso: <code>sloth-runner version</code></p> <p>Descri\u00e7\u00e3o: Todo software tem vers\u00f5es. Esta \u00e9 a do sloth-runner.</p>"},{"location":"pt/CLI/#sloth-runner-scheduler","title":"<code>sloth-runner scheduler</code>","text":"<p>Gerencia o agendador de tarefas do <code>sloth-runner</code>, permitindo habilitar, desabilitar, listar e excluir tarefas agendadas.</p> <p>Para informa\u00e7\u00f5es detalhadas sobre os comandos e configura\u00e7\u00e3o do agendador, consulte a documenta\u00e7\u00e3o do Agendador de Tarefas.</p> <p>Subcomandos:</p> <ul> <li><code>sloth-runner scheduler enable</code>: Inicia o agendador como um processo em segundo plano.</li> <li><code>sloth-runner scheduler disable</code>: Para o processo do agendador em execu\u00e7\u00e3o.</li> <li><code>sloth-runner scheduler list</code>: Lista todas as tarefas agendadas configuradas.</li> <li><code>sloth-runner scheduler delete &lt;task_name&gt;</code>: Exclui uma tarefa agendada espec\u00edfica.</li> </ul>"},{"location":"pt/CLI/#sloth-runner-template-list","title":"<code>sloth-runner template list</code>","text":"<p>Lista todos os modelos dispon\u00edveis.</p> <p>Uso: <code>sloth-runner template list</code></p> <p>Descri\u00e7\u00e3o: Exibe uma tabela de todos os modelos dispon\u00edveis que podem ser usados com o comando 'new'.</p>"},{"location":"pt/CLI/#sloth-runner-artifacts","title":"<code>sloth-runner artifacts</code>","text":"<p>Gerencia os artefatos de tarefas, que s\u00e3o arquivos ou diret\u00f3rios produzidos pelas tarefas.</p> <p>Subcomandos:</p> <ul> <li><code>sloth-runner artifacts list</code>: Lista todos os artefatos coletados.</li> <li><code>sloth-runner artifacts get &lt;artifact_path&gt;</code>: Baixa um artefato espec\u00edfico.</li> <li><code>sloth-runner artifacts clean</code>: Limpa artefatos antigos ou indesejados.</li> </ul>"},{"location":"pt/CLI/#modelos","title":"\ud83d\udcc4 Modelos","text":"<p><code>sloth-runner</code> oferece v\u00e1rios modelos para criar rapidamente novos arquivos de defini\u00e7\u00e3o de tarefas.</p> Nome do Modelo Descri\u00e7\u00e3o <code>simple</code> Gera um \u00fanico grupo com uma tarefa 'hello world'. Ideal para come\u00e7ar. <code>python</code> Cria um pipeline para configurar um ambiente Python, instalar depend\u00eancias e executar um script. <code>parallel</code> Demonstra como executar v\u00e1rias tarefas simultaneamente. <code>python-pulumi</code> Pipeline para implantar infraestrutura Pulumi gerenciada com Python. <code>python-pulumi-salt</code> Provisiona infraestrutura com Pulumi e a configura usando SaltStack. <code>git-python-pulumi</code> Pipeline CI/CD: Clona um reposit\u00f3rio, configura o ambiente e implanta com Pulumi. <code>dummy</code> Gera uma tarefa fict\u00edcia que n\u00e3o faz nada."},{"location":"pt/CLI/#sloth-runner-new-group-name","title":"<code>sloth-runner new &lt;group-name&gt;</code>","text":"<p>Gera um novo arquivo de defini\u00e7\u00e3o de tarefas a partir de um modelo.</p> <p>Uso: <code>sloth-runner new &lt;group-name&gt; [flags]</code></p> <p>Descri\u00e7\u00e3o: O comando <code>new</code> cria um arquivo de defini\u00e7\u00e3o de tarefas Lua boilerplate. Voc\u00ea pode escolher entre diferentes modelos e especificar um arquivo de sa\u00edda. Execute <code>sloth-runner template list</code> para ver as op\u00e7\u00f5es.</p> <p>Argumentos:</p> <ul> <li><code>&lt;group-name&gt;</code>: O nome do grupo de tarefas a ser gerado.</li> </ul> <p>Flags:</p> <ul> <li><code>-o, --output string</code>: Caminho do arquivo de sa\u00edda (padr\u00e3o: stdout)</li> <li><code>-t, --template string</code>: Modelo a ser usado. Veja <code>template list</code> para op\u00e7\u00f5es. (padr\u00e3o: \"simple\")</li> <li><code>--set key=value</code>: Passa pares chave-valor para o modelo para gera\u00e7\u00e3o din\u00e2mica de conte\u00fado.</li> </ul>"},{"location":"pt/CLI/#sloth-runner-check-dependencies","title":"<code>sloth-runner check dependencies</code>","text":"<p>Verifica as ferramentas CLI externas necess\u00e1rias.</p> <p>Uso: <code>sloth-runner check dependencies</code></p> <p>Descri\u00e7\u00e3o: Verifica se todas as ferramentas de linha de comando externas usadas pelos v\u00e1rios m\u00f3dulos (por exemplo, docker, aws, doctl) est\u00e3o instaladas e dispon\u00edveis no PATH do sistema.</p>"},{"location":"pt/advanced-examples/","title":"Exemplos Avan\u00e7ados","text":"<p>Esta se\u00e7\u00e3o apresenta exemplos mais complexos e cen\u00e1rios de uso que combinam m\u00faltiplos m\u00f3dulos do Sloth-Runner para automa\u00e7\u00e3o de ponta a ponta.</p>"},{"location":"pt/advanced-examples/#exemplo-completo-pipeline-de-cicd-end-to-end","title":"Exemplo Completo: Pipeline de CI/CD End-to-End","text":"<p>Este tutorial demonstra como construir um pipeline de CI/CD completo usando os m\u00f3dulos <code>git</code>, <code>pulumi</code> e <code>salt</code> para versionar c\u00f3digo, provisionar infraestrutura e implantar uma aplica\u00e7\u00e3o.</p>"},{"location":"pt/advanced-examples/#cenario","title":"Cen\u00e1rio","text":"<p>Imagine que voc\u00ea tem um projeto de infraestrutura Pulumi e um projeto de aplica\u00e7\u00e3o. Voc\u00ea quer automatizar o seguinte fluxo:</p> <ol> <li>Clonar o reposit\u00f3rio da infraestrutura.</li> <li>Atualizar um arquivo de vers\u00e3o dentro do reposit\u00f3rio.</li> <li>Committar e empurrar essa altera\u00e7\u00e3o para o Git.</li> <li>Executar <code>pulumi up</code> para provisionar ou atualizar a infraestrutura (por exemplo, um ambiente de staging).</li> <li>Usar o Salt para configurar os servidores provisionados e implantar a aplica\u00e7\u00e3o.</li> </ol>"},{"location":"pt/advanced-examples/#script-lua-examplespulumi_git_combined_examplesloth","title":"Script Lua (<code>examples/pulumi_git_combined_example.sloth</code>)","text":"<pre><code>-- examples/pulumi_git_combined_example.sloth\n\ncommand = function(params)\n    log.info(\"Iniciando exemplo combinado Pulumi e Git...\")\n\n    local pulumi_repo_url = \"https://github.com/my-org/my-pulumi-infra.git\" -- Exemplo de repo Pulumi\n    local pulumi_repo_path = \"./pulumi-infra-checkout\"\n    local new_infra_version = params.infra_version or \"v1.0.0-infra\"\n    local pulumi_project_workdir = pulumi_repo_path .. \"/my-vpc-project\" -- Subdiret\u00f3rio dentro do repo clonado\n    local repo\n\n    -- 1. Clonar ou abrir o reposit\u00f3rio Pulumi\n    log.info(\"Step 1: Cloning or opening Pulumi repository...\")\n    if not fs.exists(pulumi_repo_path) then\n        log.info(\"Cloning Pulumi repository: \" .. pulumi_repo_url)\n        local cloned_repo, clone_err = git.clone(pulumi_repo_url, pulumi_repo_path)\n        if clone_err then\n            log.error(\"Failed to clone Pulumi repository: \" .. clone_err)\n            return false, \"Git clone failed.\"\n        end\n        repo = cloned_repo\n    else\n        log.info(\"Pulumi repository already exists, opening local reference.\")\n        local opened_repo, open_err = git.repo(pulumi_repo_path)\n        if open_err then\n            log.error(\"Failed to open Pulumi repository: \" .. open_err)\n            return false, \"Git repo open failed.\"\n        end\n        repo = opened_repo\n    end\n\n    if not repo then\n        return false, \"Failed to get Pulumi repository reference.\"\n    end\n\n    -- 2. Atualizar o reposit\u00f3rio (pull)\n    log.info(\"Step 2: Pulling latest changes from Pulumi repository...\")\n    repo:checkout(\"main\"):pull(\"origin\", \"main\")\n    local pull_result = repo:result()\n    if not pull_result.success then\n        log.error(\"Failed to pull Pulumi repository: \" .. pull_result.stderr)\n        return false, \"Git pull failed.\"\n    end\n    log.info(\"Pulumi repository updated. Stdout: \" .. pull_result.stdout)\n\n    -- 3. Simular uma altera\u00e7\u00e3o no c\u00f3digo Pulumi (e.g., atualizar um arquivo de vers\u00e3o)\n    log.info(\"Step 3: Simulating a change in Pulumi code (updating version file)...\")\n    local infra_version_file = pulumi_repo_path .. \"/INFRA_VERSION\"\n    fs.write(infra_version_file, new_infra_version)\n    log.info(\"Updated INFRA_VERSION file to: \" .. new_infra_version)\n\n    -- 4. Commitar e empurrar as mudan\u00e7as\n    log.info(\"Step 4: Committing and pushing infrastructure version change...\")\n    local commit_message = \"ci: Bump infrastructure version to \" .. new_infra_version\n    repo:add(infra_version_file)\n        :commit(commit_message)\n        :push(\"origin\", \"main\") -- Sem follow_tags aqui, apenas o commit\n\n    local push_result = repo:result()\n    if not push_result.success then\n        log.error(\"Failed to push infrastructure changes: \" .. push_result.stderr)\n        return false, \"Git push failed for infra changes.\"\n    end\n    log.info(\"Infrastructure version change pushed. Stdout: \" .. push_result.stdout)\n\n    -- 5. Executar 'pulumi up' para o projeto\n    log.info(\"Step 5: Running pulumi up for the infrastructure project...\")\n    local infra_stack = pulumi.stack(\"my-org/my-infra/dev\", {\n        workdir = pulumi_project_workdir -- Usar o subdiret\u00f3rio do projeto Pulumi\n    })\n\n    local pulumi_up_result = infra_stack:up({ non_interactive = true })\n\n    if not pulumi_up_result.success then\n        log.error(\"Pulumi up failed: \" .. pulumi_up_result.stderr)\n        return false, \"Pulumi up failed.\"\n    end\n    log.info(\"Pulumi up completed successfully. Stdout: \" .. pulumi_up_result.stdout)\n\n    -- 6. Configurar e implantar a aplica\u00e7\u00e3o usando Salt (Exemplo)\n    log.info(\"Step 6: Configuring and deploying application using Salt...\")\n    -- Assumindo que o Pulumi up forneceu o IP ou hostname do servidor\n    -- Para este exemplo, vamos usar um IP fict\u00edcio\n    local server_ip = \"192.168.1.100\" -- Substitua pelo output real do Pulumi, se houver\n    local salt_target = salt.target(server_ip)\n\n    log.info(\"Running Salt test.ping on \" .. server_ip .. \"...\")\n    salt_target:ping()\n    local ping_result = salt_target:result()\n    if not ping_result.success then\n        log.error(\"Salt ping failed for \" .. server_ip .. \": \" .. ping_result.stderr)\n        return false, \"Salt ping failed.\"\n    end\n    log.info(\"Salt ping successful. Stdout: \" .. data.to_json(ping_result.stdout)) -- Assumindo que ping retorna JSON\n\n    log.info(\"Applying Salt state 'app.install' on \" .. server_ip .. \"...\")\n    salt_target:cmd('state.apply', 'app.install')\n    local salt_apply_result = salt_target:result()\n    if not salt_apply_result.success then\n        log.error(\"Salt state.apply failed for \" .. server_ip .. \": \" .. salt_apply_result.stderr)\n        return false, \"Salt state.apply failed.\"\n    end\n    log.info(\"Salt state.apply successful. Stdout: \" .. data.to_json(salt_apply_result.stdout))\n\n    log.info(\"Exemplo combinado Pulumi e Git conclu\u00eddo com sucesso.\")\n    return true, \"Combined Pulumi and Git example finished.\"\nend\n\nModern DSLs = {\n    pulumi_git_combined_example = {\n        description = \"Demonstrates combined usage of 'pulumi' and 'git' modules for CI/CD pipeline.\",\n        tasks = {\n            {\n                name = \"run_combined_example\",\n                command = command,\n                params = {\n                    infra_version = \"v1.0.0-test-combined\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"pt/advanced-features/","title":"Funcionalidades Avan\u00e7adas","text":"<p>Este documento aborda algumas das funcionalidades mais avan\u00e7adas do <code>sloth-runner</code>, projetadas para aprimorar seus fluxos de trabalho de desenvolvimento, depura\u00e7\u00e3o e configura\u00e7\u00e3o.</p>"},{"location":"pt/advanced-features/#executor-de-tarefas-interativo","title":"Executor de Tarefas Interativo","text":"<p>Para fluxos de trabalho complexos, pode ser \u00fatil percorrer as tarefas uma a uma, inspecionar suas sa\u00eddas e decidir se deve prosseguir, pular ou tentar novamente uma tarefa. O executor de tarefas interativo fornece uma maneira poderosa de depurar e desenvolver seus pipelines de tarefas.</p> <p>Para usar o executor interativo, adicione a flag <code>--interactive</code> ao comando <code>sloth-runner run</code>:</p> <pre><code>sloth-runner run -f examples/basic_pipeline.sloth --yes --interactive\n</code></pre> <p>Quando habilitado, o executor pausar\u00e1 antes de executar cada tarefa e solicitar\u00e1 uma a\u00e7\u00e3o:</p> <pre><code>? Tarefa: fetch_data (Simula a busca de dados brutos)\n&gt; executar\n  pular\n  abortar\n  continuar\n</code></pre> <p>A\u00e7\u00f5es:</p> <ul> <li>executar: (Padr\u00e3o) Prossegue com a execu\u00e7\u00e3o da tarefa atual.</li> <li>pular: Pula a tarefa atual e passa para a pr\u00f3xima na ordem de execu\u00e7\u00e3o.</li> <li>abortar: Aborta imediatamente toda a execu\u00e7\u00e3o da tarefa.</li> <li>continuar: Executa a tarefa atual e todas as subsequentes sem mais prompts, desativando efetivamente o modo interativo para o resto da execu\u00e7\u00e3o.</li> </ul>"},{"location":"pt/advanced-features/#modelagem-aprimorada-de-valuesyaml","title":"Modelagem Aprimorada de <code>values.yaml</code>","text":"<p>Voc\u00ea pode tornar seus arquivos <code>values.yaml</code> mais din\u00e2micos usando a sintaxe de modelo Go para injetar vari\u00e1veis de ambiente. Isso \u00e9 particularmente \u00fatil para fornecer informa\u00e7\u00f5es sens\u00edveis (como tokens ou chaves) ou configura\u00e7\u00f5es espec\u00edficas do ambiente sem codific\u00e1-las.</p> <p>O <code>sloth-runner</code> processa o <code>values.yaml</code> como um modelo Go, disponibilizando quaisquer vari\u00e1veis de ambiente no mapa <code>.Env</code>.</p> <p>Exemplo:</p> <ol> <li> <p>Crie um arquivo <code>values.yaml</code> com um placeholder de modelo:</p> <p><pre><code># values.yaml\napi_key: \"{{ .Env.MY_API_KEY }}\"\nregion: \"{{ .Env.AWS_REGION | default \"us-east-1\" }}\"\n</code></pre> Nota: Voc\u00ea pode usar <code>default</code> para fornecer um valor de fallback se a vari\u00e1vel de ambiente n\u00e3o estiver definida.</p> </li> <li> <p>Crie uma tarefa Lua que use esses valores:</p> <pre><code>-- my_task.sloth\nModern DSLs = {\n  my_group = {\n    tasks = {\n      {\n        name = \"deploy\",\n        command = function()\n          log.info(\"Implantando na regi\u00e3o: \" .. values.region)\n          log.info(\"Usando a chave de API (primeiros 5 caracteres): \" .. string.sub(values.api_key, 1, 5) .. \"...\")\n          return true, \"Implanta\u00e7\u00e3o bem-sucedida.\"\n        end\n      }\n    }\n  }\n}\n</code></pre> </li> <li> <p>Execute a tarefa com as vari\u00e1veis de ambiente definidas:</p> <pre><code>export MY_API_KEY=\"supersecretkey12345\"\nexport AWS_REGION=\"us-west-2\"\n\nsloth-runner run -f my_task.sloth -v values.yaml --yes\n</code></pre> </li> </ol> <p>Sa\u00edda:</p> <p>A sa\u00edda mostrar\u00e1 que os valores das vari\u00e1veis de ambiente foram substitu\u00eddos corretamente:</p> <pre><code>INFO Implantando na regi\u00e3o: us-west-2\nINFO Usando a chave de API (primeiros 5 caracteres): super...\n</code></pre>"},{"location":"pt/core-concepts/","title":"Conceitos Essenciais - Modern DSL","text":"<p>Este documento explica os conceitos fundamentais do <code>sloth-runner</code> usando a Modern DSL, ajudando voc\u00ea a entender como definir e orquestrar fluxos de trabalho complexos com a nova API fluente.</p>"},{"location":"pt/core-concepts/#visao-geral-da-modern-dsl","title":"Vis\u00e3o Geral da Modern DSL","text":"<p>A Modern DSL substitui a abordagem legada <code>Modern DSLs</code> por uma API mais intuitiva e fluente para definir fluxos de trabalho. Em vez de grandes estruturas de tabela, voc\u00ea agora usa m\u00e9todos encade\u00e1veis para construir tarefas e definir fluxos de trabalho de forma declarativa.</p> <pre><code>-- meu_pipeline.sloth - Modern DSL\nlocal minha_tarefa = task(\"nome_da_tarefa\")\n    :description(\"Descri\u00e7\u00e3o da tarefa\")\n    :command(function() ... end)\n    :build()\n\nworkflow.define(\"nome_do_workflow\", {\n    description = \"Descri\u00e7\u00e3o do workflow - Modern DSL\",\n    tasks = { minha_tarefa }\n})\n</code></pre>"},{"location":"pt/core-concepts/#definicao-de-tarefa-com-modern-dsl","title":"Defini\u00e7\u00e3o de Tarefa com Modern DSL","text":"<p>As tarefas agora s\u00e3o definidas usando a fun\u00e7\u00e3o <code>task()</code> e m\u00e9todos da API fluente:</p>"},{"location":"pt/core-concepts/#estrutura-basica-de-tarefa","title":"Estrutura B\u00e1sica de Tarefa","text":"<pre><code>local minha_tarefa = task(\"nome_da_tarefa\")\n    :description(\"O que esta tarefa faz\")\n    :command(function(params, deps)\n        -- L\u00f3gica da tarefa aqui\n        return true, \"Mensagem de sucesso\", { dados_de_saida = \"valor\" }\n    end)\n    :timeout(\"5m\")\n    :retries(3, \"exponential\")\n    :build()\n</code></pre>"},{"location":"pt/core-concepts/#metodos-do-task-builder","title":"M\u00e9todos do Task Builder","text":"<p>Propriedades Principais: *   <code>:description(string)</code> - Descri\u00e7\u00e3o leg\u00edvel da tarefa *   <code>:command(function|string)</code> - L\u00f3gica de execu\u00e7\u00e3o da tarefa *   <code>:timeout(string)</code> - Tempo m\u00e1ximo de execu\u00e7\u00e3o (ex: \"10s\", \"5m\", \"1h\") *   <code>:retries(number, strategy)</code> - Configura\u00e7\u00e3o de retry com estrat\u00e9gia (\"exponential\", \"linear\", \"fixed\") *   <code>:depends_on(array)</code> - Array de nomes de tarefas das quais esta tarefa depende</p> <p>Recursos Avan\u00e7ados: *   <code>:async(boolean)</code> - Habilitar execu\u00e7\u00e3o ass\u00edncrona *   <code>:artifacts(array)</code> - Arquivos para salvar ap\u00f3s execu\u00e7\u00e3o bem-sucedida *   <code>:consumes(array)</code> - Artefatos de outras tarefas para usar *   <code>:run_if(function|string)</code> - L\u00f3gica de execu\u00e7\u00e3o condicional *   <code>:abort_if(function|string)</code> - Condi\u00e7\u00e3o para abortar todo o workflow</p> <p>Hooks de Ciclo de Vida: *   <code>:on_success(function)</code> - Executar quando a tarefa for bem-sucedida *   <code>:on_failure(function)</code> - Executar quando a tarefa falhar *   <code>:on_timeout(function)</code> - Executar quando a tarefa atingir timeout *   <code>:pre_hook(function)</code> - Executar antes do comando principal *   <code>:post_hook(function)</code> - Executar ap\u00f3s o comando principal</p> <p>Exemplo: <pre><code>Modern DSLs = {\n  meu_grupo = {\n    description = \"Um grupo que gerencia seu pr\u00f3prio diret\u00f3rio tempor\u00e1rio.\",\n    create_workdir_before_run = true,\n    clean_workdir_after_run = function(result)\n      if not result.success then\n        log.warn(\"O grupo falhou. O diret\u00f3rio de trabalho ser\u00e1 mantido para depura\u00e7\u00e3o.\")\n      end\n      return result.success -- Limpa apenas se tudo foi bem-sucedido\n    end,\n    tasks = {\n      -- Tarefas aqui\n    }\n  }\n}\n</code></pre></p>"},{"location":"pt/core-concepts/#tarefas-individuais","title":"Tarefas Individuais","text":"<p>Uma tarefa \u00e9 uma \u00fanica unidade de trabalho. \u00c9 definida como uma tabela com v\u00e1rias propriedades dispon\u00edveis para controlar seu comportamento.</p>"},{"location":"pt/core-concepts/#propriedades-basicas","title":"Propriedades B\u00e1sicas","text":"<ul> <li><code>name</code> (string): O nome \u00fanico da tarefa dentro de seu grupo.</li> <li><code>description</code> (string): Uma breve descri\u00e7\u00e3o do que a tarefa faz.</li> <li><code>command</code> (string ou fun\u00e7\u00e3o): A a\u00e7\u00e3o principal da tarefa.<ul> <li>Como string: \u00c9 executada como um comando de shell.</li> <li>Como fun\u00e7\u00e3o: A fun\u00e7\u00e3o Lua \u00e9 executada. Ela recebe dois argumentos: <code>params</code> (uma tabela com seus par\u00e2metros) e <code>deps</code> (uma tabela contendo os outputs de suas depend\u00eancias). A fun\u00e7\u00e3o deve retornar:<ol> <li><code>booleano</code>: <code>true</code> para sucesso, <code>false</code> para falha.</li> <li><code>string</code>: Uma mensagem descrevendo o resultado.</li> <li><code>tabela</code> (opcional): Uma tabela de outputs da qual outras tarefas podem depender.</li> </ol> </li> </ul> </li> </ul>"},{"location":"pt/core-concepts/#dependencia-e-fluxo-de-execucao","title":"Depend\u00eancia e Fluxo de Execu\u00e7\u00e3o","text":"<ul> <li><code>depends_on</code> (string ou tabela): Uma lista de nomes de tarefas que devem ser conclu\u00eddas com sucesso antes que esta tarefa possa ser executada.</li> <li><code>next_if_fail</code> (string ou tabela): Uma lista de nomes de tarefas a serem executadas apenas se esta tarefa falhar. \u00datil para tarefas de limpeza ou notifica\u00e7\u00e3o.</li> <li><code>async</code> (booleano): Se <code>true</code>, a tarefa \u00e9 executada em segundo plano, e o runner n\u00e3o espera que ela termine para iniciar a pr\u00f3xima tarefa na ordem de execu\u00e7\u00e3o.</li> </ul>"},{"location":"pt/core-concepts/#tratamento-de-erros-e-robustez","title":"Tratamento de Erros e Robustez","text":"<ul> <li><code>retries</code> (n\u00famero): O n\u00famero de vezes que uma tarefa ser\u00e1 tentada novamente se falhar. O padr\u00e3o \u00e9 <code>0</code>.</li> <li><code>timeout</code> (string): Uma dura\u00e7\u00e3o (ex: <code>\"10s\"</code>, <code>\"1m\"</code>) ap\u00f3s a qual a tarefa ser\u00e1 encerrada se ainda estiver em execu\u00e7\u00e3o.</li> </ul>"},{"location":"pt/core-concepts/#execucao-condicional","title":"Execu\u00e7\u00e3o Condicional","text":"<ul> <li><code>run_if</code> (string ou fun\u00e7\u00e3o): A tarefa ser\u00e1 pulada a menos que esta condi\u00e7\u00e3o seja atendida.<ul> <li>Como string: Um comando de shell. Um c\u00f3digo de sa\u00edda <code>0</code> significa que a condi\u00e7\u00e3o foi atendida.</li> <li>Como fun\u00e7\u00e3o: Uma fun\u00e7\u00e3o Lua que retorna <code>true</code> se a tarefa deve ser executada.</li> </ul> </li> <li><code>abort_if</code> (string ou fun\u00e7\u00e3o): Todo o fluxo de trabalho ser\u00e1 abortado se esta condi\u00e7\u00e3o for atendida.<ul> <li>Como string: Um comando de shell. Um c\u00f3digo de sa\u00edda <code>0</code> significa abortar.</li> <li>Como fun\u00e7\u00e3o: Uma fun\u00e7\u00e3o Lua que retorna <code>true</code> para abortar.</li> </ul> </li> </ul>"},{"location":"pt/core-concepts/#hooks-de-ciclo-de-vida","title":"Hooks de Ciclo de Vida","text":"<ul> <li><code>pre_exec</code> (fun\u00e7\u00e3o): Uma fun\u00e7\u00e3o Lua que \u00e9 executada antes do <code>command</code> principal.</li> <li><code>post_exec</code> (fun\u00e7\u00e3o): Uma fun\u00e7\u00e3o Lua que \u00e9 executada ap\u00f3s o <code>command</code> principal ter sido conclu\u00eddo com sucesso.</li> </ul>"},{"location":"pt/core-concepts/#reutilizacao","title":"Reutiliza\u00e7\u00e3o","text":"<ul> <li><code>uses</code> (tabela): Especifica uma tarefa pr\u00e9-definida de outro arquivo (carregado via <code>import</code>) para usar como base. A defini\u00e7\u00e3o da tarefa atual pode ent\u00e3o sobrescrever propriedades como <code>params</code> ou <code>description</code>.</li> <li><code>params</code> (tabela): Um dicion\u00e1rio de pares chave-valor que podem ser passados para a fun\u00e7\u00e3o <code>command</code> da tarefa.</li> <li><code>artifacts</code> (string ou tabela): Um padr\u00e3o de arquivo (glob) ou uma lista de padr\u00f5es que especificam quais arquivos do <code>workdir</code> da tarefa devem ser salvos como artefatos ap\u00f3s uma execu\u00e7\u00e3o bem-sucedida.</li> <li><code>consumes</code> (string ou tabela): O nome de um artefato (ou uma lista de nomes) de uma tarefa anterior que deve ser copiado para o <code>workdir</code> desta tarefa antes que ela seja executada.</li> </ul>"},{"location":"pt/core-concepts/#gerenciamento-de-artefatos","title":"Gerenciamento de Artefatos","text":"<p>O Sloth-Runner permite que as tarefas compartilhem arquivos entre si atrav\u00e9s de um mecanismo de artefatos. Uma tarefa pode \"produzir\" um ou mais arquivos como artefatos, e tarefas subsequentes podem \"consumir\" esses artefatos.</p> <p>Isso \u00e9 \u00fatil para pipelines de CI/CD, onde uma etapa de compila\u00e7\u00e3o pode gerar um bin\u00e1rio (o artefato), que \u00e9 ent\u00e3o usado por uma etapa de teste ou de implanta\u00e7\u00e3o.</p>"},{"location":"pt/core-concepts/#como-funciona","title":"Como Funciona","text":"<ol> <li> <p>Produzindo Artefatos: Adicione a chave <code>artifacts</code> \u00e0 sua defini\u00e7\u00e3o de tarefa. O valor pode ser um \u00fanico padr\u00e3o de arquivo (ex: <code>\"report.txt\"</code>) ou uma lista (ex: <code>{\"*.log\", \"app.bin\"}</code>). Ap\u00f3s a tarefa ser executada com sucesso, o runner procurar\u00e1 por arquivos no <code>workdir</code> da tarefa que correspondam a esses padr\u00f5es e os copiar\u00e1 para um armazenamento de artefatos compartilhado para a pipeline.</p> </li> <li> <p>Consumindo Artefatos: Adicione a chave <code>consumes</code> \u00e0 defini\u00e7\u00e3o de outra tarefa (que normalmente <code>depends_on</code> da tarefa produtora). O valor deve ser o nome do arquivo do artefato que voc\u00ea deseja usar (ex: <code>\"report.txt\"</code>). Antes que esta tarefa seja executada, o runner copiar\u00e1 o artefato nomeado do armazenamento compartilhado para o <code>workdir</code> desta tarefa, tornando-o dispon\u00edvel para o <code>command</code>.</p> </li> </ol>"},{"location":"pt/core-concepts/#exemplo-de-artefatos","title":"Exemplo de Artefatos","text":"<pre><code>Modern DSLs = {\n  [\"ci-pipeline\"] = {\n    description = \"Demonstra o uso de artefatos.\",\n    create_workdir_before_run = true,\n    tasks = {\n      {\n        name = \"build\",\n        description = \"Cria um bin\u00e1rio e o declara como um artefato.\",\n        command = \"echo 'conteudo_binario' &gt; app.bin\",\n        artifacts = {\"app.bin\"}\n      },\n      {\n        name = \"test\",\n        description = \"Consome o bin\u00e1rio para executar testes.\",\n        depends_on = \"build\",\n        consumes = {\"app.bin\"},\n        command = function(params)\n          -- Neste ponto, 'app.bin' existe no workdir desta tarefa\n          local content, err = fs.read(params.workdir .. \"/app.bin\")\n          if content == \"conteudo_binario\" then\n            log.info(\"Artefato consumido com sucesso!\")\n            return true\n          else\n            return false, \"Conte\u00fado do artefato incorreto!\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"pt/core-concepts/#funcoes-globais","title":"Fun\u00e7\u00f5es Globais","text":"<p>O <code>sloth-runner</code> fornece fun\u00e7\u00f5es globais no ambiente Lua para ajudar a orquestrar os fluxos de trabalho.</p>"},{"location":"pt/core-concepts/#importpath","title":"<code>import(path)</code>","text":"<p>Carrega outro arquivo Lua e retorna o valor que ele retorna. Este \u00e9 o principal mecanismo para criar m\u00f3dulos de tarefas reutiliz\u00e1veis. O caminho \u00e9 relativo ao arquivo que chama <code>import</code>.</p> <p>Exemplo (<code>reusable_tasks.sloth</code>): <pre><code>-- Importa um m\u00f3dulo que retorna uma tabela de defini\u00e7\u00f5es de tarefas\nlocal docker_tasks = import(\"shared/docker.sloth\")\n\nModern DSLs = {\n  main = {\n    tasks = {\n      {\n        -- Usa a tarefa 'build' do m\u00f3dulo importado\n        uses = docker_tasks.build,\n        params = { image_name = \"my-app\" }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"pt/core-concepts/#paralleltasks","title":"<code>parallel(tasks)</code>","text":"<p>Executa uma lista de tarefas concorrentemente e espera que todas terminem.</p> <ul> <li><code>tasks</code> (tabela): Uma lista de tabelas de tarefas para executar em paralelo.</li> </ul> <p>Exemplo: <pre><code>command = function()\n  log.info(\"Iniciando 3 tarefas em paralelo...\")\n  local results, err = parallel({\n    { name = \"short_task\", command = \"sleep 1\" },\n    { name = \"medium_task\", command = \"sleep 2\" },\n    { name = \"long_task\", command = \"sleep 3\" }\n  })\n  if err then\n    return false, \"Execu\u00e7\u00e3o paralela falhou\"\n  end\n  return true, \"Todas as tarefas paralelas terminaram.\"\nend\n</code></pre></p>"},{"location":"pt/core-concepts/#exporttable","title":"<code>export(table)</code>","text":"<p>Exporta dados de qualquer ponto de um script para a CLI. Quando a flag <code>--return</code> \u00e9 usada, todas as tabelas exportadas s\u00e3o mescladas com o output da tarefa final em um \u00fanico objeto JSON.</p> <ul> <li><code>table</code>: Uma tabela Lua a ser exportada.</li> </ul> <p>Exemplo: <pre><code>command = function()\n  export({ valor_importante = \"dado do meio da tarefa\" })\n  return true, \"Tarefa conclu\u00edda\", { output_final = \"algum resultado\" }\nend\n</code></pre> Executar com <code>--return</code> produziria: <pre><code>{\n  \"valor_importante\": \"dado do meio da tarefa\",\n  \"output_final\": \"algum resultado\"\n}\n</code></pre></p>"},{"location":"pt/distributed/","title":"Execu\u00e7\u00e3o de Tarefas Distribu\u00eddas","text":"<p><code>sloth-runner</code> suporta a execu\u00e7\u00e3o de tarefas distribu\u00eddas, permitindo que voc\u00ea execute tarefas em agentes remotos. Isso possibilita fluxos de trabalho escal\u00e1veis e distribu\u00eddos, onde diferentes partes do seu pipeline podem ser executadas em m\u00e1quinas distintas.</p>"},{"location":"pt/distributed/#como-funciona","title":"Como Funciona","text":"<p>O modelo de execu\u00e7\u00e3o distribu\u00edda no <code>sloth-runner</code> segue uma arquitetura mestre-agente:</p> <ol> <li>Mestre: A inst\u00e2ncia principal do <code>sloth-runner</code> atua como o mestre. Ela analisa a defini\u00e7\u00e3o do fluxo de trabalho, identifica as tarefas configuradas para serem executadas em agentes remotos e as despacha.</li> <li>Agente: Uma inst\u00e2ncia do <code>sloth-runner</code> executando no modo <code>agent</code> em uma m\u00e1quina remota. Ela escuta as solicita\u00e7\u00f5es de execu\u00e7\u00e3o de tarefas recebidas do mestre, executa as tarefas e envia os resultados de volta.</li> </ol>"},{"location":"pt/distributed/#configurando-tarefas-remotas","title":"Configurando Tarefas Remotas","text":"<p>Para executar uma tarefa em um agente remoto, voc\u00ea precisa especificar o campo <code>delegate_to</code> no grupo de tarefas ou na defini\u00e7\u00e3o da tarefa individual.</p>"},{"location":"pt/distributed/#1-delegar-a-um-agente-no-nivel-do-grupo-de-tarefas","title":"1. Delegar a um Agente no N\u00edvel do Grupo de Tarefas","text":"<p>Voc\u00ea pode definir o agente diretamente dentro do seu grupo <code>Modern DSLs</code> usando o campo <code>delegate_to</code>. Todas as tarefas dentro deste grupo ser\u00e3o ent\u00e3o delegadas a este agente, a menos que sejam substitu\u00eddas por um <code>delegate_to</code> espec\u00edfico da tarefa.</p> <pre><code>Modern DSLs = {\n  my_distributed_group = {\n    description = \"Um grupo de tarefas com tarefas distribu\u00eddas.\",\n    delegate_to = { address = \"localhost:50051\" }, -- Define o agente para todo o grupo\n    tasks = {\n      {\n        name = \"remote_hello\",\n        description = \"Executa uma tarefa hello world em um agente remoto.\",\n        -- N\u00e3o \u00e9 necess\u00e1rio o campo 'delegate_to' aqui, ele herda do grupo\n        command = function(params)\n          log.info(\"Ol\u00e1 do agente remoto!\")\n          return true, \"Tarefa remota executada.\"\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"pt/distributed/#2-delegar-a-um-agente-no-nivel-da-tarefa","title":"2. Delegar a um Agente no N\u00edvel da Tarefa","text":"<p>Alternativamente, voc\u00ea pode especificar o campo <code>delegate_to</code> diretamente em uma tarefa individual. Isso substituir\u00e1 qualquer delega\u00e7\u00e3o em n\u00edvel de grupo ou permitir\u00e1 a execu\u00e7\u00e3o remota ad-hoc.</p> <pre><code>Modern DSLs = {\n  my_group = {\n    description = \"Um grupo de tarefas com uma tarefa remota espec\u00edfica.\",\n    tasks = {\n      {\n        name = \"specific_remote_task\",\n        description = \"Executa esta tarefa em um agente remoto espec\u00edfico.\",\n        delegate_to = { address = \"192.168.1.100:50051\" }, -- Define o agente apenas para esta tarefa\n        command = function(params)\n          log.info(\"Ol\u00e1 de um agente remoto espec\u00edfico!\")\n          return true, \"Tarefa remota espec\u00edfica executada.\"\n        end\n      },\n      {\n        name = \"local_task\",\n        description = \"Esta tarefa \u00e9 executada localmente.\",\n        command = \"echo 'Ol\u00e1 da m\u00e1quina local!'\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"pt/distributed/#executando-um-agente","title":"Executando um Agente","text":"<p>Para iniciar uma inst\u00e2ncia do <code>sloth-runner</code> no modo agente, use o comando <code>agent</code>:</p> <pre><code>sloth-runner agent -p 50051\n</code></pre> <ul> <li><code>-p, --port</code>: Especifica a porta em que o agente deve escutar. O padr\u00e3o \u00e9 <code>50051</code>.</li> </ul> <p>Quando um agente \u00e9 iniciado, ele escutar\u00e1 as solicita\u00e7\u00f5es gRPC recebidas da inst\u00e2ncia mestre do <code>sloth-runner</code>. Ao receber uma tarefa, ele a executar\u00e1 em seu ambiente local e retornar\u00e1 o resultado, juntamente com quaisquer arquivos de espa\u00e7o de trabalho atualizados, de volta ao mestre.</p>"},{"location":"pt/distributed/#sincronizacao-do-espaco-de-trabalho","title":"Sincroniza\u00e7\u00e3o do Espa\u00e7o de Trabalho","text":"<p>Quando uma tarefa \u00e9 despachada para um agente remoto, o <code>sloth-runner</code> lida automaticamente com a sincroniza\u00e7\u00e3o do espa\u00e7o de trabalho da tarefa:</p> <ol> <li>Mestre para Agente: O mestre cria um tarball do diret\u00f3rio de trabalho atual da tarefa e o envia para o agente.</li> <li>Execu\u00e7\u00e3o do Agente: O agente extrai o tarball para um diret\u00f3rio tempor\u00e1rio, executa a tarefa dentro desse diret\u00f3rio e quaisquer altera\u00e7\u00f5es feitas nos arquivos no diret\u00f3rio tempor\u00e1rio s\u00e3o capturadas.</li> <li>Agente para Mestre: Ap\u00f3s a conclus\u00e3o da tarefa, o agente cria um tarball do diret\u00f3rio tempor\u00e1rio modificado e o envia de volta ao mestre. O mestre ent\u00e3o extrai esse tarball, atualizando seu espa\u00e7o de trabalho local com quaisquer altera\u00e7\u00f5es feitas pela tarefa remota.</li> </ol>"},{"location":"pt/getting-started/","title":"In\u00edcio R\u00e1pido","text":"<p>Bem-vindo ao Sloth-Runner! Este guia o ajudar\u00e1 a come\u00e7ar a usar a ferramenta rapidamente.</p> <p>\ud83d\udcdd Nota Importante: A partir da vers\u00e3o atual, os arquivos de workflow do Sloth Runner usam a extens\u00e3o <code>.sloth</code> em vez de <code>.lua</code>. A sintaxe Lua permanece a mesma - apenas a extens\u00e3o do arquivo mudou para melhor identifica\u00e7\u00e3o dos arquivos DSL do Sloth Runner.</p>"},{"location":"pt/getting-started/#instalacao","title":"Instala\u00e7\u00e3o","text":"<p>Para instalar o <code>sloth-runner</code> em seu sistema, voc\u00ea pode usar o script <code>install.sh</code> fornecido. Este script detecta automaticamente seu sistema operacional e arquitetura, baixa a vers\u00e3o mais recente do GitHub e coloca o execut\u00e1vel <code>sloth-runner</code> em <code>/usr/local/bin</code>.</p> <pre><code>bash &lt;(curl -sL https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/install.sh)\n</code></pre> <p>Nota: O script <code>install.sh</code> requer privil\u00e9gios de <code>sudo</code> para mover o execut\u00e1vel para <code>/usr/local/bin</code>.</p>"},{"location":"pt/getting-started/#uso-basico","title":"Uso B\u00e1sico","text":"<p>Para executar um arquivo de tarefa Lua:</p> <pre><code>sloth-runner run -f examples/basic_pipeline.sloth\n</code></pre> <p>Para listar as tarefas em um arquivo:</p> <pre><code>sloth-runner list -f examples/basic_pipeline.sloth\n</code></pre>"},{"location":"pt/getting-started/#agendador-de-tarefas-novo","title":"Agendador de Tarefas (Novo!)","text":"<p>O Sloth-Runner agora inclui um poderoso agendador de tarefas que permite automatizar a execu\u00e7\u00e3o de seus fluxos de trabalho em segundo plano usando sintaxe cron. Para mais detalhes sobre como configurar e usar o agendador, consulte a documenta\u00e7\u00e3o completa em Agendador de Tarefas.</p>"},{"location":"pt/getting-started/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<p>Agora que voc\u00ea tem o Sloth-Runner instalado e funcionando, explore os Conceitos Essenciais para entender como definir suas tarefas, ou mergulhe diretamente nos novos M\u00f3dulos Built-in para automa\u00e7\u00e3o avan\u00e7ada com Git, Pulumi e Salt.</p> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"pt/repl/","title":"REPL Interativo","text":"<p>O comando <code>sloth-runner repl</code> inicia uma sess\u00e3o interativa de Read-Eval-Print Loop (REPL). Esta \u00e9 uma ferramenta poderosa para depura\u00e7\u00e3o, explora\u00e7\u00e3o e experimenta\u00e7\u00e3o r\u00e1pida com os m\u00f3dulos do sloth-runner.</p>"},{"location":"pt/repl/#iniciando-o-repl","title":"Iniciando o REPL","text":"<p>Para iniciar uma sess\u00e3o, simplesmente execute: <pre><code>sloth-runner repl\n</code></pre></p> <p>Voc\u00ea tamb\u00e9m pode pr\u00e9-carregar um arquivo de workflow para ter suas <code>Modern DSLs</code> e quaisquer fun\u00e7\u00f5es auxiliares dispon\u00edveis na sess\u00e3o. Isso \u00e9 incrivelmente \u00fatil para depurar uma pipeline existente.</p> <pre><code>sloth-runner repl -f /caminho/para/sua/pipeline.sloth\n</code></pre>"},{"location":"pt/repl/#funcionalidades","title":"Funcionalidades","text":""},{"location":"pt/repl/#ambiente-ao-vivo","title":"Ambiente ao Vivo","text":"<p>O REPL fornece um ambiente Lua ao vivo onde voc\u00ea pode executar qualquer c\u00f3digo Lua. Todos os m\u00f3dulos embutidos do sloth-runner (<code>aws</code>, <code>docker</code>, <code>fs</code>, <code>log</code>, etc.) s\u00e3o pr\u00e9-carregados e prontos para uso.</p> <pre><code>sloth&gt; log.info(\"Ol\u00e1 do REPL!\")\nsloth&gt; resultado = fs.read(\"README.md\")\nsloth&gt; print(string.sub(resultado, 1, 50))\n</code></pre>"},{"location":"pt/repl/#autocompletar","title":"Autocompletar","text":"<p>O REPL possui um sistema sofisticado de autocompletar. - Comece a digitar o nome de uma vari\u00e1vel global ou m\u00f3dulo (ex: <code>aws</code>) e pressione <code>Tab</code> para ver as sugest\u00f5es. - Digite o nome de um m\u00f3dulo seguido por um ponto (ex: <code>docker.</code>) e pressione <code>Tab</code> para ver todas as fun\u00e7\u00f5es dispon\u00edveis naquele m\u00f3dulo.</p>"},{"location":"pt/repl/#historico","title":"Hist\u00f3rico","text":"<p>O REPL mant\u00e9m um hist\u00f3rico de seus comandos. Use as setas para cima e para baixo para navegar pelos comandos anteriores.</p>"},{"location":"pt/repl/#exemplo-de-sessao","title":"Exemplo de Sess\u00e3o","text":"<p>Aqui est\u00e1 um exemplo de uso do REPL para depurar um comando Docker.</p> <pre><code>$ sloth-runner repl\nSloth-Runner Interactive REPL\nDigite 'exit' ou 'quit' para sair.\nsloth&gt; resultado = docker.exec({\"ps\", \"-a\"})\nsloth&gt; print(resultado.stdout)\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nsloth&gt; -- Agora vamos tentar construir uma imagem\nsloth&gt; resultado_build = docker.build({tag=\"meu-teste\", path=\"./examples/docker\"})\nsloth&gt; print(resultado_build.success)\ntrue\nsloth&gt; exit\nTchau!\n</code></pre>"},{"location":"pt/scheduler/","title":"Agendador de Tarefas","text":"<p>O <code>sloth-runner</code> agora inclui um agendador de tarefas integrado, permitindo automatizar a execu\u00e7\u00e3o de suas tarefas definidas em Lua em intervalos espec\u00edficos usando a sintaxe cron.</p>"},{"location":"pt/scheduler/#funcionalidades","title":"Funcionalidades","text":"<ul> <li>Processo em Segundo Plano: O agendador \u00e9 executado como um processo persistente em segundo plano, independente da sua sess\u00e3o de terminal.</li> <li>Agendamento Baseado em Cron: Defina agendamentos de tarefas usando strings cron flex\u00edveis.</li> <li>Persist\u00eancia: As tarefas agendadas s\u00e3o carregadas de um arquivo de configura\u00e7\u00e3o, garantindo que sejam retomadas ap\u00f3s rein\u00edcios.</li> <li>Integra\u00e7\u00e3o com Tarefas Existentes: O agendador utiliza o comando <code>sloth-runner run</code> existente para executar suas tarefas.</li> </ul>"},{"location":"pt/scheduler/#configuracao-scheduleryaml","title":"Configura\u00e7\u00e3o: <code>scheduler.yaml</code>","text":"<p>As tarefas agendadas s\u00e3o definidas em um arquivo YAML, tipicamente chamado <code>scheduler.yaml</code>. Este arquivo especifica as tarefas a serem executadas, seu agendamento e o arquivo Lua, grupo e nome da tarefa.</p> <pre><code>scheduled_tasks:\n  - name: \"my_daily_backup\"\n    schedule: \"0 0 * * *\" # Todo dia \u00e0 meia-noite\n    task_file: \"examples/my_workflow.sloth\"\n    task_group: \"backup_group\"\n    task_name: \"perform_backup\"\n  - name: \"hourly_report_generation\"\n    schedule: \"0 * * * *\" # Toda hora\n    task_file: \"examples/reporting.sloth\"\n    task_group: \"reports\"\n    task_name: \"generate_report\"\n</code></pre> <p>Campos:</p> <ul> <li><code>name</code> (string, obrigat\u00f3rio): Um nome \u00fanico para a tarefa agendada.</li> <li><code>schedule</code> (string, obrigat\u00f3rio): A string cron que define quando a tarefa deve ser executada. Suporta a sintaxe cron padr\u00e3o e alguns agendamentos predefinidos (ex: <code>@every 1h</code>, <code>@daily</code>). Consulte a documenta\u00e7\u00e3o do robfig/cron para detalhes.</li> <li><code>task_file</code> (string, obrigat\u00f3rio): O caminho para o arquivo de defini\u00e7\u00e3o da tarefa Lua.</li> <li><code>task_group</code> (string, obrigat\u00f3rio): O nome do grupo de tarefas dentro do arquivo Lua.</li> <li><code>task_name</code> (string, obrigat\u00f3rio): O nome da tarefa espec\u00edfica a ser executada dentro do grupo de tarefas.</li> </ul>"},{"location":"pt/scheduler/#comandos-cli","title":"Comandos CLI","text":""},{"location":"pt/scheduler/#sloth-runner-scheduler-enable","title":"<code>sloth-runner scheduler enable</code>","text":"<p>Inicia o agendador do <code>sloth-runner</code> como um processo em segundo plano. Este comando garante que o agendador esteja em execu\u00e7\u00e3o e pronto para processar tarefas agendadas.</p> <pre><code>sloth-runner scheduler enable --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>--scheduler-config</code> (ou <code>-c</code>): Especifica o caminho para o seu arquivo de configura\u00e7\u00e3o <code>scheduler.yaml</code>. O padr\u00e3o \u00e9 <code>scheduler.yaml</code> no diret\u00f3rio atual.</li> </ul> <p>Ap\u00f3s a execu\u00e7\u00e3o, o comando imprimir\u00e1 o PID do processo do agendador em segundo plano. O agendador continuar\u00e1 a ser executado mesmo que sua sess\u00e3o de terminal seja fechada.</p>"},{"location":"pt/scheduler/#sloth-runner-scheduler-disable","title":"<code>sloth-runner scheduler disable</code>","text":"<p>Para o processo em segundo plano do agendador do <code>sloth-runner</code> em execu\u00e7\u00e3o.</p> <pre><code>sloth-runner scheduler disable\n</code></pre> <p>Este comando tentar\u00e1 encerrar o processo do agendador de forma graciosa. Se bem-sucedido, ele remover\u00e1 o arquivo PID criado pelo comando <code>enable</code>.</p>"},{"location":"pt/scheduler/#sloth-runner-scheduler-list","title":"<code>sloth-runner scheduler list</code>","text":"<p>Lista todas as tarefas agendadas definidas no arquivo de configura\u00e7\u00e3o <code>scheduler.yaml</code>. Este comando fornece uma vis\u00e3o geral de suas tarefas configuradas, seus agendamentos e detalhes da tarefa Lua associada.</p> <pre><code>sloth-runner scheduler list --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>--scheduler-config</code> (ou <code>-c</code>): Especifica o caminho para o seu arquivo de configura\u00e7\u00e3o <code>scheduler.yaml</code>. O padr\u00e3o \u00e9 <code>scheduler.yaml</code> no diret\u00f3rio atual.</li> </ul> <p>Exemplo de Sa\u00edda:</p> <pre><code># Configured Scheduled Tasks\n\nNAME                     | SCHEDULE    | FILE                     | GROUP        | TASK\nmy_daily_backup          | 0 0 * * *   | examples/my_workflow.sloth | backup_group | perform_backup\nhourly_report_generation | 0 * * * *   | examples/reporting.sloth   | reports      | generate_report\n</code></pre>"},{"location":"pt/scheduler/#sloth-runner-scheduler-delete-task_name","title":"<code>sloth-runner scheduler delete &lt;task_name&gt;</code>","text":"<p>Exclui uma tarefa agendada espec\u00edfica do arquivo de configura\u00e7\u00e3o <code>scheduler.yaml</code>. Este comando remove a defini\u00e7\u00e3o da tarefa, e o agendador n\u00e3o a executar\u00e1 mais.</p> <pre><code>sloth-runner scheduler delete my_daily_backup --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>&lt;task_name&gt;</code> (string, obrigat\u00f3rio): O nome \u00fanico da tarefa agendada a ser exclu\u00edda.</li> <li><code>--scheduler-config</code> (ou <code>-c</code>): Especifica o caminho para o seu arquivo de configura\u00e7\u00e3o <code>scheduler.yaml</code>. O padr\u00e3o \u00e9 <code>scheduler.yaml</code> no diret\u00f3rio atual.</li> </ul> <p>Importante: Este comando modifica seu arquivo <code>scheduler.yaml</code>. Certifique-se de ter um backup, se necess\u00e1rio. Se o agendador estiver em execu\u00e7\u00e3o, pode ser necess\u00e1rio desativ\u00e1-lo e reativ\u00e1-lo para que as altera\u00e7\u00f5es entrem em vigor imediatamente.</p>"},{"location":"pt/scheduler/#registro-e-tratamento-de-erros","title":"Registro e Tratamento de Erros","text":"<p>O agendador registra suas atividades e o status de execu\u00e7\u00e3o das tarefas agendadas na sa\u00edda padr\u00e3o e no erro padr\u00e3o. Recomenda-se redirecionar essas sa\u00eddas para um arquivo de log ao executar em um ambiente de produ\u00e7\u00e3o.</p> <p>Se uma tarefa agendada falhar, o agendador registrar\u00e1 o erro e continuar\u00e1 com outras tarefas agendadas. Ele n\u00e3o ser\u00e1 interrompido devido a falhas de tarefas individuais.</p>"},{"location":"pt/scheduler/#exemplo","title":"Exemplo","text":"<ol> <li> <p>Crie um arquivo <code>scheduler.yaml</code>:</p> <pre><code>scheduled_tasks:\n  - name: \"my_test_task\"\n    schedule: \"@every 1m\"\n    task_file: \"examples/basic_pipeline.sloth\"\n    task_group: \"basic_pipeline\"\n    task_name: \"fetch_data\"\n</code></pre> </li> <li> <p>Habilite o agendador:</p> <pre><code>sloth-runner scheduler enable --scheduler-config scheduler.yaml\n</code></pre> </li> <li> <p>Observe a sa\u00edda. A cada minuto, voc\u00ea dever\u00e1 ver mensagens indicando a execu\u00e7\u00e3o de <code>my_test_task</code>.</p> </li> <li> <p>Para parar o agendador:</p> <pre><code>sloth-runner scheduler disable\n</code></pre> </li> </ol>"},{"location":"pt/testing/","title":"Testando Workflows","text":"<p>O sloth-runner inclui um framework de testes embutido que permite escrever testes unit\u00e1rios e de integra\u00e7\u00e3o para seus workflows de tarefas. Escrever testes para sua automa\u00e7\u00e3o \u00e9 crucial para garantir a confiabilidade, prevenir regress\u00f5es e ter confian\u00e7a ao fazer altera\u00e7\u00f5es.</p>"},{"location":"pt/testing/#o-comando-test","title":"O Comando <code>test</code>","text":"<p>Voc\u00ea pode executar um arquivo de teste usando o comando <code>sloth-runner test</code>. Ele requer dois arquivos principais: o workflow que voc\u00ea quer testar e o pr\u00f3prio script de teste.</p> <pre><code>sloth-runner test -w &lt;caminho_para_workflow.sloth&gt; -f &lt;caminho_para_arquivo_de_teste.sloth&gt;\n</code></pre> <ul> <li><code>-w, --workflow</code>: Especifica o caminho para o arquivo principal de <code>Modern DSLs</code> que voc\u00ea quer testar.</li> <li><code>-f, --file</code>: Especifica o caminho para o seu arquivo de teste.</li> </ul>"},{"location":"pt/testing/#escrevendo-testes","title":"Escrevendo Testes","text":"<p>Os testes s\u00e3o escritos em Lua e usam dois novos m\u00f3dulos globais fornecidos pelo executor de testes: <code>test</code> e <code>assert</code>.</p>"},{"location":"pt/testing/#o-modulo-test","title":"O M\u00f3dulo <code>test</code>","text":"<p>O m\u00f3dulo <code>test</code> \u00e9 usado para estruturar seus testes e para executar tarefas espec\u00edficas do seu workflow.</p> <ul> <li><code>test.describe(suite_name, function)</code>: Agrupa testes relacionados em uma \"su\u00edte\". Serve para organiza\u00e7\u00e3o.</li> <li><code>test.it(function)</code>: Define um caso de teste individual. A descri\u00e7\u00e3o do teste deve ser inclu\u00edda nas mensagens de asser\u00e7\u00e3o dentro desta fun\u00e7\u00e3o.</li> <li><code>test.run_task(task_name)</code>: Esta \u00e9 a fun\u00e7\u00e3o principal do framework de testes. Ela executa uma \u00fanica tarefa pelo seu nome a partir do arquivo de workflow carregado. Ela retorna uma tabela de <code>result</code> contendo os detalhes da execu\u00e7\u00e3o.</li> </ul> <p>A tabela <code>result</code> retornada por <code>run_task</code> tem a seguinte estrutura:</p> <pre><code>{\n  success = true, -- booleano: true se a tarefa foi bem-sucedida, false caso contr\u00e1rio\n  message = \"Tarefa executada com sucesso\", -- string: A mensagem retornada pela tarefa\n  duration = \"1.23ms\", -- string: A dura\u00e7\u00e3o da execu\u00e7\u00e3o\n  output = { ... }, -- tabela: A tabela de output retornada pela tarefa\n  error = nil -- string: A mensagem de erro se a tarefa falhou\n}\n</code></pre>"},{"location":"pt/testing/#o-modulo-assert","title":"O M\u00f3dulo <code>assert</code>","text":"<p>O m\u00f3dulo <code>assert</code> fornece fun\u00e7\u00f5es para verificar os resultados das execu\u00e7\u00f5es de suas tarefas.</p> <ul> <li><code>assert.is_true(value, message)</code>: Verifica se o <code>value</code> \u00e9 verdadeiro.</li> <li><code>assert.equals(actual, expected, message)</code>: Verifica se o valor <code>actual</code> \u00e9 igual ao valor <code>expected</code>.</li> </ul>"},{"location":"pt/testing/#mocking-de-modulos","title":"Mocking de M\u00f3dulos","text":"<p>Para testar a l\u00f3gica de suas pipelines sem fazer chamadas externas reais (ex: para AWS, Docker ou Terraform), o framework de testes inclui um poderoso recurso de mocking.</p>"},{"location":"pt/testing/#politica-de-mocking-estrito","title":"Pol\u00edtica de Mocking Estrito","text":"<p>O executor de testes imp\u00f5e uma pol\u00edtica de mocking estrito. Ao rodar em modo de teste, qualquer chamada a uma fun\u00e7\u00e3o de m\u00f3dulo (como <code>aws.exec</code> ou <code>docker.build</code>) que n\u00e3o tenha sido explicitamente mockada far\u00e1 com que o teste falhe imediatamente. Isso garante que seus testes sejam totalmente autocontidos, determin\u00edsticos e n\u00e3o tenham efeitos colaterais indesejados.</p>"},{"location":"pt/testing/#testmockfunction_name-mock_definition","title":"<code>test.mock(function_name, mock_definition)</code>","text":"<p>Esta fun\u00e7\u00e3o permite que voc\u00ea defina um valor de retorno falso para qualquer fun\u00e7\u00e3o de m\u00f3dulo que possa ser mockada.</p> <ul> <li><code>function_name</code> (string): O nome completo da fun\u00e7\u00e3o a ser mockada (ex: <code>\"aws.s3.sync\"</code>, <code>\"docker.build\"</code>).</li> <li><code>mock_definition</code> (tabela): Uma tabela que define o que a fun\u00e7\u00e3o mockada deve retornar. Ela deve conter uma chave <code>returns</code>, que \u00e9 uma lista dos valores que a fun\u00e7\u00e3o retornar\u00e1.</li> </ul> <p>A lista <code>returns</code> \u00e9 crucial porque fun\u00e7\u00f5es Lua podem retornar m\u00faltiplos valores.</p> <p>Exemplo:</p> <pre><code>-- Mock de uma fun\u00e7\u00e3o que retorna uma \u00fanica tabela de resultado\ntest.mock(\"docker.build\", {\n  returns = {\n    { success = true, stdout = \"Imagem constru\u00edda com sucesso\" }\n  }\n})\n\n-- Mock de uma fun\u00e7\u00e3o que retorna dois valores (ex: um valor e um erro)\n-- Isto simula uma chamada bem-sucedida a terraform.output\ntest.mock(\"terraform.output\", {\n  returns = { \"meu_arquivo.txt\", nil }\n})\n\n-- Isto simula uma chamada com falha\ntest.mock(\"terraform.output\", {\n  returns = { nil, \"output n\u00e3o encontrado\" }\n})\n</code></pre>"},{"location":"pt/testing/#exemplo-completo-de-mocking","title":"Exemplo Completo de Mocking","text":"<p>Digamos que voc\u00ea tenha uma tarefa que chama <code>aws.exec</code> e possui uma l\u00f3gica que depende do resultado.</p> <p>Tarefa em <code>meu_workflow.sloth</code>: <pre><code>-- ...\n{\n  name = \"verificar-conta\",\n  command = function()\n    local result = aws.exec({\"sts\", \"get-caller-identity\"})\n    local data = data.parse_json(result.stdout)\n    if data.Account == \"123456789012\" then\n      return true, \"Conta correta.\"\n    else\n      return false, \"Conta errada.\"\n    end\n  end\n}\n-- ...\n</code></pre></p> <p>Teste em <code>meu_teste.sloth</code>: <pre><code>test.describe(\"L\u00f3gica de Verifica\u00e7\u00e3o de Conta\", function()\n  test.it(function()\n    -- Mock do valor de retorno de aws.exec\n    test.mock(\"aws.exec\", {\n      returns = {\n        {\n          success = true,\n          stdout = '{\"Account\": \"123456789012\"}'\n        }\n      }\n    })\n\n    -- Executa a tarefa que usa o mock\n    local result = test.run_task(\"verificar-conta\")\n\n    -- Afirma que a l\u00f3gica da tarefa funcionou corretamente com os dados mockados\n    assert.is_true(result.success, \"A tarefa deve ser bem-sucedida com o ID de conta correto\")\n    assert.equals(result.message, \"Conta correta.\", \"A mensagem deve ser correta\")\n  end)\nend)\n</code></pre></p>"},{"location":"pt/modules/aws/","title":"M\u00f3dulo AWS","text":"<p>O m\u00f3dulo <code>aws</code> fornece uma interface abrangente para interagir com a Amazon Web Services usando o AWS CLI. Ele foi projetado para funcionar perfeitamente com as cadeias de credenciais padr\u00e3o da AWS e tamb\u00e9m possui suporte de primeira classe para o <code>aws-vault</code> para maior seguran\u00e7a.</p>"},{"location":"pt/modules/aws/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Nenhuma configura\u00e7\u00e3o espec\u00edfica no <code>values.yaml</code> \u00e9 necess\u00e1ria. O m\u00f3dulo depende de seu ambiente estar configurado para interagir com a AWS. Isso pode ser alcan\u00e7ado atrav\u00e9s de: - Perfis IAM para inst\u00e2ncias EC2 ou tarefas ECS/EKS. - Vari\u00e1veis de ambiente padr\u00e3o (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, etc.). - Um arquivo <code>~/.aws/credentials</code> configurado. - Usando o <code>aws-vault</code> com um perfil nomeado.</p>"},{"location":"pt/modules/aws/#executor-generico","title":"Executor Gen\u00e9rico","text":""},{"location":"pt/modules/aws/#awsexecargs-opts","title":"<code>aws.exec(args, opts)</code>","text":"<p>Esta \u00e9 a fun\u00e7\u00e3o principal do m\u00f3dulo. Ela executa qualquer comando do AWS CLI e retorna o resultado.</p> <p>Par\u00e2metros:</p> <ul> <li><code>args</code> (tabela): Obrigat\u00f3rio. Uma tabela de strings representando o comando e os argumentos a serem passados para o AWS CLI (ex: <code>{\"s3\", \"ls\", \"--recursive\"}</code>).</li> <li><code>opts</code> (tabela): Opcional. Uma tabela de op\u00e7\u00f5es para a execu\u00e7\u00e3o.<ul> <li><code>profile</code> (string): Se fornecido, o comando ser\u00e1 executado usando <code>aws-vault exec &lt;profile&gt; -- aws ...</code>. Se omitido, ele executar\u00e1 <code>aws ...</code> diretamente.</li> </ul> </li> </ul> <p>Retornos:</p> <p>Uma tabela contendo os seguintes campos: - <code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando. - <code>stderr</code> (string): O erro padr\u00e3o do comando. - <code>exit_code</code> (n\u00famero): O c\u00f3digo de sa\u00edda do comando. <code>0</code> normalmente indica sucesso.</p> <p>Exemplo:</p> <pre><code>-- Usando credenciais padr\u00e3o\nlocal result = aws.exec({\"sts\", \"get-caller-identity\"})\nif result.exit_code == 0 then\n  print(result.stdout)\nend\n\n-- Usando um perfil do aws-vault\nlocal result_with_profile = aws.exec({\"ec2\", \"describe-instances\"}, {profile = \"meu-perfil-prod\"})\n</code></pre>"},{"location":"pt/modules/aws/#ajudantes-do-s3","title":"Ajudantes do S3","text":""},{"location":"pt/modules/aws/#awss3syncparams","title":"<code>aws.s3.sync(params)</code>","text":"<p>Um wrapper de alto n\u00edvel para o comando <code>aws s3 sync</code>, \u00fatil para sincronizar diret\u00f3rios com o S3.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Uma tabela contendo os seguintes campos:<ul> <li><code>source</code> (string): Obrigat\u00f3rio. O diret\u00f3rio de origem ou caminho S3.</li> <li><code>destination</code> (string): Obrigat\u00f3rio. O diret\u00f3rio de destino ou caminho S3.</li> <li><code>profile</code> (string): Opcional. O perfil do <code>aws-vault</code> a ser usado.</li> <li><code>delete</code> (boolean): Opcional. Se <code>true</code>, adiciona a flag <code>--delete</code> ao comando de sincroniza\u00e7\u00e3o.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>true</code> em caso de sucesso.</li> <li><code>false, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local ok, err = aws.s3.sync({\n  source = \"./build\",\n  destination = \"s3://meu-bucket-app/static\",\n  profile = \"perfil-deploy\",\n  delete = true\n})\nif not ok then\n  log.error(\"Falha na sincroniza\u00e7\u00e3o com o S3: \" .. err)\nend\n</code></pre>"},{"location":"pt/modules/aws/#ajudantes-do-secrets-manager","title":"Ajudantes do Secrets Manager","text":""},{"location":"pt/modules/aws/#awssecretsmanagerget_secretparams","title":"<code>aws.secretsmanager.get_secret(params)</code>","text":"<p>Recupera o valor de um segredo do AWS Secrets Manager. Esta fun\u00e7\u00e3o simplifica o processo, retornando diretamente a <code>SecretString</code>.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Uma tabela contendo os seguintes campos:<ul> <li><code>secret_id</code> (string): Obrigat\u00f3rio. O nome ou ARN do segredo a ser recuperado.</li> <li><code>profile</code> (string): Opcional. O perfil do <code>aws-vault</code> a ser usado.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>secret_string</code> (string) em caso de sucesso.</li> <li><code>nil, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local db_password, err = aws.secretsmanager.get_secret({\n  secret_id = \"producao/database/password\",\n  profile = \"meu-perfil-app\"\n})\n\nif not db_password then\n  log.error(\"Falha ao obter o segredo: \" .. err)\n  return false, \"Configura\u00e7\u00e3o falhou.\"\nend\n\n-- Agora voc\u00ea pode usar a vari\u00e1vel db_password\n</code></pre>"},{"location":"pt/modules/azure/","title":"M\u00f3dulo Azure","text":"<p>O m\u00f3dulo <code>azure</code> fornece uma interface para interagir com o Microsoft Azure usando a ferramenta de linha de comando <code>az</code>.</p>"},{"location":"pt/modules/azure/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Este m\u00f3dulo requer que o CLI <code>az</code> esteja instalado e autenticado. Antes de executar pipelines que usam este m\u00f3dulo, voc\u00ea deve fazer login em sua conta do Azure:</p> <pre><code>az login\n</code></pre> <p>O m\u00f3dulo usar\u00e1 suas credenciais de login para todos os comandos.</p>"},{"location":"pt/modules/azure/#executor-generico","title":"Executor Gen\u00e9rico","text":""},{"location":"pt/modules/azure/#azureexecargs","title":"<code>azure.exec(args)</code>","text":"<p>Executa qualquer comando <code>az</code>. Esta fun\u00e7\u00e3o adiciona automaticamente a flag <code>--output json</code> (se ainda n\u00e3o estiver presente) para garantir que a sa\u00edda seja analis\u00e1vel por m\u00e1quina.</p> <p>Par\u00e2metros:</p> <ul> <li><code>args</code> (tabela): Obrigat\u00f3rio. Uma tabela de strings representando o comando e os argumentos a serem passados para o <code>az</code> (ex: <code>{\"group\", \"list\", \"--location\", \"eastus\"}</code>).</li> </ul> <p>Retornos:</p> <p>Uma tabela contendo os seguintes campos: - <code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando (como uma string JSON). - <code>stderr</code> (string): O erro padr\u00e3o do comando. - <code>exit_code</code> (n\u00famero): O c\u00f3digo de sa\u00edda do comando. <code>0</code> normalmente indica sucesso.</p> <p>Exemplo:</p> <pre><code>local result = azure.exec({\"account\", \"show\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"Logado como: \" .. account_info.user.name)\n  end\nend\n</code></pre>"},{"location":"pt/modules/azure/#ajudantes-de-grupo-de-recursos-rg","title":"Ajudantes de Grupo de Recursos (RG)","text":""},{"location":"pt/modules/azure/#azurergdeleteparams","title":"<code>azure.rg.delete(params)</code>","text":"<p>Exclui um grupo de recursos.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Uma tabela contendo os seguintes campos:<ul> <li><code>name</code> (string): Obrigat\u00f3rio. O nome do grupo de recursos a ser exclu\u00eddo.</li> <li><code>yes</code> (boolean): Opcional. Se <code>true</code>, adiciona a flag <code>--yes</code> para ignorar a solicita\u00e7\u00e3o de confirma\u00e7\u00e3o.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>true</code> em caso de sucesso.</li> <li><code>false, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local ok, err = azure.rg.delete({\n  name = \"meu-rg-de-teste\",\n  yes = true\n})\nif not ok then\n  log.error(\"Falha ao excluir o grupo de recursos: \" .. err)\nend\n</code></pre>"},{"location":"pt/modules/azure/#ajudantes-de-maquina-virtual-vm","title":"Ajudantes de M\u00e1quina Virtual (VM)","text":""},{"location":"pt/modules/azure/#azurevmlistparams","title":"<code>azure.vm.list(params)</code>","text":"<p>Lista m\u00e1quinas virtuais.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Opcional. Uma tabela contendo os seguintes campos:<ul> <li><code>resource_group</code> (string): O nome de um grupo de recursos para limitar a lista. Se omitido, lista as VMs em toda a assinatura.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>vms</code> (tabela) em caso de sucesso, onde a tabela \u00e9 um array JSON analisado de seus objetos VM.</li> <li><code>nil, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>-- Lista todas as VMs na assinatura\nlocal all_vms, err1 = azure.vm.list()\n\n-- Lista VMs em um grupo de recursos espec\u00edfico\nlocal specific_vms, err2 = azure.vm.list({resource_group = \"meu-rg-de-producao\"})\nif specific_vms then\n  for _, vm in ipairs(specific_vms) do\n    print(\"VM encontrada: \" .. vm.name)\n  end\nend\n</code></pre>"},{"location":"pt/modules/data/","title":"M\u00f3dulo Data","text":"<p>O m\u00f3dulo <code>data</code> fornece fun\u00e7\u00f5es para analisar (parse) e serializar dados entre tabelas Lua e formatos de dados comuns como JSON e YAML.</p> <p>---\\n</p>"},{"location":"pt/modules/data/#dataparse_jsonjson_string","title":"<code>data.parse_json(json_string)</code>","text":"<p>Analisa uma string JSON e a converte em uma tabela Lua.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>json_string</code> (string): A string formatada em JSON para analisar.</li> </ul> </li> <li>Retorna:<ul> <li><code>tabela</code>: A tabela Lua resultante.</li> <li><code>error</code>: Um objeto de erro se a an\u00e1lise falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/data/#datato_jsonlua_table","title":"<code>data.to_json(lua_table)</code>","text":"<p>Serializa uma tabela Lua em uma string JSON.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>lua_table</code> (tabela): A tabela Lua a ser serializada.</li> </ul> </li> <li>Retorna:<ul> <li><code>string</code>: A string JSON resultante.</li> <li><code>error</code>: Um objeto de erro se a serializa\u00e7\u00e3o falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/data/#dataparse_yamlyaml_string","title":"<code>data.parse_yaml(yaml_string)</code>","text":"<p>Analisa uma string YAML e a converte em uma tabela Lua.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>yaml_string</code> (string): A string formatada em YAML para analisar.</li> </ul> </li> <li>Retorna:<ul> <li><code>tabela</code>: A tabela Lua resultante.</li> <li><code>error</code>: Um objeto de erro se a an\u00e1lise falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/data/#datato_yamllua_table","title":"<code>data.to_yaml(lua_table)</code>","text":"<p>Serializa uma tabela Lua em uma string YAML.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>lua_table</code> (tabela): A tabela Lua a ser serializada.</li> </ul> </li> <li>Retorna:<ul> <li><code>string</code>: A string YAML resultante.</li> <li><code>error</code>: Um objeto de erro se a serializa\u00e7\u00e3o falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/data/#exemplo","title":"Exemplo","text":"<pre><code>command = function()\n  local data = require(\"data\")\n\n  -- Exemplo JSON\n  log.info(\"Testando serializa\u00e7\u00e3o JSON...\")\n  local minha_tabela = { name = \"sloth-runner\", version = 1.0, features = { \"tasks\", \"lua\" } }\n  local json_str, err = data.to_json(minha_tabela)\n  if err then\n    return false, \"Falha ao serializar para JSON: \" .. err\n  end\n  print(\"JSON Serializado: \" .. json_str)\n\n  log.info(\"Testando an\u00e1lise de JSON...\")\n  local tabela_parseada, err = data.parse_json(json_str)\n  if err then\n    return false, \"Falha ao analisar JSON: \" .. err\n  end\n  log.info(\"Nome extra\u00eddo do JSON: \" .. tabela_parseada.name)\n\n  -- Exemplo YAML\n  log.info(\"Testando serializa\u00e7\u00e3o YAML...\")\n  local yaml_str, err = data.to_yaml(minha_tabela)\n  if err then\n    return false, \"Falha ao serializar para YAML: \" .. err\n  end\n  print(\"YAML Serializado:\\n\" .. yaml_str)\n\n  log.info(\"Testando an\u00e1lise de YAML...\")\n  tabela_parseada, err = data.parse_yaml(yaml_str)\n  if err then\n    return false, \"Falha ao analisar YAML: \" .. err\n  end\n  log.info(\"Vers\u00e3o extra\u00edda do YAML: \" .. tabela_parseada.version)\n\n  return true, \"Opera\u00e7\u00f5es do m\u00f3dulo Data bem-sucedidas.\"\nend\n</code></pre> <p>```</p>"},{"location":"pt/modules/digitalocean/","title":"M\u00f3dulo DigitalOcean","text":"<p>O m\u00f3dulo <code>digitalocean</code> fornece uma interface para interagir com seus recursos da DigitalOcean usando a ferramenta de linha de comando <code>doctl</code>.</p>"},{"location":"pt/modules/digitalocean/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Este m\u00f3dulo requer que o CLI <code>doctl</code> esteja instalado e autenticado. A maneira padr\u00e3o de fazer isso \u00e9 gerar um token de acesso pessoal em seu painel de controle da DigitalOcean e defini-lo como a vari\u00e1vel de ambiente <code>DIGITALOCEAN_ACCESS_TOKEN</code>.</p> <pre><code>export DIGITALOCEAN_ACCESS_TOKEN=\"seu_token_de_api_da_do_aqui\"\n</code></pre> <p>O m\u00f3dulo usar\u00e1 automaticamente este token para todos os comandos.</p>"},{"location":"pt/modules/digitalocean/#executor-generico","title":"Executor Gen\u00e9rico","text":""},{"location":"pt/modules/digitalocean/#digitaloceanexecargs","title":"<code>digitalocean.exec(args)</code>","text":"<p>Executa qualquer comando <code>doctl</code>. Esta fun\u00e7\u00e3o adiciona automaticamente a flag <code>--output json</code> para garantir que a sa\u00edda seja analis\u00e1vel por m\u00e1quina.</p> <p>Par\u00e2metros:</p> <ul> <li><code>args</code> (tabela): Obrigat\u00f3rio. Uma tabela de strings representando o comando e os argumentos a serem passados para o <code>doctl</code> (ex: <code>{\"compute\", \"droplet\", \"list\"}</code>).</li> </ul> <p>Retornos:</p> <p>Uma tabela contendo os seguintes campos: - <code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando (como uma string JSON). - <code>stderr</code> (string): O erro padr\u00e3o do comando. - <code>exit_code</code> (n\u00famero): O c\u00f3digo de sa\u00edda do comando. <code>0</code> normalmente indica sucesso.</p> <p>Exemplo:</p> <pre><code>local result = digitalocean.exec({\"account\", \"get\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"Status da conta: \" .. account_info.status)\n  end\nend\n</code></pre>"},{"location":"pt/modules/digitalocean/#ajudantes-de-droplets","title":"Ajudantes de Droplets","text":""},{"location":"pt/modules/digitalocean/#digitaloceandropletslist","title":"<code>digitalocean.droplets.list()</code>","text":"<p>Um wrapper de alto n\u00edvel para listar todos os Droplets em sua conta.</p> <p>Retornos:</p> <ul> <li><code>droplets</code> (tabela) em caso de sucesso, onde a tabela \u00e9 um array JSON analisado de seus objetos Droplet.</li> <li><code>nil, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local droplets, err = digitalocean.droplets.list()\nif droplets then\n  for _, droplet in ipairs(droplets) do\n    print(\"Droplet encontrado: \" .. droplet.name)\n  end\nend\n</code></pre>"},{"location":"pt/modules/digitalocean/#digitaloceandropletsdeleteparams","title":"<code>digitalocean.droplets.delete(params)</code>","text":"<p>Exclui um Droplet espec\u00edfico pelo seu ID.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Uma tabela contendo os seguintes campos:<ul> <li><code>id</code> (string): Obrigat\u00f3rio. O ID do Droplet a ser exclu\u00eddo.</li> <li><code>force</code> (boolean): Opcional. Se <code>true</code>, adiciona a flag <code>--force</code> para ignorar a solicita\u00e7\u00e3o de confirma\u00e7\u00e3o. O padr\u00e3o \u00e9 <code>false</code>.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>true</code> em caso de sucesso.</li> <li><code>false, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local ok, err = digitalocean.droplets.delete({\n  id = \"123456789\",\n  force = true\n})\nif not ok then\n  log.error(\"Falha ao excluir o droplet: \" .. err)\nend\n</code></pre>"},{"location":"pt/modules/docker/","title":"M\u00f3dulo Docker","text":"<p>O m\u00f3dulo <code>docker</code> fornece uma interface conveniente para interagir com o daemon do Docker, permitindo que voc\u00ea construa, execute e envie imagens Docker como parte de suas pipelines.</p>"},{"location":"pt/modules/docker/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Este m\u00f3dulo requer que a CLI <code>docker</code> esteja instalada e que o daemon do Docker esteja em execu\u00e7\u00e3o e acess\u00edvel.</p>"},{"location":"pt/modules/docker/#funcoes","title":"Fun\u00e7\u00f5es","text":""},{"location":"pt/modules/docker/#dockerexecargs","title":"<code>docker.exec(args)</code>","text":"<p>Executa qualquer comando <code>docker</code> bruto.</p> <ul> <li><code>args</code> (tabela): Obrigat\u00f3rio. Uma lista de argumentos a serem passados para o comando <code>docker</code> (ex: <code>{\"ps\", \"-a\"}</code>).</li> <li>Retorna: Uma tabela de resultados com <code>success</code>, <code>stdout</code>, <code>stderr</code> e <code>exit_code</code>.</li> </ul>"},{"location":"pt/modules/docker/#dockerbuildparams","title":"<code>docker.build(params)</code>","text":"<p>Constr\u00f3i uma imagem Docker usando <code>docker build</code>.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>tag</code> (string): Obrigat\u00f3rio. A tag para a imagem (ex: <code>meu-app:latest</code>).</li> <li><code>path</code> (string): Obrigat\u00f3rio. O caminho do contexto de constru\u00e7\u00e3o.</li> <li><code>dockerfile</code> (string): Opcional. O caminho para o Dockerfile.</li> <li><code>build_args</code> (tabela): Opcional. Uma tabela de argumentos de constru\u00e7\u00e3o (ex: <code>{VERSION = \"1.0\"}</code>).</li> </ul> </li> <li>Retorna: Uma tabela de resultados.</li> </ul>"},{"location":"pt/modules/docker/#dockerpushparams","title":"<code>docker.push(params)</code>","text":"<p>Envia uma imagem Docker para um registro usando <code>docker push</code>.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>tag</code> (string): Obrigat\u00f3rio. A tag da imagem a ser enviada.</li> </ul> </li> <li>Retorna: Uma tabela de resultados.</li> </ul>"},{"location":"pt/modules/docker/#dockerrunparams","title":"<code>docker.run(params)</code>","text":"<p>Executa um cont\u00eainer Docker usando <code>docker run</code>.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>image</code> (string): Obrigat\u00f3rio. A imagem a ser executada.</li> <li><code>name</code> (string): Opcional. O nome para o cont\u00eainer.</li> <li><code>detach</code> (booleano): Opcional. Se <code>true</code>, executa o cont\u00eainer em segundo plano (<code>-d</code>).</li> <li><code>ports</code> (tabela): Opcional. Uma lista de mapeamentos de portas (ex: <code>{\"8080:80\"}</code>).</li> <li><code>env</code> (tabela): Opcional. Uma tabela de vari\u00e1veis de ambiente (ex: <code>{MINHA_VAR = \"valor\"}</code>).</li> </ul> </li> <li>Retorna: Uma tabela de resultados.</li> </ul>"},{"location":"pt/modules/docker/#exemplo","title":"Exemplo","text":"<pre><code>local image_tag = \"minha-imagem-teste:latest\"\n\n-- Tarefa 1: Build\nlocal result_build = docker.build({\n  tag = image_tag,\n  path = \"./app\"\n})\nif not result_build.success then return false, \"Build falhou\" end\n\n-- Tarefa 2: Run\nlocal result_run = docker.run({\n  image = image_tag,\n  name = \"meu-container-teste\",\n  ports = {\"8080:80\"}\n})\nif not result_run.success then return false, \"Run falhou\" end\n\n-- Tarefa 3: Push (ap\u00f3s teste bem-sucedido)\nlocal result_push = docker.push({tag = image_tag})\nif not result_push.success then return false, \"Push falhou\" end\n</code></pre>"},{"location":"pt/modules/exec/","title":"M\u00f3dulo Exec","text":"<p>O m\u00f3dulo <code>exec</code> \u00e9 um dos m\u00f3dulos mais fundamentais do <code>sloth-runner</code>. Ele fornece uma fun\u00e7\u00e3o poderosa para executar comandos de shell arbitr\u00e1rios, dando a voc\u00ea controle total sobre o ambiente de execu\u00e7\u00e3o.</p>"},{"location":"pt/modules/exec/#execruncommand-options","title":"<code>exec.run(command, [options])</code>","text":"<p>Executa um comando de shell usando <code>bash -c</code>.</p>"},{"location":"pt/modules/exec/#parametros","title":"Par\u00e2metros","text":"<ul> <li><code>command</code> (string): O comando de shell a ser executado.</li> <li><code>options</code> (tabela, opcional): Uma tabela de op\u00e7\u00f5es para controlar a execu\u00e7\u00e3o.<ul> <li><code>workdir</code> (string): O diret\u00f3rio de trabalho onde o comando deve ser executado. Se n\u00e3o for fornecido, ele \u00e9 executado no diret\u00f3rio tempor\u00e1rio do grupo de tarefas (se dispon\u00edvel) ou no diret\u00f3rio atual.</li> <li><code>env</code> (tabela): Um dicion\u00e1rio de vari\u00e1veis de ambiente (pares chave-valor) a serem definidas para a execu\u00e7\u00e3o do comando. Elas s\u00e3o adicionadas ao ambiente existente.</li> </ul> </li> </ul>"},{"location":"pt/modules/exec/#retorna","title":"Retorna","text":"<p>Uma tabela contendo o resultado da execu\u00e7\u00e3o do comando:</p> <ul> <li><code>success</code> (booleano): <code>true</code> se o comando saiu com o c\u00f3digo <code>0</code>, caso contr\u00e1rio <code>false</code>.</li> <li><code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando.</li> <li><code>stderr</code> (string): A sa\u00edda de erro padr\u00e3o do comando.</li> </ul>"},{"location":"pt/modules/exec/#exemplo","title":"Exemplo","text":"<p>Este exemplo demonstra como usar <code>exec.run</code> com um diret\u00f3rio de trabalho e vari\u00e1veis de ambiente personalizados.</p> <pre><code>-- examples/exec_module_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"Uma tarefa para demonstrar o m\u00f3dulo exec.\",\n    tasks = {\n      {\n        name = \"run-with-options\",\n        description = \"Executa um comando com um workdir e ambiente personalizados.\",\n        command = function()\n          log.info(\"Preparando para executar um comando personalizado...\")\n\n          local exec = require(\"exec\")\n\n          -- Cria um diret\u00f3rio tempor\u00e1rio para o exemplo\n          local temp_dir = \"/tmp/sloth-exec-test\"\n          fs.mkdir(temp_dir)\n          fs.write(temp_dir .. \"/test.txt\", \"ol\u00e1 do arquivo de teste\")\n\n          -- Define as op\u00e7\u00f5es\n          local options = {\n            workdir = temp_dir,\n            env = {\n              MINHA_VAR = \"SlothRunner\",\n              OUTRA_VAR = \"e_incrivel\"\n            }\n          }\n\n          -- Executa o comando\n          local result = exec.run(\"echo 'MINHA_VAR \u00e9 $MINHA_VAR' &amp;&amp; ls -l &amp;&amp; cat test.txt\", options)\n\n          -- Limpa o diret\u00f3rio tempor\u00e1rio\n          fs.rm_r(temp_dir)\n\n          if result.success then\n            log.info(\"Comando executado com sucesso!\")\n            print(\"--- STDOUT ---\")\n            print(result.stdout)\n            print(\"--------------\")\n            return true, \"Comando exec bem-sucedido.\"\n          else\n            log.error(\"Comando exec falhou.\")\n            log.error(\"Stderr: \" .. result.stderr)\n            return false, \"Comando exec falhou.\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"pt/modules/fs/","title":"M\u00f3dulo FS","text":"<p>O m\u00f3dulo <code>fs</code> fornece fun\u00e7\u00f5es essenciais para interagir com o sistema de arquivos diretamente de seus scripts Lua.</p> <p>---\\n</p>"},{"location":"pt/modules/fs/#fsreadpath","title":"<code>fs.read(path)</code>","text":"<p>L\u00ea todo o conte\u00fado de um arquivo.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho para o arquivo.</li> </ul> </li> <li>Retorna:<ul> <li><code>string</code>: O conte\u00fado do arquivo.</li> <li><code>error</code>: Um objeto de erro se a leitura falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fswritepath-content","title":"<code>fs.write(path, content)</code>","text":"<p>Escreve conte\u00fado em um arquivo, sobrescrevendo-o se ele j\u00e1 existir.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho para o arquivo.</li> <li><code>content</code> (string): O conte\u00fado a ser escrito.</li> </ul> </li> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se a escrita falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fsappendpath-content","title":"<code>fs.append(path, content)</code>","text":"<p>Adiciona conte\u00fado ao final de um arquivo. Cria o arquivo se ele n\u00e3o existir.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho para o arquivo.</li> <li><code>content</code> (string): O conte\u00fado a ser adicionado.</li> </ul> </li> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se a opera\u00e7\u00e3o falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fsexistspath","title":"<code>fs.exists(path)</code>","text":"<p>Verifica se um arquivo ou diret\u00f3rio existe no caminho fornecido.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho a ser verificado.</li> </ul> </li> <li>Retorna:<ul> <li><code>boolean</code>: <code>true</code> se o caminho existir, <code>false</code> caso contr\u00e1rio.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fsmkdirpath","title":"<code>fs.mkdir(path)</code>","text":"<p>Cria um diret\u00f3rio no caminho fornecido, incluindo quaisquer diret\u00f3rios pais necess\u00e1rios (como <code>mkdir -p</code>).</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho do diret\u00f3rio a ser criado.</li> </ul> </li> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se a cria\u00e7\u00e3o falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fsrmpath","title":"<code>fs.rm(path)</code>","text":"<p>Remove um \u00fanico arquivo.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho para o arquivo a ser removido.</li> </ul> </li> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se a remo\u00e7\u00e3o falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fsrm_rpath","title":"<code>fs.rm_r(path)</code>","text":"<p>Remove um arquivo ou diret\u00f3rio recursivamente (como <code>rm -rf</code>).</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho a ser removido.</li> </ul> </li> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se a remo\u00e7\u00e3o falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fslspath","title":"<code>fs.ls(path)</code>","text":"<p>Lista o conte\u00fado de um diret\u00f3rio.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho para o diret\u00f3rio.</li> </ul> </li> <li>Retorna:<ul> <li><code>tabela</code>: Uma tabela contendo os nomes dos arquivos e subdiret\u00f3rios.</li> <li><code>error</code>: Um objeto de erro se a listagem falhar.</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"pt/modules/fs/#fstmpname","title":"<code>fs.tmpname()</code>","text":"<p>Gera um caminho de diret\u00f3rio tempor\u00e1rio \u00fanico. Nota: Esta fun\u00e7\u00e3o apenas retorna o nome; ela n\u00e3o cria o diret\u00f3rio.</p> <ul> <li>Retorna:<ul> <li><code>string</code>: Um caminho \u00fanico adequado para um diret\u00f3rio tempor\u00e1rio.</li> <li><code>error</code>: Um objeto de erro se um nome n\u00e3o puder ser gerado.</li> </ul> </li> </ul>"},{"location":"pt/modules/fs/#exemplo","title":"Exemplo","text":"<pre><code>command = function()\n  local fs = require(\"fs\")\n\n  local tmp_dir = \"/tmp/fs-example\"\n  log.info(\"Criando diret\u00f3rio: \" .. tmp_dir)\n  fs.mkdir(tmp_dir)\n\n  local file_path = tmp_dir .. \"/meu_arquivo.txt\"\n  log.info(\"Escrevendo no arquivo: \" .. file_path)\n  fs.write(file_path, \"Ol\u00e1, Sloth Runner!\\n\")\n\n  log.info(\"Adicionando ao arquivo...\")\n  fs.append(file_path, \"Esta \u00e9 uma nova linha.\")\n\n  if fs.exists(file_path) then\n    log.info(\"Conte\u00fado do arquivo: \" .. fs.read(file_path))\n  end\n\n  log.info(\"Listando conte\u00fado de \" .. tmp_dir)\n  local contents = fs.ls(tmp_dir)\n  for i, name in ipairs(contents) do\n    print(\"- \" .. name)\n  end\n\n  log.info(\"Limpando...\")\n  fs.rm_r(tmp_dir)\n\n  return true, \"Opera\u00e7\u00f5es do m\u00f3dulo FS bem-sucedidas.\"\nend\n</code></pre> <p>```</p>"},{"location":"pt/modules/gcp/","title":"M\u00f3dulo GCP","text":"<p>O m\u00f3dulo <code>gcp</code> fornece uma interface simples para executar comandos da CLI do Google Cloud (<code>gcloud</code>) de dentro de uma tarefa do <code>sloth-runner</code>.</p>"},{"location":"pt/modules/gcp/#gcpexecargs","title":"<code>gcp.exec(args)</code>","text":"<p>Executa um comando <code>gcloud</code> com os argumentos especificados.</p>"},{"location":"pt/modules/gcp/#parametros","title":"Par\u00e2metros","text":"<ul> <li><code>args</code> (tabela): Uma tabela Lua (array) de strings representando os argumentos a serem passados para o comando <code>gcloud</code>. Por exemplo, <code>{\"compute\", \"instances\", \"list\"}</code>.</li> </ul>"},{"location":"pt/modules/gcp/#retorna","title":"Retorna","text":"<p>Uma tabela contendo o resultado da execu\u00e7\u00e3o do comando com as seguintes chaves:</p> <ul> <li><code>stdout</code> (string): A sa\u00edda padr\u00e3o do comando.</li> <li><code>stderr</code> (string): A sa\u00edda de erro padr\u00e3o do comando.</li> <li><code>exit_code</code> (n\u00famero): O c\u00f3digo de sa\u00edda do comando. Um c\u00f3digo de sa\u00edda <code>0</code> geralmente indica sucesso.</li> </ul>"},{"location":"pt/modules/gcp/#exemplo","title":"Exemplo","text":"<p>Este exemplo define uma tarefa que lista todas as inst\u00e2ncias do Compute Engine na regi\u00e3o <code>us-central1</code> para um projeto espec\u00edfico.</p> <pre><code>-- examples/gcp_cli_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"Uma tarefa para listar inst\u00e2ncias de computa\u00e7\u00e3o do GCP.\",\n    tasks = {\n      {\n        name = \"list-instances\",\n        description = \"Lista inst\u00e2ncias do GCE em us-central1.\",\n        command = function()\n          log.info(\"Listando inst\u00e2ncias do GCP...\")\n\n          -- Requer o m\u00f3dulo gcp para torn\u00e1-lo dispon\u00edvel\n          local gcp = require(\"gcp\")\n\n          -- Executa o comando gcloud\n          local result = gcp.exec({\n            \"compute\", \n            \"instances\", \n            \"list\", \n            \"--project\", \"meu-projeto-gcp-id\",\n            \"--zones\", \"us-central1-a,us-central1-b\"\n          })\n\n          -- Verifica o resultado\n          if result and result.exit_code == 0 then\n            log.info(\"Inst\u00e2ncias listadas com sucesso.\")\n            print(\"--- LISTA DE INST\u00c2NCIAS ---\")\n            print(result.stdout)\n            print(\"-------------------------\")\n            return true, \"Comando GCP bem-sucedido.\"\n          else\n            log.error(\"Falha ao listar inst\u00e2ncias do GCP.\")\n            if result then\n              log.error(\"Stderr: \" .. result.stderr)\n            end\n            return false, \"Comando GCP falhou.\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"pt/modules/git/","title":"M\u00f3dulo Git","text":"<p>O m\u00f3dulo <code>git</code> fornece uma API fluente para interagir com reposit\u00f3rios Git, permitindo que voc\u00ea automatize opera\u00e7\u00f5es comuns de controle de vers\u00e3o como clonar, commitar e enviar (push).</p>"},{"location":"pt/modules/git/#gitcloneurl-path","title":"<code>git.clone(url, path)</code>","text":"<p>Clona um reposit\u00f3rio Git para um caminho local.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>url</code> (string): A URL do reposit\u00f3rio a ser clonado.</li> <li><code>path</code> (string): O diret\u00f3rio local para onde clonar.</li> </ul> </li> <li>Retorna:<ul> <li><code>repo</code> (objeto): Um objeto <code>GitRepo</code> em caso de sucesso.</li> <li><code>error</code>: Um objeto de erro se a clonagem falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/git/#gitrepopath","title":"<code>git.repo(path)</code>","text":"<p>Abre um reposit\u00f3rio Git local existente.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho para o reposit\u00f3rio local existente.</li> </ul> </li> <li>Retorna:<ul> <li><code>repo</code> (objeto): Um objeto <code>GitRepo</code> em caso de sucesso.</li> <li><code>error</code>: Um objeto de erro se o caminho n\u00e3o for um reposit\u00f3rio Git v\u00e1lido.</li> </ul> </li> </ul>"},{"location":"pt/modules/git/#o-objeto-gitrepo","title":"O Objeto <code>GitRepo</code>","text":"<p>Este objeto representa um reposit\u00f3rio local e fornece m\u00e9todos encade\u00e1veis para realizar opera\u00e7\u00f5es Git.</p>"},{"location":"pt/modules/git/#repocheckoutref","title":"<code>repo:checkout(ref)</code>","text":"<p>Faz checkout de um branch, tag ou commit espec\u00edfico.</p> <ul> <li>Par\u00e2metros: <code>ref</code> (string).</li> </ul>"},{"location":"pt/modules/git/#repopullremote-branch","title":"<code>repo:pull(remote, branch)</code>","text":"<p>Puxa (pull) as altera\u00e7\u00f5es de um reposit\u00f3rio remoto.</p> <ul> <li>Par\u00e2metros: <code>remote</code> (string), <code>branch</code> (string).</li> </ul>"},{"location":"pt/modules/git/#repoaddpattern","title":"<code>repo:add(pattern)</code>","text":"<p>Adiciona arquivos \u00e0 \u00e1rea de prepara\u00e7\u00e3o (staging) para um commit.</p> <ul> <li>Par\u00e2metros: <code>pattern</code> (string), ex: <code>\".\"</code> ou <code>\"caminho/para/arquivo.txt\"</code>.</li> </ul>"},{"location":"pt/modules/git/#repocommitmessage","title":"<code>repo:commit(message)</code>","text":"<p>Cria um commit.</p> <ul> <li>Par\u00e2metros: <code>message</code> (string).</li> </ul>"},{"location":"pt/modules/git/#repotagname-message","title":"<code>repo:tag(name, [message])</code>","text":"<p>Cria uma nova tag.</p> <ul> <li>Par\u00e2metros: <code>name</code> (string), <code>message</code> (string, opcional).</li> </ul>"},{"location":"pt/modules/git/#repopushremote-branch-options","title":"<code>repo:push(remote, branch, [options])</code>","text":"<p>Envia (push) commits para um reposit\u00f3rio remoto.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>remote</code> (string).</li> <li><code>branch</code> (string).</li> <li><code>options</code> (tabela, opcional): ex: <code>{ follow_tags = true }</code>.</li> </ul> </li> </ul>"},{"location":"pt/modules/git/#reporesult","title":"<code>repo:result()</code>","text":"<p>Este m\u00e9todo \u00e9 chamado no final de uma cadeia para obter o resultado da \u00faltima opera\u00e7\u00e3o.</p> <ul> <li>Retorna:<ul> <li><code>result</code> (tabela): Uma tabela contendo <code>success</code> (booleano), <code>stdout</code> (string) e <code>stderr</code> (string).</li> </ul> </li> </ul>"},{"location":"pt/modules/git/#exemplo","title":"Exemplo","text":"<p>Este exemplo demonstra um fluxo de trabalho completo semelhante a CI/CD: clonar, criar um arquivo de vers\u00e3o, adicionar, commitar, criar uma tag e enviar (push).</p> <pre><code>command = function()\n  local git = require(\"git\")\n  local repo_path = \"/tmp/git-example-repo\"\n\n  -- Limpa execu\u00e7\u00f5es anteriores\n  fs.rm_r(repo_path)\n\n  -- 1. Clona o reposit\u00f3rio\n  log.info(\"Clonando reposit\u00f3rio...\")\n  local repo, err = git.clone(\"https://github.com/chalkan3-sloth/sloth-runner.git\", repo_path)\n  if err then\n    return false, \"Falha ao clonar: \" .. err\n  end\n\n  -- 2. Cria e escreve um arquivo de vers\u00e3o\n  fs.write(repo_path .. \"/VERSION\", \"1.2.3\")\n\n  -- 3. Encadear comandos Git: add -&gt; commit -&gt; tag -&gt; push\n  log.info(\"Adicionando, commitando, criando tag e enviando...\")\n  repo:add(\".\"):commit(\"ci: Bump version to 1.2.3\"):tag(\"v1.2.3\"):push(\"origin\", \"main\", { follow_tags = true })\n\n  -- 4. Obt\u00e9m o resultado da opera\u00e7\u00e3o final (push)\n  local result = repo:result()\n\n  if not result.success then\n    log.error(\"O push do Git falhou: \" .. result.stderr)\n    return false, \"O push do Git falhou.\"\n  end\n\n  log.info(\"Tag da nova vers\u00e3o enviada com sucesso.\")\n  return true, \"Opera\u00e7\u00f5es Git bem-sucedidas.\"\nend\n</code></pre>"},{"location":"pt/modules/log/","title":"M\u00f3dulo Log","text":"<p>O m\u00f3dulo <code>log</code> fornece uma interface simples e essencial para registrar mensagens de seus scripts Lua no console do <code>sloth-runner</code>. Usar este m\u00f3dulo \u00e9 a maneira padr\u00e3o de fornecer feedback e informa\u00e7\u00f5es de depura\u00e7\u00e3o durante a execu\u00e7\u00e3o de uma tarefa.</p>"},{"location":"pt/modules/log/#loginfomessage","title":"<code>log.info(message)</code>","text":"<p>Registra uma mensagem no n\u00edvel INFO. Este \u00e9 o n\u00edvel padr\u00e3o para mensagens gerais e informativas.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>message</code> (string): A mensagem a ser registrada.</li> </ul> </li> </ul>"},{"location":"pt/modules/log/#logwarnmessage","title":"<code>log.warn(message)</code>","text":"<p>Registra uma mensagem no n\u00edvel WARN. \u00c9 adequado para problemas n\u00e3o cr\u00edticos que devem ser levados \u00e0 aten\u00e7\u00e3o do usu\u00e1rio.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>message</code> (string): A mensagem a ser registrada.</li> </ul> </li> </ul>"},{"location":"pt/modules/log/#logerrormessage","title":"<code>log.error(message)</code>","text":"<p>Registra uma mensagem no n\u00edvel ERROR. Deve ser usado para erros significativos que podem fazer com que uma tarefa falhe.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>message</code> (string): A mensagem a ser registrada.</li> </ul> </li> </ul>"},{"location":"pt/modules/log/#logdebugmessage","title":"<code>log.debug(message)</code>","text":"<p>Registra uma mensagem no n\u00edvel DEBUG. Essas mensagens geralmente ficam ocultas, a menos que o runner esteja em modo detalhado ou de depura\u00e7\u00e3o. S\u00e3o \u00fateis para informa\u00e7\u00f5es de diagn\u00f3stico detalhadas.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>message</code> (string): A mensagem a ser registrada.</li> </ul> </li> </ul>"},{"location":"pt/modules/log/#exemplo","title":"Exemplo","text":"<pre><code>command = function()\n  -- O m\u00f3dulo log est\u00e1 dispon\u00edvel globalmente e n\u00e3o precisa ser requerido.\n\n  log.info(\"Iniciando a tarefa de exemplo de log.\")\n\n  local user_name = \"Sloth\"\n  log.debug(\"O usu\u00e1rio atual \u00e9: \" .. user_name)\n\n  if user_name ~= \"Sloth\" then\n    log.warn(\"O usu\u00e1rio n\u00e3o \u00e9 o esperado.\")\n  end\n\n  log.info(\"A tarefa est\u00e1 executando sua a\u00e7\u00e3o principal...\")\n\n  local success = true -- Simula uma opera\u00e7\u00e3o bem-sucedida\n  if not success then\n    log.error(\"A a\u00e7\u00e3o principal falhou inesperadamente!\")\n    return false, \"A\u00e7\u00e3o principal falhou\"\n  end\n\n  log.info(\"Tarefa de exemplo de log conclu\u00edda com sucesso.\")\n  return true, \"Log demonstrado.\"\nend\n</code></pre>"},{"location":"pt/modules/metrics/","title":"\ud83d\udcca M\u00f3dulo de M\u00e9tricas e Monitoramento","text":"<p>O m\u00f3dulo M\u00e9tricas e Monitoramento fornece capacidades abrangentes de monitoramento do sistema, coleta de m\u00e9tricas customizadas e verifica\u00e7\u00e3o de sa\u00fade. Ele habilita observabilidade em tempo real tanto dos recursos do sistema quanto da performance da aplica\u00e7\u00e3o.</p>"},{"location":"pt/modules/metrics/#recursos-principais","title":"\ud83d\ude80 Recursos Principais","text":"<ul> <li>M\u00e9tricas do Sistema: Coleta autom\u00e1tica de m\u00e9tricas de CPU, mem\u00f3ria, disco e rede</li> <li>M\u00e9tricas de Runtime: Informa\u00e7\u00f5es do runtime Go (goroutines, heap, GC)</li> <li>M\u00e9tricas Customizadas: Gauges, contadores, histogramas e timers</li> <li>Verifica\u00e7\u00f5es de Sa\u00fade: Monitoramento autom\u00e1tico da sa\u00fade do sistema</li> <li>Endpoints HTTP: Export de m\u00e9tricas compat\u00edvel com Prometheus</li> <li>Sistema de Alertas: Alertas baseados em thresholds</li> <li>API JSON: Dados completos de m\u00e9tricas para integra\u00e7\u00f5es</li> </ul>"},{"location":"pt/modules/metrics/#metricas-do-sistema","title":"\ud83d\udcca M\u00e9tricas do Sistema","text":""},{"location":"pt/modules/metrics/#monitoramento-de-cpu-memoria-e-disco","title":"Monitoramento de CPU, Mem\u00f3ria e Disco","text":"<pre><code>-- Obter uso atual de CPU\nlocal uso_cpu = metrics.system_cpu()\nlog.info(\"Uso de CPU: \" .. string.format(\"%.1f%%\", uso_cpu))\n\n-- Obter informa\u00e7\u00f5es de mem\u00f3ria\nlocal info_memoria = metrics.system_memory()\nlog.info(\"Mem\u00f3ria: \" .. string.format(\"%.1f%% (%.0f/%.0f MB)\", \n    info_memoria.percent, info_memoria.used_mb, info_memoria.total_mb))\n\n-- Obter uso de disco\nlocal info_disco = metrics.system_disk(\"/\")\nlog.info(\"Disco: \" .. string.format(\"%.1f%% (%.1f/%.1f GB)\", \n    info_disco.percent, info_disco.used_gb, info_disco.total_gb))\n\n-- Verificar caminho espec\u00edfico do disco\nlocal disco_var = metrics.system_disk(\"/var\")\nlog.info(\"Uso do disco /var: \" .. string.format(\"%.1f%%\", disco_var.percent))\n</code></pre>"},{"location":"pt/modules/metrics/#informacoes-de-runtime","title":"Informa\u00e7\u00f5es de Runtime","text":"<pre><code>-- Obter m\u00e9tricas do runtime Go\nlocal runtime = metrics.runtime_info()\nlog.info(\"Informa\u00e7\u00f5es de Runtime:\")\nlog.info(\"  Goroutines: \" .. runtime.goroutines)\nlog.info(\"  N\u00facleos de CPU: \" .. runtime.num_cpu)\nlog.info(\"  Heap alocado: \" .. string.format(\"%.1f MB\", runtime.heap_alloc_mb))\nlog.info(\"  Heap do sistema: \" .. string.format(\"%.1f MB\", runtime.heap_sys_mb))\nlog.info(\"  Ciclos de GC: \" .. runtime.num_gc)\nlog.info(\"  Vers\u00e3o do Go: \" .. runtime.go_version)\n</code></pre>"},{"location":"pt/modules/metrics/#metricas-customizadas","title":"\ud83d\udcc8 M\u00e9tricas Customizadas","text":""},{"location":"pt/modules/metrics/#metricas-gauge-valores-atuais","title":"M\u00e9tricas Gauge (Valores Atuais)","text":"<pre><code>-- Definir valores simples de gauge\nmetrics.gauge(\"temperatura_cpu\", 65.4)\nmetrics.gauge(\"conexoes_ativas\", 142)\nmetrics.gauge(\"tamanho_fila\", 23)\n\n-- Definir gauge com tags\nmetrics.gauge(\"uso_memoria\", percentual_memoria, {\n    servidor = \"web-01\",\n    ambiente = \"producao\",\n    regiao = \"us-east-1\"\n})\n\n-- Atualizar status de deployment\nmetrics.gauge(\"progresso_deployment\", 75.5, {\n    app = \"frontend\",\n    versao = \"v2.1.0\"\n})\n</code></pre>"},{"location":"pt/modules/metrics/#metricas-counter-valores-incrementais","title":"M\u00e9tricas Counter (Valores Incrementais)","text":"<pre><code>-- Incrementar contadores\nlocal total_requisicoes = metrics.counter(\"requisicoes_http_total\", 1)\nlocal contador_erros = metrics.counter(\"erros_http_total\", 1, {\n    codigo_status = \"500\",\n    endpoint = \"/api/usuarios\"\n})\n\n-- Incremento em lote\nlocal processados = metrics.counter(\"mensagens_processadas\", 50, {\n    fila = \"notificacoes_usuario\",\n    prioridade = \"alta\"\n})\n\nlog.info(\"Total de requisi\u00e7\u00f5es processadas: \" .. total_requisicoes)\n</code></pre>"},{"location":"pt/modules/metrics/#metricas-histogram-distribuicao-de-valores","title":"M\u00e9tricas Histogram (Distribui\u00e7\u00e3o de Valores)","text":"<pre><code>-- Registrar tempos de resposta\nmetrics.histogram(\"tempo_resposta_ms\", 245.6, {\n    endpoint = \"/api/usuarios\",\n    metodo = \"GET\"\n})\n\n-- Registrar tamanhos de payload\nmetrics.histogram(\"tamanho_payload_bytes\", 1024, {\n    tipo_conteudo = \"application/json\"\n})\n\n-- Registrar tamanhos de lote\nmetrics.histogram(\"tamanho_lote\", 150, {\n    operacao = \"insercao_lote\",\n    tabela = \"eventos_usuario\"\n})\n</code></pre>"},{"location":"pt/modules/metrics/#metricas-timer-tempo-de-execucao-de-funcoes","title":"M\u00e9tricas Timer (Tempo de Execu\u00e7\u00e3o de Fun\u00e7\u00f5es)","text":"<pre><code>-- Cronometrar execu\u00e7\u00e3o de fun\u00e7\u00e3o automaticamente\nlocal duracao = metrics.timer(\"consulta_banco\", function()\n    -- Simular consulta ao banco\n    local resultado = exec.run(\"sleep 0.1\")\n    return resultado\nend, {\n    tipo_consulta = \"select\",\n    tabela = \"usuarios\"\n})\n\nlog.info(\"Consulta ao banco levou: \" .. string.format(\"%.2f ms\", duracao))\n\n-- Cronometrar opera\u00e7\u00f5es complexas\nlocal tempo_processamento = metrics.timer(\"processamento_dados\", function()\n    -- Processar dataset grande\n    local dados = {}\n    for i = 1, 100000 do\n        dados[i] = math.sqrt(i) * 2.5\n    end\n    return #dados\nend, {\n    operacao = \"computacao_matematica\",\n    tamanho = \"grande\"\n})\n\nlog.info(\"Processamento de dados conclu\u00eddo em: \" .. string.format(\"%.2f ms\", tempo_processamento))\n</code></pre>"},{"location":"pt/modules/metrics/#monitoramento-de-saude","title":"\ud83c\udfe5 Monitoramento de Sa\u00fade","text":""},{"location":"pt/modules/metrics/#status-de-saude-automatico","title":"Status de Sa\u00fade Autom\u00e1tico","text":"<pre><code>-- Obter status abrangente de sa\u00fade\nlocal saude = metrics.health_status()\nlog.info(\"Status Geral de Sa\u00fade: \" .. saude.overall)\n\n-- Verificar componentes individuais\nlocal componentes = {\"cpu\", \"memory\", \"disk\"}\nfor _, componente in ipairs(componentes) do\n    local info_comp = saude[componente]\n    if info_comp then\n        local icone_status = \"\u2705\"\n        if info_comp.status == \"warning\" then\n            icone_status = \"\u26a0\ufe0f\"\n        elseif info_comp.status == \"critical\" then\n            icone_status = \"\u274c\"\n        end\n\n        log.info(string.format(\"  %s %s: %.1f%% (%s)\", \n            icone_status, componente:upper(), info_comp.usage, info_comp.status))\n    end\nend\n</code></pre>"},{"location":"pt/modules/metrics/#verificacoes-de-saude-customizadas","title":"Verifica\u00e7\u00f5es de Sa\u00fade Customizadas","text":"<pre><code>-- Criar fun\u00e7\u00e3o de verifica\u00e7\u00e3o de sa\u00fade\nfunction verificar_saude_aplicacao()\n    local pontuacao_saude = 100\n    local problemas = {}\n\n    -- Verificar conectividade do banco\n    local resultado_bd = exec.run(\"pg_isready -h localhost -p 5432\")\n    if resultado_bd ~= \"\" then\n        pontuacao_saude = pontuacao_saude - 20\n        table.insert(problemas, \"Falha na conex\u00e3o com o banco de dados\")\n    end\n\n    -- Verificar espa\u00e7o em disco\n    local disco = metrics.system_disk(\"/\")\n    if disco.percent &gt; 90 then\n        pontuacao_saude = pontuacao_saude - 30\n        table.insert(problemas, \"Espa\u00e7o em disco cr\u00edtico: \" .. string.format(\"%.1f%%\", disco.percent))\n    end\n\n    -- Verificar uso de mem\u00f3ria\n    local memoria = metrics.system_memory()\n    if memoria.percent &gt; 85 then\n        pontuacao_saude = pontuacao_saude - 25\n        table.insert(problemas, \"Uso de mem\u00f3ria alto: \" .. string.format(\"%.1f%%\", memoria.percent))\n    end\n\n    -- Registrar pontua\u00e7\u00e3o de sa\u00fade\n    metrics.gauge(\"pontuacao_saude_aplicacao\", pontuacao_saude)\n\n    if pontuacao_saude &lt; 70 then\n        metrics.alert(\"saude_aplicacao\", {\n            level = \"warning\",\n            message = \"Sa\u00fade da aplica\u00e7\u00e3o degradada: \" .. table.concat(problemas, \", \"),\n            pontuacao = pontuacao_saude\n        })\n    end\n\n    return pontuacao_saude &gt;= 70\nend\n\n-- Usar em tasks\nModern DSLs = {\n    monitoramento_saude = {\n        tasks = {\n            verificacao_saude = {\n                command = function()\n                    local saudavel = verificar_saude_aplicacao()\n                    return saudavel, saudavel and \"Sistema saud\u00e1vel\" or \"Problemas de sa\u00fade detectados\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"pt/modules/metrics/#sistema-de-alertas","title":"\ud83d\udea8 Sistema de Alertas","text":""},{"location":"pt/modules/metrics/#criando-alertas","title":"Criando Alertas","text":"<pre><code>-- Alerta simples por threshold\nlocal cpu = metrics.system_cpu()\nif cpu &gt; 80 then\n    metrics.alert(\"uso_alto_cpu\", {\n        level = \"warning\",\n        message = \"Uso de CPU est\u00e1 alto: \" .. string.format(\"%.1f%%\", cpu),\n        threshold = 80,\n        value = cpu,\n        severidade = \"media\"\n    })\nend\n\n-- Alerta complexo com m\u00faltiplas condi\u00e7\u00f5es\nlocal memoria = metrics.system_memory()\nlocal disco = metrics.system_disk()\n\nif memoria.percent &gt; 90 and disco.percent &gt; 85 then\n    metrics.alert(\"esgotamento_recursos\", {\n        level = \"critical\",\n        message = string.format(\"Uso cr\u00edtico de recursos - Mem\u00f3ria: %.1f%%, Disco: %.1f%%\", \n            memoria.percent, disco.percent),\n        uso_memoria = memoria.percent,\n        uso_disco = disco.percent,\n        acao_recomendada = \"Escalar recursos imediatamente\"\n    })\nend\n\n-- Alertas espec\u00edficos da aplica\u00e7\u00e3o\nlocal tamanho_fila = state.get(\"tamanho_fila_tarefas\", 0)\nif tamanho_fila &gt; 1000 then\n    metrics.alert(\"acumulo_fila\", {\n        level = \"warning\", \n        message = \"Ac\u00famulo detectado na fila de tarefas: \" .. tamanho_fila .. \" itens\",\n        tamanho_fila = tamanho_fila,\n        tempo_processamento_estimado = tamanho_fila * 2 .. \" segundos\"\n    })\nend\n</code></pre>"},{"location":"pt/modules/metrics/#gerenciamento-de-metricas","title":"\ud83d\udd0d Gerenciamento de M\u00e9tricas","text":""},{"location":"pt/modules/metrics/#recuperando-metricas-customizadas","title":"Recuperando M\u00e9tricas Customizadas","text":"<pre><code>-- Obter m\u00e9trica customizada espec\u00edfica\nlocal metrica_cpu = metrics.get_custom(\"temperatura_cpu\")\nif metrica_cpu then\n    log.info(\"M\u00e9trica de temperatura da CPU: \" .. data.to_json(metrica_cpu))\nend\n\n-- Listar todas as m\u00e9tricas customizadas\nlocal todas_metricas = metrics.list_custom()\nlog.info(\"Total de m\u00e9tricas customizadas: \" .. #todas_metricas)\nfor i, nome_metrica in ipairs(todas_metricas) do\n    log.info(\"  \" .. i .. \". \" .. nome_metrica)\nend\n</code></pre>"},{"location":"pt/modules/metrics/#exemplo-de-monitoramento-de-performance","title":"Exemplo de Monitoramento de Performance","text":"<pre><code>Modern DSLs = {\n    monitoramento_performance = {\n        tasks = {\n            monitorar_performance_api = {\n                command = function()\n                    -- Iniciar sess\u00e3o de monitoramento\n                    log.info(\"Iniciando monitoramento de performance da API...\")\n\n                    -- Simular chamadas de API e medir performance\n                    for i = 1, 10 do\n                        local tempo_api = metrics.timer(\"chamada_api_\" .. i, function()\n                            -- Simular chamada de API\n                            exec.run(\"curl -s -o /dev/null -w '%{time_total}' https://api.exemplo.com/health\")\n                        end, {\n                            endpoint = \"health\",\n                            numero_chamada = tostring(i)\n                        })\n\n                        -- Registrar tempo de resposta\n                        metrics.histogram(\"tempo_resposta_api\", tempo_api, {\n                            endpoint = \"health\"\n                        })\n\n                        -- Verificar se o tempo de resposta \u00e9 aceit\u00e1vel\n                        if tempo_api &gt; 1000 then -- 1 segundo\n                            metrics.counter(\"chamadas_api_lentas\", 1, {\n                                endpoint = \"health\"\n                            })\n\n                            metrics.alert(\"resposta_api_lenta\", {\n                                level = \"warning\",\n                                message = string.format(\"Resposta lenta da API: %.2f ms\", tempo_api),\n                                tempo_resposta = tempo_api,\n                                threshold = 1000\n                            })\n                        end\n\n                        -- Breve atraso entre chamadas\n                        exec.run(\"sleep 0.1\")\n                    end\n\n                    -- Obter estat\u00edsticas resumidas\n                    local saude_sistema = metrics.health_status()\n                    log.info(\"Sa\u00fade do sistema ap\u00f3s testes da API: \" .. saude_sistema.overall)\n\n                    return true, \"Monitoramento de performance da API conclu\u00eddo\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"pt/modules/metrics/#endpoints-http","title":"\ud83c\udf10 Endpoints HTTP","text":"<p>O m\u00f3dulo de m\u00e9tricas exp\u00f5e automaticamente endpoints HTTP para sistemas de monitoramento externos:</p>"},{"location":"pt/modules/metrics/#formato-prometheus-metrics","title":"Formato Prometheus (<code>/metrics</code>)","text":"<pre><code># Acessar m\u00e9tricas compat\u00edveis com Prometheus\ncurl http://agente:8080/metrics\n\n# Exemplo de sa\u00edda:\n# sloth_agent_cpu_usage_percent 15.4\n# sloth_agent_memory_usage_mb 2048.5\n# sloth_agent_disk_usage_percent 67.2\n# sloth_agent_tasks_total 142\n</code></pre>"},{"location":"pt/modules/metrics/#formato-json-metricsjson","title":"Formato JSON (<code>/metrics/json</code>)","text":"<pre><code># Obter m\u00e9tricas completas em formato JSON\ncurl http://agente:8080/metrics/json\n\n# Exemplo de resposta:\n{\n  \"agent_name\": \"meuagente1\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"system\": {\n    \"cpu_usage_percent\": 15.4,\n    \"memory_usage_mb\": 2048.5,\n    \"disk_usage_percent\": 67.2\n  },\n  \"runtime\": {\n    \"num_goroutines\": 25,\n    \"heap_alloc_mb\": 45.2\n  },\n  \"custom\": {\n    \"tempo_resposta_api\": {...},\n    \"progresso_deployment\": 85.5\n  }\n}\n</code></pre>"},{"location":"pt/modules/metrics/#verificacao-de-saude-health","title":"Verifica\u00e7\u00e3o de Sa\u00fade (<code>/health</code>)","text":"<pre><code># Verificar status de sa\u00fade do agente\ncurl http://agente:8080/health\n\n# Exemplo de resposta:\n{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"checks\": {\n    \"cpu\": {\"usage\": 15.4, \"status\": \"healthy\"},\n    \"memory\": {\"usage\": 45.8, \"status\": \"healthy\"},\n    \"disk\": {\"usage\": 67.2, \"status\": \"healthy\"}\n  }\n}\n</code></pre>"},{"location":"pt/modules/metrics/#referencia-da-api","title":"\ud83d\udccb Refer\u00eancia da API","text":""},{"location":"pt/modules/metrics/#metricas-do-sistema_1","title":"M\u00e9tricas do Sistema","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>metrics.system_cpu()</code> - uso: number Obter percentual atual de uso de CPU <code>metrics.system_memory()</code> - info: table Obter informa\u00e7\u00f5es de uso de mem\u00f3ria <code>metrics.system_disk(caminho?)</code> caminho?: string info: table Obter uso de disco para caminho (padr\u00e3o: \"/\") <code>metrics.runtime_info()</code> - info: table Obter informa\u00e7\u00f5es do runtime Go"},{"location":"pt/modules/metrics/#metricas-customizadas_1","title":"M\u00e9tricas Customizadas","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>metrics.gauge(nome, valor, tags?)</code> nome: string, valor: number, tags?: table sucesso: boolean Definir m\u00e9trica gauge <code>metrics.counter(nome, incremento?, tags?)</code> nome: string, incremento?: number, tags?: table novo_valor: number Incrementar contador <code>metrics.histogram(nome, valor, tags?)</code> nome: string, valor: number, tags?: table sucesso: boolean Registrar valor de histograma <code>metrics.timer(nome, funcao, tags?)</code> nome: string, funcao: function, tags?: table duracao: number Cronometrar execu\u00e7\u00e3o de fun\u00e7\u00e3o"},{"location":"pt/modules/metrics/#saude-e-monitoramento","title":"Sa\u00fade e Monitoramento","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>metrics.health_status()</code> - status: table Obter status abrangente de sa\u00fade <code>metrics.alert(nome, dados)</code> nome: string, dados: table sucesso: boolean Criar alerta"},{"location":"pt/modules/metrics/#utilitarios","title":"Utilit\u00e1rios","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>metrics.get_custom(nome)</code> nome: string metrica: table | nil Obter m\u00e9trica customizada por nome <code>metrics.list_custom()</code> - nomes: table Listar todos os nomes de m\u00e9tricas customizadas"},{"location":"pt/modules/metrics/#melhores-praticas","title":"\ud83c\udfaf Melhores Pr\u00e1ticas","text":"<ol> <li>Use tipos apropriados de m\u00e9tricas - gauges para valores atuais, contadores para totais, histogramas para distribui\u00e7\u00f5es</li> <li>Adicione tags significativas para categorizar e filtrar m\u00e9tricas</li> <li>Defina thresholds razo\u00e1veis para alertas para evitar fadiga de alertas</li> <li>Monitore o impacto na performance da coleta extensiva de m\u00e9tricas</li> <li>Use timers para opera\u00e7\u00f5es cr\u00edticas para identificar gargalos</li> <li>Implemente health checks para todos os componentes cr\u00edticos do sistema</li> <li>Exporte m\u00e9tricas para sistemas externos como Prometheus para armazenamento de longo prazo</li> </ol> <p>O m\u00f3dulo M\u00e9tricas e Monitoramento fornece observabilidade abrangente para seu ambiente distribu\u00eddo sloth-runner! \ud83d\udcca\ud83d\ude80</p>"},{"location":"pt/modules/net/","title":"M\u00f3dulo Net","text":"<p>O m\u00f3dulo <code>net</code> fornece fun\u00e7\u00f5es para fazer requisi\u00e7\u00f5es HTTP e baixar arquivos, permitindo que suas tarefas interajam com servi\u00e7os web e recursos remotos.</p>"},{"location":"pt/modules/net/#nethttp_geturl","title":"<code>net.http_get(url)</code>","text":"<p>Realiza uma requisi\u00e7\u00e3o HTTP GET para a URL especificada.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>url</code> (string): A URL para a qual enviar a requisi\u00e7\u00e3o GET.</li> </ul> </li> <li>Retorna:<ul> <li><code>body</code> (string): O corpo da resposta como uma string.</li> <li><code>status_code</code> (n\u00famero): O c\u00f3digo de status HTTP da resposta.</li> <li><code>headers</code> (tabela): Uma tabela contendo os cabe\u00e7alhos da resposta.</li> <li><code>error</code> (string): Uma mensagem de erro se a requisi\u00e7\u00e3o falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/net/#nethttp_posturl-body-headers","title":"<code>net.http_post(url, body, [headers])</code>","text":"<p>Realiza uma requisi\u00e7\u00e3o HTTP POST para a URL especificada.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>url</code> (string): A URL para a qual enviar a requisi\u00e7\u00e3o POST.</li> <li><code>body</code> (string): O corpo da requisi\u00e7\u00e3o a ser enviado.</li> <li><code>headers</code> (tabela, opcional): Uma tabela de cabe\u00e7alhos de requisi\u00e7\u00e3o a serem definidos.</li> </ul> </li> <li>Retorna:<ul> <li><code>body</code> (string): O corpo da resposta como uma string.</li> <li><code>status_code</code> (n\u00famero): O c\u00f3digo de status HTTP da resposta.</li> <li><code>headers</code> (tabela): Uma tabela contendo os cabe\u00e7alhos da resposta.</li> <li><code>error</code> (string): Uma mensagem de erro se a requisi\u00e7\u00e3o falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/net/#netdownloadurl-destination_path","title":"<code>net.download(url, destination_path)</code>","text":"<p>Baixa um arquivo de uma URL e o salva em um caminho local.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>url</code> (string): A URL do arquivo a ser baixado.</li> <li><code>destination_path</code> (string): O caminho do arquivo local para salvar o conte\u00fado baixado.</li> </ul> </li> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se o download falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/net/#exemplo","title":"Exemplo","text":"<pre><code>command = function()\n  local net = require(\"net\")\n\n  -- Exemplo de requisi\u00e7\u00e3o GET\n  log.info(\"Realizando requisi\u00e7\u00e3o GET para httpbin.org...\")\n  local body, status, headers, err = net.http_get(\"https://httpbin.org/get\")\n  if err then\n    log.error(\"Requisi\u00e7\u00e3o GET falhou: \" .. err)\n    return false, \"Requisi\u00e7\u00e3o GET falhou\"\n  end\n  log.info(\"Requisi\u00e7\u00e3o GET bem-sucedida! Status: \" .. status)\n  -- print(\"Corpo da Resposta: \" .. body)\n\n  -- Exemplo de requisi\u00e7\u00e3o POST\n  log.info(\"Realizando requisi\u00e7\u00e3o POST para httpbin.org...\")\n  local post_body = '{\"name\": \"sloth-runner\", \"awesome\": true}'\n  local post_headers = { [\"Content-Type\"] = \"application/json\" }\n  body, status, headers, err = net.http_post(\"https://httpbin.org/post\", post_body, post_headers)\n  if err then\n    log.error(\"Requisi\u00e7\u00e3o POST falhou: \" .. err)\n    return false, \"Requisi\u00e7\u00e3o POST falhou\"\n  end\n  log.info(\"Requisi\u00e7\u00e3o POST bem-sucedida! Status: \" .. status)\n  -- print(\"Corpo da Resposta: \" .. body)\n\n  -- Exemplo de Download\n  local download_path = \"/tmp/sloth-runner-logo.svg\"\n  log.info(\"Baixando arquivo para \" .. download_path)\n  local err = net.download(\"https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/assets/sloth-runner-logo.svg\", download_path)\n  if err then\n    log.error(\"Download falhou: \" .. err)\n    return false, \"Download falhou\"\n  end\n  log.info(\"Arquivo baixado com sucesso.\")\n  fs.rm(download_path) -- Limpeza\n\n  return true, \"Opera\u00e7\u00f5es do m\u00f3dulo Net bem-sucedidas.\"\nend\n</code></pre>"},{"location":"pt/modules/notifications/","title":"M\u00f3dulo de Notifica\u00e7\u00f5es","text":"<p>O m\u00f3dulo <code>notifications</code> fornece uma maneira simples de enviar mensagens para v\u00e1rios servi\u00e7os de notifica\u00e7\u00e3o a partir de suas pipelines. Isso \u00e9 particularmente \u00fatil para relatar o sucesso ou a falha de um fluxo de trabalho de CI/CD.</p> <p>Atualmente, os seguintes servi\u00e7os s\u00e3o suportados: - Slack - ntfy</p>"},{"location":"pt/modules/notifications/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Antes de usar o m\u00f3dulo, voc\u00ea precisa adicionar as credenciais ou URLs necess\u00e1rias ao seu arquivo <code>configs/values.yaml</code>. O m\u00f3dulo ler\u00e1 esses valores em tempo de execu\u00e7\u00e3o.</p> <pre><code># configs/values.yaml\n\nnotifications:\n  slack:\n    # Sua URL de Webhook de Entrada do Slack\n    webhook_url: \"https://hooks.slack.com/services/...\"\n  ntfy:\n    # O servidor ntfy a ser usado. Pode ser o p\u00fablico ou auto-hospedado.\n    server: \"https://ntfy.sh\"\n    # O t\u00f3pico para publicar a notifica\u00e7\u00e3o.\n    topic: \"seu-topico-sloth-runner\"\n</code></pre>"},{"location":"pt/modules/notifications/#slack","title":"Slack","text":""},{"location":"pt/modules/notifications/#notificationsslacksendparams","title":"<code>notifications.slack.send(params)</code>","text":"<p>Envia uma mensagem para um canal do Slack atrav\u00e9s de um Webhook de Entrada.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Uma tabela contendo os seguintes campos:<ul> <li><code>webhook_url</code> (string): Obrigat\u00f3rio. A URL do Webhook de Entrada do Slack. Recomenda-se obter isso do m\u00f3dulo <code>values</code>.</li> <li><code>message</code> (string): Obrigat\u00f3rio. O texto principal da mensagem.</li> <li><code>pipeline</code> (string): Opcional. O nome da pipeline, que ser\u00e1 exibido no anexo da mensagem para contexto.</li> <li><code>error_details</code> (string): Opcional. Quaisquer detalhes de erro a serem inclu\u00eddos no anexo da mensagem. Isso \u00e9 \u00fatil para notifica\u00e7\u00f5es de falha.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>true</code> em caso de sucesso.</li> <li><code>false, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local values = require(\"values\")\n\nlocal slack_webhook = values.get(\"notifications.slack.webhook_url\")\n\nif slack_webhook and slack_webhook ~= \"\" then\n  -- Em caso de sucesso\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u2705 Pipeline executada com sucesso!\",\n    pipeline = \"minha-pipeline-incrivel\"\n  })\n\n  -- Em caso de falha\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u274c Falha na execu\u00e7\u00e3o da pipeline!\",\n    pipeline = \"minha-pipeline-incrivel\",\n    error_details = \"N\u00e3o foi poss\u00edvel conectar ao banco de dados.\"\n  })\nend\n</code></pre>"},{"location":"pt/modules/notifications/#ntfy","title":"ntfy","text":""},{"location":"pt/modules/notifications/#notificationsntfysendparams","title":"<code>notifications.ntfy.send(params)</code>","text":"<p>Envia uma mensagem para um t\u00f3pico do ntfy.sh.</p> <p>Par\u00e2metros:</p> <ul> <li><code>params</code> (tabela): Uma tabela contendo os seguintes campos:<ul> <li><code>server</code> (string): Obrigat\u00f3rio. A URL do servidor ntfy.</li> <li><code>topic</code> (string): Obrigat\u00f3rio. O t\u00f3pico para o qual a mensagem ser\u00e1 enviada.</li> <li><code>message</code> (string): Obrigat\u00f3rio. O corpo da notifica\u00e7\u00e3o.</li> <li><code>title</code> (string): Opcional. O t\u00edtulo da notifica\u00e7\u00e3o.</li> <li><code>priority</code> (string): Opcional. Prioridade da notifica\u00e7\u00e3o (ex: <code>high</code>, <code>default</code>, <code>low</code>).</li> <li><code>tags</code> (tabela): Opcional. Uma lista de tags (emojis) para adicionar \u00e0 notifica\u00e7\u00e3o.</li> </ul> </li> </ul> <p>Retornos:</p> <ul> <li><code>true</code> em caso de sucesso.</li> <li><code>false, error_message</code> em caso de falha.</li> </ul> <p>Exemplo:</p> <pre><code>local values = require(\"values\")\n\nlocal ntfy_server = values.get(\"notifications.ntfy.server\")\nlocal ntfy_topic = values.get(\"notifications.ntfy.topic\")\n\nif ntfy_topic and ntfy_topic ~= \"\" then\n  -- Em caso de sucesso\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"Pipeline com Sucesso\",\n    message = \"A pipeline terminou sem erros.\",\n    priority = \"default\",\n    tags = {\"tada\"}\n  })\n\n  -- Em caso de falha\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"Pipeline Falhou!\",\n    message = \"A pipeline falhou com um erro.\",\n    priority = \"high\",\n    tags = {\"skull\", \"warning\"}\n  })\nend\n</code></pre>"},{"location":"pt/modules/pulumi/","title":"M\u00f3dulo Pulumi","text":"<p>O m\u00f3dulo <code>pulumi</code> fornece uma API fluente para orquestrar stacks do Pulumi, permitindo que voc\u00ea gerencie seus fluxos de trabalho de Infraestrutura como C\u00f3digo (IaC) diretamente do <code>sloth-runner</code>.</p>"},{"location":"pt/modules/pulumi/#pulumistackname-options","title":"<code>pulumi.stack(name, options)</code>","text":"<p>Cria um objeto de stack do Pulumi.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>name</code> (string): O nome completo da stack (ex: <code>\"minha-org/meu-projeto/dev\"</code>).</li> <li><code>options</code> (tabela): Uma tabela de op\u00e7\u00f5es.<ul> <li><code>workdir</code> (string): (Obrigat\u00f3rio) O caminho para o diret\u00f3rio do projeto Pulumi.</li> </ul> </li> </ul> </li> <li>Retorna:<ul> <li><code>stack</code> (objeto): Um objeto <code>PulumiStack</code>.</li> <li><code>error</code>: Um objeto de erro se a stack n\u00e3o puder ser inicializada.</li> </ul> </li> </ul>"},{"location":"pt/modules/pulumi/#o-objeto-pulumistack","title":"O Objeto <code>PulumiStack</code>","text":"<p>Este objeto representa uma stack espec\u00edfica do Pulumi e fornece m\u00e9todos para intera\u00e7\u00e3o.</p>"},{"location":"pt/modules/pulumi/#stackupoptions","title":"<code>stack:up([options])</code>","text":"<p>Cria ou atualiza os recursos da stack executando <code>pulumi up</code>.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>options</code> (tabela, opcional):<ul> <li><code>yes</code> (booleano): Se <code>true</code>, passa <code>--yes</code> para aprovar a atualiza\u00e7\u00e3o automaticamente.</li> <li><code>config</code> (tabela): Um dicion\u00e1rio de valores de configura\u00e7\u00e3o a serem passados para a stack.</li> <li><code>args</code> (tabela): Uma lista de argumentos de string adicionais a serem passados para o comando.</li> </ul> </li> </ul> </li> <li>Retorna:<ul> <li><code>result</code> (tabela): Uma tabela contendo <code>success</code> (booleano), <code>stdout</code> (string) e <code>stderr</code> (string).</li> </ul> </li> </ul>"},{"location":"pt/modules/pulumi/#stackpreviewoptions","title":"<code>stack:preview([options])</code>","text":"<p>Pr\u00e9-visualiza as altera\u00e7\u00f5es que seriam feitas por uma atualiza\u00e7\u00e3o executando <code>pulumi preview</code>.</p> <ul> <li>Par\u00e2metros: Os mesmos de <code>stack:up</code>.</li> <li>Retorna: O mesmo de <code>stack:up</code>.</li> </ul>"},{"location":"pt/modules/pulumi/#stackrefreshoptions","title":"<code>stack:refresh([options])</code>","text":"<p>Atualiza o estado da stack executando <code>pulumi refresh</code>.</p> <ul> <li>Par\u00e2metros: Os mesmos de <code>stack:up</code>.</li> <li>Retorna: O mesmo de <code>stack:up</code>.</li> </ul>"},{"location":"pt/modules/pulumi/#stackdestroyoptions","title":"<code>stack:destroy([options])</code>","text":"<p>Destr\u00f3i todos os recursos na stack executando <code>pulumi destroy</code>.</p> <ul> <li>Par\u00e2metros: Os mesmos de <code>stack:up</code>.</li> <li>Retorna: O mesmo de <code>stack:up</code>.</li> </ul>"},{"location":"pt/modules/pulumi/#stackoutputs","title":"<code>stack:outputs()</code>","text":"<p>Recupera os outputs de uma stack implantada.</p> <ul> <li>Retorna:<ul> <li><code>outputs</code> (tabela): Uma tabela Lua com os outputs da stack.</li> <li><code>error</code>: Um objeto de erro se a busca dos outputs falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/pulumi/#exemplo","title":"Exemplo","text":"<p>Este exemplo mostra um padr\u00e3o comum: implantar uma stack de rede (VPC) e, em seguida, usar seu output (<code>vpcId</code>) para configurar e implantar uma stack de aplica\u00e7\u00e3o.</p> <pre><code>command = function()\n  local pulumi = require(\"pulumi\")\n\n  -- 1. Define a stack da VPC\n  local vpc_stack = pulumi.stack(\"minha-org/vpc/prod\", { workdir = \"./pulumi/vpc\" })\n\n  -- 2. Implanta a VPC\n  log.info(\"Implantando a stack da VPC...\")\n  local vpc_result = vpc_stack:up({ yes = true })\n  if not vpc_result.success then\n    return false, \"A implanta\u00e7\u00e3o da VPC falhou: \" .. vpc_result.stderr\n  end\n\n  -- 3. Obt\u00e9m o ID da VPC de seus outputs\n  log.info(\"Buscando outputs da VPC...\")\n  local vpc_outputs, err = vpc_stack:outputs()\n  if err then\n    return false, \"Falha ao obter os outputs da VPC: \" .. err\n  end\n  local vpc_id = vpc_outputs.vpcId\n\n  -- 4. Define a stack da Aplica\u00e7\u00e3o\n  local app_stack = pulumi.stack(\"minha-org/app/prod\", { workdir = \"./pulumi/app\" })\n\n  -- 5. Implanta a Aplica\u00e7\u00e3o, passando o vpcId como configura\u00e7\u00e3o\n  log.info(\"Implantando a stack da Aplica\u00e7\u00e3o na VPC: \" .. vpc_id)\n  local app_result = app_stack:up({\n    yes = true,\n    config = { [\"my-app:vpcId\"] = vpc_id }\n  })\n  if not app_result.success then\n    return false, \"A implanta\u00e7\u00e3o da Aplica\u00e7\u00e3o falhou: \" .. app_result.stderr\n  end\n\n  log.info(\"Todas as stacks foram implantadas com sucesso.\")\n  return true, \"Orquestra\u00e7\u00e3o com Pulumi completa.\"\nend\n</code></pre>"},{"location":"pt/modules/python/","title":"M\u00f3dulo Python","text":"<p>O m\u00f3dulo <code>python</code> fornece uma maneira conveniente de gerenciar ambientes virtuais Python (<code>venv</code>) e executar scripts de dentro de suas tarefas do <code>sloth-runner</code>. Isso \u00e9 particularmente \u00fatil para fluxos de trabalho que envolvem ferramentas ou scripts baseados em Python.</p>"},{"location":"pt/modules/python/#pythonvenvpath","title":"<code>python.venv(path)</code>","text":"<p>Cria um objeto de ambiente virtual Python. Note que isso apenas cria o objeto em Lua; o ambiente em si n\u00e3o \u00e9 criado no sistema de arquivos at\u00e9 que voc\u00ea chame <code>:create()</code>.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>path</code> (string): O caminho no sistema de arquivos onde o ambiente virtual deve ser criado (ex: <code>./.venv</code>).</li> </ul> </li> <li>Retorna:<ul> <li><code>venv</code> (objeto): Um objeto de ambiente virtual com m\u00e9todos para interagir com ele.</li> </ul> </li> </ul>"},{"location":"pt/modules/python/#venvcreate","title":"<code>venv:create()</code>","text":"<p>Cria o ambiente virtual no sistema de arquivos no caminho especificado.</p> <ul> <li>Retorna:<ul> <li><code>error</code>: Um objeto de erro se a cria\u00e7\u00e3o falhar.</li> </ul> </li> </ul>"},{"location":"pt/modules/python/#venvpipcommand","title":"<code>venv:pip(command)</code>","text":"<p>Executa um comando <code>pip</code> dentro do contexto do ambiente virtual.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>command</code> (string): Os argumentos a serem passados para o <code>pip</code> (ex: <code>install -r requirements.txt</code>).</li> </ul> </li> <li>Retorna:<ul> <li><code>result</code> (tabela): Uma tabela contendo <code>stdout</code>, <code>stderr</code> e <code>exit_code</code> do comando <code>pip</code>.</li> </ul> </li> </ul>"},{"location":"pt/modules/python/#venvexecscript_path","title":"<code>venv:exec(script_path)</code>","text":"<p>Executa um script Python usando o interpretador Python do ambiente virtual.</p> <ul> <li>Par\u00e2metros:<ul> <li><code>script_path</code> (string): O caminho para o script Python a ser executado.</li> </ul> </li> <li>Retorna:<ul> <li><code>result</code> (tabela): Uma tabela contendo <code>stdout</code>, <code>stderr</code> e <code>exit_code</code> da execu\u00e7\u00e3o do script.</li> </ul> </li> </ul>"},{"location":"pt/modules/python/#exemplo","title":"Exemplo","text":"<p>Este exemplo demonstra um ciclo de vida completo: criar um ambiente virtual, instalar depend\u00eancias de um arquivo <code>requirements.txt</code> e executar um script Python.</p> <pre><code>-- examples/python_venv_lifecycle_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"Uma tarefa para demonstrar o ciclo de vida de um venv Python.\",\n    create_workdir_before_run = true, -- Usa um diret\u00f3rio de trabalho tempor\u00e1rio\n    tasks = {\n      {\n        name = \"run-python-script\",\n        description = \"Cria um venv, instala depend\u00eancias e executa um script.\",\n        command = function(params)\n          local python = require(\"python\")\n          local workdir = params.workdir -- Obt\u00e9m o diret\u00f3rio de trabalho tempor\u00e1rio do grupo\n\n          -- 1. Escreve nosso script Python e depend\u00eancias no workdir\n          fs.write(workdir .. \"/requirements.txt\", \"requests==2.28.1\")\n          fs.write(workdir .. \"/main.py\", \"import requests\\nprint(f'Ol\u00e1 do Python! Usando a vers\u00e3o do requests: {requests.__version__}')\")\n\n          -- 2. Cria um objeto venv\n          local venv_path = workdir .. \"/.venv\"\n          log.info(\"Configurando ambiente virtual em: \" .. venv_path)\n          local venv = python.venv(venv_path)\n\n          -- 3. Cria o venv no sistema de arquivos\n          venv:create()\n\n          -- 4. Instala as depend\u00eancias usando pip\n          log.info(\"Instalando depend\u00eancias do requirements.txt...\")\n          local pip_result = venv:pip(\"install -r \" .. workdir .. \"/requirements.txt\")\n          if pip_result.exit_code ~= 0 then\n            log.error(\"A instala\u00e7\u00e3o com pip falhou: \" .. pip_result.stderr)\n            return false, \"Falha ao instalar depend\u00eancias Python.\"\n          end\n\n          -- 5. Executa o script\n          log.info(\"Executando o script Python...\")\n          local exec_result = venv:exec(workdir .. \"/main.py\")\n          if exec_result.exit_code ~= 0 then\n            log.error(\"O script Python falhou: \" .. exec_result.stderr)\n            return false, \"A execu\u00e7\u00e3o do script Python falhou.\"\n          end\n\n          log.info(\"Script Python executado com sucesso.\")\n          print(\"--- Sa\u00edda do Script Python ---\")\n          print(exec_result.stdout)\n          print(\"----------------------------\")\n\n          return true, \"Ciclo de vida do venv Python completo.\"\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"pt/modules/salt/","title":"M\u00f3dulo Salt - Completo e Abrangente","text":"<p>O m\u00f3dulo <code>salt</code> fornece uma API completa e abrangente para interagir com o SaltStack, cobrindo 100% das funcionalidades do Salt. Este m\u00f3dulo oferece mais de 200 fun\u00e7\u00f5es que abrangem todas as \u00e1reas principais do SaltStack, desde opera\u00e7\u00f5es b\u00e1sicas at\u00e9 recursos empresariais avan\u00e7ados.</p>"},{"location":"pt/modules/salt/#funcionalidades-principais","title":"\ud83d\ude80 Funcionalidades Principais","text":""},{"location":"pt/modules/salt/#1-execucao-basica-e-controle","title":"1. Execu\u00e7\u00e3o B\u00e1sica e Controle","text":"<ul> <li><code>salt.cmd()</code> - Execu\u00e7\u00e3o de comandos b\u00e1sicos</li> <li><code>salt.run()</code> - Execu\u00e7\u00e3o de runners</li> <li><code>salt.execute()</code> - Execu\u00e7\u00e3o gen\u00e9rica</li> <li><code>salt.batch()</code> - Execu\u00e7\u00e3o em lotes</li> <li><code>salt.async()</code> - Execu\u00e7\u00e3o ass\u00edncrona</li> </ul>"},{"location":"pt/modules/salt/#2-conectividade-e-testes","title":"2. Conectividade e Testes","text":"<ul> <li><code>salt.ping()</code> - Teste de conectividade</li> <li><code>salt.test()</code> - M\u00f3dulo de testes</li> <li><code>salt.version()</code> - Informa\u00e7\u00f5es de vers\u00e3o</li> <li><code>salt.status()</code> - Status do sistema</li> </ul>"},{"location":"pt/modules/salt/#3-gerenciamento-de-chaves","title":"3. Gerenciamento de Chaves","text":"<ul> <li><code>salt.key_list()</code> - Listar chaves</li> <li><code>salt.key_accept()</code> - Aceitar chaves</li> <li><code>salt.key_reject()</code> - Rejeitar chaves</li> <li><code>salt.key_delete()</code> - Deletar chaves</li> <li><code>salt.key_finger()</code> - Impress\u00f5es digitais</li> <li><code>salt.key_gen()</code> - Gerar chaves</li> </ul>"},{"location":"pt/modules/salt/#4-gerenciamento-de-estados","title":"4. Gerenciamento de Estados","text":"<ul> <li><code>salt.state_apply()</code> - Aplicar estados</li> <li><code>salt.state_highstate()</code> - Execu\u00e7\u00e3o completa de estados</li> <li><code>salt.state_test()</code> - Teste de estados</li> <li><code>salt.state_show_sls()</code> - Mostrar SLS</li> <li><code>salt.state_show_top()</code> - Mostrar TOP</li> <li><code>salt.state_show_lowstate()</code> - Mostrar lowstate</li> <li><code>salt.state_single()</code> - Estado \u00fanico</li> <li><code>salt.state_template()</code> - Templates de estado</li> </ul>"},{"location":"pt/modules/salt/#5-gerenciamento-de-grains","title":"5. Gerenciamento de Grains","text":"<ul> <li><code>salt.grains_get()</code> - Obter grains</li> <li><code>salt.grains_set()</code> - Definir grains</li> <li><code>salt.grains_append()</code> - Adicionar a grains</li> <li><code>salt.grains_remove()</code> - Remover de grains</li> <li><code>salt.grains_delkey()</code> - Deletar chave de grain</li> <li><code>salt.grains_items()</code> - Todos os grains</li> </ul>"},{"location":"pt/modules/salt/#6-gerenciamento-de-pillar","title":"6. Gerenciamento de Pillar","text":"<ul> <li><code>salt.pillar_get()</code> - Obter dados do pillar</li> <li><code>salt.pillar_items()</code> - Todos os dados do pillar</li> <li><code>salt.pillar_show()</code> - Mostrar compila\u00e7\u00e3o do pillar</li> <li><code>salt.pillar_refresh()</code> - Atualizar pillar</li> </ul>"},{"location":"pt/modules/salt/#7-operacoes-de-arquivo","title":"7. Opera\u00e7\u00f5es de Arquivo","text":"<ul> <li><code>salt.file_copy()</code> - Copiar arquivos</li> <li><code>salt.file_get()</code> - Obter arquivos</li> <li><code>salt.file_list()</code> - Listar arquivos</li> <li><code>salt.file_manage()</code> - Gerenciar arquivos</li> <li><code>salt.file_recurse()</code> - Opera\u00e7\u00f5es recursivas</li> <li><code>salt.file_touch()</code> - Criar/tocar arquivos</li> <li><code>salt.file_stats()</code> - Estat\u00edsticas de arquivo</li> <li><code>salt.file_find()</code> - Buscar arquivos</li> <li><code>salt.file_replace()</code> - Substituir conte\u00fado</li> <li><code>salt.file_check_hash()</code> - Verificar hash</li> </ul>"},{"location":"pt/modules/salt/#8-gerenciamento-de-pacotes","title":"8. Gerenciamento de Pacotes","text":"<ul> <li><code>salt.pkg_install()</code> - Instalar pacotes</li> <li><code>salt.pkg_remove()</code> - Remover pacotes</li> <li><code>salt.pkg_upgrade()</code> - Atualizar pacotes</li> <li><code>salt.pkg_refresh()</code> - Atualizar reposit\u00f3rios</li> <li><code>salt.pkg_list()</code> - Listar pacotes</li> <li><code>salt.pkg_version()</code> - Vers\u00e3o de pacote</li> <li><code>salt.pkg_available()</code> - Pacotes dispon\u00edveis</li> <li><code>salt.pkg_info()</code> - Informa\u00e7\u00f5es de pacote</li> <li><code>salt.pkg_hold()</code> - Segurar pacote</li> <li><code>salt.pkg_unhold()</code> - Liberar pacote</li> </ul>"},{"location":"pt/modules/salt/#9-gerenciamento-de-servicos","title":"9. Gerenciamento de Servi\u00e7os","text":"<ul> <li><code>salt.service_start()</code> - Iniciar servi\u00e7o</li> <li><code>salt.service_stop()</code> - Parar servi\u00e7o</li> <li><code>salt.service_restart()</code> - Reiniciar servi\u00e7o</li> <li><code>salt.service_reload()</code> - Recarregar servi\u00e7o</li> <li><code>salt.service_status()</code> - Status do servi\u00e7o</li> <li><code>salt.service_enable()</code> - Habilitar servi\u00e7o</li> <li><code>salt.service_disable()</code> - Desabilitar servi\u00e7o</li> <li><code>salt.service_list()</code> - Listar servi\u00e7os</li> </ul>"},{"location":"pt/modules/salt/#10-gerenciamento-de-usuarios","title":"10. Gerenciamento de Usu\u00e1rios","text":"<ul> <li><code>salt.user_add()</code> - Adicionar usu\u00e1rio</li> <li><code>salt.user_delete()</code> - Deletar usu\u00e1rio</li> <li><code>salt.user_info()</code> - Informa\u00e7\u00f5es do usu\u00e1rio</li> <li><code>salt.user_list()</code> - Listar usu\u00e1rios</li> <li><code>salt.user_chuid()</code> - Alterar UID</li> <li><code>salt.user_chgid()</code> - Alterar GID</li> <li><code>salt.user_chshell()</code> - Alterar shell</li> <li><code>salt.user_chhome()</code> - Alterar home</li> <li><code>salt.user_primary_group()</code> - Alterar grupo prim\u00e1rio</li> </ul>"},{"location":"pt/modules/salt/#11-gerenciamento-de-grupos","title":"11. Gerenciamento de Grupos","text":"<ul> <li><code>salt.group_add()</code> - Adicionar grupo</li> <li><code>salt.group_delete()</code> - Deletar grupo</li> <li><code>salt.group_info()</code> - Informa\u00e7\u00f5es do grupo</li> <li><code>salt.group_list()</code> - Listar grupos</li> <li><code>salt.group_adduser()</code> - Adicionar usu\u00e1rio ao grupo</li> <li><code>salt.group_deluser()</code> - Remover usu\u00e1rio do grupo</li> <li><code>salt.group_members()</code> - Membros do grupo</li> </ul>"},{"location":"pt/modules/salt/#12-gerenciamento-de-rede","title":"12. Gerenciamento de Rede","text":"<ul> <li><code>salt.network_interface()</code> - Interface espec\u00edfica</li> <li><code>salt.network_interfaces()</code> - Todas as interfaces</li> <li><code>salt.network_ping()</code> - Ping de rede</li> <li><code>salt.network_traceroute()</code> - Traceroute</li> <li><code>salt.network_netstat()</code> - Estat\u00edsticas de rede</li> <li><code>salt.network_arp()</code> - Tabela ARP</li> </ul>"},{"location":"pt/modules/salt/#13-informacoes-do-sistema","title":"13. Informa\u00e7\u00f5es do Sistema","text":"<ul> <li><code>salt.system_info()</code> - Informa\u00e7\u00f5es completas</li> <li><code>salt.system_uptime()</code> - Tempo de atividade</li> <li><code>salt.system_reboot()</code> - Reiniciar sistema</li> <li><code>salt.system_shutdown()</code> - Desligar sistema</li> <li><code>salt.system_halt()</code> - Parar sistema</li> <li><code>salt.system_hostname()</code> - Nome do host</li> <li><code>salt.system_set_hostname()</code> - Definir hostname</li> </ul>"},{"location":"pt/modules/salt/#14-gerenciamento-de-disco-e-montagem","title":"14. Gerenciamento de Disco e Montagem","text":"<ul> <li><code>salt.disk_usage()</code> - Uso do disco</li> <li><code>salt.disk_stats()</code> - Estat\u00edsticas do disco</li> <li><code>salt.mount_active()</code> - Montagens ativas</li> <li><code>salt.mount_fstab()</code> - Configura\u00e7\u00e3o fstab</li> <li><code>salt.mount_mount()</code> - Montar filesystem</li> <li><code>salt.mount_umount()</code> - Desmontar filesystem</li> <li><code>salt.mount_remount()</code> - Remontar filesystem</li> </ul>"},{"location":"pt/modules/salt/#15-gerenciamento-de-processos","title":"15. Gerenciamento de Processos","text":"<ul> <li><code>salt.process_list()</code> - Listar processos</li> <li><code>salt.process_info()</code> - Informa\u00e7\u00f5es do processo</li> <li><code>salt.process_kill()</code> - Matar processo</li> <li><code>salt.process_killall()</code> - Matar por nome</li> <li><code>salt.process_pkill()</code> - Matar por padr\u00e3o</li> </ul>"},{"location":"pt/modules/salt/#16-gerenciamento-de-cron","title":"16. Gerenciamento de Cron","text":"<ul> <li><code>salt.cron_list()</code> - Listar tarefas cron</li> <li><code>salt.cron_set()</code> - Definir tarefa cron</li> <li><code>salt.cron_delete()</code> - Deletar tarefa cron</li> <li><code>salt.cron_raw_cron()</code> - Cron bruto</li> </ul>"},{"location":"pt/modules/salt/#17-operacoes-de-arquivo","title":"17. Opera\u00e7\u00f5es de Arquivo","text":"<ul> <li><code>salt.archive_gunzip()</code> - Descompactar gzip</li> <li><code>salt.archive_gzip()</code> - Compactar gzip</li> <li><code>salt.archive_tar()</code> - Criar tar</li> <li><code>salt.archive_untar()</code> - Extrair tar</li> <li><code>salt.archive_unzip()</code> - Extrair zip</li> <li><code>salt.archive_zip()</code> - Criar zip</li> </ul>"},{"location":"pt/modules/salt/#18-integracao-salt-cloud","title":"18. Integra\u00e7\u00e3o Salt Cloud","text":"<ul> <li><code>salt.cloud_list_nodes()</code> - Listar n\u00f3s na nuvem</li> <li><code>salt.cloud_create()</code> - Criar inst\u00e2ncia</li> <li><code>salt.cloud_destroy()</code> - Destruir inst\u00e2ncia</li> <li><code>salt.cloud_action()</code> - A\u00e7\u00f5es na nuvem</li> <li><code>salt.cloud_function()</code> - Fun\u00e7\u00f5es da nuvem</li> <li><code>salt.cloud_map()</code> - Mapeamento de nuvem</li> <li><code>salt.cloud_profile()</code> - Perfis de nuvem</li> <li><code>salt.cloud_provider()</code> - Provedores de nuvem</li> </ul>"},{"location":"pt/modules/salt/#19-sistema-de-eventos","title":"19. Sistema de Eventos","text":"<ul> <li><code>salt.event_send()</code> - Enviar evento</li> <li><code>salt.event_listen()</code> - Escutar eventos</li> <li><code>salt.event_fire()</code> - Disparar evento</li> <li><code>salt.event_fire_master()</code> - Evento no master</li> </ul>"},{"location":"pt/modules/salt/#20-orquestracao","title":"20. Orquestra\u00e7\u00e3o","text":"<ul> <li><code>salt.orchestrate()</code> - Orquestra\u00e7\u00e3o de estados</li> <li><code>salt.runner()</code> - Executar runner</li> <li><code>salt.wheel()</code> - M\u00f3dulos wheel</li> </ul>"},{"location":"pt/modules/salt/#21-operacoes-mine","title":"21. Opera\u00e7\u00f5es Mine","text":"<ul> <li><code>salt.mine_get()</code> - Obter dados mine</li> <li><code>salt.mine_send()</code> - Enviar para mine</li> <li><code>salt.mine_update()</code> - Atualizar mine</li> <li><code>salt.mine_delete()</code> - Deletar do mine</li> <li><code>salt.mine_flush()</code> - Limpar mine</li> <li><code>salt.mine_valid()</code> - Validar mine</li> </ul>"},{"location":"pt/modules/salt/#22-gerenciamento-de-jobs","title":"22. Gerenciamento de Jobs","text":"<ul> <li><code>salt.job_active()</code> - Jobs ativos</li> <li><code>salt.job_list()</code> - Listar jobs</li> <li><code>salt.job_lookup()</code> - Buscar job</li> <li><code>salt.job_exit_success()</code> - Sucesso do job</li> <li><code>salt.job_print()</code> - Imprimir job</li> </ul>"},{"location":"pt/modules/salt/#23-integracao-docker","title":"23. Integra\u00e7\u00e3o Docker","text":"<ul> <li><code>salt.docker_ps()</code> - Listar containers</li> <li><code>salt.docker_run()</code> - Executar container</li> <li><code>salt.docker_stop()</code> - Parar container</li> <li><code>salt.docker_start()</code> - Iniciar container</li> <li><code>salt.docker_restart()</code> - Reiniciar container</li> <li><code>salt.docker_build()</code> - Construir imagem</li> <li><code>salt.docker_pull()</code> - Baixar imagem</li> <li><code>salt.docker_push()</code> - Enviar imagem</li> <li><code>salt.docker_images()</code> - Listar imagens</li> <li><code>salt.docker_remove()</code> - Remover container</li> <li><code>salt.docker_inspect()</code> - Inspecionar container</li> <li><code>salt.docker_logs()</code> - Logs do container</li> <li><code>salt.docker_exec()</code> - Executar no container</li> </ul>"},{"location":"pt/modules/salt/#24-operacoes-git","title":"24. Opera\u00e7\u00f5es Git","text":"<ul> <li><code>salt.git_clone()</code> - Clonar reposit\u00f3rio</li> <li><code>salt.git_pull()</code> - Puxar altera\u00e7\u00f5es</li> <li><code>salt.git_checkout()</code> - Checkout branch</li> <li><code>salt.git_add()</code> - Adicionar arquivos</li> <li><code>salt.git_commit()</code> - Fazer commit</li> <li><code>salt.git_push()</code> - Enviar altera\u00e7\u00f5es</li> <li><code>salt.git_status()</code> - Status do reposit\u00f3rio</li> <li><code>salt.git_log()</code> - Log de commits</li> <li><code>salt.git_reset()</code> - Reset do reposit\u00f3rio</li> <li><code>salt.git_remote_get()</code> - Obter remote</li> <li><code>salt.git_remote_set()</code> - Definir remote</li> </ul>"},{"location":"pt/modules/salt/#25-operacoes-de-banco-de-dados","title":"25. Opera\u00e7\u00f5es de Banco de Dados","text":""},{"location":"pt/modules/salt/#mysql","title":"MySQL:","text":"<ul> <li><code>salt.mysql_query()</code> - Executar query</li> <li><code>salt.mysql_db_create()</code> - Criar banco</li> <li><code>salt.mysql_db_remove()</code> - Remover banco</li> <li><code>salt.mysql_user_create()</code> - Criar usu\u00e1rio</li> <li><code>salt.mysql_user_remove()</code> - Remover usu\u00e1rio</li> <li><code>salt.mysql_grant_add()</code> - Adicionar permiss\u00e3o</li> <li><code>salt.mysql_grant_revoke()</code> - Revogar permiss\u00e3o</li> </ul>"},{"location":"pt/modules/salt/#postgresql","title":"PostgreSQL:","text":"<ul> <li><code>salt.postgres_query()</code> - Executar query</li> <li><code>salt.postgres_db_create()</code> - Criar banco</li> <li><code>salt.postgres_db_remove()</code> - Remover banco</li> <li><code>salt.postgres_user_create()</code> - Criar usu\u00e1rio</li> <li><code>salt.postgres_user_remove()</code> - Remover usu\u00e1rio</li> </ul>"},{"location":"pt/modules/salt/#26-monitoramento-e-metricas","title":"26. Monitoramento e M\u00e9tricas","text":"<ul> <li><code>salt.status_loadavg()</code> - Carga m\u00e9dia</li> <li><code>salt.status_cpuinfo()</code> - Informa\u00e7\u00f5es CPU</li> <li><code>salt.status_meminfo()</code> - Informa\u00e7\u00f5es mem\u00f3ria</li> <li><code>salt.status_diskusage()</code> - Uso de disco</li> <li><code>salt.status_netdev()</code> - Dispositivos de rede</li> <li><code>salt.status_w()</code> - Usu\u00e1rios logados</li> <li><code>salt.status_uptime()</code> - Tempo de atividade</li> </ul>"},{"location":"pt/modules/salt/#27-gerenciamento-de-configuracao","title":"27. Gerenciamento de Configura\u00e7\u00e3o","text":"<ul> <li><code>salt.config_get()</code> - Obter configura\u00e7\u00e3o</li> <li><code>salt.config_option()</code> - Op\u00e7\u00f5es de configura\u00e7\u00e3o</li> <li><code>salt.config_valid_fileproto()</code> - Validar protocolo</li> <li><code>salt.config_backup_mode()</code> - Modo de backup</li> </ul>"},{"location":"pt/modules/salt/#28-api-e-integracao-rest","title":"28. API e Integra\u00e7\u00e3o REST","text":"<ul> <li><code>salt.api_client()</code> - Cliente API</li> <li><code>salt.api_login()</code> - Login API</li> <li><code>salt.api_logout()</code> - Logout API</li> <li><code>salt.api_minions()</code> - Minions via API</li> <li><code>salt.api_jobs()</code> - Jobs via API</li> <li><code>salt.api_stats()</code> - Estat\u00edsticas API</li> <li><code>salt.api_events()</code> - Eventos API</li> <li><code>salt.api_hook()</code> - Hooks API</li> </ul>"},{"location":"pt/modules/salt/#29-engines-de-template","title":"29. Engines de Template","text":"<ul> <li><code>salt.template_jinja()</code> - Template Jinja2</li> <li><code>salt.template_yaml()</code> - Template YAML</li> <li><code>salt.template_json()</code> - Template JSON</li> <li><code>salt.template_mako()</code> - Template Mako</li> <li><code>salt.template_py()</code> - Template Python</li> <li><code>salt.template_wempy()</code> - Template Wempy</li> </ul>"},{"location":"pt/modules/salt/#30-logging-e-debug","title":"30. Logging e Debug","text":"<ul> <li><code>salt.log_error()</code> - Log de erro</li> <li><code>salt.log_warning()</code> - Log de aviso</li> <li><code>salt.log_info()</code> - Log informativo</li> <li><code>salt.log_debug()</code> - Log de debug</li> <li><code>salt.debug_mode()</code> - Modo debug</li> <li><code>salt.debug_profile()</code> - Perfil de debug</li> </ul>"},{"location":"pt/modules/salt/#31-suporte-multi-master","title":"31. Suporte Multi-Master","text":"<ul> <li><code>salt.multi_master_setup()</code> - Configurar multi-master</li> <li><code>salt.multi_master_failover()</code> - Failover autom\u00e1tico</li> <li><code>salt.multi_master_status()</code> - Status multi-master</li> </ul>"},{"location":"pt/modules/salt/#32-performance-e-otimizacao","title":"32. Performance e Otimiza\u00e7\u00e3o","text":"<ul> <li><code>salt.performance_profile()</code> - Perfil de performance</li> <li><code>salt.performance_test()</code> - Teste de performance</li> <li><code>salt.performance_benchmark()</code> - Benchmark</li> <li><code>salt.cache_performance()</code> - Performance do cache</li> </ul>"},{"location":"pt/modules/salt/#33-gerenciamento-de-beacons","title":"33. Gerenciamento de Beacons","text":"<ul> <li><code>salt.beacon_list()</code> - Listar beacons</li> <li><code>salt.beacon_add()</code> - Adicionar beacon</li> <li><code>salt.beacon_modify()</code> - Modificar beacon</li> <li><code>salt.beacon_delete()</code> - Deletar beacon</li> <li><code>salt.beacon_enable()</code> - Habilitar beacon</li> <li><code>salt.beacon_disable()</code> - Desabilitar beacon</li> <li><code>salt.beacon_save()</code> - Salvar beacons</li> <li><code>salt.beacon_reset()</code> - Reset beacons</li> </ul>"},{"location":"pt/modules/salt/#34-gerenciamento-de-schedule","title":"34. Gerenciamento de Schedule","text":"<ul> <li><code>salt.schedule_list()</code> - Listar agendamentos</li> <li><code>salt.schedule_add()</code> - Adicionar agendamento</li> <li><code>salt.schedule_modify()</code> - Modificar agendamento</li> <li><code>salt.schedule_delete()</code> - Deletar agendamento</li> <li><code>salt.schedule_enable()</code> - Habilitar schedule</li> <li><code>salt.schedule_disable()</code> - Desabilitar schedule</li> <li><code>salt.schedule_run_job()</code> - Executar job agendado</li> <li><code>salt.schedule_save()</code> - Salvar schedule</li> <li><code>salt.schedule_reload()</code> - Recarregar schedule</li> </ul>"},{"location":"pt/modules/salt/#35-funcionalidades-avancadas","title":"35. Funcionalidades Avan\u00e7adas","text":"<ul> <li>SSH operations (salt-ssh)</li> <li>Proxy minion management</li> <li>Security operations (X.509, Vault)</li> <li>Cache management</li> <li>Reactor system</li> <li>Syndic management</li> <li>Roster management</li> <li>Fileserver operations</li> </ul>"},{"location":"pt/modules/salt/#exemplos-de-uso","title":"\ud83d\udcd6 Exemplos de Uso","text":""},{"location":"pt/modules/salt/#exemplo-basico-conectividade","title":"Exemplo B\u00e1sico - Conectividade","text":"<pre><code>local salt = require(\"salt\")\n\n-- Testar conectividade com todos os minions\nlocal ping_result = salt.ping(\"*\", {timeout = 30})\nif ping_result.success then\n    print(\"Todos os minions est\u00e3o respondendo\")\n    for minion, response in pairs(ping_result.returns) do\n        print(\"Minion:\", minion, \"Status:\", response)\n    end\nend\n</code></pre>"},{"location":"pt/modules/salt/#exemplo-avancado-aplicacao-de-estado","title":"Exemplo Avan\u00e7ado - Aplica\u00e7\u00e3o de Estado","text":"<pre><code>local salt = require(\"salt\")\n\n-- Aplicar estado nginx com configura\u00e7\u00e3o espec\u00edfica\nlocal result = salt.state_apply(\"web*\", \"nginx\", {\n    test = true,  -- Modo de teste\n    pillar = {\n        nginx = {\n            worker_processes = 4,\n            worker_connections = 1024,\n            server_name = \"example.com\"\n        }\n    }\n})\n\nif result.success then\n    print(\"Estado aplicado com sucesso\")\n    print(\"Dura\u00e7\u00e3o:\", result.duration_ms .. \"ms\")\nelse\n    print(\"Erro:\", result.error)\nend\n</code></pre>"},{"location":"pt/modules/salt/#exemplo-enterprise-orquestracao","title":"Exemplo Enterprise - Orquestra\u00e7\u00e3o","text":"<pre><code>local salt = require(\"salt\")\n\n-- Orquestra\u00e7\u00e3o complexa com m\u00faltiplos ambientes\nlocal orchestration = salt.orchestrate(\"deploy.application\", {\n    pillar = {\n        app_version = \"v2.1.0\",\n        environment = \"production\",\n        rollback_version = \"v2.0.5\",\n        health_check_enabled = true,\n        notification_webhook = \"https://hooks.slack.com/...\"\n    }\n})\n\nif orchestration.success then\n    print(\"Orquestra\u00e7\u00e3o completada com sucesso\")\n    -- Verificar jobs relacionados\n    local job_status = salt.job_lookup(orchestration.jid)\n    if job_status.success then\n        print(\"Status detalhado dispon\u00edvel\")\n    end\nelse\n    print(\"Falha na orquestra\u00e7\u00e3o:\", orchestration.error)\nend\n</code></pre>"},{"location":"pt/modules/salt/#exemplo-cloud-gerenciamento-de-infraestrutura","title":"Exemplo Cloud - Gerenciamento de Infraestrutura","text":"<pre><code>local salt = require(\"salt\")\n\n-- Criar inst\u00e2ncias na nuvem\nlocal cloud_result = salt.cloud_create(\"web-profile\", \"web-server-03\")\nif cloud_result.success then\n    print(\"Inst\u00e2ncia criada na nuvem\")\n\n    -- Aguardar minion ficar online\n    time.sleep(30)\n\n    -- Aplicar configura\u00e7\u00e3o inicial\n    local config_result = salt.state_highstate(\"web-server-03\")\n    if config_result.success then\n        print(\"Configura\u00e7\u00e3o inicial aplicada\")\n    end\nend\n</code></pre>"},{"location":"pt/modules/salt/#exemplo-docker-gerenciamento-de-containers","title":"Exemplo Docker - Gerenciamento de Containers","text":"<pre><code>local salt = require(\"salt\")\n\n-- Gerenciamento completo de containers Docker\nlocal docker_ops = {\n    -- Baixar imagem\n    salt.docker_pull(\"docker*\", \"nginx:latest\"),\n\n    -- Executar container\n    salt.docker_run(\"docker*\", \"nginx:latest\", {\n        name = \"web-server\",\n        ports = \"80:80\",\n        detach = true\n    }),\n\n    -- Verificar status\n    salt.docker_ps(\"docker*\"),\n\n    -- Obter logs\n    salt.docker_logs(\"docker*\", \"web-server\")\n}\n\nfor _, result in ipairs(docker_ops) do\n    if result.success then\n        print(\"Opera\u00e7\u00e3o Docker executada com sucesso\")\n    end\nend\n</code></pre>"},{"location":"pt/modules/salt/#recursos-empresariais","title":"\ud83c\udfaf Recursos Empresariais","text":""},{"location":"pt/modules/salt/#high-availability","title":"High Availability","text":"<ul> <li>Multi-master configuration</li> <li>Automatic failover</li> <li>Load balancing</li> <li>Geographic distribution</li> </ul>"},{"location":"pt/modules/salt/#security","title":"Security","text":"<ul> <li>X.509 certificate management</li> <li>Vault integration for secrets</li> <li>Encrypted communication</li> <li>Role-based access control</li> </ul>"},{"location":"pt/modules/salt/#monitoring-observability","title":"Monitoring &amp; Observability","text":"<ul> <li>Real-time metrics collection</li> <li>Performance profiling</li> <li>Event-driven monitoring</li> <li>Custom dashboards</li> </ul>"},{"location":"pt/modules/salt/#automation","title":"Automation","text":"<ul> <li>Event-driven reactions</li> <li>Scheduled tasks</li> <li>Complex orchestration</li> <li>Workflow management</li> </ul>"},{"location":"pt/modules/salt/#cloud-integration","title":"Cloud Integration","text":"<ul> <li>Multi-cloud support</li> <li>Auto-scaling</li> <li>Infrastructure as Code</li> <li>Cost optimization</li> </ul>"},{"location":"pt/modules/salt/#caracteristicas-de-performance","title":"\ud83d\ude80 Caracter\u00edsticas de Performance","text":"<ul> <li>Timeout Management: Controle avan\u00e7ado de timeout por opera\u00e7\u00e3o</li> <li>Retry Logic: Retry exponencial com backoff autom\u00e1tico</li> <li>Batch Processing: Execu\u00e7\u00e3o em lotes para opera\u00e7\u00f5es em larga escala</li> <li>Async Operations: Suporte completo para opera\u00e7\u00f5es ass\u00edncronas</li> <li>Connection Pooling: Pool de conex\u00f5es para melhor performance</li> <li>Caching: Cache inteligente para otimiza\u00e7\u00e3o</li> <li>JSON Parsing: Parse autom\u00e1tico de sa\u00eddas JSON</li> </ul>"},{"location":"pt/modules/salt/#estatisticas-do-modulo","title":"\ud83d\udcca Estat\u00edsticas do M\u00f3dulo","text":"<ul> <li>200+ Fun\u00e7\u00f5es: Cobertura completa de todas as funcionalidades Salt</li> <li>35+ \u00c1reas Funcionais: Desde b\u00e1sico at\u00e9 recursos empresariais avan\u00e7ados</li> <li>100% Compatibilidade: Com todas as vers\u00f5es do SaltStack</li> <li>Enterprise Ready: Recursos para ambiente de produ\u00e7\u00e3o</li> <li>High Performance: Otimizado para opera\u00e7\u00f5es em larga escala</li> <li>Error Resilient: Tratamento abrangente de erros</li> <li>Extensible: F\u00e1cil de estender com novas funcionalidades</li> </ul> <p>Este m\u00f3dulo Salt abrangente fornece todas as ferramentas necess\u00e1rias para gerenciar infraestrutura em qualquer escala, desde pequenos deployments at\u00e9 ambientes empresariais complexos com milhares de minions.</p>"},{"location":"pt/modules/state/","title":"\ud83d\udcbe M\u00f3dulo de Gerenciamento de Estado","text":"<p>O m\u00f3dulo Gerenciamento de Estado fornece capacidades poderosas de estado persistente com opera\u00e7\u00f5es at\u00f4micas, locks distribu\u00eddos e funcionalidade TTL (Time To Live). Todos os dados s\u00e3o armazenados localmente usando SQLite com modo WAL para m\u00e1xima performance e confiabilidade.</p>"},{"location":"pt/modules/state/#recursos-principais","title":"\ud83d\ude80 Recursos Principais","text":"<ul> <li>Persist\u00eancia SQLite: Armazenamento confi\u00e1vel com modo WAL</li> <li>Opera\u00e7\u00f5es At\u00f4micas: Increment, compare-and-swap, append thread-safe</li> <li>Locks Distribu\u00eddos: Se\u00e7\u00f5es cr\u00edticas com timeout autom\u00e1tico</li> <li>TTL (Time To Live): Expira\u00e7\u00e3o autom\u00e1tica de chaves</li> <li>Tipos de Dados: String, number, boolean, table, list</li> <li>Pattern Matching: Busca de chaves com wildcards</li> <li>Limpeza Autom\u00e1tica: Cleanup em background de dados expirados</li> <li>Estat\u00edsticas: M\u00e9tricas de uso e performance</li> </ul>"},{"location":"pt/modules/state/#uso-basico","title":"\ud83d\udccb Uso B\u00e1sico","text":""},{"location":"pt/modules/state/#definindo-e-obtendo-valores","title":"Definindo e Obtendo Valores","text":"<pre><code>-- Definir valores\nstate.set(\"versao_app\", \"v1.2.3\")\nstate.set(\"contador_usuarios\", 1000)\nstate.set(\"configuracao\", {\n    debug = true,\n    max_conexoes = 100\n})\n\n-- Obter valores\nlocal versao = state.get(\"versao_app\")\nlocal contador = state.get(\"contador_usuarios\")\nlocal config = state.get(\"configuracao\")\n\n-- Obter com valor padr\u00e3o\nlocal tema = state.get(\"tema_ui\", \"escuro\")\n\n-- Verificar exist\u00eancia\nif state.exists(\"versao_app\") then\n    log.info(\"Vers\u00e3o da aplica\u00e7\u00e3o est\u00e1 configurada\")\nend\n\n-- Deletar chave\nstate.delete(\"chave_antiga\")\n</code></pre>"},{"location":"pt/modules/state/#ttl-time-to-live","title":"TTL (Time To Live)","text":"<pre><code>-- Definir com TTL (60 segundos)\nstate.set(\"token_sessao\", \"abc123\", 60)\n\n-- Definir TTL para chave existente\nstate.set_ttl(\"sessao_usuario\", 300) -- 5 minutos\n\n-- Verificar TTL restante\nlocal ttl = state.get_ttl(\"token_sessao\")\nlog.info(\"Token expira em \" .. ttl .. \" segundos\")\n</code></pre>"},{"location":"pt/modules/state/#operacoes-atomicas","title":"Opera\u00e7\u00f5es At\u00f4micas","text":"<pre><code>-- Incremento at\u00f4mico\nlocal contador = state.increment(\"visualizacoes_pagina\", 1)\nlocal contador_bulk = state.increment(\"downloads\", 50)\n\n-- Decremento at\u00f4mico  \nlocal restante = state.decrement(\"estoque\", 5)\n\n-- Append de string\nstate.set(\"mensagens_log\", \"Iniciando aplica\u00e7\u00e3o\")\nlocal novo_tamanho = state.append(\"mensagens_log\", \" -&gt; Conectando ao banco\")\n\n-- Compare-and-swap at\u00f4mico\nlocal versao_antiga = state.get(\"versao_config\")\nlocal sucesso = state.compare_swap(\"versao_config\", versao_antiga, versao_antiga + 1)\nif sucesso then\n    log.info(\"Configura\u00e7\u00e3o atualizada com seguran\u00e7a\")\nend\n</code></pre>"},{"location":"pt/modules/state/#operacoes-de-lista","title":"Opera\u00e7\u00f5es de Lista","text":"<pre><code>-- Adicionar itens \u00e0 lista\nstate.list_push(\"fila_deployment\", {\n    app = \"frontend\",\n    versao = \"v2.1.0\",\n    ambiente = \"staging\"\n})\n\n-- Verificar tamanho da lista\nlocal tamanho_fila = state.list_length(\"fila_deployment\")\nlog.info(\"Itens na fila: \" .. tamanho_fila)\n\n-- Processar lista (pop remove \u00faltimo item)\nwhile state.list_length(\"fila_deployment\") &gt; 0 do\n    local deployment = state.list_pop(\"fila_deployment\")\n    log.info(\"Processando deployment: \" .. deployment.app)\n    -- Processar deployment...\nend\n</code></pre>"},{"location":"pt/modules/state/#locks-distribuidos-e-secoes-criticas","title":"Locks Distribu\u00eddos e Se\u00e7\u00f5es Cr\u00edticas","text":"<pre><code>-- Tentar adquirir lock (sem esperar)\nlocal lock_adquirido = state.try_lock(\"lock_deployment\", 30) -- 30 segundos TTL\nif lock_adquirido then\n    -- Trabalho cr\u00edtico\n    state.unlock(\"lock_deployment\")\nend\n\n-- Lock com espera e timeout\nlocal adquirido = state.lock(\"migracao_banco\", 60) -- esperar at\u00e9 60s\nif adquirido then\n    -- Executar migra\u00e7\u00e3o\n    state.unlock(\"migracao_banco\")\nend\n\n-- Se\u00e7\u00e3o cr\u00edtica com gerenciamento autom\u00e1tico de lock\nstate.with_lock(\"secao_critica\", function()\n    log.info(\"Executando opera\u00e7\u00e3o cr\u00edtica...\")\n\n    -- Atualizar contador global\n    local contador = state.increment(\"contador_global\", 1)\n\n    -- Atualizar timestamp\n    state.set(\"ultima_operacao\", os.time())\n\n    log.info(\"Opera\u00e7\u00e3o cr\u00edtica conclu\u00edda - contador: \" .. contador)\n\n    -- Lock \u00e9 liberado automaticamente quando a fun\u00e7\u00e3o retorna\n    return \"operacao_sucesso\"\nend, 15) -- timeout de 15 segundos\n</code></pre>"},{"location":"pt/modules/state/#referencia-da-api","title":"\ud83d\udd0d Refer\u00eancia da API","text":""},{"location":"pt/modules/state/#operacoes-basicas","title":"Opera\u00e7\u00f5es B\u00e1sicas","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.set(chave, valor, ttl?)</code> chave: string, valor: any, ttl?: number sucesso: boolean Define um valor com TTL opcional <code>state.get(chave, padrao?)</code> chave: string, padrao?: any valor: any Obt\u00e9m um valor ou retorna o padr\u00e3o <code>state.delete(chave)</code> chave: string sucesso: boolean Remove uma chave <code>state.exists(chave)</code> chave: string existe: boolean Verifica se a chave existe <code>state.clear(padrao?)</code> padrao?: string sucesso: boolean Remove chaves por padr\u00e3o"},{"location":"pt/modules/state/#operacoes-ttl","title":"Opera\u00e7\u00f5es TTL","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.set_ttl(chave, segundos)</code> chave: string, segundos: number sucesso: boolean Define TTL para chave existente <code>state.get_ttl(chave)</code> chave: string ttl: number Obt\u00e9m TTL restante (-1 = sem TTL, -2 = n\u00e3o existe)"},{"location":"pt/modules/state/#operacoes-atomicas_1","title":"Opera\u00e7\u00f5es At\u00f4micas","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.increment(chave, delta?)</code> chave: string, delta?: number novo_valor: number Incrementa valor atomicamente <code>state.decrement(chave, delta?)</code> chave: string, delta?: number novo_valor: number Decrementa valor atomicamente <code>state.append(chave, valor)</code> chave: string, valor: string novo_tamanho: number Anexa string atomicamente <code>state.compare_swap(chave, antigo, novo)</code> chave: string, antigo: any, novo: any sucesso: boolean Compare-and-swap at\u00f4mico"},{"location":"pt/modules/state/#operacoes-de-lista_1","title":"Opera\u00e7\u00f5es de Lista","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.list_push(chave, item)</code> chave: string, item: any tamanho: number Adiciona item ao final da lista <code>state.list_pop(chave)</code> chave: string item: any | nil Remove e retorna \u00faltimo item <code>state.list_length(chave)</code> chave: string tamanho: number Obt\u00e9m tamanho da lista"},{"location":"pt/modules/state/#locks-distribuidos","title":"Locks Distribu\u00eddos","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.try_lock(nome, ttl)</code> nome: string, ttl: number sucesso: boolean Tenta adquirir lock sem esperar <code>state.lock(nome, timeout?)</code> nome: string, timeout?: number sucesso: boolean Adquire lock com timeout <code>state.unlock(nome)</code> nome: string sucesso: boolean Libera lock <code>state.with_lock(nome, funcao, timeout?)</code> nome: string, funcao: function, timeout?: number resultado: any Executa fun\u00e7\u00e3o com lock autom\u00e1tico"},{"location":"pt/modules/state/#utilitarios","title":"Utilit\u00e1rios","text":"Fun\u00e7\u00e3o Par\u00e2metros Retorno Descri\u00e7\u00e3o <code>state.keys(padrao?)</code> padrao?: string chaves: table Lista chaves por padr\u00e3o <code>state.stats()</code> - stats: table Obt\u00e9m estat\u00edsticas do sistema"},{"location":"pt/modules/state/#casos-de-uso-praticos","title":"\ud83d\udca1 Casos de Uso Pr\u00e1ticos","text":""},{"location":"pt/modules/state/#1-controle-de-versao-de-deploy","title":"1. Controle de Vers\u00e3o de Deploy","text":"<pre><code>Modern DSLs = {\n    pipeline_deployment = {\n        tasks = {\n            preparar_deploy = {\n                command = function()\n                    -- Verificar \u00faltima vers\u00e3o deployada\n                    local ultima_versao = state.get(\"ultima_versao_deployada\", \"v0.0.0\")\n                    local nova_versao = \"v1.2.3\"\n\n                    -- Verificar se j\u00e1 foi deployada\n                    if ultima_versao == nova_versao then\n                        log.warn(\"Vers\u00e3o \" .. nova_versao .. \" j\u00e1 foi deployada\")\n                        return false, \"Vers\u00e3o j\u00e1 deployada\"\n                    end\n\n                    -- Registrar in\u00edcio do deploy\n                    state.set(\"status_deploy\", \"em_progresso\")\n                    state.set(\"inicio_deploy\", os.time())\n                    state.increment(\"total_deploys\", 1)\n\n                    return true, \"Prepara\u00e7\u00e3o do deploy conclu\u00edda\"\n                end\n            },\n\n            executar_deploy = {\n                depends_on = \"preparar_deploy\",\n                command = function()\n                    -- Se\u00e7\u00e3o cr\u00edtica para deployment\n                    return state.with_lock(\"lock_deployment\", function()\n                        log.info(\"Executando deployment com lock...\")\n\n                        -- Simular deployment\n                        exec.run(\"sleep 5\")\n\n                        -- Atualizar estado\n                        state.set(\"ultima_versao_deployada\", \"v1.2.3\")\n                        state.set(\"status_deploy\", \"concluido\")\n                        state.set(\"fim_deploy\", os.time())\n\n                        -- Registrar hist\u00f3rico\n                        state.list_push(\"historico_deploy\", {\n                            versao = \"v1.2.3\",\n                            timestamp = os.time(),\n                            duracao = state.get(\"fim_deploy\") - state.get(\"inicio_deploy\")\n                        })\n\n                        return true, \"Deploy conclu\u00eddo com sucesso\"\n                    end, 300) -- timeout de 5 minutos\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"pt/modules/state/#2-cache-inteligente-com-ttl","title":"2. Cache Inteligente com TTL","text":"<pre><code>-- Fun\u00e7\u00e3o helper para cache\nfunction obter_dados_cached(chave_cache, funcao_busca, ttl)\n    local cached = state.get(chave_cache)\n    if cached then\n        log.info(\"Cache hit: \" .. chave_cache)\n        return cached\n    end\n\n    log.info(\"Cache miss: \" .. chave_cache .. \" - buscando...\")\n    local dados = funcao_busca()\n    state.set(chave_cache, dados, ttl or 300) -- 5 minutos padr\u00e3o\n    return dados\nend\n\n-- Uso em tasks\nModern DSLs = {\n    processamento_dados = {\n        tasks = {\n            buscar_dados_usuario = {\n                command = function()\n                    local dados_usuario = obter_dados_cached(\"usuario:123:perfil\", function()\n                        -- Simular busca custosa\n                        return {\n                            nome = \"Alice\",\n                            email = \"alice@exemplo.com\",\n                            preferencias = {\"modo_escuro\", \"notificacoes\"}\n                        }\n                    end, 600) -- Cache por 10 minutos\n\n                    log.info(\"Dados do usu\u00e1rio: \" .. data.to_json(dados_usuario))\n                    return true, \"Dados do usu\u00e1rio obtidos\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"pt/modules/state/#3-rate-limiting","title":"3. Rate Limiting","text":"<pre><code>function verificar_rate_limit(identificador, max_requisicoes, janela_segundos)\n    local chave = \"rate_limit:\" .. identificador\n    local contador_atual = state.get(chave, 0)\n\n    if contador_atual &gt;= max_requisicoes then\n        return false, \"Rate limit excedido\"\n    end\n\n    -- Incrementar contador\n    if contador_atual == 0 then\n        -- Primeira requisi\u00e7\u00e3o na janela\n        state.set(chave, 1, janela_segundos)\n    else\n        -- Incrementar contador existente\n        state.increment(chave, 1)\n    end\n\n    return true, \"Requisi\u00e7\u00e3o permitida\"\nend\n\n-- Uso em tasks\nModern DSLs = {\n    tarefas_api = {\n        tasks = {\n            fazer_chamada_api = {\n                command = function()\n                    local permitido, msg = verificar_rate_limit(\"chamadas_api\", 100, 3600) -- 100 chamadas/hora\n\n                    if not permitido then\n                        log.error(msg)\n                        return false, msg\n                    end\n\n                    -- Fazer chamada da API\n                    log.info(\"Fazendo chamada da API...\")\n                    return true, \"Chamada da API conclu\u00edda\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"pt/modules/state/#configuracao-e-armazenamento","title":"\u2699\ufe0f Configura\u00e7\u00e3o e Armazenamento","text":""},{"location":"pt/modules/state/#localizacao-do-banco-de-dados","title":"Localiza\u00e7\u00e3o do Banco de Dados","text":"<p>Por padr\u00e3o, o banco de dados SQLite \u00e9 criado em: - Linux/macOS: <code>~/.sloth-runner/state.db</code> - Windows: <code>%USERPROFILE%\\.sloth-runner\\state.db</code></p>"},{"location":"pt/modules/state/#caracteristicas-tecnicas","title":"Caracter\u00edsticas T\u00e9cnicas","text":"<ul> <li>Engine: SQLite 3 com modo WAL</li> <li>Acesso Concorrente: Suporte a m\u00faltiplas conex\u00f5es simult\u00e2neas</li> <li>Limpeza Autom\u00e1tica: Limpeza autom\u00e1tica de dados expirados a cada 5 minutos</li> <li>Timeout de Lock: Locks expirados s\u00e3o limpos automaticamente</li> <li>Serializa\u00e7\u00e3o: JSON para objetos complexos, formato nativo para tipos simples</li> </ul>"},{"location":"pt/modules/state/#limitacoes","title":"Limita\u00e7\u00f5es","text":"<ul> <li>Escopo Local: Estado \u00e9 persistido apenas na m\u00e1quina local</li> <li>Concorr\u00eancia: Locks s\u00e3o efetivos apenas no processo local</li> <li>Tamanho: Adequado para datasets pequenos a m\u00e9dios (&lt; 1GB)</li> </ul>"},{"location":"pt/modules/state/#melhores-praticas","title":"\ud83d\udd04 Melhores Pr\u00e1ticas","text":"<ol> <li>Use TTL para dados tempor\u00e1rios para evitar crescimento desnecess\u00e1rio</li> <li>Use locks para se\u00e7\u00f5es cr\u00edticas para evitar condi\u00e7\u00f5es de corrida</li> <li>Use padr\u00f5es para opera\u00e7\u00f5es em lote para gerenciar chaves relacionadas</li> <li>Monitore o tamanho do armazenamento usando <code>state.stats()</code></li> <li>Use opera\u00e7\u00f5es at\u00f4micas em vez de padr\u00f5es read-modify-write</li> <li>Limpe chaves expiradas regularmente com <code>state.clear(padrao)</code></li> </ol> <p>O m\u00f3dulo Gerenciamento de Estado transforma o sloth-runner em uma plataforma stateful e confi\u00e1vel para orquestra\u00e7\u00e3o complexa de tarefas! \ud83d\ude80</p>"},{"location":"pt/modules/terraform/","title":"M\u00f3dulo Terraform","text":"<p>O m\u00f3dulo <code>terraform</code> fornece uma interface de alto n\u00edvel para orquestrar comandos da CLI <code>terraform</code>, permitindo que voc\u00ea gerencie o ciclo de vida de sua infraestrutura diretamente de dentro de uma pipeline do Sloth-Runner.</p>"},{"location":"pt/modules/terraform/#configuracao","title":"Configura\u00e7\u00e3o","text":"<p>Este m\u00f3dulo requer que a CLI <code>terraform</code> esteja instalada e dispon\u00edvel no PATH do sistema. Todos os comandos devem ser executados dentro de um <code>workdir</code> espec\u00edfico onde seus arquivos <code>.tf</code> est\u00e3o localizados.</p>"},{"location":"pt/modules/terraform/#funcoes","title":"Fun\u00e7\u00f5es","text":""},{"location":"pt/modules/terraform/#terraforminitparams","title":"<code>terraform.init(params)</code>","text":"<p>Inicializa um diret\u00f3rio de trabalho do Terraform.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>workdir</code> (string): Obrigat\u00f3rio. O caminho para o diret\u00f3rio que cont\u00e9m os arquivos do Terraform.</li> </ul> </li> <li>Retorna: Uma tabela de resultados com <code>success</code>, <code>stdout</code>, <code>stderr</code> e <code>exit_code</code>.</li> </ul>"},{"location":"pt/modules/terraform/#terraformplanparams","title":"<code>terraform.plan(params)</code>","text":"<p>Cria um plano de execu\u00e7\u00e3o do Terraform.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>workdir</code> (string): Obrigat\u00f3rio. O caminho para o diret\u00f3rio.</li> <li><code>out</code> (string): Opcional. O nome do arquivo para salvar o plano gerado.</li> </ul> </li> <li>Retorna: Uma tabela de resultados.</li> </ul>"},{"location":"pt/modules/terraform/#terraformapplyparams","title":"<code>terraform.apply(params)</code>","text":"<p>Aplica um plano do Terraform.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>workdir</code> (string): Obrigat\u00f3rio. O caminho para o diret\u00f3rio.</li> <li><code>plan</code> (string): Opcional. O caminho para um arquivo de plano a ser aplicado.</li> <li><code>auto_approve</code> (boolean): Opcional. Se <code>true</code>, aplica as altera\u00e7\u00f5es sem aprova\u00e7\u00e3o interativa.</li> </ul> </li> <li>Retorna: Uma tabela de resultados.</li> </ul>"},{"location":"pt/modules/terraform/#terraformdestroyparams","title":"<code>terraform.destroy(params)</code>","text":"<p>Destr\u00f3i a infraestrutura gerenciada pelo Terraform.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>workdir</code> (string): Obrigat\u00f3rio. O caminho para o diret\u00f3rio.</li> <li><code>auto_approve</code> (boolean): Opcional. Se <code>true</code>, destr\u00f3i os recursos sem aprova\u00e7\u00e3o interativa.</li> </ul> </li> <li>Retorna: Uma tabela de resultados.</li> </ul>"},{"location":"pt/modules/terraform/#terraformoutputparams","title":"<code>terraform.output(params)</code>","text":"<p>L\u00ea uma vari\u00e1vel de sa\u00edda de um arquivo de estado do Terraform.</p> <ul> <li><code>params</code> (tabela):<ul> <li><code>workdir</code> (string): Obrigat\u00f3rio. O caminho para o diret\u00f3rio.</li> <li><code>name</code> (string): Opcional. O nome de uma sa\u00edda espec\u00edfica para ler. Se omitido, todas as sa\u00eddas s\u00e3o retornadas como uma tabela.</li> </ul> </li> <li>Retorna:<ul> <li>Em caso de sucesso: O valor JSON analisado da sa\u00edda (pode ser uma string, tabela, etc.).</li> <li>Em caso de falha: <code>nil, error_message</code>.</li> </ul> </li> </ul>"},{"location":"pt/modules/terraform/#exemplo-de-ciclo-de-vida-completo","title":"Exemplo de Ciclo de Vida Completo","text":"<pre><code>local tf_workdir = \"./examples/terraform\"\n\n-- Tarefa 1: Init\nlocal result_init = terraform.init({workdir = tf_workdir})\nif not result_init.success then return false, \"Init falhou\" end\n\n-- Tarefa 2: Plan\nlocal result_plan = terraform.plan({workdir = tf_workdir})\nif not result_plan.success then return false, \"Plan falhou\" end\n\n-- Tarefa 3: Apply\nlocal result_apply = terraform.apply({workdir = tf_workdir, auto_approve = true})\nif not result_apply.success then return false, \"Apply falhou\" end\n\n-- Tarefa 4: Get Output\nlocal filename, err = terraform.output({workdir = tf_workdir, name = \"report_filename\"})\nif not filename then return false, \"Output falhou: \" .. err end\nlog.info(\"Arquivo criado pelo Terraform: \" .. filename)\n\n-- Tarefa 5: Destroy\nlocal result_destroy = terraform.destroy({workdir = tf_workdir, auto_approve = true})\nif not result_destroy.success then return false, \"Destroy falhou\" end\n</code></pre>"},{"location":"zh/","title":"Sloth-Runner \u6587\u6863","text":"<p>\u6b22\u8fce\u6765\u5230 Sloth-Runner \u7684\u5b8c\u6574\u6587\u6863\uff0c\u8fd9\u662f\u4e00\u4e2a\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u4f7f\u7528 Lua \u811a\u672c\u8fdb\u884c\u4efb\u52a1\u81ea\u52a8\u5316\u548c\u5de5\u4f5c\u6d41\u7f16\u6392\u3002</p> <p>\u5728\u8fd9\u91cc\uff0c\u60a8\u5c06\u627e\u5230\u8be6\u7ec6\u7684\u6307\u5357\u3001API \u53c2\u8003\u548c\u5b9e\u7528\u793a\u4f8b\uff0c\u4ee5\u5e2e\u52a9\u60a8\u5145\u5206\u5229\u7528 Sloth-Runner \u7684\u5f3a\u5927\u529f\u80fd\u3002</p>"},{"location":"zh/#_1","title":"\u76ee\u5f55","text":"<ul> <li>\u4efb\u52a1\u8c03\u5ea6\u5668</li> <li>\u5feb\u901f\u5165\u95e8</li> <li>\u6838\u5fc3\u6982\u5ff5</li> <li>\u5206\u5e03\u5f0f\u4efb\u52a1\u6267\u884c</li> <li>CLI \u547d\u4ee4</li> <li>\u4ea4\u4e92\u5f0f REPL</li> <li>\u5185\u7f6e\u6a21\u5757\uff1a<ul> <li>AWS \u6a21\u5757</li> <li>Azure \u6a21\u5757</li> <li>Data \u6a21\u5757</li> <li>DigitalOcean \u6a21\u5757</li> <li>Docker \u6a21\u5757</li> <li>Exec \u6a21\u5757</li> <li>FS \u6a21\u5757</li> <li>GCP \u6a21\u5757</li> <li>Git \u6a21\u5757</li> <li>Log \u6a21\u5757</li> <li>Net \u6a21\u5757</li> <li>\u901a\u77e5\u6a21\u5757</li> <li>Pulumi \u6a21\u5757</li> <li>Python \u6a21\u5757</li> <li>Salt \u6a21\u5757</li> <li>Terraform \u6a21\u5757</li> </ul> </li> <li>\u9ad8\u7ea7\u793a\u4f8b</li> <li>\u9ad8\u7ea7\u529f\u80fd</li> </ul> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"zh/CLI/","title":"CLI \u547d\u4ee4","text":"<p><code>sloth-runner</code> \u547d\u4ee4\u884c\u754c\u9762 (CLI) \u662f\u4e0e\u60a8\u7684\u4efb\u52a1\u7ba1\u9053\u4ea4\u4e92\u7684\u4e3b\u8981\u65b9\u5f0f\u3002\u5b83\u63d0\u4f9b\u4e86\u8fd0\u884c\u3001\u5217\u51fa\u3001\u9a8c\u8bc1\u548c\u7ba1\u7406\u5de5\u4f5c\u6d41\u7684\u547d\u4ee4\u3002</p>"},{"location":"zh/CLI/#sloth-runner-run","title":"<code>sloth-runner run</code>","text":"<p>\u6267\u884c\u5728 Lua \u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u4efb\u52a1\u3002\u8fd9\u662f\u60a8\u5c06\u4f7f\u7528\u7684\u6700\u5e38\u89c1\u7684\u547d\u4ee4\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner run [flags]\n</code></pre></p> <p>\u6807\u5fd7:</p> <ul> <li><code>-f, --file string</code>: (\u5fc5\u9700) Lua \u4efb\u52a1\u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>-g, --group string</code>: \u4ec5\u8fd0\u884c\u7279\u5b9a\u4efb\u52a1\u7ec4\u4e2d\u7684\u4efb\u52a1\u3002\u5982\u679c\u672a\u63d0\u4f9b\uff0c<code>sloth-runner</code> \u5c06\u8fd0\u884c\u6240\u6709\u7ec4\u4e2d\u7684\u4efb\u52a1\u3002</li> <li><code>-t, --tasks string</code>: \u8981\u8fd0\u884c\u7684\u7279\u5b9a\u4efb\u52a1\u7684\u9017\u53f7\u5206\u9694\u5217\u8868 (\u4f8b\u5982, <code>task1,task2</code>)\u3002\u5982\u679c\u672a\u63d0\u4f9b\uff0c\u5c06\u8003\u8651\u6307\u5b9a\u7ec4\uff08\u6216\u6240\u6709\u7ec4\uff09\u4e2d\u7684\u6240\u6709\u4efb\u52a1\u3002</li> <li><code>-v, --values string</code>: \u5305\u542b\u8981\u4f20\u9012\u7ed9 Lua \u811a\u672c\u7684\u503c\u7684 YAML \u6587\u4ef6\u7684\u8def\u5f84\u3002\u8fd9\u4e9b\u503c\u53ef\u901a\u8fc7\u5168\u5c40 <code>values</code> \u8868\u5728 Lua \u4e2d\u8bbf\u95ee\u3002</li> <li><code>-d, --dry-run</code>: \u6a21\u62df\u4efb\u52a1\u7684\u6267\u884c\u3002\u5b83\u5c06\u6253\u5370\u5c06\u8981\u8fd0\u884c\u7684\u4efb\u52a1\u53ca\u5176\u987a\u5e8f\uff0c\u4f46\u4e0d\u4f1a\u6267\u884c\u5b83\u4eec\u7684 <code>command</code>\u3002</li> <li><code>--return</code>: \u5c06\u5df2\u6267\u884c\u4efb\u52a1\u7684\u6700\u7ec8\u8f93\u51fa\u4f5c\u4e3a JSON \u5bf9\u8c61\u6253\u5370\u5230\u6807\u51c6\u8f93\u51fa\u3002\u8fd9\u5305\u62ec\u6700\u540e\u4e00\u4e2a\u4efb\u52a1\u7684\u8fd4\u56de\u503c\u548c\u4f20\u9012\u7ed9\u5168\u5c40 <code>export()</code> \u51fd\u6570\u7684\u4efb\u4f55\u6570\u636e\u3002</li> <li><code>-y, --yes</code>: \u5728\u672a\u4f7f\u7528 <code>-t</code> \u63d0\u4f9b\u7279\u5b9a\u4efb\u52a1\u65f6\uff0c\u7ed5\u8fc7\u4ea4\u4e92\u5f0f\u4efb\u52a1\u9009\u62e9\u63d0\u793a\u3002</li> <li><code>--interactive</code>: \u542f\u7528\u4efb\u52a1\u6267\u884c\u7684\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5728\u6bcf\u4e2a\u4efb\u52a1\u4e4b\u524d\u63d0\u793a\u7528\u6237\u8f93\u5165\u3002</li> </ul> <p>\u793a\u4f8b:</p> <ul> <li>\u8fd0\u884c\u7279\u5b9a\u7ec4\u4e2d\u7684\u6240\u6709\u4efb\u52a1:     <pre><code>sloth-runner run -f examples/basic_pipeline.sloth -g my_group\n</code></pre></li> <li>\u8fd0\u884c\u5355\u4e2a\u7279\u5b9a\u4efb\u52a1:     <pre><code>sloth-runner run -f examples/basic_pipeline.sloth -g my_group -t my_task\n</code></pre></li> <li>\u8fd0\u884c\u591a\u4e2a\u4efb\u52a1\u5e76\u5c06\u5176\u7ec4\u5408\u8f93\u51fa\u4f5c\u4e3a JSON \u83b7\u53d6:     <pre><code>sloth-runner run -f examples/export_example.sloth -t export-data-task --return\n</code></pre></li> </ul>"},{"location":"zh/CLI/#sloth-runner-list","title":"<code>sloth-runner list</code>","text":"<p>\u5217\u51fa\u5728 Lua \u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u6240\u6709\u53ef\u7528\u4efb\u52a1\u7ec4\u548c\u4efb\u52a1\uff0c\u4ee5\u53ca\u5b83\u4eec\u7684\u63cf\u8ff0\u548c\u4f9d\u8d56\u5173\u7cfb\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner list [flags]\n</code></pre></p> <p>\u6807\u5fd7:</p> <ul> <li><code>-f, --file string</code>: (\u5fc5\u9700) Lua \u4efb\u52a1\u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>-v, --values string</code>: YAML \u503c\u6587\u4ef6\u7684\u8def\u5f84\uff0c\u4ee5\u9632\u60a8\u7684\u4efb\u52a1\u5b9a\u4e49\u4f9d\u8d56\u4e8e\u5b83\u3002</li> </ul>"},{"location":"zh/CLI/#sloth-runner-new","title":"<code>sloth-runner new</code>","text":"<p>\u4ece\u6a21\u677f\u751f\u6210\u4e00\u4e2a\u65b0\u7684 Lua \u4efb\u52a1\u5b9a\u4e49\u6837\u677f\u6587\u4ef6\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner new &lt;group-name&gt; [flags]\n</code></pre></p> <p>\u53c2\u6570:</p> <ul> <li><code>&lt;group-name&gt;</code>: \u8981\u5728\u6587\u4ef6\u4e2d\u521b\u5efa\u7684\u4e3b\u4efb\u52a1\u7ec4\u7684\u540d\u79f0\u3002</li> </ul> <p>\u6807\u5fd7:</p> <ul> <li><code>-t, --template string</code>: \u8981\u4f7f\u7528\u7684\u6a21\u677f\u3002\u9ed8\u8ba4\u4e3a <code>simple</code>\u3002\u8fd0\u884c <code>sloth-runner template list</code> \u67e5\u770b\u6240\u6709\u53ef\u7528\u9009\u9879\u3002</li> <li><code>-o, --output string</code>: \u8f93\u51fa\u6587\u4ef6\u7684\u8def\u5f84\u3002\u5982\u679c\u672a\u63d0\u4f9b\uff0c\u751f\u6210\u7684\u5185\u5bb9\u5c06\u6253\u5370\u5230\u6807\u51c6\u8f93\u51fa\u3002</li> <li><code>--set key=value</code>: \u4f20\u9012\u952e\u503c\u5bf9\u5230\u6a21\u677f\uff0c\u7528\u4e8e\u52a8\u6001\u5185\u5bb9\u751f\u6210\u3002</li> </ul> <p>\u793a\u4f8b: <pre><code>sloth-runner new my-python-pipeline -t python -o my_pipeline.sloth\n</code></pre></p>"},{"location":"zh/CLI/#sloth-runner-validate","title":"<code>sloth-runner validate</code>","text":"<p>\u9a8c\u8bc1 sloth \u4efb\u52a1\u6587\u4ef6\u7684\u8bed\u6cd5\u548c\u57fa\u672c\u7ed3\u6784\uff0c\u800c\u4e0d\u6267\u884c\u4efb\u4f55\u4efb\u52a1\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner validate [flags]\n</code></pre></p> <p>\u6807\u5fd7:</p> <ul> <li><code>-f, --file string</code>: (\u5fc5\u9700) \u8981\u9a8c\u8bc1\u7684 Lua \u4efb\u52a1\u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>-v, --values string</code>: \u5982\u679c\u9a8c\u8bc1\u9700\u8981\uff0c\u5219\u4e3a YAML \u503c\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul>"},{"location":"zh/CLI/#sloth-runner-test","title":"<code>sloth-runner test</code>","text":"<p>\u5bf9\u5de5\u4f5c\u6d41\u6587\u4ef6\u6267\u884c\u57fa\u4e8e Lua \u7684\u6d4b\u8bd5\u6587\u4ef6\u3002(\u8fd9\u662f\u4e00\u4e2a\u9ad8\u7ea7\u529f\u80fd)\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner test [flags]\n</code></pre></p> <p>\u6807\u5fd7:</p> <ul> <li><code>-w, --workflow string</code>: (\u5fc5\u9700) \u8981\u6d4b\u8bd5\u7684 Lua \u5de5\u4f5c\u6d41\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>-f, --file string</code>: (\u5fc5\u9700) Lua \u6d4b\u8bd5\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul>"},{"location":"zh/CLI/#sloth-runner-template-list","title":"<code>sloth-runner template list</code>","text":"<p>\u5217\u51fa\u53ef\u4e0e <code>sloth-runner new</code> \u547d\u4ee4\u4e00\u8d77\u4f7f\u7528\u7684\u6240\u6709\u53ef\u7528\u6a21\u677f\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner template list\n</code></pre></p>"},{"location":"zh/CLI/#sloth-runner-artifacts","title":"<code>sloth-runner artifacts</code>","text":"<p>\u7ba1\u7406\u4efb\u52a1\u4ea7\u7269\uff0c\u5373\u4efb\u52a1\u751f\u6210\u7684\u6587\u4ef6\u6216\u76ee\u5f55\u3002</p> <p>\u5b50\u547d\u4ee4:</p> <ul> <li><code>sloth-runner artifacts list</code>: \u5217\u51fa\u6240\u6709\u6536\u96c6\u7684\u4ea7\u7269\u3002</li> <li><code>sloth-runner artifacts get &lt;artifact_path&gt;</code>: \u4e0b\u8f7d\u7279\u5b9a\u7684\u4ea7\u7269\u3002</li> <li><code>sloth-runner artifacts clean</code>: \u6e05\u7406\u65e7\u7684\u6216\u4e0d\u9700\u8981\u7684\u4ea7\u7269\u3002</li> </ul>"},{"location":"zh/CLI/#sloth-runner-version","title":"<code>sloth-runner version</code>","text":"<p>\u6253\u5370 <code>sloth-runner</code> \u5e94\u7528\u7a0b\u5e8f\u7684\u5f53\u524d\u7248\u672c\u3002</p> <p>\u7528\u6cd5: <pre><code>sloth-runner version\n</code></pre></p>"},{"location":"zh/CLI/#sloth-runner-scheduler","title":"<code>sloth-runner scheduler</code>","text":"<p>\u7ba1\u7406 <code>sloth-runner</code> \u4efb\u52a1\u8c03\u5ea6\u5668\uff0c\u5141\u8bb8\u60a8\u542f\u7528\u3001\u7981\u7528\u3001\u5217\u51fa\u548c\u5220\u9664\u8c03\u5ea6\u4efb\u52a1\u3002</p> <p>\u6709\u5173\u8c03\u5ea6\u5668\u547d\u4ee4\u548c\u914d\u7f6e\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 \u4efb\u52a1\u8c03\u5ea6\u5668\u6587\u6863\u3002</p> <p>\u5b50\u547d\u4ee4:</p> <ul> <li><code>sloth-runner scheduler enable</code>: \u5c06\u8c03\u5ea6\u5668\u4f5c\u4e3a\u540e\u53f0\u8fdb\u7a0b\u542f\u52a8\u3002</li> <li><code>sloth-runner scheduler disable</code>: \u505c\u6b62\u6b63\u5728\u8fd0\u884c\u7684\u8c03\u5ea6\u5668\u8fdb\u7a0b\u3002</li> <li><code>sloth-runner scheduler list</code>: \u5217\u51fa\u6240\u6709\u5df2\u914d\u7f6e\u7684\u8c03\u5ea6\u4efb\u52a1\u3002</li> <li><code>sloth-runner scheduler delete &lt;task_name&gt;</code>: \u5220\u9664\u7279\u5b9a\u7684\u8c03\u5ea6\u4efb\u52a1\u3002</li> </ul>"},{"location":"zh/advanced-examples/","title":"\u9ad8\u7ea7\u793a\u4f8b","text":"<p>\u672c\u8282\u4ecb\u7ecd\u4e86\u66f4\u590d\u6742\u7684\u793a\u4f8b\u548c\u7528\u4f8b\uff0c\u5b83\u4eec\u7ed3\u5408\u4e86\u591a\u4e2a Sloth-Runner \u6a21\u5757\u4ee5\u5b9e\u73b0\u7aef\u5230\u7aef\u81ea\u52a8\u5316\u3002</p>"},{"location":"zh/advanced-examples/#cicd","title":"\u5b8c\u6574\u793a\u4f8b\uff1a\u7aef\u5230\u7aef CI/CD \u6d41\u6c34\u7ebf","text":"<p>\u672c\u6559\u7a0b\u6f14\u793a\u4e86\u5982\u4f55\u4f7f\u7528 <code>git</code>\u3001<code>pulumi</code> \u548c <code>salt</code> \u6a21\u5757\u6784\u5efa\u5b8c\u6574\u7684 CI/CD \u6d41\u6c34\u7ebf\uff0c\u4ee5\u7248\u672c\u5316\u4ee3\u7801\u3001\u9884\u7f6e\u57fa\u7840\u8bbe\u65bd\u548c\u90e8\u7f72\u5e94\u7528\u7a0b\u5e8f\u3002</p>"},{"location":"zh/advanced-examples/#_2","title":"\u573a\u666f","text":"<p>\u5047\u8bbe\u60a8\u6709\u4e00\u4e2a Pulumi \u57fa\u7840\u8bbe\u65bd\u9879\u76ee\u548c\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u9879\u76ee\u3002\u60a8\u5e0c\u671b\u81ea\u52a8\u5316\u4ee5\u4e0b\u6d41\u7a0b\uff1a</p> <ol> <li>\u514b\u9686\u57fa\u7840\u8bbe\u65bd\u5b58\u50a8\u5e93\u3002</li> <li>\u66f4\u65b0\u5b58\u50a8\u5e93\u4e2d\u7684\u7248\u672c\u6587\u4ef6\u3002</li> <li>\u63d0\u4ea4\u5e76\u5c06\u6b64\u66f4\u6539\u63a8\u9001\u5230 Git\u3002</li> <li>\u6267\u884c <code>pulumi up</code> \u4ee5\u9884\u7f6e\u6216\u66f4\u65b0\u57fa\u7840\u8bbe\u65bd\uff08\u4f8b\u5982\uff0c\u6682\u5b58\u73af\u5883\uff09\u3002</li> <li>\u4f7f\u7528 Salt \u914d\u7f6e\u9884\u7f6e\u7684\u670d\u52a1\u5668\u5e76\u90e8\u7f72\u5e94\u7528\u7a0b\u5e8f\u3002</li> </ol>"},{"location":"zh/advanced-examples/#lua-examplespulumi_git_combined_examplesloth","title":"Lua \u811a\u672c (<code>examples/pulumi_git_combined_example.sloth</code>)","text":"<pre><code>-- examples/pulumi_git_combined_example.sloth\n\ncommand = function(params)\n    log.info(\"Starting combined Pulumi and Git example...\")\n\n    local pulumi_repo_url = \"https://github.com/my-org/my-pulumi-infra.git\" -- Example Pulumi repo\n    local pulumi_repo_path = \"./pulumi-infra-checkout\"\n    local new_infra_version = params.infra_version or \"v1.0.0-infra\"\n    local pulumi_project_workdir = pulumi_repo_path .. \"/my-vpc-project\" -- Subdirectory within the cloned repo\n    local repo\n\n    -- 1. Clone or open the Pulumi repository\n    log.info(\"Step 1: Cloning or opening Pulumi repository...\")\n    if not fs.exists(pulumi_repo_path) then\n        log.info(\"Cloning Pulumi repository: \" .. pulumi_repo_url)\n        local cloned_repo, clone_err = git.clone(pulumi_repo_url, pulumi_repo_path)\n        if clone_err then\n            log.error(\"Failed to clone Pulumi repository: \" .. clone_err)\n            return false, \"Git clone failed.\"\n        end\n        repo = cloned_repo\n    else\n        log.info(\"Pulumi repository already exists, opening local reference.\")\n        local opened_repo, open_err = git.repo(pulumi_repo_path)\n        if open_err then\n            log.error(\"Failed to open Pulumi repository: \" .. open_err)\n            return false, \"Git repo open failed.\"\n        end\n        repo = opened_repo\n    end\n\n    if not repo then\n        return false, \"Failed to get Pulumi repository reference.\"\n    end\n\n    -- 2. Update the repository (pull)\n    log.info(\"Step 2: Pulling latest changes from Pulumi repository...\")\n    repo:checkout(\"main\"):pull(\"origin\", \"main\")\n    local pull_result = repo:result()\n    if not pull_result.success then\n        log.error(\"Failed to pull Pulumi repository: \" .. pull_result.stderr)\n        return false, \"Git pull failed.\"\n    end\n    log.info(\"Pulumi repository updated. Stdout: \" .. pull_result.stdout)\n\n    -- 3. Simulate a change in the Pulumi code (e.g., update a version file)\n    log.info(\"Step 3: Simulating a change in Pulumi code (updating version file)...\")\n    local infra_version_file = pulumi_repo_path .. \"/INFRA_VERSION\"\n    fs.write(infra_version_file, new_infra_version)\n    log.info(\"Updated INFRA_VERSION file to: \" .. new_infra_version)\n\n    -- 4. Commit and push the changes\n    log.info(\"Step 4: Committing and pushing infrastructure version change...\")\n    local commit_message = \"ci: Bump infrastructure version to \" .. new_infra_version\n    repo:add(infra_version_file)\n        :commit(commit_message)\n        :push(\"origin\", \"main\") -- No follow_tags here, just the commit\n\n    local push_result = repo:result()\n    if not push_result.success then\n        log.error(\"Failed to push infrastructure changes: \" .. push_result.stderr)\n        return false, \"Git push failed for infra changes.\"\n    end\n    log.info(\"Infrastructure version change pushed. Stdout: \" .. push_result.stdout)\n\n    -- 5. Execute 'pulumi up' for the project\n    log.info(\"Step 5: Running pulumi up for the infrastructure project...\")\n    local infra_stack = pulumi.stack(\"my-org/my-infra/dev\", {\n        workdir = pulumi_project_workdir -- Use the subdirectory of the Pulumi project\n    })\n\n    local pulumi_up_result = infra_stack:up({ non_interactive = true })\n\n    if not pulumi_up_result.success then\n        log.error(\"Pulumi up failed: \" .. pulumi_up_result.stderr)\n        return false, \"Pulumi up failed.\"\n    end\n    log.info(\"Pulumi up completed successfully. Stdout: \" .. pulumi_up_result.stdout)\n\n    -- 6. Configure and deploy application using Salt (Example)\n    log.info(\"Step 6: Configuring and deploying application using Salt...\")\n    -- Assuming Pulumi up provided the server IP or hostname\n    -- For this example, we'll use a fictitious IP\n    local server_ip = \"192.168.1.100\" -- Replace with actual output from Pulumi, if any\n    local salt_target = salt.target(server_ip)\n\n    log.info(\"Running Salt test.ping on \" .. server_ip .. \"...\")\n    salt_target:ping()\n    local ping_result = salt_target:result()\n    if not ping_result.success then\n        log.error(\"Salt ping failed for \" .. server_ip .. \": \" .. ping_result.stderr)\n        return false, \"Salt ping failed.\"\n    end\n    log.info(\"Salt ping successful. Stdout: \" .. data.to_json(ping_result.stdout)) -- Assuming ping returns JSON\n\n    log.info(\"Applying Salt state 'app.install' on \" .. server_ip .. \"...\")\n    salt_target:cmd('state.apply', 'app.install')\n    local salt_apply_result = salt_target:result()\n    if not salt_apply_result.success then\n        log.error(\"Salt state.apply failed for \" .. server_ip .. \": \" .. salt_apply_result.stderr)\n        return false, \"Salt state.apply failed.\"\n    end\n    log.info(\"Salt state.apply successful. Stdout: \" .. data.to_json(salt_apply_result.stdout))\n\n    log.info(\"Combined Pulumi and Git example finished successfully.\")\n    return true, \"Combined Pulumi and Git example finished.\"\nend\n\nModern DSLs = {\n    pulumi_git_combined_example = {\n        description = \"Demonstrates combined usage of 'pulumi' and 'git' modules for CI/CD pipeline.\",\n        tasks = {\n            {\n                name = \"run_combined_example\",\n                command = command,\n                params = {\n                    infra_version = \"v1.0.0-test-combined\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"zh/advanced-features/","title":"\u9ad8\u7ea7\u529f\u80fd","text":"<p>\u672c\u6587\u6863\u4ecb\u7ecd <code>sloth-runner</code> \u7684\u4e00\u4e9b\u66f4\u9ad8\u7ea7\u7684\u529f\u80fd\uff0c\u65e8\u5728\u589e\u5f3a\u60a8\u7684\u5f00\u53d1\u3001\u8c03\u8bd5\u548c\u914d\u7f6e\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"zh/advanced-features/#_2","title":"\u4ea4\u4e92\u5f0f\u4efb\u52a1\u8fd0\u884c\u5668","text":"<p>\u5bf9\u4e8e\u590d\u6742\u7684\u5de5\u4f5c\u6d41\uff0c\u9010\u4e2a\u6267\u884c\u4efb\u52a1\u3001\u68c0\u67e5\u5176\u8f93\u51fa\u5e76\u51b3\u5b9a\u662f\u7ee7\u7eed\u3001\u8df3\u8fc7\u8fd8\u662f\u91cd\u8bd5\u4efb\u52a1\u53ef\u80fd\u5f88\u6709\u7528\u3002\u4ea4\u4e92\u5f0f\u4efb\u52a1\u8fd0\u884c\u5668\u4e3a\u8c03\u8bd5\u548c\u5f00\u53d1\u4efb\u52a1\u7ba1\u9053\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u7684\u65b9\u6cd5\u3002</p> <p>\u8981\u4f7f\u7528\u4ea4\u4e92\u5f0f\u8fd0\u884c\u5668\uff0c\u8bf7\u5c06 <code>--interactive</code> \u6807\u5fd7\u6dfb\u52a0\u5230 <code>sloth-runner run</code> \u547d\u4ee4\u4e2d\uff1a</p> <pre><code>sloth-runner run -f examples/basic_pipeline.sloth --yes --interactive\n</code></pre> <p>\u542f\u7528\u540e\uff0c\u8fd0\u884c\u5668\u5c06\u5728\u6267\u884c\u6bcf\u4e2a\u4efb\u52a1\u4e4b\u524d\u6682\u505c\u5e76\u63d0\u793a\u60a8\u6267\u884c\u64cd\u4f5c\uff1a</p> <pre><code>? \u4efb\u52a1: fetch_data (\u6a21\u62df\u83b7\u53d6\u539f\u59cb\u6570\u636e)\n&gt; \u8fd0\u884c\n  \u8df3\u8fc7\n  \u4e2d\u6b62\n  \u7ee7\u7eed\n</code></pre> <p>\u64cd\u4f5c:</p> <ul> <li>\u8fd0\u884c: (\u9ed8\u8ba4) \u7ee7\u7eed\u6267\u884c\u5f53\u524d\u4efb\u52a1\u3002</li> <li>\u8df3\u8fc7: \u8df3\u8fc7\u5f53\u524d\u4efb\u52a1\u5e76\u8f6c\u5230\u6267\u884c\u987a\u5e8f\u4e2d\u7684\u4e0b\u4e00\u4e2a\u4efb\u52a1\u3002</li> <li>\u4e2d\u6b62: \u7acb\u5373\u4e2d\u6b62\u6574\u4e2a\u4efb\u52a1\u6267\u884c\u3002</li> <li>\u7ee7\u7eed: \u6267\u884c\u5f53\u524d\u4efb\u52a1\u548c\u6240\u6709\u540e\u7eed\u4efb\u52a1\uff0c\u4e0d\u518d\u63d0\u793a\uff0c\u4ece\u800c\u6709\u6548\u5730\u4e3a\u4f59\u4e0b\u7684\u8fd0\u884c\u7981\u7528\u4ea4\u4e92\u6a21\u5f0f\u3002</li> </ul>"},{"location":"zh/advanced-features/#valuesyaml","title":"\u589e\u5f3a\u7684 <code>values.yaml</code> \u6a21\u677f","text":"<p>\u60a8\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 Go \u6a21\u677f\u8bed\u6cd5\u6ce8\u5165\u73af\u5883\u53d8\u91cf\u6765\u4f7f <code>values.yaml</code> \u6587\u4ef6\u66f4\u52a0\u52a8\u6001\u3002\u8fd9\u5bf9\u4e8e\u63d0\u4f9b\u654f\u611f\u4fe1\u606f\uff08\u5982\u4ee4\u724c\u6216\u5bc6\u94a5\uff09\u6216\u7279\u5b9a\u4e8e\u73af\u5883\u7684\u914d\u7f6e\u7279\u522b\u6709\u7528\uff0c\u800c\u65e0\u9700\u5bf9\u5176\u8fdb\u884c\u786c\u7f16\u7801\u3002</p> <p><code>sloth-runner</code> \u5c06 <code>values.yaml</code> \u4f5c\u4e3a Go \u6a21\u677f\u5904\u7406\uff0c\u4f7f\u4efb\u4f55\u73af\u5883\u53d8\u91cf\u90fd\u53ef\u4ee5\u5728 <code>.Env</code> \u6620\u5c04\u4e0b\u4f7f\u7528\u3002</p> <p>\u793a\u4f8b:</p> <ol> <li> <p>\u521b\u5efa\u4e00\u4e2a\u5e26\u6709\u6a21\u677f\u5360\u4f4d\u7b26\u7684 <code>values.yaml</code> \u6587\u4ef6\uff1a</p> <p><pre><code># values.yaml\napi_key: \"{{ .Env.MY_API_KEY }}\"\nregion: \"{{ .Env.AWS_REGION | default \"us-east-1\" }}\"\n</code></pre> \u6ce8\u610f\uff1a\u5982\u679c\u672a\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528 <code>default</code> \u63d0\u4f9b\u5907\u7528\u503c\u3002</p> </li> <li> <p>\u521b\u5efa\u4e00\u4e2a\u4f7f\u7528\u8fd9\u4e9b\u503c\u7684 Lua \u4efb\u52a1\uff1a</p> <pre><code>-- my_task.sloth\nModern DSLs = {\n  my_group = {\n    tasks = {\n      {\n        name = \"deploy\",\n        command = function()\n          log.info(\"\u90e8\u7f72\u5230\u533a\u57df: \" .. values.region)\n          log.info(\"\u4f7f\u7528 API \u5bc6\u94a5 (\u524d 5 \u4e2a\u5b57\u7b26): \" .. string.sub(values.api_key, 1, 5) .. \"...\")\n          return true, \"\u90e8\u7f72\u6210\u529f\u3002\"\n        end\n      }\n    }\n  }\n}\n</code></pre> </li> <li> <p>\u5728\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\u7684\u60c5\u51b5\u4e0b\u8fd0\u884c\u4efb\u52a1\uff1a</p> <pre><code>export MY_API_KEY=\"supersecretkey12345\"\nexport AWS_REGION=\"us-west-2\"\n\nsloth-runner run -f my_task.sloth -v values.yaml --yes\n</code></pre> </li> </ol> <p>\u8f93\u51fa:</p> <p>\u8f93\u51fa\u5c06\u663e\u793a\u73af\u5883\u53d8\u91cf\u4e2d\u7684\u503c\u5df2\u6b63\u786e\u66ff\u6362\uff1a</p> <pre><code>INFO \u90e8\u7f72\u5230\u533a\u57df: us-west-2\nINFO \u4f7f\u7528 API \u5bc6\u94a5 (\u524d 5 \u4e2a\u5b57\u7b26): super...\n</code></pre>"},{"location":"zh/core-concepts/","title":"\u6838\u5fc3\u6982\u5ff5","text":"<p>\u672c\u6587\u6863\u89e3\u91ca\u4e86 <code>sloth-runner</code> \u7684\u57fa\u672c\u6982\u5ff5\uff0c\u5e2e\u52a9\u60a8\u7406\u89e3\u5982\u4f55\u5b9a\u4e49\u548c\u7f16\u6392\u590d\u6742\u7684\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"zh/core-concepts/#modern-dsls","title":"<code>Modern DSLs</code> \u8868","text":"<p>\u4efb\u4f55 <code>sloth-runner</code> \u5de5\u4f5c\u6d41\u7684\u5165\u53e3\u70b9\u90fd\u662f\u4e00\u4e2a\u8fd4\u56de\u540d\u4e3a <code>Modern DSLs</code> \u7684\u5168\u5c40 Lua \u8868\u7684 Lua \u6587\u4ef6\u3002\u6b64\u8868\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u5176\u4e2d\u6bcf\u4e2a\u952e\u90fd\u662f\u4e00\u4e2a \u4efb\u52a1\u7ec4 \u540d\u79f0\u3002</p> <pre><code>-- my_pipeline.sloth\nModern DSLs = {\n  -- \u5728\u6b64\u5904\u5b9a\u4e49\u4efb\u52a1\u7ec4\n}\n</code></pre>"},{"location":"zh/core-concepts/#_2","title":"\u4efb\u52a1\u7ec4","text":"<p>\u4efb\u52a1\u7ec4\u662f\u76f8\u5173\u4efb\u52a1\u7684\u96c6\u5408\u3002\u5b83\u8fd8\u53ef\u4ee5\u5b9a\u4e49\u5f71\u54cd\u5176\u4e2d\u6240\u6709\u4efb\u52a1\u7684\u5c5e\u6027\u3002</p> <p>\u7ec4\u5c5e\u6027:</p> <ul> <li><code>description</code> (string): \u7ec4\u529f\u80fd\u7684\u63cf\u8ff0\u3002</li> <li><code>tasks</code> (table): \u5355\u4e2a\u4efb\u52a1\u8868\u7684\u5217\u8868\u3002</li> <li><code>create_workdir_before_run</code> (boolean): \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u5728\u4efb\u4f55\u4efb\u52a1\u8fd0\u884c\u4e4b\u524d\u4e3a\u8be5\u7ec4\u521b\u5efa\u4e00\u4e2a\u4e34\u65f6\u5de5\u4f5c\u76ee\u5f55\u3002\u6b64\u76ee\u5f55\u4f1a\u4f20\u9012\u7ed9\u6bcf\u4e2a\u4efb\u52a1\u3002</li> <li><code>clean_workdir_after_run</code> (function): \u4e00\u4e2a Lua \u51fd\u6570\uff0c\u7528\u4e8e\u51b3\u5b9a\u5728\u7ec4\u5b8c\u6210\u540e\u662f\u5426\u5e94\u5220\u9664\u4e34\u65f6\u5de5\u4f5c\u76ee\u5f55\u3002\u5b83\u63a5\u6536\u7ec4\u7684\u6700\u7ec8\u7ed3\u679c (<code>{success = true/false, ...}</code>)\u3002\u8fd4\u56de <code>true</code> \u5c06\u5220\u9664\u76ee\u5f55\u3002</li> </ul> <p>\u793a\u4f8b: <pre><code>Modern DSLs = {\n  my_group = {\n    description = \"\u4e00\u4e2a\u7ba1\u7406\u81ea\u5df1\u4e34\u65f6\u76ee\u5f55\u7684\u7ec4\u3002\",\n    create_workdir_before_run = true,\n    clean_workdir_after_run = function(result)\n      if not result.success then\n        log.warn(\"\u7ec4\u5931\u8d25\u3002\u5de5\u4f5c\u76ee\u5f55\u5c06\u4fdd\u7559\u7528\u4e8e\u8c03\u8bd5\u3002\")\n      end\n      return result.success -- \u4ec5\u5728\u4e00\u5207\u6210\u529f\u65f6\u6e05\u7406\n    end,\n    tasks = {\n      -- \u4efb\u52a1\u5728\u6b64\u5904\u5b9a\u4e49\n    }\n  }\n}\n</code></pre></p>"},{"location":"zh/core-concepts/#_3","title":"\u5355\u4e2a\u4efb\u52a1","text":"<p>\u4efb\u52a1\u662f\u5de5\u4f5c\u7684\u5355\u4e2a\u5355\u5143\u3002\u5b83\u88ab\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u5177\u6709\u591a\u4e2a\u53ef\u7528\u5c5e\u6027\u4ee5\u63a7\u5236\u5176\u884c\u4e3a\u7684\u8868\u3002</p>"},{"location":"zh/core-concepts/#_4","title":"\u57fa\u672c\u5c5e\u6027","text":"<ul> <li><code>name</code> (string): \u4efb\u52a1\u5728\u5176\u7ec4\u4e2d\u7684\u552f\u4e00\u540d\u79f0\u3002</li> <li><code>description</code> (string): \u4efb\u52a1\u529f\u80fd\u7684\u7b80\u8981\u63cf\u8ff0\u3002</li> <li><code>command</code> (string \u6216 function): \u4efb\u52a1\u7684\u6838\u5fc3\u64cd\u4f5c\u3002<ul> <li>\u4f5c\u4e3a\u5b57\u7b26\u4e32: \u4f5c\u4e3a shell \u547d\u4ee4\u6267\u884c\u3002</li> <li>\u4f5c\u4e3a\u51fd\u6570: \u6267\u884c Lua \u51fd\u6570\u3002\u5b83\u63a5\u6536\u4e24\u4e2a\u53c2\u6570\uff1a<code>params</code> (\u5176\u53c2\u6570\u8868) \u548c <code>deps</code> (\u5176\u4f9d\u8d56\u9879\u7684\u8f93\u51fa\u8868)\u3002\u8be5\u51fd\u6570\u5fc5\u987b\u8fd4\u56de\uff1a<ol> <li><code>boolean</code>: <code>true</code> \u8868\u793a\u6210\u529f\uff0c<code>false</code> \u8868\u793a\u5931\u8d25\u3002</li> <li><code>string</code>: \u63cf\u8ff0\u7ed3\u679c\u7684\u6d88\u606f\u3002</li> <li><code>table</code> (\u53ef\u9009): \u5176\u4ed6\u4efb\u52a1\u53ef\u4ee5\u4f9d\u8d56\u7684\u8f93\u51fa\u8868\u3002</li> </ol> </li> </ul> </li> </ul>"},{"location":"zh/core-concepts/#_5","title":"\u4f9d\u8d56\u4e0e\u6267\u884c\u6d41\u7a0b","text":"<ul> <li><code>depends_on</code> (string \u6216 table): \u5728\u6b64\u4efb\u52a1\u8fd0\u884c\u4e4b\u524d\u5fc5\u987b\u6210\u529f\u5b8c\u6210\u7684\u4efb\u52a1\u540d\u79f0\u5217\u8868\u3002</li> <li><code>next_if_fail</code> (string \u6216 table): \u4ec5\u5f53 \u6b64\u4efb\u52a1\u5931\u8d25\u65f6\u624d\u8fd0\u884c\u7684\u4efb\u52a1\u540d\u79f0\u5217\u8868\u3002\u8fd9\u5bf9\u4e8e\u6e05\u7406\u6216\u901a\u77e5\u4efb\u52a1\u5f88\u6709\u7528\u3002</li> <li><code>async</code> (boolean): \u5982\u679c\u4e3a <code>true</code>\uff0c\u4efb\u52a1\u5c06\u5728\u540e\u53f0\u8fd0\u884c\uff0c\u8fd0\u884c\u5668\u4e0d\u4f1a\u7b49\u5f85\u5b83\u5b8c\u6210\u518d\u5f00\u59cb\u6267\u884c\u987a\u5e8f\u4e2d\u7684\u4e0b\u4e00\u4e2a\u4efb\u52a1\u3002</li> </ul>"},{"location":"zh/core-concepts/#_6","title":"\u9519\u8bef\u5904\u7406\u4e0e\u7a33\u5065\u6027","text":"<ul> <li><code>retries</code> (number): \u5982\u679c\u4efb\u52a1\u5931\u8d25\uff0c\u91cd\u8bd5\u7684\u6b21\u6570\u3002\u9ed8\u8ba4\u4e3a <code>0</code>\u3002</li> <li><code>timeout</code> (string): \u4e00\u4e2a\u6301\u7eed\u65f6\u95f4 (\u4f8b\u5982 <code>\"10s\"</code>, <code>\"1m\"</code>), \u5982\u679c\u4efb\u52a1\u4ecd\u5728\u8fd0\u884c\uff0c\u5219\u5728\u6b64\u65f6\u95f4\u540e\u7ec8\u6b62\u3002</li> </ul>"},{"location":"zh/core-concepts/#_7","title":"\u6761\u4ef6\u6267\u884c","text":"<ul> <li><code>run_if</code> (string \u6216 function): \u9664\u975e\u6ee1\u8db3\u6b64\u6761\u4ef6\uff0c\u5426\u5219\u5c06\u8df3\u8fc7\u8be5\u4efb\u52a1\u3002<ul> <li>\u4f5c\u4e3a\u5b57\u7b26\u4e32: \u4e00\u4e2a shell \u547d\u4ee4\u3002\u9000\u51fa\u4ee3\u7801 <code>0</code> \u8868\u793a\u6761\u4ef6\u6ee1\u8db3\u3002</li> <li>\u4f5c\u4e3a\u51fd\u6570: \u4e00\u4e2a\u8fd4\u56de <code>true</code> \u8868\u793a\u4efb\u52a1\u5e94\u8fd0\u884c\u7684 Lua \u51fd\u6570\u3002</li> </ul> </li> <li><code>abort_if</code> (string \u6216 function): \u5982\u679c\u6ee1\u8db3\u6b64\u6761\u4ef6\uff0c\u6574\u4e2a\u5de5\u4f5c\u6d41\u5c06\u88ab\u4e2d\u6b62\u3002<ul> <li>\u4f5c\u4e3a\u5b57\u7b26\u4e32: \u4e00\u4e2a shell \u547d\u4ee4\u3002\u9000\u51fa\u4ee3\u7801 <code>0</code> \u8868\u793a\u4e2d\u6b62\u3002</li> <li>\u4f5c\u4e3a\u51fd\u6570: \u4e00\u4e2a\u8fd4\u56de <code>true</code> \u8868\u793a\u4e2d\u6b62\u7684 Lua \u51fd\u6570\u3002</li> </ul> </li> </ul>"},{"location":"zh/core-concepts/#_8","title":"\u751f\u547d\u5468\u671f\u94a9\u5b50","text":"<ul> <li><code>pre_exec</code> (function): \u5728\u4e3b <code>command</code> \u4e4b\u524d \u8fd0\u884c\u7684 Lua \u51fd\u6570\u3002</li> <li><code>post_exec</code> (function): \u5728\u4e3b <code>command</code> \u6210\u529f\u5b8c\u6210 \u4e4b\u540e \u8fd0\u884c\u7684 Lua \u51fd\u6570\u3002</li> </ul>"},{"location":"zh/core-concepts/#_9","title":"\u53ef\u91cd\u7528\u6027","text":"<ul> <li><code>uses</code> (table): \u6307\u5b9a\u4ece\u53e6\u4e00\u4e2a\u6587\u4ef6\uff08\u901a\u8fc7 <code>import</code> \u52a0\u8f7d\uff09\u7684\u9884\u5b9a\u4e49\u4efb\u52a1\u4f5c\u4e3a\u57fa\u7840\u3002\u7136\u540e\uff0c\u5f53\u524d\u4efb\u52a1\u5b9a\u4e49\u53ef\u4ee5\u8986\u76d6 <code>params</code> \u6216 <code>description</code> \u7b49\u5c5e\u6027\u3002</li> <li><code>params</code> (table): \u53ef\u4ee5\u4f20\u9012\u7ed9\u4efb\u52a1\u7684 <code>command</code> \u51fd\u6570\u7684\u952e\u503c\u5bf9\u5b57\u5178\u3002</li> <li><code>artifacts</code> (string \u6216 table): \u4e00\u4e2a\u6587\u4ef6\u6a21\u5f0f (glob) \u6216\u6a21\u5f0f\u5217\u8868\uff0c\u6307\u5b9a\u6210\u529f\u8fd0\u884c\u540e\u5e94\u5c06\u4efb\u52a1 <code>workdir</code> \u4e2d\u7684\u54ea\u4e9b\u6587\u4ef6\u4fdd\u5b58\u4e3a\u5de5\u4ef6\u3002</li> <li><code>consumes</code> (string \u6216 table): \u524d\u4e00\u4e2a\u4efb\u52a1\u7684\u5de5\u4ef6\u540d\u79f0\uff08\u6216\u540d\u79f0\u5217\u8868\uff09\uff0c\u5728\u8fd0\u884c\u6b64\u4efb\u52a1\u4e4b\u524d\u5e94\u5c06\u5176\u590d\u5236\u5230\u6b64\u4efb\u52a1\u7684 <code>workdir</code> \u4e2d\u3002</li> </ul>"},{"location":"zh/core-concepts/#_10","title":"\u5de5\u4ef6\u7ba1\u7406","text":"<p>Sloth-Runner \u5141\u8bb8\u4efb\u52a1\u901a\u8fc7\u5de5\u4ef6\u673a\u5236\u76f8\u4e92\u5171\u4eab\u6587\u4ef6\u3002\u4e00\u4e2a\u4efb\u52a1\u53ef\u4ee5\u201c\u751f\u4ea7\u201d\u4e00\u4e2a\u6216\u591a\u4e2a\u6587\u4ef6\u4f5c\u4e3a\u5de5\u4ef6\uff0c\u540e\u7eed\u4efb\u52a1\u53ef\u4ee5\u201c\u6d88\u8d39\u201d\u8fd9\u4e9b\u5de5\u4ef6\u3002</p> <p>\u8fd9\u5bf9\u4e8e CI/CD \u7ba1\u9053\u975e\u5e38\u6709\u7528\uff0c\u5176\u4e2d\u6784\u5efa\u6b65\u9aa4\u53ef\u80fd\u4f1a\u751f\u6210\u4e00\u4e2a\u4e8c\u8fdb\u5236\u6587\u4ef6\uff08\u5de5\u4ef6\uff09\uff0c\u7136\u540e\u7531\u6d4b\u8bd5\u6216\u90e8\u7f72\u6b65\u9aa4\u4f7f\u7528\u3002</p>"},{"location":"zh/core-concepts/#_11","title":"\u5de5\u4f5c\u539f\u7406","text":"<ol> <li> <p>\u751f\u4ea7\u5de5\u4ef6: \u5c06 <code>artifacts</code> \u952e\u6dfb\u52a0\u5230\u60a8\u7684\u4efb\u52a1\u5b9a\u4e49\u4e2d\u3002\u8be5\u503c\u53ef\u4ee5\u662f\u5355\u4e2a\u6587\u4ef6\u6a21\u5f0f (\u4f8b\u5982 <code>\"report.txt\"</code>) \u6216\u5217\u8868 (\u4f8b\u5982 <code>{\"*.log\", \"app.bin\"}</code>)\u3002\u4efb\u52a1\u6210\u529f\u8fd0\u884c\u540e\uff0c\u8fd0\u884c\u5668\u5c06\u5728\u4efb\u52a1\u7684 <code>workdir</code> \u4e2d\u67e5\u627e\u4e0e\u8fd9\u4e9b\u6a21\u5f0f\u5339\u914d\u7684\u6587\u4ef6\uff0c\u5e76\u5c06\u5b83\u4eec\u590d\u5236\u5230\u7ba1\u9053\u7684\u5171\u4eab\u5de5\u4ef6\u5b58\u50a8\u4e2d\u3002</p> </li> <li> <p>\u6d88\u8d39\u5de5\u4ef6: \u5c06 <code>consumes</code> \u952e\u6dfb\u52a0\u5230\u53e6\u4e00\u4e2a\u4efb\u52a1\u7684\u5b9a\u4e49\u4e2d\uff08\u901a\u5e38 <code>depends_on</code> \u751f\u4ea7\u8005\u4efb\u52a1\uff09\u3002\u8be5\u503c\u5e94\u8be5\u662f\u60a8\u8981\u4f7f\u7528\u7684\u5de5\u4ef6\u7684\u6587\u4ef6\u540d (\u4f8b\u5982 <code>\"report.txt\"</code>)\u3002\u5728\u6b64\u4efb\u52a1\u8fd0\u884c\u4e4b\u524d\uff0c\u8fd0\u884c\u5668\u4f1a\u5c06\u6307\u5b9a\u7684\u5de5\u4ef6\u4ece\u5171\u4eab\u5b58\u50a8\u590d\u5236\u5230\u6b64\u4efb\u52a1\u7684 <code>workdir</code> \u4e2d\uff0c\u4f7f\u5176\u53ef\u7528\u4e8e <code>command</code>\u3002</p> </li> </ol>"},{"location":"zh/core-concepts/#_12","title":"\u5de5\u4ef6\u793a\u4f8b","text":"<pre><code>Modern DSLs = {\n  [\"ci-pipeline\"] = {\n    description = \"\u6f14\u793a\u5de5\u4ef6\u7684\u4f7f\u7528\u3002\",\n    create_workdir_before_run = true,\n    tasks = {\n      {\n        name = \"build\",\n        description = \"\u521b\u5efa\u4e00\u4e2a\u4e8c\u8fdb\u5236\u6587\u4ef6\u5e76\u5c06\u5176\u58f0\u660e\u4e3a\u5de5\u4ef6\u3002\",\n        command = \"echo 'binary_content' &gt; app.bin\",\n        artifacts = {\"app.bin\"}\n      },\n      {\n        name = \"test\",\n        description = \"\u6d88\u8d39\u4e8c\u8fdb\u5236\u6587\u4ef6\u4ee5\u8fd0\u884c\u6d4b\u8bd5\u3002\",\n        depends_on = \"build\",\n        consumes = {\"app.bin\"},\n        command = function(params)\n          -- \u6b64\u65f6, 'app.bin' \u5b58\u5728\u4e8e\u6b64\u4efb\u52a1\u7684 workdir \u4e2d\n          local content, err = fs.read(params.workdir .. \"/app.bin\")\n          if content == \"binary_content\" then\n            log.info(\"\u6210\u529f\u6d88\u8d39\u5de5\u4ef6\uff01\")\n            return true\n          else\n            return false, \"\u5de5\u4ef6\u5185\u5bb9\u4e0d\u6b63\u786e\uff01\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"zh/core-concepts/#_13","title":"\u5168\u5c40\u51fd\u6570","text":"<p><code>sloth-runner</code> \u5728 Lua \u73af\u5883\u4e2d\u63d0\u4f9b\u5168\u5c40\u51fd\u6570\u4ee5\u5e2e\u52a9\u7f16\u6392\u5de5\u4f5c\u6d41\u3002</p>"},{"location":"zh/core-concepts/#importpath","title":"<code>import(path)</code>","text":"<p>\u52a0\u8f7d\u53e6\u4e00\u4e2a Lua \u6587\u4ef6\u5e76\u8fd4\u56de\u5176\u8fd4\u56de\u7684\u503c\u3002\u8fd9\u662f\u521b\u5efa\u53ef\u91cd\u7528\u4efb\u52a1\u6a21\u5757\u7684\u4e3b\u8981\u673a\u5236\u3002\u8def\u5f84\u662f\u76f8\u5bf9\u4e8e\u8c03\u7528 <code>import</code> \u7684\u6587\u4ef6\u7684\u3002</p> <p>\u793a\u4f8b (<code>reusable_tasks.sloth</code>): <pre><code>-- \u5bfc\u5165\u4e00\u4e2a\u8fd4\u56de\u4efb\u52a1\u5b9a\u4e49\u8868\u7684\u6a21\u5757\nlocal docker_tasks = import(\"shared/docker.sloth\")\n\nModern DSLs = {\n  main = {\n    tasks = {\n      {\n        -- \u4f7f\u7528\u5bfc\u5165\u6a21\u5757\u4e2d\u7684 'build' \u4efb\u52a1\n        uses = docker_tasks.build,\n        params = { image_name = \"my-app\" }\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"zh/core-concepts/#paralleltasks","title":"<code>parallel(tasks)</code>","text":"<p>\u5e76\u53d1\u6267\u884c\u4efb\u52a1\u5217\u8868\uff0c\u5e76\u7b49\u5f85\u6240\u6709\u4efb\u52a1\u5b8c\u6210\u3002</p> <ul> <li><code>tasks</code> (table): \u8981\u5e76\u884c\u8fd0\u884c\u7684\u4efb\u52a1\u8868\u5217\u8868\u3002</li> </ul> <p>\u793a\u4f8b: <pre><code>command = function()\n  log.info(\"\u5e76\u884c\u542f\u52a83\u4e2a\u4efb\u52a1...\")\n  local results, err = parallel({\n    { name = \"short_task\", command = \"sleep 1\" },\n    { name = \"medium_task\", command = \"sleep 2\" },\n    { name = \"long_task\", command = \"sleep 3\" }\n  })\n  if err then\n    return false, \"\u5e76\u884c\u6267\u884c\u5931\u8d25\"\n  end\n  return true, \"\u6240\u6709\u5e76\u884c\u4efb\u52a1\u5df2\u5b8c\u6210\u3002\"\nend\n</code></pre></p>"},{"location":"zh/core-concepts/#exporttable","title":"<code>export(table)</code>","text":"<p>\u5c06\u6570\u636e\u4ece\u811a\u672c\u7684\u4efb\u4f55\u4f4d\u7f6e\u5bfc\u51fa\u5230 CLI\u3002\u5f53\u4f7f\u7528 <code>--return</code> \u6807\u5fd7\u65f6\uff0c\u6240\u6709\u5bfc\u51fa\u7684\u8868\u90fd\u4f1a\u4e0e\u6700\u7ec8\u4efb\u52a1\u7684\u8f93\u51fa\u5408\u5e76\u6210\u4e00\u4e2a JSON \u5bf9\u8c61\u3002</p> <ul> <li><code>table</code>: \u8981\u5bfc\u51fa\u7684 Lua \u8868\u3002</li> </ul> <p>\u793a\u4f8b: <pre><code>command = function()\n  export({ important_value = \"\u6765\u81ea\u4efb\u52a1\u4e2d\u95f4\u7684\u6570\u636e\" })\n  return true, \"\u4efb\u52a1\u5b8c\u6210\", { final_output = \"\u4e00\u4e9b\u7ed3\u679c\" }\nend\n</code></pre> \u4f7f\u7528 <code>--return</code> \u8fd0\u884c\u5c06\u4ea7\u751f\uff1a <pre><code>{\n  \"important_value\": \"\u6765\u81ea\u4efb\u52a1\u4e2d\u95f4\u7684\u6570\u636e\",\n  \"final_output\": \"\u4e00\u4e9b\u7ed3\u679c\"\n}\n</code></pre></p>"},{"location":"zh/distributed/","title":"\u5206\u5e03\u5f0f\u4efb\u52a1\u6267\u884c","text":"<p><code>sloth-runner</code> \u652f\u6301\u5206\u5e03\u5f0f\u4efb\u52a1\u6267\u884c\uff0c\u5141\u8bb8\u60a8\u5728\u8fdc\u7a0b\u4ee3\u7406\u4e0a\u8fd0\u884c\u4efb\u52a1\u3002\u8fd9\u4f7f\u5f97\u53ef\u6269\u5c55\u7684\u5206\u5e03\u5f0f\u5de5\u4f5c\u6d41\u6210\u4e3a\u53ef\u80fd\uff0c\u5176\u4e2d\u7ba1\u9053\u7684\u4e0d\u540c\u90e8\u5206\u53ef\u4ee5\u5728\u4e0d\u540c\u7684\u673a\u5668\u4e0a\u6267\u884c\u3002</p>"},{"location":"zh/distributed/#_2","title":"\u5de5\u4f5c\u539f\u7406","text":"<p><code>sloth-runner</code> \u4e2d\u7684\u5206\u5e03\u5f0f\u6267\u884c\u6a21\u578b\u9075\u5faa\u4e3b\u4ece\u67b6\u6784\uff1a</p> <ol> <li>\u4e3b\u8282\u70b9\uff1a \u4e3b\u8981\u7684 <code>sloth-runner</code> \u5b9e\u4f8b\u5145\u5f53\u4e3b\u8282\u70b9\u3002\u5b83\u89e3\u6790\u5de5\u4f5c\u6d41\u5b9a\u4e49\uff0c\u8bc6\u522b\u914d\u7f6e\u4e3a\u5728\u8fdc\u7a0b\u4ee3\u7406\u4e0a\u8fd0\u884c\u7684\u4efb\u52a1\uff0c\u5e76\u5206\u6d3e\u5b83\u4eec\u3002</li> <li>\u4ee3\u7406\uff1a \u5728\u8fdc\u7a0b\u673a\u5668\u4e0a\u4ee5 <code>agent</code> \u6a21\u5f0f\u8fd0\u884c\u7684 <code>sloth-runner</code> \u5b9e\u4f8b\u3002\u5b83\u4fa6\u542c\u6765\u81ea\u4e3b\u8282\u70b9\u7684\u4f20\u5165\u4efb\u52a1\u6267\u884c\u8bf7\u6c42\uff0c\u6267\u884c\u4efb\u52a1\uff0c\u5e76\u5c06\u7ed3\u679c\u53d1\u56de\u3002</li> </ol>"},{"location":"zh/distributed/#_3","title":"\u914d\u7f6e\u8fdc\u7a0b\u4efb\u52a1","text":"<p>\u8981\u5728\u8fdc\u7a0b\u4ee3\u7406\u4e0a\u8fd0\u884c\u4efb\u52a1\uff0c\u60a8\u9700\u8981\u5728\u4efb\u52a1\u7ec4\u6216\u5355\u4e2a\u4efb\u52a1\u5b9a\u4e49\u4e2d\u6307\u5b9a <code>delegate_to</code> \u5b57\u6bb5\u3002</p>"},{"location":"zh/distributed/#1","title":"1. \u5728\u4efb\u52a1\u7ec4\u7ea7\u522b\u59d4\u6258\u7ed9\u4ee3\u7406","text":"<p>\u60a8\u53ef\u4ee5\u4f7f\u7528 <code>delegate_to</code> \u5b57\u6bb5\u76f4\u63a5\u5728 <code>Modern DSLs</code> \u7ec4\u4e2d\u5b9a\u4e49\u4ee3\u7406\u3002\u6b64\u7ec4\u4e2d\u7684\u6240\u6709\u4efb\u52a1\u90fd\u5c06\u59d4\u6258\u7ed9\u6b64\u4ee3\u7406\uff0c\u9664\u975e\u88ab\u4efb\u52a1\u7279\u5b9a\u7684 <code>delegate_to</code> \u8986\u76d6\u3002</p> <pre><code>Modern DSLs = {\n  my_distributed_group = {\n    description = \"\u4e00\u4e2a\u5305\u542b\u5206\u5e03\u5f0f\u4efb\u52a1\u7684\u4efb\u52a1\u7ec4\u3002\",\n    delegate_to = { address = \"localhost:50051\" }, -- \u4e3a\u6574\u4e2a\u7ec4\u5b9a\u4e49\u4ee3\u7406\n    tasks = {\n      {\n        name = \"remote_hello\",\n        description = \"\u5728\u8fdc\u7a0b\u4ee3\u7406\u4e0a\u8fd0\u884c hello world \u4efb\u52a1\u3002\",\n        -- \u6b64\u5904\u4e0d\u9700\u8981 'delegate_to' \u5b57\u6bb5\uff0c\u5b83\u7ee7\u627f\u81ea\u7ec4\n        command = function(params)\n          log.info(\"\u6765\u81ea\u8fdc\u7a0b\u4ee3\u7406\u7684\u95ee\u5019\uff01\")\n          return true, \"\u8fdc\u7a0b\u4efb\u52a1\u5df2\u6267\u884c\u3002\"\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"zh/distributed/#2","title":"2. \u5728\u4efb\u52a1\u7ea7\u522b\u59d4\u6258\u7ed9\u4ee3\u7406","text":"<p>\u6216\u8005\uff0c\u60a8\u53ef\u4ee5\u76f4\u63a5\u5728\u5355\u4e2a\u4efb\u52a1\u4e0a\u6307\u5b9a <code>delegate_to</code> \u5b57\u6bb5\u3002\u8fd9\u5c06\u8986\u76d6\u4efb\u4f55\u7ec4\u7ea7\u522b\u7684\u59d4\u6258\u6216\u5141\u8bb8\u5373\u5e2d\u8fdc\u7a0b\u6267\u884c\u3002</p> <pre><code>Modern DSLs = {\n  my_group = {\n    description = \"\u4e00\u4e2a\u5305\u542b\u7279\u5b9a\u8fdc\u7a0b\u4efb\u52a1\u7684\u4efb\u52a1\u7ec4\u3002\",\n    tasks = {\n      {\n        name = \"specific_remote_task\",\n        description = \"\u5728\u7279\u5b9a\u8fdc\u7a0b\u4ee3\u7406\u4e0a\u8fd0\u884c\u6b64\u4efb\u52a1\u3002\",\n        delegate_to = { address = \"192.168.1.100:50051\" }, -- \u4ec5\u4e3a\u6b64\u4efb\u52a1\u5b9a\u4e49\u4ee3\u7406\n        command = function(params)\n          log.info(\"\u6765\u81ea\u7279\u5b9a\u8fdc\u7a0b\u4ee3\u7406\u7684\u95ee\u5019\uff01\")\n          return true, \"\u7279\u5b9a\u8fdc\u7a0b\u4efb\u52a1\u5df2\u6267\u884c\u3002\"\n        end\n      },\n      {\n        name = \"local_task\",\n        description = \"\u6b64\u4efb\u52a1\u5728\u672c\u5730\u8fd0\u884c\u3002\",\n        command = \"echo '\u6765\u81ea\u672c\u5730\u673a\u5668\u7684\u95ee\u5019\uff01'\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"zh/distributed/#_4","title":"\u8fd0\u884c\u4ee3\u7406","text":"<p>\u8981\u4ee5\u4ee3\u7406\u6a21\u5f0f\u542f\u52a8 <code>sloth-runner</code> \u5b9e\u4f8b\uff0c\u8bf7\u4f7f\u7528 <code>agent</code> \u547d\u4ee4\uff1a</p> <pre><code>sloth-runner agent -p 50051\n</code></pre> <ul> <li><code>-p, --port</code>\uff1a\u6307\u5b9a\u4ee3\u7406\u5e94\u4fa6\u542c\u7684\u7aef\u53e3\u3002\u9ed8\u8ba4\u4e3a <code>50051</code>\u3002</li> </ul> <p>\u5f53\u4ee3\u7406\u542f\u52a8\u65f6\uff0c\u5b83\u5c06\u4fa6\u542c\u6765\u81ea\u4e3b <code>sloth-runner</code> \u5b9e\u4f8b\u7684\u4f20\u5165 gRPC \u8bf7\u6c42\u3002\u6536\u5230\u4efb\u52a1\u540e\uff0c\u5b83\u5c06\u5728\u5176\u672c\u5730\u73af\u5883\u4e2d\u6267\u884c\u4efb\u52a1\uff0c\u5e76\u5c06\u7ed3\u679c\u4ee5\u53ca\u4efb\u4f55\u66f4\u65b0\u7684\u5de5\u4f5c\u533a\u6587\u4ef6\u8fd4\u56de\u7ed9\u4e3b\u8282\u70b9\u3002</p>"},{"location":"zh/distributed/#_5","title":"\u5de5\u4f5c\u533a\u540c\u6b65","text":"<p>\u5f53\u4efb\u52a1\u5206\u6d3e\u5230\u8fdc\u7a0b\u4ee3\u7406\u65f6\uff0c<code>sloth-runner</code> \u4f1a\u81ea\u52a8\u5904\u7406\u4efb\u52a1\u5de5\u4f5c\u533a\u7684\u540c\u6b65\uff1a</p> <ol> <li>\u4e3b\u8282\u70b9\u5230\u4ee3\u7406\uff1a \u4e3b\u8282\u70b9\u521b\u5efa\u5f53\u524d\u4efb\u52a1\u5de5\u4f5c\u76ee\u5f55\u7684 tarball\uff0c\u5e76\u5c06\u5176\u53d1\u9001\u5230\u4ee3\u7406\u3002</li> <li>\u4ee3\u7406\u6267\u884c\uff1a \u4ee3\u7406\u5c06 tarball \u89e3\u538b\u7f29\u5230\u4e34\u65f6\u76ee\u5f55\u4e2d\uff0c\u5728\u8be5\u76ee\u5f55\u4e2d\u6267\u884c\u4efb\u52a1\uff0c\u5e76\u6355\u83b7\u5bf9\u4e34\u65f6\u76ee\u5f55\u4e2d\u6587\u4ef6\u6240\u505a\u7684\u4efb\u4f55\u66f4\u6539\u3002</li> <li>\u4ee3\u7406\u5230\u4e3b\u8282\u70b9\uff1a \u4efb\u52a1\u5b8c\u6210\u540e\uff0c\u4ee3\u7406\u521b\u5efa\u4fee\u6539\u540e\u7684\u4e34\u65f6\u76ee\u5f55\u7684 tarball\uff0c\u5e76\u5c06\u5176\u53d1\u56de\u7ed9\u4e3b\u8282\u70b9\u3002\u7136\u540e\uff0c\u4e3b\u8282\u70b9\u89e3\u538b\u7f29\u6b64 tarball\uff0c\u7528\u8fdc\u7a0b\u4efb\u52a1\u6240\u505a\u7684\u4efb\u4f55\u66f4\u6539\u66f4\u65b0\u5176\u672c\u5730\u5de5\u4f5c\u533a\u3002</li> </ol>"},{"location":"zh/getting-started/","title":"\u5feb\u901f\u5165\u95e8","text":"<p>\u6b22\u8fce\u4f7f\u7528 Sloth-Runner\uff01\u672c\u6307\u5357\u5c06\u5e2e\u52a9\u60a8\u5feb\u901f\u5f00\u59cb\u4f7f\u7528\u8be5\u5de5\u5177\u3002</p> <p>\ud83d\udcdd \u91cd\u8981\u8bf4\u660e\uff1a \u4ece\u5f53\u524d\u7248\u672c\u5f00\u59cb\uff0cSloth Runner \u5de5\u4f5c\u6d41\u6587\u4ef6\u4f7f\u7528 <code>.sloth</code> \u6269\u5c55\u540d\u800c\u4e0d\u662f <code>.lua</code>\u3002Lua \u8bed\u6cd5\u4fdd\u6301\u4e0d\u53d8 - \u53ea\u662f\u6587\u4ef6\u6269\u5c55\u540d\u66f4\u6539\u4e3a\u66f4\u597d\u5730\u8bc6\u522b Sloth Runner DSL \u6587\u4ef6\u3002</p>"},{"location":"zh/getting-started/#_2","title":"\u5b89\u88c5","text":"<p>\u8981\u5728\u60a8\u7684\u7cfb\u7edf\u4e0a\u5b89\u88c5 <code>sloth-runner</code>\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u63d0\u4f9b\u7684 <code>install.sh</code> \u811a\u672c\u3002\u6b64\u811a\u672c\u4f1a\u81ea\u52a8\u68c0\u6d4b\u60a8\u7684\u64cd\u4f5c\u7cfb\u7edf\u548c\u67b6\u6784\uff0c\u4ece GitHub \u4e0b\u8f7d\u6700\u65b0\u7248\u672c\uff0c\u5e76\u5c06 <code>sloth-runner</code> \u53ef\u6267\u884c\u6587\u4ef6\u653e\u7f6e\u5728 <code>/usr/local/bin</code> \u4e2d\u3002</p> <pre><code>bash &lt;(curl -sL https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/install.sh)\n</code></pre> <p>\u6ce8\u610f\uff1a <code>install.sh</code> \u811a\u672c\u9700\u8981 <code>sudo</code> \u6743\u9650\u624d\u80fd\u5c06\u53ef\u6267\u884c\u6587\u4ef6\u79fb\u52a8\u5230 <code>/usr/local/bin</code>\u3002</p>"},{"location":"zh/getting-started/#_3","title":"\u57fa\u672c\u7528\u6cd5","text":"<p>\u8981\u8fd0\u884c sloth \u4efb\u52a1\u6587\u4ef6\uff1a</p> <pre><code>sloth-runner run -f examples/basic_pipeline.sloth\n</code></pre> <p>\u8981\u5217\u51fa\u6587\u4ef6\u4e2d\u7684\u4efb\u52a1\uff1a</p> <pre><code>sloth-runner list -f examples/basic_pipeline.sloth\n</code></pre>"},{"location":"zh/getting-started/#_4","title":"\u4e0b\u4e00\u6b65","text":"<p>\u73b0\u5728\u60a8\u5df2\u7ecf\u5b89\u88c5\u5e76\u8fd0\u884c\u4e86 Sloth-Runner\uff0c\u8bf7\u63a2\u7d22\u6838\u5fc3\u6982\u5ff5\u4ee5\u4e86\u89e3\u5982\u4f55\u5b9a\u4e49\u4efb\u52a1\uff0c\u6216\u8005\u76f4\u63a5\u6df1\u5165\u4e86\u89e3\u65b0\u7684\u5185\u7f6e\u6a21\u5757\u4ee5\u4f7f\u7528 Git\u3001Pulumi \u548c Salt \u8fdb\u884c\u9ad8\u7ea7\u81ea\u52a8\u5316\u3002</p> <p>English | Portugu\u00eas | \u4e2d\u6587</p>"},{"location":"zh/repl/","title":"\u4ea4\u4e92\u5f0f REPL","text":"<p><code>sloth-runner repl</code> \u547d\u4ee4\u5c06\u60a8\u5e26\u5165\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u7684 Read-Eval-Print Loop (REPL) \u4f1a\u8bdd\u3002\u8fd9\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u8c03\u8bd5\u3001\u63a2\u7d22\u548c\u5feb\u901f\u5b9e\u9a8c sloth-runner \u6a21\u5757\u3002</p>"},{"location":"zh/repl/#repl_1","title":"\u542f\u52a8 REPL","text":"<p>\u8981\u542f\u52a8\u4f1a\u8bdd\uff0c\u53ea\u9700\u8fd0\u884c\uff1a <pre><code>sloth-runner repl\n</code></pre></p> <p>\u60a8\u8fd8\u53ef\u4ee5\u9884\u52a0\u8f7d\u4e00\u4e2a\u5de5\u4f5c\u6d41\u6587\u4ef6\uff0c\u4ee5\u4f7f\u5176 <code>Modern DSLs</code> \u548c\u4efb\u4f55\u8f85\u52a9\u51fd\u6570\u5728\u4f1a\u8bdd\u4e2d\u53ef\u7528\u3002\u8fd9\u5bf9\u4e8e\u8c03\u8bd5\u73b0\u6709\u7684\u7ba1\u9053\u975e\u5e38\u6709\u7528\u3002</p> <pre><code>sloth-runner repl -f /path/to/your/pipeline.sloth\n</code></pre>"},{"location":"zh/repl/#_1","title":"\u529f\u80fd","text":""},{"location":"zh/repl/#_2","title":"\u5b9e\u65f6\u73af\u5883","text":"<p>REPL \u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u65f6\u7684 Lua \u73af\u5883\uff0c\u60a8\u53ef\u4ee5\u5728\u5176\u4e2d\u6267\u884c\u4efb\u4f55 Lua \u4ee3\u7801\u3002\u6240\u6709\u5185\u7f6e\u7684 sloth-runner \u6a21\u5757\uff08<code>aws</code>\u3001<code>docker</code>\u3001<code>fs</code>\u3001<code>log</code> \u7b49\uff09\u90fd\u5df2\u9884\u52a0\u8f7d\u5e76\u53ef\u4f9b\u4f7f\u7528\u3002</p> <pre><code>sloth&gt; log.info(\"\u6765\u81ea REPL \u7684\u4f60\u597d\uff01\")\nsloth&gt; result = fs.read(\"README.md\")\nsloth&gt; print(string.sub(result, 1, 50))\n</code></pre>"},{"location":"zh/repl/#_3","title":"\u81ea\u52a8\u8865\u5168","text":"<p>REPL \u6709\u4e00\u4e2a\u590d\u6742\u7684\u81ea\u52a8\u8865\u5168\u7cfb\u7edf\u3002 - \u5f00\u59cb\u8f93\u5165\u5168\u5c40\u53d8\u91cf\u6216\u6a21\u5757\u7684\u540d\u79f0\uff08\u4f8b\u5982 <code>aws</code>\uff09\u5e76\u6309 <code>Tab</code> \u67e5\u770b\u5efa\u8bae\u3002 - \u8f93\u5165\u6a21\u5757\u540d\u79f0\u540e\u8ddf\u4e00\u4e2a\u70b9\uff08\u4f8b\u5982 <code>docker.</code>\uff09\u5e76\u6309 <code>Tab</code> \u67e5\u770b\u8be5\u6a21\u5757\u4e2d\u6240\u6709\u53ef\u7528\u7684\u51fd\u6570\u3002</p>"},{"location":"zh/repl/#_4","title":"\u5386\u53f2\u8bb0\u5f55","text":"<p>REPL \u4f1a\u4fdd\u7559\u60a8\u7684\u547d\u4ee4\u5386\u53f2\u8bb0\u5f55\u3002\u4f7f\u7528\u5411\u4e0a\u548c\u5411\u4e0b\u7bad\u5934\u952e\u6d4f\u89c8\u4ee5\u524d\u7684\u547d\u4ee4\u3002</p>"},{"location":"zh/repl/#_5","title":"\u4f1a\u8bdd\u793a\u4f8b","text":"<p>\u4ee5\u4e0b\u662f\u4f7f\u7528 REPL \u8c03\u8bd5 Docker \u547d\u4ee4\u7684\u793a\u4f8b\u3002</p> <pre><code>$ sloth-runner repl\nSloth-Runner Interactive REPL\n\u8f93\u5165 'exit' \u6216 'quit' \u79bb\u5f00\u3002\nsloth&gt; result = docker.exec({\"ps\", \"-a\"})\nsloth&gt; print(result.stdout)\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nsloth&gt; -- \u73b0\u5728\u8ba9\u6211\u4eec\u5c1d\u8bd5\u6784\u5efa\u4e00\u4e2a\u955c\u50cf\nsloth&gt; build_result = docker.build({tag=\"my-test\", path=\"./examples/docker\"})\nsloth&gt; print(build_result.success)\ntrue\nsloth&gt; exit\n\u518d\u89c1\uff01\n</code></pre>"},{"location":"zh/scheduler/","title":"\u4efb\u52a1\u8c03\u5ea6\u5668","text":"<p><code>sloth-runner</code> \u73b0\u5728\u5305\u542b\u4e00\u4e2a\u5185\u7f6e\u7684\u4efb\u52a1\u8c03\u5ea6\u5668\uff0c\u5141\u8bb8\u60a8\u4f7f\u7528 cron \u8bed\u6cd5\u5728\u6307\u5b9a\u7684\u65f6\u95f4\u95f4\u9694\u81ea\u52a8\u6267\u884c\u60a8\u7684 Lua \u5b9a\u4e49\u4efb\u52a1\u3002</p>"},{"location":"zh/scheduler/#_2","title":"\u529f\u80fd","text":"<ul> <li>\u540e\u53f0\u8fdb\u7a0b: \u8c03\u5ea6\u5668\u4f5c\u4e3a\u6301\u4e45\u7684\u540e\u53f0\u8fdb\u7a0b\u8fd0\u884c\uff0c\u72ec\u7acb\u4e8e\u60a8\u7684\u7ec8\u7aef\u4f1a\u8bdd\u3002</li> <li>\u57fa\u4e8e Cron \u7684\u8c03\u5ea6: \u4f7f\u7528\u7075\u6d3b\u7684 cron \u5b57\u7b26\u4e32\u5b9a\u4e49\u4efb\u52a1\u8c03\u5ea6\u3002</li> <li>\u6301\u4e45\u6027: \u8c03\u5ea6\u4efb\u52a1\u4ece\u914d\u7f6e\u6587\u4ef6\u52a0\u8f7d\uff0c\u786e\u4fdd\u5728\u91cd\u542f\u540e\u6062\u590d\u3002</li> <li>\u4e0e\u73b0\u6709\u4efb\u52a1\u96c6\u6210: \u8c03\u5ea6\u5668\u5229\u7528\u73b0\u6709\u7684 <code>sloth-runner run</code> \u547d\u4ee4\u6765\u6267\u884c\u60a8\u7684\u4efb\u52a1\u3002</li> </ul>"},{"location":"zh/scheduler/#scheduleryaml","title":"\u914d\u7f6e: <code>scheduler.yaml</code>","text":"<p>\u8c03\u5ea6\u4efb\u52a1\u5728 YAML \u6587\u4ef6\u4e2d\u5b9a\u4e49\uff0c\u901a\u5e38\u547d\u540d\u4e3a <code>scheduler.yaml</code>\u3002\u6b64\u6587\u4ef6\u6307\u5b9a\u8981\u8fd0\u884c\u7684\u4efb\u52a1\u3001\u5b83\u4eec\u7684\u8c03\u5ea6\u4ee5\u53ca Lua \u6587\u4ef6\u3001\u7ec4\u548c\u4efb\u52a1\u540d\u79f0\u3002</p> <pre><code>scheduled_tasks:\n  - name: \"my_daily_backup\"\n    schedule: \"0 0 * * *\" # \u6bcf\u5929\u5348\u591c\n    task_file: \"examples/my_workflow.sloth\"\n    task_group: \"backup_group\"\n    task_name: \"perform_backup\"\n  - name: \"hourly_report_generation\"\n    schedule: \"0 * * * *\" # \u6bcf\u5c0f\u65f6\n    task_file: \"examples/reporting.sloth\"\n    task_group: \"reports\"\n    task_name: \"generate_report\"\n</code></pre> <p>\u5b57\u6bb5:</p> <ul> <li><code>name</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b): \u8c03\u5ea6\u4efb\u52a1\u7684\u552f\u4e00\u540d\u79f0\u3002</li> <li><code>schedule</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b): \u5b9a\u4e49\u4efb\u52a1\u4f55\u65f6\u8fd0\u884c\u7684 cron \u5b57\u7b26\u4e32\u3002\u652f\u6301\u6807\u51c6 cron \u8bed\u6cd5\u548c\u4e00\u4e9b\u9884\u5b9a\u4e49\u8c03\u5ea6 (\u4f8b\u5982, <code>@every 1h</code>, <code>@daily</code>)\u3002\u6709\u5173\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 robfig/cron \u6587\u6863\u3002</li> <li><code>task_file</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b): Lua \u4efb\u52a1\u5b9a\u4e49\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>task_group</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b): Lua \u6587\u4ef6\u4e2d\u7684\u4efb\u52a1\u7ec4\u540d\u79f0\u3002</li> <li><code>task_name</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b): \u5728\u4efb\u52a1\u7ec4\u4e2d\u6267\u884c\u7684\u7279\u5b9a\u4efb\u52a1\u540d\u79f0\u3002</li> </ul>"},{"location":"zh/scheduler/#cli","title":"CLI \u547d\u4ee4","text":""},{"location":"zh/scheduler/#sloth-runner-scheduler-enable","title":"<code>sloth-runner scheduler enable</code>","text":"<p>\u5c06 <code>sloth-runner</code> \u8c03\u5ea6\u5668\u4f5c\u4e3a\u540e\u53f0\u8fdb\u7a0b\u542f\u52a8\u3002\u6b64\u547d\u4ee4\u786e\u4fdd\u8c03\u5ea6\u5668\u6b63\u5728\u8fd0\u884c\u5e76\u51c6\u5907\u597d\u5904\u7406\u8c03\u5ea6\u4efb\u52a1\u3002</p> <pre><code>sloth-runner scheduler enable --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>--scheduler-config</code> (\u6216 <code>-c</code>): \u6307\u5b9a <code>scheduler.yaml</code> \u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a\u5f53\u524d\u76ee\u5f55\u4e2d\u7684 <code>scheduler.yaml</code>\u3002</li> </ul> <p>\u6267\u884c\u540e\uff0c\u547d\u4ee4\u5c06\u6253\u5370\u540e\u53f0\u8c03\u5ea6\u5668\u8fdb\u7a0b\u7684 PID\u3002\u5373\u4f7f\u60a8\u7684\u7ec8\u7aef\u4f1a\u8bdd\u5173\u95ed\uff0c\u8c03\u5ea6\u5668\u4e5f\u5c06\u7ee7\u7eed\u8fd0\u884c\u3002</p>"},{"location":"zh/scheduler/#sloth-runner-scheduler-disable","title":"<code>sloth-runner scheduler disable</code>","text":"<p>\u505c\u6b62\u6b63\u5728\u8fd0\u884c\u7684 <code>sloth-runner</code> \u8c03\u5ea6\u5668\u540e\u53f0\u8fdb\u7a0b\u3002</p> <pre><code>sloth-runner scheduler disable\n</code></pre> <p>\u6b64\u547d\u4ee4\u5c06\u5c1d\u8bd5\u4f18\u96c5\u5730\u7ec8\u6b62\u8c03\u5ea6\u5668\u8fdb\u7a0b\u3002\u5982\u679c\u6210\u529f\uff0c\u5b83\u5c06\u5220\u9664\u7531 <code>enable</code> \u547d\u4ee4\u521b\u5efa\u7684 PID \u6587\u4ef6\u3002</p>"},{"location":"zh/scheduler/#sloth-runner-scheduler-list","title":"<code>sloth-runner scheduler list</code>","text":"<p>\u5217\u51fa <code>scheduler.yaml</code> \u914d\u7f6e\u6587\u4ef6\u4e2d\u5b9a\u4e49\u7684\u6240\u6709\u8c03\u5ea6\u4efb\u52a1\u3002\u6b64\u547d\u4ee4\u63d0\u4f9b\u5df2\u914d\u7f6e\u4efb\u52a1\u3001\u5176\u8c03\u5ea6\u548c\u76f8\u5173 Lua \u4efb\u52a1\u8be6\u7ec6\u4fe1\u606f\u7684\u6982\u8ff0\u3002</p> <pre><code>sloth-runner scheduler list --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>--scheduler-config</code> (\u6216 <code>-c</code>): \u6307\u5b9a <code>scheduler.yaml</code> \u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a\u5f53\u524d\u76ee\u5f55\u4e2d\u7684 <code>scheduler.yaml</code>\u3002</li> </ul> <p>\u793a\u4f8b\u8f93\u51fa:</p> <pre><code># Configured Scheduled Tasks\n\nNAME                     | SCHEDULE    | FILE                     | GROUP        | TASK\nmy_daily_backup          | 0 0 * * *   | examples/my_workflow.sloth | backup_group | perform_backup\nhourly_report_generation | 0 * * * *   | examples/reporting.sloth   | reports      | generate_report\n</code></pre>"},{"location":"zh/scheduler/#sloth-runner-scheduler-delete-task_name","title":"<code>sloth-runner scheduler delete &lt;task_name&gt;</code>","text":"<p>\u4ece <code>scheduler.yaml</code> \u914d\u7f6e\u6587\u4ef6\u4e2d\u5220\u9664\u7279\u5b9a\u7684\u8c03\u5ea6\u4efb\u52a1\u3002\u6b64\u547d\u4ee4\u5c06\u5220\u9664\u4efb\u52a1\u5b9a\u4e49\uff0c\u8c03\u5ea6\u5668\u5c06\u4e0d\u518d\u6267\u884c\u5b83\u3002</p> <pre><code>sloth-runner scheduler delete my_daily_backup --scheduler-config scheduler.yaml\n</code></pre> <ul> <li><code>&lt;task_name&gt;</code> (\u5b57\u7b26\u4e32, \u5fc5\u586b): \u8981\u5220\u9664\u7684\u8c03\u5ea6\u4efb\u52a1\u7684\u552f\u4e00\u540d\u79f0\u3002</li> <li><code>--scheduler-config</code> (\u6216 <code>-c</code>): \u6307\u5b9a <code>scheduler.yaml</code> \u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002\u9ed8\u8ba4\u4e3a\u5f53\u524d\u76ee\u5f55\u4e2d\u7684 <code>scheduler.yaml</code>\u3002</li> </ul> <p>\u91cd\u8981: \u6b64\u547d\u4ee4\u4f1a\u4fee\u6539\u60a8\u7684 <code>scheduler.yaml</code> \u6587\u4ef6\u3002\u5982\u6709\u5fc5\u8981\uff0c\u8bf7\u786e\u4fdd\u60a8\u6709\u5907\u4efd\u3002\u5982\u679c\u8c03\u5ea6\u5668\u5f53\u524d\u6b63\u5728\u8fd0\u884c\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u7981\u7528\u5e76\u91cd\u65b0\u542f\u7528\u5b83\u624d\u80fd\u4f7f\u66f4\u6539\u7acb\u5373\u751f\u6548\u3002</p>"},{"location":"zh/scheduler/#_3","title":"\u65e5\u5fd7\u548c\u9519\u8bef\u5904\u7406","text":"<p>\u8c03\u5ea6\u5668\u5c06\u5176\u6d3b\u52a8\u548c\u8c03\u5ea6\u4efb\u52a1\u7684\u6267\u884c\u72b6\u6001\u8bb0\u5f55\u5230\u6807\u51c6\u8f93\u51fa\u548c\u6807\u51c6\u9519\u8bef\u3002\u5efa\u8bae\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u8fd0\u884c\u65f6\u5c06\u8fd9\u4e9b\u8f93\u51fa\u91cd\u5b9a\u5411\u5230\u65e5\u5fd7\u6587\u4ef6\u3002</p> <p>\u5982\u679c\u8c03\u5ea6\u4efb\u52a1\u5931\u8d25\uff0c\u8c03\u5ea6\u5668\u5c06\u8bb0\u5f55\u9519\u8bef\u5e76\u7ee7\u7eed\u6267\u884c\u5176\u4ed6\u8c03\u5ea6\u4efb\u52a1\u3002\u5b83\u4e0d\u4f1a\u56e0\u5355\u4e2a\u4efb\u52a1\u5931\u8d25\u800c\u505c\u6b62\u3002</p>"},{"location":"zh/scheduler/#_4","title":"\u793a\u4f8b","text":"<ol> <li> <p>\u521b\u5efa <code>scheduler.yaml</code> \u6587\u4ef6:</p> <pre><code>scheduled_tasks:\n  - name: \"my_test_task\"\n    schedule: \"@every 1m\"\n    task_file: \"examples/basic_pipeline.sloth\"\n    task_group: \"basic_pipeline\"\n    task_name: \"fetch_data\"\n</code></pre> </li> <li> <p>\u542f\u7528\u8c03\u5ea6\u5668:</p> <pre><code>sloth-runner scheduler enable --scheduler-config scheduler.yaml\n</code></pre> </li> <li> <p>\u89c2\u5bdf\u8f93\u51fa\u3002\u6bcf\u5206\u949f\uff0c\u60a8\u5e94\u8be5\u4f1a\u770b\u5230\u6307\u793a <code>my_test_task</code> \u6267\u884c\u7684\u6d88\u606f\u3002</p> </li> <li> <p>\u505c\u6b62\u8c03\u5ea6\u5668:</p> <pre><code>sloth-runner scheduler disable\n</code></pre> </li> </ol>"},{"location":"zh/testing/","title":"\u6d4b\u8bd5\u5de5\u4f5c\u6d41","text":"<p>sloth-runner \u5305\u542b\u4e00\u4e2a\u5185\u7f6e\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u5141\u8bb8\u60a8\u4e3a\u4efb\u52a1\u5de5\u4f5c\u6d41\u7f16\u5199\u5355\u5143\u548c\u96c6\u6210\u6d4b\u8bd5\u3002\u4e3a\u60a8\u7684\u81ea\u52a8\u5316\u7f16\u5199\u6d4b\u8bd5\u5bf9\u4e8e\u786e\u4fdd\u53ef\u9760\u6027\u3001\u9632\u6b62\u56de\u5f52\u4ee5\u53ca\u5728\u8fdb\u884c\u66f4\u6539\u65f6\u5145\u6ee1\u4fe1\u5fc3\u81f3\u5173\u91cd\u8981\u3002</p>"},{"location":"zh/testing/#test","title":"<code>test</code> \u547d\u4ee4","text":"<p>\u60a8\u53ef\u4ee5\u4f7f\u7528 <code>sloth-runner test</code> \u547d\u4ee4\u8fd0\u884c\u6d4b\u8bd5\u6587\u4ef6\u3002\u5b83\u9700\u8981\u4e24\u4e2a\u4e3b\u8981\u6587\u4ef6\uff1a\u60a8\u8981\u6d4b\u8bd5\u7684\u5de5\u4f5c\u6d41\u548c\u6d4b\u8bd5\u811a\u672c\u672c\u8eab\u3002</p> <pre><code>sloth-runner test -w &lt;\u5de5\u4f5c\u6d41\u8def\u5f84.sloth&gt; -f &lt;\u6d4b\u8bd5\u6587\u4ef6\u8def\u5f84.sloth&gt;\n</code></pre> <ul> <li><code>-w, --workflow</code>: \u6307\u5b9a\u8981\u6d4b\u8bd5\u7684\u4e3b <code>Modern DSLs</code> \u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>-f, --file</code>: \u6307\u5b9a\u60a8\u7684\u6d4b\u8bd5\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul>"},{"location":"zh/testing/#_2","title":"\u7f16\u5199\u6d4b\u8bd5","text":"<p>\u6d4b\u8bd5\u662f\u7528 Lua \u7f16\u5199\u7684\uff0c\u5e76\u4f7f\u7528\u6d4b\u8bd5\u8fd0\u884c\u5668\u63d0\u4f9b\u7684\u4e24\u4e2a\u65b0\u7684\u5168\u5c40\u6a21\u5757\uff1a<code>test</code> \u548c <code>assert</code>\u3002</p>"},{"location":"zh/testing/#test_1","title":"<code>test</code> \u6a21\u5757","text":"<p><code>test</code> \u6a21\u5757\u7528\u4e8e\u6784\u5efa\u60a8\u7684\u6d4b\u8bd5\u5e76\u8fd0\u884c\u5de5\u4f5c\u6d41\u4e2d\u7684\u7279\u5b9a\u4efb\u52a1\u3002</p> <ul> <li><code>test.describe(suite_name, function)</code>: \u5c06\u76f8\u5173\u6d4b\u8bd5\u5206\u7ec4\u5230\u4e00\u4e2a\u201c\u5957\u4ef6\u201d\u4e2d\u3002\u8fd9\u7528\u4e8e\u7ec4\u7ec7\u3002</li> <li><code>test.it(function)</code>: \u5b9a\u4e49\u5355\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u3002\u6d4b\u8bd5\u7684\u63cf\u8ff0\u5e94\u5305\u542b\u5728\u6b64\u51fd\u6570\u5185\u7684\u65ad\u8a00\u6d88\u606f\u4e2d\u3002</li> <li><code>test.run_task(task_name)</code>: \u8fd9\u662f\u6d4b\u8bd5\u6846\u67b6\u7684\u6838\u5fc3\u529f\u80fd\u3002\u5b83\u4ece\u52a0\u8f7d\u7684\u5de5\u4f5c\u6d41\u6587\u4ef6\u4e2d\u6309\u540d\u79f0\u6267\u884c\u5355\u4e2a\u4efb\u52a1\u3002\u5b83\u8fd4\u56de\u4e00\u4e2a\u5305\u542b\u6267\u884c\u8be6\u7ec6\u4fe1\u606f\u7684 <code>result</code> \u8868\u3002</li> </ul> <p><code>run_task</code> \u8fd4\u56de\u7684 <code>result</code> \u8868\u5177\u6709\u4ee5\u4e0b\u7ed3\u6784\uff1a</p> <pre><code>{\n  success = true, -- \u5e03\u5c14\u503c\uff1a\u5982\u679c\u4efb\u52a1\u6210\u529f\u5219\u4e3a true\uff0c\u5426\u5219\u4e3a false\n  message = \"\u4efb\u52a1\u6267\u884c\u6210\u529f\", -- \u5b57\u7b26\u4e32\uff1a\u4efb\u52a1\u8fd4\u56de\u7684\u6d88\u606f\n  duration = \"1.23ms\", -- \u5b57\u7b26\u4e32\uff1a\u6267\u884c\u6301\u7eed\u65f6\u95f4\n  output = { ... }, -- \u8868\uff1a\u4efb\u52a1\u8fd4\u56de\u7684\u8f93\u51fa\u8868\n  error = nil -- \u5b57\u7b26\u4e32\uff1a\u5982\u679c\u4efb\u52a1\u5931\u8d25\uff0c\u5219\u4e3a\u9519\u8bef\u6d88\u606f\n}\n</code></pre>"},{"location":"zh/testing/#assert","title":"<code>assert</code> \u6a21\u5757","text":"<p><code>assert</code> \u6a21\u5757\u63d0\u4f9b\u7528\u4e8e\u68c0\u67e5\u4efb\u52a1\u6267\u884c\u7ed3\u679c\u7684\u51fd\u6570\u3002</p> <ul> <li><code>assert.is_true(value, message)</code>: \u68c0\u67e5 <code>value</code> \u662f\u5426\u4e3a true\u3002</li> <li><code>assert.equals(actual, expected, message)</code>: \u68c0\u67e5 <code>actual</code> \u503c\u662f\u5426\u7b49\u4e8e <code>expected</code> \u503c\u3002</li> </ul>"},{"location":"zh/testing/#mocking","title":"\u6a21\u5757\u6a21\u62df (Mocking)","text":"<p>\u4e3a\u4e86\u6d4b\u8bd5\u60a8\u7684\u7ba1\u9053\u903b\u8f91\u800c\u65e0\u9700\u8fdb\u884c\u5b9e\u9645\u7684\u5916\u90e8\u8c03\u7528\uff08\u4f8b\u5982\uff0c\u5bf9 AWS\u3001Docker \u6216 Terraform\uff09\uff0c\u6d4b\u8bd5\u6846\u67b6\u5305\u542b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6a21\u62df\u529f\u80fd\u3002</p>"},{"location":"zh/testing/#_3","title":"\u4e25\u683c\u6a21\u62df\u7b56\u7565","text":"<p>\u6d4b\u8bd5\u8fd0\u884c\u5668\u5f3a\u5236\u6267\u884c \u4e25\u683c\u7684\u6a21\u62df\u7b56\u7565\u3002\u5728\u6d4b\u8bd5\u6a21\u5f0f\u4e0b\u8fd0\u884c\u65f6\uff0c\u4efb\u4f55\u5bf9\u6a21\u5757\u51fd\u6570\uff08\u5982 <code>aws.exec</code> \u6216 <code>docker.build</code>\uff09\u7684\u8c03\u7528\u5982\u679c \u6ca1\u6709 \u88ab\u660e\u786e\u6a21\u62df\uff0c\u5c06\u5bfc\u81f4\u6d4b\u8bd5\u7acb\u5373\u5931\u8d25\u3002\u8fd9\u53ef\u786e\u4fdd\u60a8\u7684\u6d4b\u8bd5\u662f\u5b8c\u5168\u81ea\u5305\u542b\u7684\u3001\u786e\u5b9a\u6027\u7684\uff0c\u5e76\u4e14\u6ca1\u6709\u610f\u5916\u7684\u526f\u4f5c\u7528\u3002</p>"},{"location":"zh/testing/#testmockfunction_name-mock_definition","title":"<code>test.mock(function_name, mock_definition)</code>","text":"<p>\u6b64\u51fd\u6570\u5141\u8bb8\u60a8\u4e3a\u4efb\u4f55\u53ef\u6a21\u62df\u7684\u6a21\u5757\u51fd\u6570\u5b9a\u4e49\u4e00\u4e2a\u4f2a\u9020\u7684\u8fd4\u56de\u503c\u3002</p> <ul> <li><code>function_name</code> (string): \u8981\u6a21\u62df\u7684\u51fd\u6570\u7684\u5168\u540d\uff08\u4f8b\u5982 <code>\"aws.s3.sync\"</code>, <code>\"docker.build\"</code>\uff09\u3002</li> <li><code>mock_definition</code> (table): \u4e00\u4e2a\u5b9a\u4e49\u6a21\u62df\u51fd\u6570\u5e94\u8fd4\u56de\u4ec0\u4e48\u7684\u8868\u3002\u5b83 \u5fc5\u987b \u5305\u542b\u4e00\u4e2a <code>returns</code> \u952e\uff0c\u8be5\u952e\u662f\u4e00\u4e2a\u51fd\u6570\u5c06\u8fd4\u56de\u7684\u503c\u7684\u5217\u8868\u3002</li> </ul> <p><code>returns</code> \u5217\u8868\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a Lua \u51fd\u6570\u53ef\u4ee5\u8fd4\u56de\u591a\u4e2a\u503c\u3002</p> <p>\u793a\u4f8b:</p> <pre><code>-- \u6a21\u62df\u4e00\u4e2a\u8fd4\u56de\u5355\u4e2a\u7ed3\u679c\u8868\u7684\u51fd\u6570\ntest.mock(\"docker.build\", {\n  returns = {\n    { success = true, stdout = \"\u6210\u529f\u6784\u5efa\u955c\u50cf\" }\n  }\n})\n\n-- \u6a21\u62df\u4e00\u4e2a\u8fd4\u56de\u4e24\u4e2a\u503c\u7684\u51fd\u6570\uff08\u4f8b\u5982\uff0c\u4e00\u4e2a\u503c\u548c\u4e00\u4e2a\u9519\u8bef\uff09\n-- \u8fd9\u6a21\u62df\u4e86\u5bf9 terraform.output \u7684\u6210\u529f\u8c03\u7528\ntest.mock(\"terraform.output\", {\n  returns = { \"my_file.txt\", nil }\n})\n\n-- \u8fd9\u6a21\u62df\u4e86\u5931\u8d25\u7684\u8c03\u7528\ntest.mock(\"terraform.output\", {\n  returns = { nil, \"\u672a\u627e\u5230\u8f93\u51fa\" }\n})\n</code></pre>"},{"location":"zh/testing/#_4","title":"\u5b8c\u6574\u7684\u6a21\u62df\u793a\u4f8b","text":"<p>\u5047\u8bbe\u60a8\u6709\u4e00\u4e2a\u8c03\u7528 <code>aws.exec</code> \u7684\u4efb\u52a1\uff0c\u5e76\u4e14\u5176\u903b\u8f91\u53d6\u51b3\u4e8e\u8f93\u51fa\u3002</p> <p><code>my_workflow.sloth</code> \u4e2d\u7684\u4efb\u52a1: <pre><code>-- ...\n{\n  name = \"check-account\",\n  command = function()\n    local result = aws.exec({\"sts\", \"get-caller-identity\"})\n    local data = data.parse_json(result.stdout)\n    if data.Account == \"123456789012\" then\n      return true, \"\u6b63\u786e\u7684\u5e10\u6237\u3002\"\n    else\n      return false, \"\u9519\u8bef\u7684\u5e10\u6237\u3002\"\n    end\n  end\n}\n-- ...\n</code></pre></p> <p><code>my_test.sloth</code> \u4e2d\u7684\u6d4b\u8bd5: <pre><code>test.describe(\"\u5e10\u6237\u68c0\u67e5\u903b\u8f91\", function()\n  test.it(function()\n    -- \u6a21\u62df aws.exec \u7684\u8fd4\u56de\u503c\n    test.mock(\"aws.exec\", {\n      returns = {\n        {\n          success = true,\n          stdout = '{\"Account\": \"123456789012\"}'\n        }\n      }\n    })\n\n    -- \u8fd0\u884c\u4f7f\u7528\u6a21\u62df\u7684\u4efb\u52a1\n    local result = test.run_task(\"check-account\")\n\n    -- \u65ad\u8a00\u4efb\u52a1\u7684\u903b\u8f91\u5728\u6a21\u62df\u6570\u636e\u4e0b\u662f\u5426\u6b63\u5e38\u5de5\u4f5c\n    assert.is_true(result.success, \"\u4f7f\u7528\u6b63\u786e\u7684\u5e10\u6237 ID\uff0c\u4efb\u52a1\u5e94\u8be5\u6210\u529f\")\n    assert.equals(result.message, \"\u6b63\u786e\u7684\u5e10\u6237\u3002\", \"\u6d88\u606f\u5e94\u8be5\u662f\u6b63\u786e\u7684\")\n  end)\nend)\n</code></pre></p>"},{"location":"zh/modules/aws/","title":"AWS \u6a21\u5757","text":"<p><code>aws</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u754c\u9762\uff0c\u7528\u4e8e\u4f7f\u7528 AWS CLI \u4e0e\u4e9a\u9a6c\u900a\u7f51\u7edc\u670d\u52a1\u8fdb\u884c\u4ea4\u4e92\u3002\u5b83\u65e8\u5728\u4e0e\u6807\u51c6\u7684 AWS \u51ed\u8bc1\u94fe\u65e0\u7f1d\u534f\u4f5c\uff0c\u5e76\u4e3a <code>aws-vault</code> \u63d0\u4f9b\u4e00\u6d41\u7684\u652f\u6301\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\u3002</p>"},{"location":"zh/modules/aws/#_1","title":"\u914d\u7f6e","text":"<p><code>values.yaml</code> \u4e2d\u65e0\u9700\u7279\u5b9a\u914d\u7f6e\u3002\u8be5\u6a21\u5757\u4f9d\u8d56\u4e8e\u60a8\u7684\u73af\u5883\u914d\u7f6e\u4e3a\u53ef\u4e0e AWS \u4ea4\u4e92\u3002\u8fd9\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5b9e\u73b0\uff1a - EC2 \u5b9e\u4f8b\u6216 ECS/EKS \u4efb\u52a1\u7684 IAM \u89d2\u8272\u3002 - \u6807\u51c6\u73af\u5883\u53d8\u91cf\uff08<code>AWS_ACCESS_KEY_ID</code>\u3001<code>AWS_SECRET_ACCESS_KEY</code> \u7b49\uff09\u3002 - \u5df2\u914d\u7f6e\u7684 <code>~/.aws/credentials</code> \u6587\u4ef6\u3002 - \u4f7f\u7528\u5e26\u6709\u547d\u540d\u914d\u7f6e\u6587\u4ef6\u7684 <code>aws-vault</code>\u3002</p>"},{"location":"zh/modules/aws/#_2","title":"\u901a\u7528\u6267\u884c\u5668","text":""},{"location":"zh/modules/aws/#awsexecargs-opts","title":"<code>aws.exec(args, opts)</code>","text":"<p>\u8fd9\u662f\u8be5\u6a21\u5757\u7684\u6838\u5fc3\u529f\u80fd\u3002\u5b83\u6267\u884c\u4efb\u4f55 AWS CLI \u547d\u4ee4\u5e76\u8fd4\u56de\u7ed3\u679c\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>args</code> (table): \u5fc5\u9700\u3002 \u4e00\u4e2a\u5b57\u7b26\u4e32\u8868\uff0c\u8868\u793a\u8981\u4f20\u9012\u7ed9 AWS CLI \u7684\u547d\u4ee4\u548c\u53c2\u6570\uff08\u4f8b\u5982 <code>{\"s3\", \"ls\", \"--recursive\"}</code>\uff09\u3002</li> <li><code>opts</code> (table): \u53ef\u9009\u3002 \u4e00\u4e2a\u6267\u884c\u9009\u9879\u8868\u3002<ul> <li><code>profile</code> (string): \u5982\u679c\u63d0\u4f9b\uff0c\u5c06\u4f7f\u7528 <code>aws-vault exec &lt;profile&gt; -- aws ...</code> \u6267\u884c\u547d\u4ee4\u3002\u5982\u679c\u7701\u7565\uff0c\u5c06\u76f4\u63a5\u8fd0\u884c <code>aws ...</code>\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <p>\u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a - <code>stdout</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u8f93\u51fa\u3002 - <code>stderr</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u9519\u8bef\u3002 - <code>exit_code</code> (number): \u547d\u4ee4\u7684\u9000\u51fa\u4ee3\u7801\u3002<code>0</code> \u901a\u5e38\u8868\u793a\u6210\u529f\u3002</p> <p>\u793a\u4f8b:</p> <pre><code>-- \u4f7f\u7528\u9ed8\u8ba4\u51ed\u8bc1\nlocal result = aws.exec({\"sts\", \"get-caller-identity\"})\nif result.exit_code == 0 then\n  print(result.stdout)\nend\n\n-- \u4f7f\u7528 aws-vault \u914d\u7f6e\u6587\u4ef6\nlocal result_with_profile = aws.exec({\"ec2\", \"describe-instances\"}, {profile = \"my-prod-profile\"})\n</code></pre>"},{"location":"zh/modules/aws/#s3","title":"S3 \u8f85\u52a9\u51fd\u6570","text":""},{"location":"zh/modules/aws/#awss3syncparams","title":"<code>aws.s3.sync(params)</code>","text":"<p><code>aws s3 sync</code> \u547d\u4ee4\u7684\u9ad8\u7ea7\u5305\u88c5\u5668\uff0c\u7528\u4e8e\u5c06\u76ee\u5f55\u4e0e S3 \u540c\u6b65\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>source</code> (string): \u5fc5\u9700\u3002 \u6e90\u76ee\u5f55\u6216 S3 \u8def\u5f84\u3002</li> <li><code>destination</code> (string): \u5fc5\u9700\u3002 \u76ee\u6807\u76ee\u5f55\u6216 S3 \u8def\u5f84\u3002</li> <li><code>profile</code> (string): \u53ef\u9009\u3002 \u8981\u4f7f\u7528\u7684 <code>aws-vault</code> \u914d\u7f6e\u6587\u4ef6\u3002</li> <li><code>delete</code> (boolean): \u53ef\u9009\u3002 \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u5411\u540c\u6b65\u547d\u4ee4\u6dfb\u52a0 <code>--delete</code> \u6807\u5fd7\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>true</code>\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>false, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local ok, err = aws.s3.sync({\n  source = \"./build\",\n  destination = \"s3://my-app-bucket/static\",\n  profile = \"deployment-profile\",\n  delete = true\n})\nif not ok then\n  log.error(\"S3 \u540c\u6b65\u5931\u8d25: \" .. err)\nend\n</code></pre>"},{"location":"zh/modules/aws/#secrets-manager","title":"Secrets Manager \u8f85\u52a9\u51fd\u6570","text":""},{"location":"zh/modules/aws/#awssecretsmanagerget_secretparams","title":"<code>aws.secretsmanager.get_secret(params)</code>","text":"<p>\u4ece AWS Secrets Manager \u68c0\u7d22\u5bc6\u94a5\u7684\u503c\u3002\u6b64\u51fd\u6570\u901a\u8fc7\u76f4\u63a5\u8fd4\u56de <code>SecretString</code> \u6765\u7b80\u5316\u8be5\u8fc7\u7a0b\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>secret_id</code> (string): \u5fc5\u9700\u3002 \u8981\u68c0\u7d22\u7684\u5bc6\u94a5\u7684\u540d\u79f0\u6216 ARN\u3002</li> <li><code>profile</code> (string): \u53ef\u9009\u3002 \u8981\u4f7f\u7528\u7684 <code>aws-vault</code> \u914d\u7f6e\u6587\u4ef6\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>secret_string</code> (string)\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>nil, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local db_password, err = aws.secretsmanager.get_secret({\n  secret_id = \"production/database/password\",\n  profile = \"my-app-profile\"\n})\n\nif not db_password then\n  log.error(\"\u83b7\u53d6\u5bc6\u94a5\u5931\u8d25: \" .. err)\n  return false, \"\u914d\u7f6e\u5931\u8d25\u3002\"\nend\n\n-- \u73b0\u5728\u60a8\u53ef\u4ee5\u4f7f\u7528 db_password \u53d8\u91cf\n</code></pre>"},{"location":"zh/modules/azure/","title":"Azure \u6a21\u5757","text":"<p><code>azure</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4f7f\u7528 <code>az</code> \u547d\u4ee4\u884c\u5de5\u5177\u4e0e Microsoft Azure \u8fdb\u884c\u4ea4\u4e92\u7684\u754c\u9762\u3002</p>"},{"location":"zh/modules/azure/#_1","title":"\u914d\u7f6e","text":"<p>\u6b64\u6a21\u5757\u9700\u8981\u5b89\u88c5\u5e76\u9a8c\u8bc1 <code>az</code> CLI\u3002\u5728\u4f7f\u7528\u6b64\u6a21\u5757\u7684\u7ba1\u9053\u8fd0\u884c\u4e4b\u524d\uff0c\u60a8\u5fc5\u987b\u767b\u5f55\u5230\u60a8\u7684 Azure \u5e10\u6237\uff1a</p> <pre><code>az login\n</code></pre> <p>\u8be5\u6a21\u5757\u5c06\u4f7f\u7528\u60a8\u767b\u5f55\u7684\u51ed\u636e\u6267\u884c\u6240\u6709\u547d\u4ee4\u3002</p>"},{"location":"zh/modules/azure/#_2","title":"\u901a\u7528\u6267\u884c\u5668","text":""},{"location":"zh/modules/azure/#azureexecargs","title":"<code>azure.exec(args)</code>","text":"<p>\u6267\u884c\u4efb\u4f55 <code>az</code> \u547d\u4ee4\u3002\u6b64\u51fd\u6570\u4f1a\u81ea\u52a8\u6dfb\u52a0 <code>--output json</code> \u6807\u5fd7\uff08\u5982\u679c\u5c1a\u4e0d\u5b58\u5728\uff09\uff0c\u4ee5\u786e\u4fdd\u8f93\u51fa\u662f\u673a\u5668\u53ef\u89e3\u6790\u7684\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>args</code> (table): \u5fc5\u9700\u3002 \u4e00\u4e2a\u5b57\u7b26\u4e32\u8868\uff0c\u8868\u793a\u8981\u4f20\u9012\u7ed9 <code>az</code> \u7684\u547d\u4ee4\u548c\u53c2\u6570\uff08\u4f8b\u5982 <code>{\"group\", \"list\", \"--location\", \"eastus\"}</code>\uff09\u3002</li> </ul> <p>\u8fd4\u56de:</p> <p>\u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a - <code>stdout</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u8f93\u51fa\uff08\u4f5c\u4e3a JSON \u5b57\u7b26\u4e32\uff09\u3002 - <code>stderr</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u9519\u8bef\u3002 - <code>exit_code</code> (number): \u547d\u4ee4\u7684\u9000\u51fa\u4ee3\u7801\u3002<code>0</code> \u901a\u5e38\u8868\u793a\u6210\u529f\u3002</p> <p>\u793a\u4f8b:</p> <pre><code>local result = azure.exec({\"account\", \"show\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"\u767b\u5f55\u4e3a: \" .. account_info.user.name)\n  end\nend\n</code></pre>"},{"location":"zh/modules/azure/#rg","title":"\u8d44\u6e90\u7ec4 (RG) \u8f85\u52a9\u51fd\u6570","text":""},{"location":"zh/modules/azure/#azurergdeleteparams","title":"<code>azure.rg.delete(params)</code>","text":"<p>\u5220\u9664\u8d44\u6e90\u7ec4\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>name</code> (string): \u5fc5\u9700\u3002 \u8981\u5220\u9664\u7684\u8d44\u6e90\u7ec4\u7684\u540d\u79f0\u3002</li> <li><code>yes</code> (boolean): \u53ef\u9009\u3002 \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u6dfb\u52a0 <code>--yes</code> \u6807\u5fd7\u4ee5\u7ed5\u8fc7\u786e\u8ba4\u63d0\u793a\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>true</code>\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>false, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local ok, err = azure.rg.delete({\n  name = \"my-test-rg\",\n  yes = true\n})\nif not ok then\n  log.error(\"\u5220\u9664\u8d44\u6e90\u7ec4\u5931\u8d25: \" .. err)\nend\n</code></pre>"},{"location":"zh/modules/azure/#vm","title":"\u865a\u62df\u673a (VM) \u8f85\u52a9\u51fd\u6570","text":""},{"location":"zh/modules/azure/#azurevmlistparams","title":"<code>azure.vm.list(params)</code>","text":"<p>\u5217\u51fa\u865a\u62df\u673a\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u53ef\u9009\u3002 \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>resource_group</code> (string): \u7528\u4e8e\u5c06\u5217\u8868\u8303\u56f4\u9650\u5b9a\u4e3a\u7684\u8d44\u6e90\u7ec4\u7684\u540d\u79f0\u3002\u5982\u679c\u7701\u7565\uff0c\u5219\u5217\u51fa\u6574\u4e2a\u8ba2\u9605\u4e2d\u7684 VM\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>vms</code> (table)\uff0c\u8be5\u8868\u662f\u60a8\u7684 VM \u5bf9\u8c61\u7684\u5df2\u89e3\u6790 JSON \u6570\u7ec4\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>nil, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>-- \u5217\u51fa\u8ba2\u9605\u4e2d\u7684\u6240\u6709 VM\nlocal all_vms, err1 = azure.vm.list()\n\n-- \u5217\u51fa\u7279\u5b9a\u8d44\u6e90\u7ec4\u4e2d\u7684 VM\nlocal specific_vms, err2 = azure.vm.list({resource_group = \"my-production-rg\"})\nif specific_vms then\n  for _, vm in ipairs(specific_vms) do\n    print(\"\u627e\u5230 VM: \" .. vm.name)\n  end\nend\n</code></pre>"},{"location":"zh/modules/data/","title":"Data \u6a21\u5757","text":"<p><code>data</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u5728 Lua \u8868\u548c\u5e38\u89c1\u6570\u636e\u683c\u5f0f\uff08\u5982 JSON \u548c YAML\uff09\u4e4b\u95f4\u89e3\u6790\u548c\u5e8f\u5217\u5316\u6570\u636e\u7684\u529f\u80fd\u3002</p>"},{"location":"zh/modules/data/#dataparse_jsonjson_string","title":"<code>data.parse_json(json_string)</code>","text":"<p>\u5c06 JSON \u5b57\u7b26\u4e32\u89e3\u6790\u4e3a Lua \u8868\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>json_string</code> (string): \u8981\u89e3\u6790\u7684 JSON \u683c\u5f0f\u5b57\u7b26\u4e32\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>table</code>: \u751f\u6210\u7684 Lua \u8868\u3002</li> <li><code>error</code>: \u5982\u679c\u89e3\u6790\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/data/#datato_jsonlua_table","title":"<code>data.to_json(lua_table)</code>","text":"<p>\u5c06 Lua \u8868\u5e8f\u5217\u5316\u4e3a JSON \u5b57\u7b26\u4e32\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>lua_table</code> (table): \u8981\u5e8f\u5217\u5316\u7684 Lua \u8868\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>string</code>: \u751f\u6210\u7684 JSON \u5b57\u7b26\u4e32\u3002</li> <li><code>error</code>: \u5982\u679c\u5e8f\u5217\u5316\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/data/#dataparse_yamlyaml_string","title":"<code>data.parse_yaml(yaml_string)</code>","text":"<p>\u5c06 YAML \u5b57\u7b26\u4e32\u89e3\u6790\u4e3a Lua \u8868\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>yaml_string</code> (string): \u8981\u89e3\u6790\u7684 YAML \u683c\u5f0f\u5b57\u7b26\u4e32\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>table</code>: \u751f\u6210\u7684 Lua \u8868\u3002</li> <li><code>error</code>: \u5982\u679c\u89e3\u6790\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/data/#datato_yamllua_table","title":"<code>data.to_yaml(lua_table)</code>","text":"<p>\u5c06 Lua \u8868\u5e8f\u5217\u5316\u4e3a YAML \u5b57\u7b26\u4e32\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>lua_table</code> (table): \u8981\u5e8f\u5217\u5316\u7684 Lua \u8868\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>string</code>: \u751f\u6210\u7684 YAML \u5b57\u7b26\u4e32\u3002</li> <li><code>error</code>: \u5982\u679c\u5e8f\u5217\u5316\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/data/#_1","title":"\u793a\u4f8b","text":"<pre><code>command = function()\n  local data = require(\"data\")\n\n  -- JSON \u793a\u4f8b\n  log.info(\"\u6d4b\u8bd5 JSON \u5e8f\u5217\u5316...\")\n  local my_table = { name = \"sloth-runner\", version = 1.0, features = { \"tasks\", \"lua\" } }\n  local json_str, err = data.to_json(my_table)\n  if err then\n    return false, \"\u5e8f\u5217\u5316\u5230 JSON \u5931\u8d25: \" .. err\n  end\n  print(\"\u5e8f\u5217\u5316\u7684 JSON: \" .. json_str)\n\n  log.info(\"\u6d4b\u8bd5 JSON \u89e3\u6790...\")\n  local parsed_table, err = data.parse_json(json_str)\n  if err then\n    return false, \"\u89e3\u6790 JSON \u5931\u8d25: \" .. err\n  end\n  log.info(\"\u4ece JSON \u89e3\u6790\u7684\u540d\u79f0: \" .. parsed_table.name)\n\n  -- YAML \u793a\u4f8b\n  log.info(\"\u6d4b\u8bd5 YAML \u5e8f\u5217\u5316...\")\n  local yaml_str, err = data.to_yaml(my_table)\n  if err then\n    return false, \"\u5e8f\u5217\u5316\u5230 YAML \u5931\u8d25: \" .. err\n  end\n  print(\"\u5e8f\u5217\u5316\u7684 YAML:\\n\" .. yaml_str)\n\n  log.info(\"\u6d4b\u8bd5 YAML \u89e3\u6790...\")\n  parsed_table, err = data.parse_yaml(yaml_str)\n  if err then\n    return false, \"\u89e3\u6790 YAML \u5931\u8d25: \" .. err\n  end\n  log.info(\"\u4ece YAML \u89e3\u6790\u7684\u7248\u672c: \" .. parsed_table.version)\n\n  return true, \"Data \u6a21\u5757\u64cd\u4f5c\u6210\u529f\u3002\"\nend\n</code></pre> <p>```</p>"},{"location":"zh/modules/digitalocean/","title":"DigitalOcean \u6a21\u5757","text":"<p><code>digitalocean</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4f7f\u7528 <code>doctl</code> \u547d\u4ee4\u884c\u5de5\u5177\u4e0e\u60a8\u7684 DigitalOcean \u8d44\u6e90\u8fdb\u884c\u4ea4\u4e92\u7684\u754c\u9762\u3002</p>"},{"location":"zh/modules/digitalocean/#_1","title":"\u914d\u7f6e","text":"<p>\u6b64\u6a21\u5757\u9700\u8981\u5b89\u88c5\u5e76\u9a8c\u8bc1 <code>doctl</code> CLI\u3002\u6807\u51c6\u65b9\u6cd5\u662f\u5728\u60a8\u7684 DigitalOcean \u63a7\u5236\u9762\u677f\u4e2d\u751f\u6210\u4e2a\u4eba\u8bbf\u95ee\u4ee4\u724c\uff0c\u5e76\u5c06\u5176\u8bbe\u7f6e\u4e3a <code>DIGITALOCEAN_ACCESS_TOKEN</code> \u73af\u5883\u53d8\u91cf\u3002</p> <pre><code>export DIGITALOCEAN_ACCESS_TOKEN=\"your_do_api_token_here\"\n</code></pre> <p>\u8be5\u6a21\u5757\u5c06\u81ea\u52a8\u5c06\u6b64\u4ee4\u724c\u7528\u4e8e\u6240\u6709\u547d\u4ee4\u3002</p>"},{"location":"zh/modules/digitalocean/#_2","title":"\u901a\u7528\u6267\u884c\u5668","text":""},{"location":"zh/modules/digitalocean/#digitaloceanexecargs","title":"<code>digitalocean.exec(args)</code>","text":"<p>\u6267\u884c\u4efb\u4f55 <code>doctl</code> \u547d\u4ee4\u3002\u6b64\u51fd\u6570\u4f1a\u81ea\u52a8\u6dfb\u52a0 <code>--output json</code> \u6807\u5fd7\uff0c\u4ee5\u786e\u4fdd\u8f93\u51fa\u662f\u673a\u5668\u53ef\u89e3\u6790\u7684\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>args</code> (table): \u5fc5\u9700\u3002 \u4e00\u4e2a\u5b57\u7b26\u4e32\u8868\uff0c\u8868\u793a\u8981\u4f20\u9012\u7ed9 <code>doctl</code> \u7684\u547d\u4ee4\u548c\u53c2\u6570\uff08\u4f8b\u5982 <code>{\"compute\", \"droplet\", \"list\"}</code>\uff09\u3002</li> </ul> <p>\u8fd4\u56de:</p> <p>\u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a - <code>stdout</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u8f93\u51fa\uff08\u4f5c\u4e3a JSON \u5b57\u7b26\u4e32\uff09\u3002 - <code>stderr</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u9519\u8bef\u3002 - <code>exit_code</code> (number): \u547d\u4ee4\u7684\u9000\u51fa\u4ee3\u7801\u3002<code>0</code> \u901a\u5e38\u8868\u793a\u6210\u529f\u3002</p> <p>\u793a\u4f8b:</p> <pre><code>local result = digitalocean.exec({\"account\", \"get\"})\nif result.exit_code == 0 then\n  local account_info, err = data.parse_json(result.stdout)\n  if account_info then\n    log.info(\"\u5e10\u6237\u72b6\u6001: \" .. account_info.status)\n  end\nend\n</code></pre>"},{"location":"zh/modules/digitalocean/#droplets","title":"Droplets \u8f85\u52a9\u51fd\u6570","text":""},{"location":"zh/modules/digitalocean/#digitaloceandropletslist","title":"<code>digitalocean.droplets.list()</code>","text":"<p>\u4e00\u4e2a\u9ad8\u7ea7\u5305\u88c5\u5668\uff0c\u7528\u4e8e\u5217\u51fa\u60a8\u5e10\u6237\u4e2d\u7684\u6240\u6709 Droplet\u3002</p> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>droplets</code> (table)\uff0c\u8be5\u8868\u662f\u60a8\u7684 Droplet \u5bf9\u8c61\u7684\u5df2\u89e3\u6790 JSON \u6570\u7ec4\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>nil, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local droplets, err = digitalocean.droplets.list()\nif droplets then\n  for _, droplet in ipairs(droplets) do\n    print(\"\u627e\u5230 Droplet: \" .. droplet.name)\n  end\nend\n</code></pre>"},{"location":"zh/modules/digitalocean/#digitaloceandropletsdeleteparams","title":"<code>digitalocean.droplets.delete(params)</code>","text":"<p>\u6309 ID \u5220\u9664\u7279\u5b9a\u7684 Droplet\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>id</code> (string): \u5fc5\u9700\u3002 \u8981\u5220\u9664\u7684 Droplet \u7684 ID\u3002</li> <li><code>force</code> (boolean): \u53ef\u9009\u3002 \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u6dfb\u52a0 <code>--force</code> \u6807\u5fd7\u4ee5\u7ed5\u8fc7\u786e\u8ba4\u63d0\u793a\u3002\u9ed8\u8ba4\u4e3a <code>false</code>\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>true</code>\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>false, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local ok, err = digitalocean.droplets.delete({\n  id = \"123456789\",\n  force = true\n})\nif not ok then\n  log.error(\"\u5220\u9664 droplet \u5931\u8d25: \" .. err)\nend\n</code></pre>"},{"location":"zh/modules/docker/","title":"Docker \u6a21\u5757","text":"<p><code>docker</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b9\u4fbf\u7684\u754c\u9762\uff0c\u7528\u4e8e\u4e0e Docker \u5b88\u62a4\u8fdb\u7a0b\u4ea4\u4e92\uff0c\u5141\u8bb8\u60a8\u5728\u7ba1\u9053\u4e2d\u6784\u5efa\u3001\u8fd0\u884c\u548c\u63a8\u9001 Docker \u955c\u50cf\u3002</p>"},{"location":"zh/modules/docker/#_1","title":"\u914d\u7f6e","text":"<p>\u6b64\u6a21\u5757\u9700\u8981\u5b89\u88c5 <code>docker</code> CLI\uff0c\u5e76\u4e14 Docker \u5b88\u62a4\u8fdb\u7a0b\u6b63\u5728\u8fd0\u884c\u4e14\u53ef\u8bbf\u95ee\u3002</p>"},{"location":"zh/modules/docker/#_2","title":"\u51fd\u6570","text":""},{"location":"zh/modules/docker/#dockerexecargs","title":"<code>docker.exec(args)</code>","text":"<p>\u6267\u884c\u4efb\u4f55\u539f\u59cb\u7684 <code>docker</code> \u547d\u4ee4\u3002</p> <ul> <li><code>args</code> (table): \u5fc5\u9700\u3002 \u8981\u4f20\u9012\u7ed9 <code>docker</code> \u547d\u4ee4\u7684\u53c2\u6570\u5217\u8868\uff08\u4f8b\u5982 <code>{\"ps\", \"-a\"}</code>\uff09\u3002</li> <li>\u8fd4\u56de: \u5305\u542b <code>success</code>\u3001<code>stdout</code>\u3001<code>stderr</code> \u548c <code>exit_code</code> \u7684\u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/docker/#dockerbuildparams","title":"<code>docker.build(params)</code>","text":"<p>\u4f7f\u7528 <code>docker build</code> \u6784\u5efa Docker \u955c\u50cf\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>tag</code> (string): \u5fc5\u9700\u3002 \u955c\u50cf\u7684\u6807\u7b7e\uff08\u4f8b\u5982 <code>my-app:latest</code>\uff09\u3002</li> <li><code>path</code> (string): \u5fc5\u9700\u3002 \u6784\u5efa\u4e0a\u4e0b\u6587\u8def\u5f84\u3002</li> <li><code>dockerfile</code> (string): \u53ef\u9009\u3002 Dockerfile \u7684\u8def\u5f84\u3002</li> <li><code>build_args</code> (table): \u53ef\u9009\u3002 \u6784\u5efa\u53c2\u6570\u8868\uff08\u4f8b\u5982 <code>{VERSION = \"1.0\"}</code>\uff09\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/docker/#dockerpushparams","title":"<code>docker.push(params)</code>","text":"<p>\u4f7f\u7528 <code>docker push</code> \u5c06 Docker \u955c\u50cf\u63a8\u9001\u5230\u6ce8\u518c\u8868\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>tag</code> (string): \u5fc5\u9700\u3002 \u8981\u63a8\u9001\u7684\u955c\u50cf\u7684\u6807\u7b7e\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/docker/#dockerrunparams","title":"<code>docker.run(params)</code>","text":"<p>\u4f7f\u7528 <code>docker run</code> \u8fd0\u884c Docker \u5bb9\u5668\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>image</code> (string): \u5fc5\u9700\u3002 \u8981\u8fd0\u884c\u7684\u955c\u50cf\u3002</li> <li><code>name</code> (string): \u53ef\u9009\u3002 \u5bb9\u5668\u7684\u540d\u79f0\u3002</li> <li><code>detach</code> (boolean): \u53ef\u9009\u3002 \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u5728\u540e\u53f0\u8fd0\u884c\u5bb9\u5668 (<code>-d</code>)\u3002</li> <li><code>ports</code> (table): \u53ef\u9009\u3002 \u7aef\u53e3\u6620\u5c04\u5217\u8868\uff08\u4f8b\u5982 <code>{\"8080:80\"}</code>\uff09\u3002</li> <li><code>env</code> (table): \u53ef\u9009\u3002 \u73af\u5883\u53d8\u91cf\u8868\uff08\u4f8b\u5982 <code>{MY_VAR = \"value\"}</code>\uff09\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/docker/#_3","title":"\u793a\u4f8b","text":"<pre><code>local image_tag = \"my-test-image:latest\"\n\n-- \u4efb\u52a1 1: Build\nlocal result_build = docker.build({\n  tag = image_tag,\n  path = \"./app\"\n})\nif not result_build.success then return false, \"\u6784\u5efa\u5931\u8d25\" end\n\n-- \u4efb\u52a1 2: Run\nlocal result_run = docker.run({\n  image = image_tag,\n  name = \"my-test-container\",\n  ports = {\"8080:80\"}\n})\nif not result_run.success then return false, \"\u8fd0\u884c\u5931\u8d25\" end\n\n-- \u4efb\u52a1 3: Push (\u6d4b\u8bd5\u6210\u529f\u540e)\nlocal result_push = docker.push({tag = image_tag})\nif not result_push.success then return false, \"\u63a8\u9001\u5931\u8d25\" end\n</code></pre>"},{"location":"zh/modules/exec/","title":"Exec \u6a21\u5757","text":"<p><code>exec</code> \u6a21\u5757\u662f <code>sloth-runner</code> \u4e2d\u6700\u57fa\u672c\u7684\u6a21\u5757\u4e4b\u4e00\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u51fd\u6570\u6765\u6267\u884c\u4efb\u610f\u7684 shell \u547d\u4ee4\uff0c\u8ba9\u60a8\u53ef\u4ee5\u5b8c\u5168\u63a7\u5236\u6267\u884c\u73af\u5883\u3002</p>"},{"location":"zh/modules/exec/#execruncommand-options","title":"<code>exec.run(command, [options])</code>","text":"<p>\u4f7f\u7528 <code>bash -c</code> \u6267\u884c\u4e00\u4e2a shell \u547d\u4ee4\u3002</p>"},{"location":"zh/modules/exec/#_1","title":"\u53c2\u6570","text":"<ul> <li><code>command</code> (string): \u8981\u6267\u884c\u7684 shell \u547d\u4ee4\u3002</li> <li><code>options</code> (table, \u53ef\u9009): \u7528\u4e8e\u63a7\u5236\u6267\u884c\u7684\u9009\u9879\u8868\u3002<ul> <li><code>workdir</code> (string): \u547d\u4ee4\u5e94\u5728\u5176\u4e2d\u6267\u884c\u7684\u5de5\u4f5c\u76ee\u5f55\u3002\u5982\u679c\u672a\u63d0\u4f9b\uff0c\u5b83\u5c06\u5728\u4efb\u52a1\u7ec4\u7684\u4e34\u65f6\u76ee\u5f55\uff08\u5982\u679c\u53ef\u7528\uff09\u6216\u5f53\u524d\u76ee\u5f55\u4e2d\u8fd0\u884c\u3002</li> <li><code>env</code> (table): \u4e3a\u547d\u4ee4\u6267\u884c\u8bbe\u7f6e\u7684\u73af\u5883\u53d8\u91cf\u5b57\u5178\uff08\u952e\u503c\u5bf9\uff09\u3002\u8fd9\u4e9b\u53d8\u91cf\u4f1a\u6dfb\u52a0\u5230\u73b0\u6709\u73af\u5883\u4e2d\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/exec/#_2","title":"\u8fd4\u56de","text":"<p>\u4e00\u4e2a\u5305\u542b\u547d\u4ee4\u6267\u884c\u7ed3\u679c\u7684\u8868\uff1a</p> <ul> <li><code>success</code> (boolean): \u5982\u679c\u547d\u4ee4\u4ee5\u4ee3\u7801 <code>0</code> \u9000\u51fa\uff0c\u5219\u4e3a <code>true</code>\uff0c\u5426\u5219\u4e3a <code>false</code>\u3002</li> <li><code>stdout</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u8f93\u51fa\u3002</li> <li><code>stderr</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u9519\u8bef\u8f93\u51fa\u3002</li> </ul>"},{"location":"zh/modules/exec/#_3","title":"\u793a\u4f8b","text":"<p>\u6b64\u793a\u4f8b\u6f14\u793a\u5982\u4f55\u4f7f\u7528\u5e26\u6709\u81ea\u5b9a\u4e49\u5de5\u4f5c\u76ee\u5f55\u548c\u73af\u5883\u53d8\u91cf\u7684 <code>exec.run</code>\u3002</p> <pre><code>-- examples/exec_module_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"\u4e00\u4e2a\u6f14\u793a exec \u6a21\u5757\u7684\u4efb\u52a1\u3002\",\n    tasks = {\n      {\n        name = \"run-with-options\",\n        description = \"\u4f7f\u7528\u81ea\u5b9a\u4e49\u5de5\u4f5c\u76ee\u5f55\u548c\u73af\u5883\u6267\u884c\u547d\u4ee4\u3002\",\n        command = function()\n          log.info(\"\u51c6\u5907\u8fd0\u884c\u81ea\u5b9a\u4e49\u547d\u4ee4...\")\n\n          local exec = require(\"exec\")\n\n          -- \u4e3a\u793a\u4f8b\u521b\u5efa\u4e00\u4e2a\u4e34\u65f6\u76ee\u5f55\n          local temp_dir = \"/tmp/sloth-exec-test\"\n          fs.mkdir(temp_dir)\n          fs.write(temp_dir .. \"/test.txt\", \"\u6765\u81ea\u6d4b\u8bd5\u6587\u4ef6\u7684\u95ee\u5019\")\n\n          -- \u5b9a\u4e49\u9009\u9879\n          local options = {\n            workdir = temp_dir,\n            env = {\n              MY_VAR = \"SlothRunner\",\n              ANOTHER_VAR = \"is_awesome\"\n            }\n          }\n\n          -- \u6267\u884c\u547d\u4ee4\n          local result = exec.run(\"echo 'MY_VAR is $MY_VAR' &amp;&amp; ls -l &amp;&amp; cat test.txt\", options)\n\n          -- \u6e05\u7406\u4e34\u65f6\u76ee\u5f55\n          fs.rm_r(temp_dir)\n\n          if result.success then\n            log.info(\"\u547d\u4ee4\u6210\u529f\u6267\u884c\uff01\")\n            print(\"--- STDOUT ---\")\n            print(result.stdout)\n            print(\"--------------\")\n            return true, \"Exec \u547d\u4ee4\u6210\u529f\u3002\"\n          else\n            log.error(\"Exec \u547d\u4ee4\u5931\u8d25\u3002\")\n            log.error(\"Stderr: \" .. result.stderr)\n            return false, \"Exec \u547d\u4ee4\u5931\u8d25\u3002\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"zh/modules/fs/","title":"FS \u6a21\u5757","text":"<p><code>fs</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4ece\u60a8\u7684 Lua \u811a\u672c\u76f4\u63a5\u4e0e\u6587\u4ef6\u7cfb\u7edf\u4ea4\u4e92\u7684\u57fa\u672c\u529f\u80fd\u3002</p> <p>---\\n</p>"},{"location":"zh/modules/fs/#fsreadpath","title":"<code>fs.read(path)</code>","text":"<p>\u8bfb\u53d6\u6587\u4ef6\u7684\u5168\u90e8\u5185\u5bb9\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u6587\u4ef6\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>string</code>: \u6587\u4ef6\u5185\u5bb9\u3002</li> <li><code>error</code>: \u5982\u679c\u8bfb\u53d6\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fswritepath-content","title":"<code>fs.write(path, content)</code>","text":"<p>\u5c06\u5185\u5bb9\u5199\u5165\u6587\u4ef6\uff0c\u5982\u679c\u6587\u4ef6\u5df2\u5b58\u5728\u5219\u8986\u76d6\u5b83\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u6587\u4ef6\u8def\u5f84\u3002</li> <li><code>content</code> (string): \u8981\u5199\u5165\u7684\u5185\u5bb9\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u5199\u5165\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fsappendpath-content","title":"<code>fs.append(path, content)</code>","text":"<p>\u5c06\u5185\u5bb9\u8ffd\u52a0\u5230\u6587\u4ef6\u672b\u5c3e\u3002\u5982\u679c\u6587\u4ef6\u4e0d\u5b58\u5728\uff0c\u5219\u521b\u5efa\u5b83\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u6587\u4ef6\u8def\u5f84\u3002</li> <li><code>content</code> (string): \u8981\u8ffd\u52a0\u7684\u5185\u5bb9\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u8ffd\u52a0\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fsexistspath","title":"<code>fs.exists(path)</code>","text":"<p>\u68c0\u67e5\u7ed9\u5b9a\u8def\u5f84\u7684\u6587\u4ef6\u6216\u76ee\u5f55\u662f\u5426\u5b58\u5728\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u8981\u68c0\u67e5\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>boolean</code>: \u5982\u679c\u8def\u5f84\u5b58\u5728\uff0c\u5219\u4e3a <code>true</code>\uff0c\u5426\u5219\u4e3a <code>false</code>\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fsmkdirpath","title":"<code>fs.mkdir(path)</code>","text":"<p>\u5728\u7ed9\u5b9a\u8def\u5f84\u521b\u5efa\u4e00\u4e2a\u76ee\u5f55\uff0c\u5305\u62ec\u4efb\u4f55\u5fc5\u8981\u7684\u7236\u76ee\u5f55 (\u7c7b\u4f3c\u4e8e <code>mkdir -p</code>)\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u8981\u521b\u5efa\u7684\u76ee\u5f55\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u521b\u5efa\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fsrmpath","title":"<code>fs.rm(path)</code>","text":"<p>\u5220\u9664\u5355\u4e2a\u6587\u4ef6\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u8981\u5220\u9664\u7684\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u5220\u9664\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fsrm_rpath","title":"<code>fs.rm_r(path)</code>","text":"<p>\u9012\u5f52\u5730\u5220\u9664\u6587\u4ef6\u6216\u76ee\u5f55 (\u7c7b\u4f3c\u4e8e <code>rm -rf</code>)\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u8981\u5220\u9664\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u5220\u9664\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fslspath","title":"<code>fs.ls(path)</code>","text":"<p>\u5217\u51fa\u76ee\u5f55\u7684\u5185\u5bb9\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u76ee\u5f55\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>table</code>: \u5305\u542b\u6587\u4ef6\u548c\u5b50\u76ee\u5f55\u540d\u79f0\u7684\u8868\u3002</li> <li><code>error</code>: \u5982\u679c\u5217\u51fa\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul> <p>---\\n</p>"},{"location":"zh/modules/fs/#fstmpname","title":"<code>fs.tmpname()</code>","text":"<p>\u751f\u6210\u4e00\u4e2a\u552f\u4e00\u7684\u4e34\u65f6\u76ee\u5f55\u8def\u5f84\u3002\u6ce8\u610f\uff1a\u6b64\u51fd\u6570\u4ec5\u8fd4\u56de\u540d\u79f0\uff0c\u4e0d\u521b\u5efa\u76ee\u5f55\u3002</p> <ul> <li>\u8fd4\u56de:<ul> <li><code>string</code>: \u9002\u5408\u7528\u4f5c\u4e34\u65f6\u76ee\u5f55\u7684\u552f\u4e00\u8def\u5f84\u3002</li> <li><code>error</code>: \u5982\u679c\u65e0\u6cd5\u751f\u6210\u540d\u79f0\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/fs/#_1","title":"\u793a\u4f8b","text":"<pre><code>command = function()\n  local fs = require(\"fs\")\n\n  local tmp_dir = \"/tmp/fs-example\"\n  log.info(\"\u6b63\u5728\u521b\u5efa\u76ee\u5f55: \" .. tmp_dir)\n  fs.mkdir(tmp_dir)\n\n  local file_path = tmp_dir .. \"/my_file.txt\"\n  log.info(\"\u6b63\u5728\u5199\u5165\u6587\u4ef6: \" .. file_path)\n  fs.write(file_path, \"\u4f60\u597d, Sloth Runner!\\n\")\n\n  log.info(\"\u6b63\u5728\u8ffd\u52a0\u5230\u6587\u4ef6...\")\n  fs.append(file_path, \"\u8fd9\u662f\u4e00\u4e2a\u65b0\u884c\u3002\")\n\n  if fs.exists(file_path) then\n    log.info(\"\u6587\u4ef6\u5185\u5bb9: \" .. fs.read(file_path))\n  end\n\n  log.info(\"\u6b63\u5728\u5217\u51fa \" .. tmp_dir .. \" \u7684\u5185\u5bb9\")\n  local contents = fs.ls(tmp_dir)\n  for i, name in ipairs(contents) do\n    print(\"- \" .. name)\n  end\n\n  log.info(\"\u6b63\u5728\u6e05\u7406...\")\n  fs.rm_r(tmp_dir)\n\n  return true, \"FS \u6a21\u5757\u64cd\u4f5c\u6210\u529f\u3002\"\nend\n</code></pre> <p>```</p>"},{"location":"zh/modules/gcp/","title":"GCP \u6a21\u5757","text":"<p><code>gcp</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u754c\u9762\uff0c\u7528\u4e8e\u4ece <code>sloth-runner</code> \u4efb\u52a1\u5185\u90e8\u6267\u884c\u8c37\u6b4c\u4e91\u547d\u4ee4\u884c\u754c\u9762 (<code>gcloud</code>) \u547d\u4ee4\u3002</p>"},{"location":"zh/modules/gcp/#gcpexecargs","title":"<code>gcp.exec(args)</code>","text":"<p>\u4f7f\u7528\u6307\u5b9a\u7684\u53c2\u6570\u6267\u884c <code>gcloud</code> \u547d\u4ee4\u3002</p>"},{"location":"zh/modules/gcp/#_1","title":"\u53c2\u6570","text":"<ul> <li><code>args</code> (table): \u4e00\u4e2a Lua \u8868\uff08\u6570\u7ec4\uff09\uff0c\u5305\u542b\u8981\u4f20\u9012\u7ed9 <code>gcloud</code> \u547d\u4ee4\u7684\u5b57\u7b26\u4e32\u53c2\u6570\u3002\u4f8b\u5982\uff0c<code>{\"compute\", \"instances\", \"list\"}</code>\u3002</li> </ul>"},{"location":"zh/modules/gcp/#_2","title":"\u8fd4\u56de","text":"<p>\u4e00\u4e2a\u5305\u542b\u547d\u4ee4\u6267\u884c\u7ed3\u679c\u7684\u8868\uff0c\u5176\u4e2d\u5305\u542b\u4ee5\u4e0b\u952e\uff1a</p> <ul> <li><code>stdout</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u8f93\u51fa\u3002</li> <li><code>stderr</code> (string): \u547d\u4ee4\u7684\u6807\u51c6\u9519\u8bef\u8f93\u51fa\u3002</li> <li><code>exit_code</code> (number): \u547d\u4ee4\u7684\u9000\u51fa\u4ee3\u7801\u3002\u9000\u51fa\u4ee3\u7801 <code>0</code> \u901a\u5e38\u8868\u793a\u6210\u529f\u3002</li> </ul>"},{"location":"zh/modules/gcp/#_3","title":"\u793a\u4f8b","text":"<p>\u6b64\u793a\u4f8b\u5b9a\u4e49\u4e86\u4e00\u4e2a\u4efb\u52a1\uff0c\u7528\u4e8e\u5217\u51fa\u7279\u5b9a\u9879\u76ee\u5728 <code>us-central1</code> \u533a\u57df\u4e2d\u7684\u6240\u6709 Compute Engine \u5b9e\u4f8b\u3002</p> <pre><code>-- examples/gcp_cli_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"\u4e00\u4e2a\u5217\u51fa GCP \u8ba1\u7b97\u5b9e\u4f8b\u7684\u4efb\u52a1\u3002\",\n    tasks = {\n      {\n        name = \"list-instances\",\n        description = \"\u5217\u51fa us-central1 \u4e2d\u7684 GCE \u5b9e\u4f8b\u3002\",\n        command = function()\n          log.info(\"\u6b63\u5728\u5217\u51fa GCP \u5b9e\u4f8b...\")\n\n          -- \u9700\u8981 gcp \u6a21\u5757\u4f7f\u5176\u53ef\u7528\n          local gcp = require(\"gcp\")\n\n          -- \u6267\u884c gcloud \u547d\u4ee4\n          local result = gcp.exec({\n            \"compute\", \n            \"instances\", \n            \"list\", \n            \"--project\", \"my-gcp-project-id\",\n            \"--zones\", \"us-central1-a,us-central1-b\"\n          })\n\n          -- \u68c0\u67e5\u7ed3\u679c\n          if result and result.exit_code == 0 then\n            log.info(\"\u6210\u529f\u5217\u51fa\u5b9e\u4f8b\u3002\")\n            print(\"--- \u5b9e\u4f8b\u5217\u8868 ---\")\n            print(result.stdout)\n            print(\"---------------------\")\n            return true, \"GCP \u547d\u4ee4\u6210\u529f\u3002\"\n          else\n            log.error(\"\u672a\u80fd\u5217\u51fa GCP \u5b9e\u4f8b\u3002\")\n            if result then\n              log.error(\"Stderr: \" .. result.stderr)\n            end\n            return false, \"GCP \u547d\u4ee4\u5931\u8d25\u3002\"\n          end\n        end\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"zh/modules/git/","title":"Git \u6a21\u5757","text":"<p><code>git</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6d41\u7545\u7684 API \u6765\u4e0e Git \u5b58\u50a8\u5e93\u8fdb\u884c\u4ea4\u4e92\uff0c\u5141\u8bb8\u60a8\u81ea\u52a8\u5316\u5e38\u89c1\u7684\u7248\u672c\u63a7\u5236\u64cd\u4f5c\uff0c\u5982\u514b\u9686\u3001\u63d0\u4ea4\u548c\u63a8\u9001\u3002</p>"},{"location":"zh/modules/git/#gitcloneurl-path","title":"<code>git.clone(url, path)</code>","text":"<p>\u5c06 Git \u5b58\u50a8\u5e93\u514b\u9686\u5230\u672c\u5730\u8def\u5f84\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>url</code> (string): \u8981\u514b\u9686\u7684\u5b58\u50a8\u5e93\u7684 URL\u3002</li> <li><code>path</code> (string): \u8981\u514b\u9686\u5230\u7684\u672c\u5730\u76ee\u5f55\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>repo</code> (object): \u6210\u529f\u65f6\u8fd4\u56de\u4e00\u4e2a <code>GitRepo</code> \u5bf9\u8c61\u3002</li> <li><code>error</code>: \u5982\u679c\u514b\u9686\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/git/#gitrepopath","title":"<code>git.repo(path)</code>","text":"<p>\u6253\u5f00\u4e00\u4e2a\u73b0\u6709\u7684\u672c\u5730 Git \u5b58\u50a8\u5e93\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u73b0\u6709\u672c\u5730\u5b58\u50a8\u5e93\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>repo</code> (object): \u6210\u529f\u65f6\u8fd4\u56de\u4e00\u4e2a <code>GitRepo</code> \u5bf9\u8c61\u3002</li> <li><code>error</code>: \u5982\u679c\u8def\u5f84\u4e0d\u662f\u6709\u6548\u7684 Git \u5b58\u50a8\u5e93\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/git/#gitrepo","title":"<code>GitRepo</code> \u5bf9\u8c61","text":"<p>\u6b64\u5bf9\u8c61\u8868\u793a\u4e00\u4e2a\u672c\u5730\u5b58\u50a8\u5e93\uff0c\u5e76\u63d0\u4f9b\u53ef\u94fe\u63a5\u7684\u65b9\u6cd5\u6765\u6267\u884c Git \u64cd\u4f5c\u3002</p>"},{"location":"zh/modules/git/#repocheckoutref","title":"<code>repo:checkout(ref)</code>","text":"<p>\u68c0\u51fa\u7279\u5b9a\u7684\u5206\u652f\u3001\u6807\u7b7e\u6216\u63d0\u4ea4\u3002</p> <ul> <li>\u53c2\u6570: <code>ref</code> (string)\u3002</li> </ul>"},{"location":"zh/modules/git/#repopullremote-branch","title":"<code>repo:pull(remote, branch)</code>","text":"<p>\u4ece\u8fdc\u7a0b\u62c9\u53d6\u66f4\u6539\u3002</p> <ul> <li>\u53c2\u6570: <code>remote</code> (string), <code>branch</code> (string)\u3002</li> </ul>"},{"location":"zh/modules/git/#repoaddpattern","title":"<code>repo:add(pattern)</code>","text":"<p>\u5c06\u6587\u4ef6\u6682\u5b58\u4ee5\u8fdb\u884c\u63d0\u4ea4\u3002</p> <ul> <li>\u53c2\u6570: <code>pattern</code> (string), \u4f8b\u5982 <code>\".\"</code> \u6216 <code>\"path/to/file.txt\"</code>\u3002</li> </ul>"},{"location":"zh/modules/git/#repocommitmessage","title":"<code>repo:commit(message)</code>","text":"<p>\u521b\u5efa\u4e00\u4e2a\u63d0\u4ea4\u3002</p> <ul> <li>\u53c2\u6570: <code>message</code> (string)\u3002</li> </ul>"},{"location":"zh/modules/git/#repotagname-message","title":"<code>repo:tag(name, [message])</code>","text":"<p>\u521b\u5efa\u4e00\u4e2a\u65b0\u6807\u7b7e\u3002</p> <ul> <li>\u53c2\u6570: <code>name</code> (string), <code>message</code> (string, \u53ef\u9009)\u3002</li> </ul>"},{"location":"zh/modules/git/#repopushremote-branch-options","title":"<code>repo:push(remote, branch, [options])</code>","text":"<p>\u5c06\u63d0\u4ea4\u63a8\u9001\u5230\u8fdc\u7a0b\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>remote</code> (string)\u3002</li> <li><code>branch</code> (string)\u3002</li> <li><code>options</code> (table, \u53ef\u9009): \u4f8b\u5982 <code>{ follow_tags = true }</code>\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/git/#reporesult","title":"<code>repo:result()</code>","text":"<p>\u6b64\u65b9\u6cd5\u5728\u94fe\u7684\u672b\u5c3e\u8c03\u7528\uff0c\u4ee5\u83b7\u53d6\u6700\u540e\u4e00\u4e2a\u64cd\u4f5c\u7684\u7ed3\u679c\u3002</p> <ul> <li>\u8fd4\u56de:<ul> <li><code>result</code> (table): \u4e00\u4e2a\u5305\u542b <code>success</code> (boolean)\u3001<code>stdout</code> (string) \u548c <code>stderr</code> (string) \u7684\u8868\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/git/#_1","title":"\u793a\u4f8b","text":"<p>\u6b64\u793a\u4f8b\u6f14\u793a\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u7c7b\u4f3c CI/CD \u7684\u5de5\u4f5c\u6d41\uff1a\u514b\u9686\u3001\u521b\u5efa\u7248\u672c\u6587\u4ef6\u3001\u6dfb\u52a0\u3001\u63d0\u4ea4\u3001\u6253\u6807\u7b7e\u548c\u63a8\u9001\u3002</p> <pre><code>command = function()\n  local git = require(\"git\")\n  local repo_path = \"/tmp/git-example-repo\"\n\n  -- \u6e05\u7406\u4ee5\u524d\u7684\u8fd0\u884c\n  fs.rm_r(repo_path)\n\n  -- 1. \u514b\u9686\u5b58\u50a8\u5e93\n  log.info(\"\u6b63\u5728\u514b\u9686\u5b58\u50a8\u5e93...\")\n  local repo, err = git.clone(\"https://github.com/chalkan3-sloth/sloth-runner.git\", repo_path)\n  if err then\n    return false, \"\u514b\u9686\u5931\u8d25: \" .. err\n  end\n\n  -- 2. \u521b\u5efa\u5e76\u5199\u5165\u7248\u672c\u6587\u4ef6\n  fs.write(repo_path .. \"/VERSION\", \"1.2.3\")\n\n  -- 3. \u94fe\u63a5 Git \u547d\u4ee4: add -&gt; commit -&gt; tag -&gt; push\n  log.info(\"\u6b63\u5728\u6dfb\u52a0\u3001\u63d0\u4ea4\u3001\u6253\u6807\u7b7e\u548c\u63a8\u9001...\")\n  repo:add(\".\"):commit(\"ci: Bump version to 1.2.3\"):tag(\"v1.2.3\"):push(\"origin\", \"main\", { follow_tags = true })\n\n  -- 4. \u83b7\u53d6\u6700\u7ec8\u64cd\u4f5c (push) \u7684\u7ed3\u679c\n  local result = repo:result()\n\n  if not result.success then\n    log.error(\"Git \u63a8\u9001\u5931\u8d25: \" .. result.stderr)\n    return false, \"Git \u63a8\u9001\u5931\u8d25\u3002\"\n  end\n\n  log.info(\"\u6210\u529f\u63a8\u9001\u65b0\u7248\u672c\u6807\u7b7e\u3002\")\n  return true, \"Git \u64cd\u4f5c\u6210\u529f\u3002\"\nend\n</code></pre>"},{"location":"zh/modules/log/","title":"Log \u6a21\u5757","text":"<p><code>log</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u5fc5\u8981\u7684\u63a5\u53e3\uff0c\u7528\u4e8e\u4ece\u60a8\u7684 Lua \u811a\u672c\u4e2d\u5c06\u6d88\u606f\u8bb0\u5f55\u5230 <code>sloth-runner</code> \u63a7\u5236\u53f0\u3002\u5728\u4efb\u52a1\u6267\u884c\u671f\u95f4\uff0c\u4f7f\u7528\u6b64\u6a21\u5757\u662f\u63d0\u4f9b\u53cd\u9988\u548c\u8c03\u8bd5\u4fe1\u606f\u7684\u6807\u51c6\u65b9\u5f0f\u3002</p>"},{"location":"zh/modules/log/#loginfomessage","title":"<code>log.info(message)</code>","text":"<p>\u4ee5 INFO \u7ea7\u522b\u8bb0\u5f55\u4e00\u6761\u6d88\u606f\u3002\u8fd9\u662f\u7528\u4e8e\u4e00\u822c\u4fe1\u606f\u6027\u6d88\u606f\u7684\u6807\u51c6\u7ea7\u522b\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>message</code> (string): \u8981\u8bb0\u5f55\u7684\u6d88\u606f\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/log/#logwarnmessage","title":"<code>log.warn(message)</code>","text":"<p>\u4ee5 WARN \u7ea7\u522b\u8bb0\u5f55\u4e00\u6761\u6d88\u606f\u3002\u8fd9\u9002\u7528\u4e8e\u5e94\u5f15\u8d77\u7528\u6237\u6ce8\u610f\u7684\u975e\u5173\u952e\u95ee\u9898\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>message</code> (string): \u8981\u8bb0\u5f55\u7684\u6d88\u606f\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/log/#logerrormessage","title":"<code>log.error(message)</code>","text":"<p>\u4ee5 ERROR \u7ea7\u522b\u8bb0\u5f55\u4e00\u6761\u6d88\u606f\u3002\u8fd9\u5e94\u7528\u4e8e\u53ef\u80fd\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\u7684\u91cd\u5927\u9519\u8bef\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>message</code> (string): \u8981\u8bb0\u5f55\u7684\u6d88\u606f\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/log/#logdebugmessage","title":"<code>log.debug(message)</code>","text":"<p>\u4ee5 DEBUG \u7ea7\u522b\u8bb0\u5f55\u4e00\u6761\u6d88\u606f\u3002\u9664\u975e\u8fd0\u884c\u5668\u5904\u4e8e\u8be6\u7ec6\u6216\u8c03\u8bd5\u6a21\u5f0f\uff0c\u5426\u5219\u8fd9\u4e9b\u6d88\u606f\u901a\u5e38\u662f\u9690\u85cf\u7684\u3002\u5b83\u4eec\u5bf9\u4e8e\u8be6\u7ec6\u7684\u8bca\u65ad\u4fe1\u606f\u5f88\u6709\u7528\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>message</code> (string): \u8981\u8bb0\u5f55\u7684\u6d88\u606f\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/log/#_1","title":"\u793a\u4f8b","text":"<pre><code>command = function()\n  -- log \u6a21\u5757\u662f\u5168\u5c40\u53ef\u7528\u7684\uff0c\u4e0d\u9700\u8981 require\u3002\n\n  log.info(\"\u542f\u52a8\u65e5\u5fd7\u8bb0\u5f55\u793a\u4f8b\u4efb\u52a1\u3002\")\n\n  local user_name = \"Sloth\"\n  log.debug(\"\u5f53\u524d\u7528\u6237\u662f: \" .. user_name)\n\n  if user_name ~= \"Sloth\" then\n    log.warn(\"\u7528\u6237\u4e0d\u662f\u9884\u671f\u7684\u7528\u6237\u3002\")\n  end\n\n  log.info(\"\u4efb\u52a1\u6b63\u5728\u6267\u884c\u5176\u4e3b\u8981\u64cd\u4f5c...\")\n\n  local success = true -- \u6a21\u62df\u4e00\u6b21\u6210\u529f\u7684\u64cd\u4f5c\n  if not success then\n    log.error(\"\u4e3b\u8981\u64cd\u4f5c\u610f\u5916\u5931\u8d25\uff01\")\n    return false, \"\u4e3b\u8981\u64cd\u4f5c\u5931\u8d25\"\n  end\n\n  log.info(\"\u65e5\u5fd7\u8bb0\u5f55\u793a\u4f8b\u4efb\u52a1\u6210\u529f\u5b8c\u6210\u3002\")\n  return true, \"\u65e5\u5fd7\u8bb0\u5f55\u5df2\u6f14\u793a\u3002\"\nend\n</code></pre>"},{"location":"zh/modules/metrics/","title":"\ud83d\udcca \u6307\u6807\u548c\u76d1\u63a7\u6a21\u5757","text":"<p>\u6307\u6807\u548c\u76d1\u63a7\u6a21\u5757\u63d0\u4f9b\u5168\u9762\u7684\u7cfb\u7edf\u76d1\u63a7\u3001\u81ea\u5b9a\u4e49\u6307\u6807\u6536\u96c6\u548c\u5065\u5eb7\u68c0\u67e5\u529f\u80fd\u3002\u5b83\u5b9e\u73b0\u4e86\u5bf9\u7cfb\u7edf\u8d44\u6e90\u548c\u5e94\u7528\u7a0b\u5e8f\u6027\u80fd\u7684\u5b9e\u65f6\u89c2\u5bdf\u80fd\u529b\u3002</p>"},{"location":"zh/modules/metrics/#_2","title":"\ud83d\ude80 \u6838\u5fc3\u7279\u6027","text":"<ul> <li>\u7cfb\u7edf\u6307\u6807: \u81ea\u52a8\u6536\u96c6CPU\u3001\u5185\u5b58\u3001\u78c1\u76d8\u548c\u7f51\u7edc\u6307\u6807</li> <li>\u8fd0\u884c\u65f6\u6307\u6807: Go\u8fd0\u884c\u65f6\u4fe1\u606f\uff08\u534f\u7a0b\u3001\u5806\u3001GC\uff09</li> <li>\u81ea\u5b9a\u4e49\u6307\u6807: \u8ba1\u91cf\u5668\u3001\u8ba1\u6570\u5668\u3001\u76f4\u65b9\u56fe\u548c\u8ba1\u65f6\u5668</li> <li>\u5065\u5eb7\u68c0\u67e5: \u81ea\u52a8\u7cfb\u7edf\u5065\u5eb7\u76d1\u63a7</li> <li>HTTP\u7aef\u70b9: \u517c\u5bb9Prometheus\u7684\u6307\u6807\u5bfc\u51fa</li> <li>\u544a\u8b66\u7cfb\u7edf: \u57fa\u4e8e\u9608\u503c\u7684\u544a\u8b66</li> <li>JSON API: \u5b8c\u6574\u7684\u6307\u6807\u6570\u636e\u7528\u4e8e\u96c6\u6210</li> </ul>"},{"location":"zh/modules/metrics/#_3","title":"\ud83d\udcca \u7cfb\u7edf\u6307\u6807","text":""},{"location":"zh/modules/metrics/#cpu","title":"CPU\u3001\u5185\u5b58\u548c\u78c1\u76d8\u76d1\u63a7","text":"<pre><code>-- \u83b7\u53d6\u5f53\u524dCPU\u4f7f\u7528\u7387\nlocal cpu_usage = metrics.system_cpu()\nlog.info(\"CPU\u4f7f\u7528\u7387: \" .. string.format(\"%.1f%%\", cpu_usage))\n\n-- \u83b7\u53d6\u5185\u5b58\u4fe1\u606f\nlocal memory_info = metrics.system_memory()\nlog.info(\"\u5185\u5b58: \" .. string.format(\"%.1f%% (%.0f/%.0f MB)\", \n    memory_info.percent, memory_info.used_mb, memory_info.total_mb))\n\n-- \u83b7\u53d6\u78c1\u76d8\u4f7f\u7528\u60c5\u51b5\nlocal disk_info = metrics.system_disk(\"/\")\nlog.info(\"\u78c1\u76d8: \" .. string.format(\"%.1f%% (%.1f/%.1f GB)\", \n    disk_info.percent, disk_info.used_gb, disk_info.total_gb))\n\n-- \u68c0\u67e5\u7279\u5b9a\u78c1\u76d8\u8def\u5f84\nlocal var_disk = metrics.system_disk(\"/var\")\nlog.info(\"/var \u78c1\u76d8\u4f7f\u7528\u7387: \" .. string.format(\"%.1f%%\", var_disk.percent))\n</code></pre>"},{"location":"zh/modules/metrics/#_4","title":"\u8fd0\u884c\u65f6\u4fe1\u606f","text":"<pre><code>-- \u83b7\u53d6Go\u8fd0\u884c\u65f6\u6307\u6807\nlocal runtime = metrics.runtime_info()\nlog.info(\"\u8fd0\u884c\u65f6\u4fe1\u606f:\")\nlog.info(\"  \u534f\u7a0b\u6570: \" .. runtime.goroutines)\nlog.info(\"  CPU\u6838\u5fc3: \" .. runtime.num_cpu)\nlog.info(\"  \u5806\u5df2\u5206\u914d: \" .. string.format(\"%.1f MB\", runtime.heap_alloc_mb))\nlog.info(\"  \u5806\u7cfb\u7edf: \" .. string.format(\"%.1f MB\", runtime.heap_sys_mb))\nlog.info(\"  GC\u6b21\u6570: \" .. runtime.num_gc)\nlog.info(\"  Go\u7248\u672c: \" .. runtime.go_version)\n</code></pre>"},{"location":"zh/modules/metrics/#_5","title":"\ud83d\udcc8 \u81ea\u5b9a\u4e49\u6307\u6807","text":""},{"location":"zh/modules/metrics/#_6","title":"\u8ba1\u91cf\u5668\u6307\u6807\uff08\u5f53\u524d\u503c\uff09","text":"<pre><code>-- \u8bbe\u7f6e\u7b80\u5355\u7684\u8ba1\u91cf\u5668\u503c\nmetrics.gauge(\"cpu_temperature\", 65.4)\nmetrics.gauge(\"active_connections\", 142)\nmetrics.gauge(\"queue_size\", 23)\n\n-- \u5e26\u6807\u7b7e\u8bbe\u7f6e\u8ba1\u91cf\u5668\nmetrics.gauge(\"memory_usage\", memory_percent, {\n    server = \"web-01\",\n    environment = \"production\",\n    region = \"us-east-1\"\n})\n\n-- \u66f4\u65b0\u90e8\u7f72\u72b6\u6001\nmetrics.gauge(\"deployment_progress\", 75.5, {\n    app = \"frontend\",\n    version = \"v2.1.0\"\n})\n</code></pre>"},{"location":"zh/modules/metrics/#_7","title":"\u8ba1\u6570\u5668\u6307\u6807\uff08\u589e\u91cf\u503c\uff09","text":"<pre><code>-- \u589e\u91cf\u8ba1\u6570\u5668\nlocal total_requests = metrics.counter(\"http_requests_total\", 1)\nlocal error_count = metrics.counter(\"http_errors_total\", 1, {\n    status_code = \"500\",\n    endpoint = \"/api/users\"\n})\n\n-- \u6279\u91cf\u589e\u91cf\nlocal processed = metrics.counter(\"messages_processed\", 50, {\n    queue = \"user_notifications\",\n    priority = \"high\"\n})\n\nlog.info(\"\u5904\u7406\u7684\u603b\u8bf7\u6c42\u6570: \" .. total_requests)\n</code></pre>"},{"location":"zh/modules/metrics/#_8","title":"\u76f4\u65b9\u56fe\u6307\u6807\uff08\u503c\u5206\u5e03\uff09","text":"<pre><code>-- \u8bb0\u5f55\u54cd\u5e94\u65f6\u95f4\nmetrics.histogram(\"response_time_ms\", 245.6, {\n    endpoint = \"/api/users\",\n    method = \"GET\"\n})\n\n-- \u8bb0\u5f55\u8d1f\u8f7d\u5927\u5c0f\nmetrics.histogram(\"payload_size_bytes\", 1024, {\n    content_type = \"application/json\"\n})\n\n-- \u8bb0\u5f55\u6279\u5904\u7406\u5927\u5c0f\nmetrics.histogram(\"batch_size\", 150, {\n    operation = \"bulk_insert\",\n    table = \"user_events\"\n})\n</code></pre>"},{"location":"zh/modules/metrics/#_9","title":"\u8ba1\u65f6\u5668\u6307\u6807\uff08\u51fd\u6570\u6267\u884c\u65f6\u95f4\uff09","text":"<pre><code>-- \u81ea\u52a8\u8ba1\u65f6\u51fd\u6570\u6267\u884c\nlocal duration = metrics.timer(\"database_query\", function()\n    -- \u6a21\u62df\u6570\u636e\u5e93\u67e5\u8be2\n    local result = exec.run(\"sleep 0.1\")\n    return result\nend, {\n    query_type = \"select\",\n    table = \"users\"\n})\n\nlog.info(\"\u6570\u636e\u5e93\u67e5\u8be2\u8017\u65f6: \" .. string.format(\"%.2f ms\", duration))\n\n-- \u8ba1\u65f6\u590d\u6742\u64cd\u4f5c\nlocal processing_time = metrics.timer(\"data_processing\", function()\n    -- \u5904\u7406\u5927\u6570\u636e\u96c6\n    local data = {}\n    for i = 1, 100000 do\n        data[i] = math.sqrt(i) * 2.5\n    end\n    return #data\nend, {\n    operation = \"mathematical_computation\",\n    size = \"large\"\n})\n\nlog.info(\"\u6570\u636e\u5904\u7406\u5b8c\u6210\u7528\u65f6: \" .. string.format(\"%.2f ms\", processing_time))\n</code></pre>"},{"location":"zh/modules/metrics/#_10","title":"\ud83c\udfe5 \u5065\u5eb7\u76d1\u63a7","text":""},{"location":"zh/modules/metrics/#_11","title":"\u81ea\u52a8\u5065\u5eb7\u72b6\u6001","text":"<pre><code>-- \u83b7\u53d6\u5168\u9762\u7684\u5065\u5eb7\u72b6\u6001\nlocal health = metrics.health_status()\nlog.info(\"\u6574\u4f53\u5065\u5eb7\u72b6\u6001: \" .. health.overall)\n\n-- \u68c0\u67e5\u5404\u4e2a\u7ec4\u4ef6\nlocal components = {\"cpu\", \"memory\", \"disk\"}\nfor _, component in ipairs(components) do\n    local comp_info = health[component]\n    if comp_info then\n        local status_icon = \"\u2705\"\n        if comp_info.status == \"warning\" then\n            status_icon = \"\u26a0\ufe0f\"\n        elseif comp_info.status == \"critical\" then\n            status_icon = \"\u274c\"\n        end\n\n        log.info(string.format(\"  %s %s: %.1f%% (%s)\", \n            status_icon, component:upper(), comp_info.usage, comp_info.status))\n    end\nend\n</code></pre>"},{"location":"zh/modules/metrics/#_12","title":"\u81ea\u5b9a\u4e49\u5065\u5eb7\u68c0\u67e5","text":"<pre><code>-- \u521b\u5efa\u5e94\u7528\u5065\u5eb7\u68c0\u67e5\u51fd\u6570\nfunction check_application_health()\n    local health_score = 100\n    local issues = {}\n\n    -- \u68c0\u67e5\u6570\u636e\u5e93\u8fde\u901a\u6027\n    local db_result = exec.run(\"pg_isready -h localhost -p 5432\")\n    if db_result ~= \"\" then\n        health_score = health_score - 20\n        table.insert(issues, \"\u6570\u636e\u5e93\u8fde\u63a5\u5931\u8d25\")\n    end\n\n    -- \u68c0\u67e5\u78c1\u76d8\u7a7a\u95f4\n    local disk = metrics.system_disk(\"/\")\n    if disk.percent &gt; 90 then\n        health_score = health_score - 30\n        table.insert(issues, \"\u78c1\u76d8\u7a7a\u95f4\u4e25\u91cd\u4e0d\u8db3: \" .. string.format(\"%.1f%%\", disk.percent))\n    end\n\n    -- \u68c0\u67e5\u5185\u5b58\u4f7f\u7528\n    local memory = metrics.system_memory()\n    if memory.percent &gt; 85 then\n        health_score = health_score - 25\n        table.insert(issues, \"\u5185\u5b58\u4f7f\u7528\u7387\u9ad8: \" .. string.format(\"%.1f%%\", memory.percent))\n    end\n\n    -- \u8bb0\u5f55\u5065\u5eb7\u5f97\u5206\n    metrics.gauge(\"application_health_score\", health_score)\n\n    if health_score &lt; 70 then\n        metrics.alert(\"application_health\", {\n            level = \"warning\",\n            message = \"\u5e94\u7528\u5065\u5eb7\u72b6\u51b5\u4e0b\u964d: \" .. table.concat(issues, \", \"),\n            score = health_score\n        })\n    end\n\n    return health_score &gt;= 70\nend\n\n-- \u5728\u4efb\u52a1\u4e2d\u4f7f\u7528\nModern DSLs = {\n    health_monitoring = {\n        tasks = {\n            health_check = {\n                command = function()\n                    local healthy = check_application_health()\n                    return healthy, healthy and \"\u7cfb\u7edf\u5065\u5eb7\" or \"\u68c0\u6d4b\u5230\u7cfb\u7edf\u5065\u5eb7\u95ee\u9898\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"zh/modules/metrics/#_13","title":"\ud83d\udea8 \u544a\u8b66\u7cfb\u7edf","text":""},{"location":"zh/modules/metrics/#_14","title":"\u521b\u5efa\u544a\u8b66","text":"<pre><code>-- \u7b80\u5355\u9608\u503c\u544a\u8b66\nlocal cpu = metrics.system_cpu()\nif cpu &gt; 80 then\n    metrics.alert(\"high_cpu_usage\", {\n        level = \"warning\",\n        message = \"CPU\u4f7f\u7528\u7387\u8fc7\u9ad8: \" .. string.format(\"%.1f%%\", cpu),\n        threshold = 80,\n        value = cpu,\n        severity = \"medium\"\n    })\nend\n\n-- \u591a\u6761\u4ef6\u590d\u6742\u544a\u8b66\nlocal memory = metrics.system_memory()\nlocal disk = metrics.system_disk()\n\nif memory.percent &gt; 90 and disk.percent &gt; 85 then\n    metrics.alert(\"resource_exhaustion\", {\n        level = \"critical\",\n        message = string.format(\"\u8d44\u6e90\u4f7f\u7528\u4e25\u91cd - \u5185\u5b58: %.1f%%, \u78c1\u76d8: %.1f%%\", \n            memory.percent, disk.percent),\n        memory_usage = memory.percent,\n        disk_usage = disk.percent,\n        recommended_action = \"\u7acb\u5373\u6269\u5c55\u8d44\u6e90\"\n    })\nend\n\n-- \u5e94\u7528\u7279\u5b9a\u544a\u8b66\nlocal queue_size = state.get(\"task_queue_size\", 0)\nif queue_size &gt; 1000 then\n    metrics.alert(\"queue_backlog\", {\n        level = \"warning\", \n        message = \"\u68c0\u6d4b\u5230\u4efb\u52a1\u961f\u5217\u79ef\u538b: \" .. queue_size .. \" \u4e2a\u9879\u76ee\",\n        queue_size = queue_size,\n        estimated_processing_time = queue_size * 2 .. \" \u79d2\"\n    })\nend\n</code></pre>"},{"location":"zh/modules/metrics/#_15","title":"\ud83d\udd0d \u6307\u6807\u7ba1\u7406","text":""},{"location":"zh/modules/metrics/#_16","title":"\u68c0\u7d22\u81ea\u5b9a\u4e49\u6307\u6807","text":"<pre><code>-- \u83b7\u53d6\u7279\u5b9a\u81ea\u5b9a\u4e49\u6307\u6807\nlocal cpu_metric = metrics.get_custom(\"cpu_temperature\")\nif cpu_metric then\n    log.info(\"CPU\u6e29\u5ea6\u6307\u6807: \" .. data.to_json(cpu_metric))\nend\n\n-- \u5217\u51fa\u6240\u6709\u81ea\u5b9a\u4e49\u6307\u6807\nlocal all_metrics = metrics.list_custom()\nlog.info(\"\u81ea\u5b9a\u4e49\u6307\u6807\u603b\u6570: \" .. #all_metrics)\nfor i, metric_name in ipairs(all_metrics) do\n    log.info(\"  \" .. i .. \". \" .. metric_name)\nend\n</code></pre>"},{"location":"zh/modules/metrics/#_17","title":"\u6027\u80fd\u76d1\u63a7\u793a\u4f8b","text":"<pre><code>Modern DSLs = {\n    performance_monitoring = {\n        tasks = {\n            monitor_api_performance = {\n                command = function()\n                    -- \u5f00\u59cb\u76d1\u63a7\u4f1a\u8bdd\n                    log.info(\"\u5f00\u59cbAPI\u6027\u80fd\u76d1\u63a7...\")\n\n                    -- \u6a21\u62dfAPI\u8c03\u7528\u5e76\u6d4b\u91cf\u6027\u80fd\n                    for i = 1, 10 do\n                        local api_time = metrics.timer(\"api_call_\" .. i, function()\n                            -- \u6a21\u62dfAPI\u8c03\u7528\n                            exec.run(\"curl -s -o /dev/null -w '%{time_total}' https://api.example.com/health\")\n                        end, {\n                            endpoint = \"health\",\n                            call_number = tostring(i)\n                        })\n\n                        -- \u8bb0\u5f55\u54cd\u5e94\u65f6\u95f4\n                        metrics.histogram(\"api_response_time\", api_time, {\n                            endpoint = \"health\"\n                        })\n\n                        -- \u68c0\u67e5\u54cd\u5e94\u65f6\u95f4\u662f\u5426\u53ef\u63a5\u53d7\n                        if api_time &gt; 1000 then -- 1\u79d2\n                            metrics.counter(\"slow_api_calls\", 1, {\n                                endpoint = \"health\"\n                            })\n\n                            metrics.alert(\"slow_api_response\", {\n                                level = \"warning\",\n                                message = string.format(\"API\u54cd\u5e94\u6162: %.2f ms\", api_time),\n                                response_time = api_time,\n                                threshold = 1000\n                            })\n                        end\n\n                        -- \u8c03\u7528\u95f4\u77ed\u6682\u5ef6\u8fdf\n                        exec.run(\"sleep 0.1\")\n                    end\n\n                    -- \u83b7\u53d6\u6c47\u603b\u7edf\u8ba1\n                    local system_health = metrics.health_status()\n                    log.info(\"API\u6d4b\u8bd5\u540e\u7cfb\u7edf\u5065\u5eb7: \" .. system_health.overall)\n\n                    return true, \"API\u6027\u80fd\u76d1\u63a7\u5b8c\u6210\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"zh/modules/metrics/#http","title":"\ud83c\udf10 HTTP\u7aef\u70b9","text":"<p>\u6307\u6807\u6a21\u5757\u81ea\u52a8\u4e3a\u5916\u90e8\u76d1\u63a7\u7cfb\u7edf\u516c\u5f00HTTP\u7aef\u70b9\uff1a</p>"},{"location":"zh/modules/metrics/#prometheus-metrics","title":"Prometheus\u683c\u5f0f (<code>/metrics</code>)","text":"<pre><code># \u8bbf\u95ee\u517c\u5bb9Prometheus\u7684\u6307\u6807\ncurl http://agent:8080/metrics\n\n# \u793a\u4f8b\u8f93\u51fa:\n# sloth_agent_cpu_usage_percent 15.4\n# sloth_agent_memory_usage_mb 2048.5\n# sloth_agent_disk_usage_percent 67.2\n# sloth_agent_tasks_total 142\n</code></pre>"},{"location":"zh/modules/metrics/#json-metricsjson","title":"JSON\u683c\u5f0f (<code>/metrics/json</code>)","text":"<pre><code># \u83b7\u53d6JSON\u683c\u5f0f\u7684\u5b8c\u6574\u6307\u6807\ncurl http://agent:8080/metrics/json\n\n# \u793a\u4f8b\u54cd\u5e94:\n{\n  \"agent_name\": \"myagent1\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"system\": {\n    \"cpu_usage_percent\": 15.4,\n    \"memory_usage_mb\": 2048.5,\n    \"disk_usage_percent\": 67.2\n  },\n  \"runtime\": {\n    \"num_goroutines\": 25,\n    \"heap_alloc_mb\": 45.2\n  },\n  \"custom\": {\n    \"api_response_time\": {...},\n    \"deployment_progress\": 85.5\n  }\n}\n</code></pre>"},{"location":"zh/modules/metrics/#health","title":"\u5065\u5eb7\u68c0\u67e5 (<code>/health</code>)","text":"<pre><code># \u68c0\u67e5\u4ee3\u7406\u5065\u5eb7\u72b6\u6001\ncurl http://agent:8080/health\n\n# \u793a\u4f8b\u54cd\u5e94:\n{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"checks\": {\n    \"cpu\": {\"usage\": 15.4, \"status\": \"healthy\"},\n    \"memory\": {\"usage\": 45.8, \"status\": \"healthy\"},\n    \"disk\": {\"usage\": 67.2, \"status\": \"healthy\"}\n  }\n}\n</code></pre>"},{"location":"zh/modules/metrics/#api","title":"\ud83d\udccb API\u53c2\u8003","text":""},{"location":"zh/modules/metrics/#_18","title":"\u7cfb\u7edf\u6307\u6807","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>metrics.system_cpu()</code> - usage: number \u83b7\u53d6\u5f53\u524dCPU\u4f7f\u7528\u767e\u5206\u6bd4 <code>metrics.system_memory()</code> - info: table \u83b7\u53d6\u5185\u5b58\u4f7f\u7528\u4fe1\u606f <code>metrics.system_disk(path?)</code> path?: string info: table \u83b7\u53d6\u8def\u5f84\u7684\u78c1\u76d8\u4f7f\u7528\u60c5\u51b5 (\u9ed8\u8ba4: \"/\") <code>metrics.runtime_info()</code> - info: table \u83b7\u53d6Go\u8fd0\u884c\u65f6\u4fe1\u606f"},{"location":"zh/modules/metrics/#_19","title":"\u81ea\u5b9a\u4e49\u6307\u6807","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>metrics.gauge(name, value, tags?)</code> name: string, value: number, tags?: table success: boolean \u8bbe\u7f6e\u8ba1\u91cf\u5668\u6307\u6807 <code>metrics.counter(name, increment?, tags?)</code> name: string, increment?: number, tags?: table new_value: number \u589e\u91cf\u8ba1\u6570\u5668 <code>metrics.histogram(name, value, tags?)</code> name: string, value: number, tags?: table success: boolean \u8bb0\u5f55\u76f4\u65b9\u56fe\u503c <code>metrics.timer(name, function, tags?)</code> name: string, func: function, tags?: table duration: number \u8ba1\u65f6\u51fd\u6570\u6267\u884c"},{"location":"zh/modules/metrics/#_20","title":"\u5065\u5eb7\u548c\u76d1\u63a7","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>metrics.health_status()</code> - status: table \u83b7\u53d6\u5168\u9762\u5065\u5eb7\u72b6\u6001 <code>metrics.alert(name, data)</code> name: string, data: table success: boolean \u521b\u5efa\u544a\u8b66"},{"location":"zh/modules/metrics/#_21","title":"\u5b9e\u7528\u5de5\u5177","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>metrics.get_custom(name)</code> name: string metric: table | nil \u6309\u540d\u79f0\u83b7\u53d6\u81ea\u5b9a\u4e49\u6307\u6807 <code>metrics.list_custom()</code> - names: table \u5217\u51fa\u6240\u6709\u81ea\u5b9a\u4e49\u6307\u6807\u540d\u79f0"},{"location":"zh/modules/metrics/#_22","title":"\ud83c\udfaf \u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u4f7f\u7528\u5408\u9002\u7684\u6307\u6807\u7c7b\u578b - \u8ba1\u91cf\u5668\u7528\u4e8e\u5f53\u524d\u503c\uff0c\u8ba1\u6570\u5668\u7528\u4e8e\u603b\u8ba1\uff0c\u76f4\u65b9\u56fe\u7528\u4e8e\u5206\u5e03</li> <li>\u6dfb\u52a0\u6709\u610f\u4e49\u7684\u6807\u7b7e \u6765\u5206\u7c7b\u548c\u8fc7\u6ee4\u6307\u6807</li> <li>\u8bbe\u7f6e\u5408\u7406\u7684\u544a\u8b66\u9608\u503c \u4ee5\u907f\u514d\u544a\u8b66\u75b2\u52b3</li> <li>\u76d1\u63a7\u5e7f\u6cdb\u6307\u6807\u6536\u96c6\u7684\u6027\u80fd\u5f71\u54cd</li> <li>\u5bf9\u6027\u80fd\u5173\u952e\u64cd\u4f5c\u4f7f\u7528\u8ba1\u65f6\u5668 \u6765\u8bc6\u522b\u74f6\u9888</li> <li>\u4e3a\u6240\u6709\u5173\u952e\u7cfb\u7edf\u7ec4\u4ef6\u5b9e\u65bd\u5065\u5eb7\u68c0\u67e5</li> <li>\u5c06\u6307\u6807\u5bfc\u51fa\u5230\u5916\u90e8\u7cfb\u7edf \u5982Prometheus\u8fdb\u884c\u957f\u671f\u5b58\u50a8</li> </ol> <p>\u6307\u6807\u548c\u76d1\u63a7\u6a21\u5757\u4e3a\u60a8\u7684\u5206\u5e03\u5f0fsloth-runner\u73af\u5883\u63d0\u4f9b\u5168\u9762\u7684\u53ef\u89c2\u6d4b\u6027! \ud83d\udcca\ud83d\ude80</p>"},{"location":"zh/modules/net/","title":"Net \u6a21\u5757","text":"<p><code>net</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u53d1\u51fa HTTP \u8bf7\u6c42\u548c\u4e0b\u8f7d\u6587\u4ef6\u7684\u529f\u80fd\uff0c\u5141\u8bb8\u60a8\u7684\u4efb\u52a1\u4e0e Web \u670d\u52a1\u548c\u8fdc\u7a0b\u8d44\u6e90\u8fdb\u884c\u4ea4\u4e92\u3002</p>"},{"location":"zh/modules/net/#nethttp_geturl","title":"<code>net.http_get(url)</code>","text":"<p>\u5411\u6307\u5b9a\u7684 URL \u6267\u884c HTTP GET \u8bf7\u6c42\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>url</code> (string): \u8981\u53d1\u9001 GET \u8bf7\u6c42\u7684 URL\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>body</code> (string): \u4f5c\u4e3a\u5b57\u7b26\u4e32\u7684\u54cd\u5e94\u4f53\u3002</li> <li><code>status_code</code> (number): \u54cd\u5e94\u7684 HTTP \u72b6\u6001\u7801\u3002</li> <li><code>headers</code> (table): \u5305\u542b\u54cd\u5e94\u5934\u7684\u8868\u3002</li> <li><code>error</code> (string): \u5982\u679c\u8bf7\u6c42\u5931\u8d25\uff0c\u5219\u4e3a\u9519\u8bef\u6d88\u606f\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/net/#nethttp_posturl-body-headers","title":"<code>net.http_post(url, body, [headers])</code>","text":"<p>\u5411\u6307\u5b9a\u7684 URL \u6267\u884c HTTP POST \u8bf7\u6c42\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>url</code> (string): \u8981\u53d1\u9001 POST \u8bf7\u6c42\u7684 URL\u3002</li> <li><code>body</code> (string): \u8981\u53d1\u9001\u7684\u8bf7\u6c42\u4f53\u3002</li> <li><code>headers</code> (table, \u53ef\u9009): \u8981\u8bbe\u7f6e\u7684\u8bf7\u6c42\u5934\u8868\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>body</code> (string): \u4f5c\u4e3a\u5b57\u7b26\u4e32\u7684\u54cd\u5e94\u4f53\u3002</li> <li><code>status_code</code> (number): \u54cd\u5e94\u7684 HTTP \u72b6\u6001\u7801\u3002</li> <li><code>headers</code> (table): \u5305\u542b\u54cd\u5e94\u5934\u7684\u8868\u3002</li> <li><code>error</code> (string): \u5982\u679c\u8bf7\u6c42\u5931\u8d25\uff0c\u5219\u4e3a\u9519\u8bef\u6d88\u606f\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/net/#netdownloadurl-destination_path","title":"<code>net.download(url, destination_path)</code>","text":"<p>\u4ece URL \u4e0b\u8f7d\u6587\u4ef6\u5e76\u5c06\u5176\u4fdd\u5b58\u5230\u672c\u5730\u8def\u5f84\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>url</code> (string): \u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u7684 URL\u3002</li> <li><code>destination_path</code> (string): \u7528\u4e8e\u4fdd\u5b58\u4e0b\u8f7d\u5185\u5bb9\u7684\u672c\u5730\u6587\u4ef6\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u4e0b\u8f7d\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/net/#_1","title":"\u793a\u4f8b","text":"<pre><code>command = function()\n  local net = require(\"net\")\n\n  -- GET \u8bf7\u6c42\u793a\u4f8b\n  log.info(\"\u6b63\u5728\u5411 httpbin.org \u6267\u884c GET \u8bf7\u6c42...\")\n  local body, status, headers, err = net.http_get(\"https://httpbin.org/get\")\n  if err then\n    log.error(\"GET \u8bf7\u6c42\u5931\u8d25: \" .. err)\n    return false, \"GET \u8bf7\u6c42\u5931\u8d25\"\n  end\n  log.info(\"GET \u8bf7\u6c42\u6210\u529f\uff01\u72b6\u6001: \" .. status)\n  -- print(\"\u54cd\u5e94\u4f53: \" .. body)\n\n  -- POST \u8bf7\u6c42\u793a\u4f8b\n  log.info(\"\u6b63\u5728\u5411 httpbin.org \u6267\u884c POST \u8bf7\u6c42...\")\n  local post_body = '{\"name\": \"sloth-runner\", \"awesome\": true}'\n  local post_headers = { [\"Content-Type\"] = \"application/json\" }\n  body, status, headers, err = net.http_post(\"https://httpbin.org/post\", post_body, post_headers)\n  if err then\n    log.error(\"POST \u8bf7\u6c42\u5931\u8d25: \" .. err)\n    return false, \"POST \u8bf7\u6c42\u5931\u8d25\"\n  end\n  log.info(\"POST \u8bf7\u6c42\u6210\u529f\uff01\u72b6\u6001: \" .. status)\n  -- print(\"\u54cd\u5e94\u4f53: \" .. body)\n\n  -- \u4e0b\u8f7d\u793a\u4f8b\n  local download_path = \"/tmp/sloth-runner-logo.svg\"\n  log.info(\"\u6b63\u5728\u4e0b\u8f7d\u6587\u4ef6\u5230 \" .. download_path)\n  local err = net.download(\"https://raw.githubusercontent.com/chalkan3-sloth/sloth-runner/master/assets/sloth-runner-logo.svg\", download_path)\n  if err then\n    log.error(\"\u4e0b\u8f7d\u5931\u8d25: \" .. err)\n    return false, \"\u4e0b\u8f7d\u5931\u8d25\"\n  end\n  log.info(\"\u6587\u4ef6\u4e0b\u8f7d\u6210\u529f\u3002\")\n  fs.rm(download_path) -- \u6e05\u7406\n\n  return true, \"Net \u6a21\u5757\u64cd\u4f5c\u6210\u529f\u3002\"\nend\n</code></pre>"},{"location":"zh/modules/notifications/","title":"\u901a\u77e5\u6a21\u5757","text":"<p><code>notifications</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u79cd\u4ece\u60a8\u7684\u7ba1\u9053\u5411\u5404\u79cd\u901a\u77e5\u670d\u52a1\u53d1\u9001\u6d88\u606f\u7684\u7b80\u5355\u65b9\u6cd5\u3002\u8fd9\u5bf9\u4e8e\u62a5\u544a CI/CD \u5de5\u4f5c\u6d41\u7684\u6210\u529f\u6216\u5931\u8d25\u7279\u522b\u6709\u7528\u3002</p> <p>\u76ee\u524d\u652f\u6301\u4ee5\u4e0b\u670d\u52a1\uff1a - Slack - ntfy</p>"},{"location":"zh/modules/notifications/#_2","title":"\u914d\u7f6e","text":"<p>\u5728\u4f7f\u7528\u8be5\u6a21\u5757\u4e4b\u524d\uff0c\u60a8\u9700\u8981\u5c06\u6240\u9700\u7684\u51ed\u636e\u6216 URL \u6dfb\u52a0\u5230\u60a8\u7684 <code>configs/values.yaml</code> \u6587\u4ef6\u4e2d\u3002\u8be5\u6a21\u5757\u5c06\u5728\u8fd0\u884c\u65f6\u8bfb\u53d6\u8fd9\u4e9b\u503c\u3002</p> <pre><code># configs/values.yaml\n\nnotifications:\n  slack:\n    # \u60a8\u7684 Slack Incoming Webhook URL\n    webhook_url: \"https://hooks.slack.com/services/...\"\n  ntfy:\n    # \u8981\u4f7f\u7528\u7684 ntfy \u670d\u52a1\u5668\u3002\u53ef\u4ee5\u662f\u516c\u5171\u670d\u52a1\u5668\u6216\u81ea\u6258\u7ba1\u670d\u52a1\u5668\u3002\n    server: \"https://ntfy.sh\"\n    # \u7528\u4e8e\u53d1\u5e03\u901a\u77e5\u7684\u4e3b\u9898\u3002\n    topic: \"your-sloth-runner-topic\"\n</code></pre>"},{"location":"zh/modules/notifications/#slack","title":"Slack","text":""},{"location":"zh/modules/notifications/#notificationsslacksendparams","title":"<code>notifications.slack.send(params)</code>","text":"<p>\u901a\u8fc7 Incoming Webhook \u5411 Slack \u9891\u9053\u53d1\u9001\u6d88\u606f\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>webhook_url</code> (string): \u5fc5\u9700\u3002 Slack Incoming Webhook URL\u3002\u5efa\u8bae\u4ece <code>values</code> \u6a21\u5757\u83b7\u53d6\u3002</li> <li><code>message</code> (string): \u5fc5\u9700\u3002 \u6d88\u606f\u7684\u4e3b\u8981\u6587\u672c\u3002</li> <li><code>pipeline</code> (string): \u53ef\u9009\u3002 \u7ba1\u9053\u7684\u540d\u79f0\uff0c\u5c06\u663e\u793a\u5728\u6d88\u606f\u9644\u4ef6\u4e2d\u4ee5\u63d0\u4f9b\u4e0a\u4e0b\u6587\u3002</li> <li><code>error_details</code> (string): \u53ef\u9009\u3002 \u8981\u5305\u542b\u5728\u6d88\u606f\u9644\u4ef6\u4e2d\u7684\u4efb\u4f55\u9519\u8bef\u8be6\u7ec6\u4fe1\u606f\u3002\u8fd9\u5bf9\u4e8e\u5931\u8d25\u901a\u77e5\u5f88\u6709\u7528\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>true</code>\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>false, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local values = require(\"values\")\n\nlocal slack_webhook = values.get(\"notifications.slack.webhook_url\")\n\nif slack_webhook and slack_webhook ~= \"\" then\n  -- \u6210\u529f\u65f6\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u2705 \u7ba1\u9053\u6210\u529f\u6267\u884c\uff01\",\n    pipeline = \"my-awesome-pipeline\"\n  })\n\n  -- \u5931\u8d25\u65f6\n  notifications.slack.send({\n    webhook_url = slack_webhook,\n    message = \"\u274c \u7ba1\u9053\u6267\u884c\u5931\u8d25\uff01\",\n    pipeline = \"my-awesome-pipeline\",\n    error_details = \"\u65e0\u6cd5\u8fde\u63a5\u5230\u6570\u636e\u5e93\u3002\"\n  })\nend\n</code></pre>"},{"location":"zh/modules/notifications/#ntfy","title":"ntfy","text":""},{"location":"zh/modules/notifications/#notificationsntfysendparams","title":"<code>notifications.ntfy.send(params)</code>","text":"<p>\u5411 ntfy.sh \u4e3b\u9898\u53d1\u9001\u6d88\u606f\u3002</p> <p>\u53c2\u6570:</p> <ul> <li><code>params</code> (table): \u4e00\u4e2a\u5305\u542b\u4ee5\u4e0b\u5b57\u6bb5\u7684\u8868\uff1a<ul> <li><code>server</code> (string): \u5fc5\u9700\u3002 ntfy \u670d\u52a1\u5668 URL\u3002</li> <li><code>topic</code> (string): \u5fc5\u9700\u3002 \u8981\u53d1\u9001\u6d88\u606f\u7684\u4e3b\u9898\u3002</li> <li><code>message</code> (string): \u5fc5\u9700\u3002 \u901a\u77e5\u7684\u6b63\u6587\u3002</li> <li><code>title</code> (string): \u53ef\u9009\u3002 \u901a\u77e5\u7684\u6807\u9898\u3002</li> <li><code>priority</code> (string): \u53ef\u9009\u3002 \u901a\u77e5\u4f18\u5148\u7ea7\uff08\u4f8b\u5982 <code>high</code>, <code>default</code>, <code>low</code>\uff09\u3002</li> <li><code>tags</code> (table): \u53ef\u9009\u3002 \u8981\u6dfb\u52a0\u5230\u901a\u77e5\u4e2d\u7684\u6807\u7b7e\uff08\u8868\u60c5\u7b26\u53f7\uff09\u5217\u8868\u3002</li> </ul> </li> </ul> <p>\u8fd4\u56de:</p> <ul> <li>\u6210\u529f\u65f6\u8fd4\u56de <code>true</code>\u3002</li> <li>\u5931\u8d25\u65f6\u8fd4\u56de <code>false, error_message</code>\u3002</li> </ul> <p>\u793a\u4f8b:</p> <pre><code>local values = require(\"values\")\n\nlocal ntfy_server = values.get(\"notifications.ntfy.server\")\nlocal ntfy_topic = values.get(\"notifications.ntfy.topic\")\n\nif ntfy_topic and ntfy_topic ~= \"\" then\n  -- \u6210\u529f\u65f6\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"\u7ba1\u9053\u6210\u529f\",\n    message = \"\u7ba1\u9053\u65e0\u9519\u8bef\u5b8c\u6210\u3002\",\n    priority = \"default\",\n    tags = {\"tada\"}\n  })\n\n  -- \u5931\u8d25\u65f6\n  notifications.ntfy.send({\n    server = ntfy_server,\n    topic = ntfy_topic,\n    title = \"\u7ba1\u9053\u5931\u8d25\uff01\",\n    message = \"\u7ba1\u9053\u56e0\u9519\u8bef\u800c\u5931\u8d25\u3002\",\n    priority = \"high\",\n    tags = {\"skull\", \"warning\"}\n  })\nend\n</code></pre>"},{"location":"zh/modules/pulumi/","title":"Pulumi \u6a21\u5757","text":"<p><code>pulumi</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6d41\u7545\u7684 API \u6765\u7f16\u6392 Pulumi \u5806\u6808\uff0c\u4f7f\u60a8\u80fd\u591f\u76f4\u63a5\u4ece <code>sloth-runner</code> \u7ba1\u7406\u60a8\u7684\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801 (IaC) \u5de5\u4f5c\u6d41\u3002</p>"},{"location":"zh/modules/pulumi/#pulumistackname-options","title":"<code>pulumi.stack(name, options)</code>","text":"<p>\u521b\u5efa\u4e00\u4e2a Pulumi \u5806\u6808\u5bf9\u8c61\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>name</code> (string): \u5806\u6808\u7684\u5168\u540d (\u4f8b\u5982, <code>\"my-org/my-project/dev\"</code>)\u3002</li> <li><code>options</code> (table): \u4e00\u4e2a\u9009\u9879\u8868\u3002<ul> <li><code>workdir</code> (string): (\u5fc5\u9700) Pulumi \u9879\u76ee\u76ee\u5f55\u7684\u8def\u5f84\u3002</li> </ul> </li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>stack</code> (object): \u4e00\u4e2a <code>PulumiStack</code> \u5bf9\u8c61\u3002</li> <li><code>error</code>: \u5982\u679c\u65e0\u6cd5\u521d\u59cb\u5316\u5806\u6808\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/pulumi/#pulumistack","title":"<code>PulumiStack</code> \u5bf9\u8c61","text":"<p>\u6b64\u5bf9\u8c61\u8868\u793a\u4e00\u4e2a\u7279\u5b9a\u7684 Pulumi \u5806\u6808\uff0c\u5e76\u63d0\u4f9b\u7528\u4e8e\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002</p>"},{"location":"zh/modules/pulumi/#stackupoptions","title":"<code>stack:up([options])</code>","text":"<p>\u901a\u8fc7\u8fd0\u884c <code>pulumi up</code> \u521b\u5efa\u6216\u66f4\u65b0\u5806\u6808\u7684\u8d44\u6e90\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>options</code> (table, \u53ef\u9009):<ul> <li><code>yes</code> (boolean): \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u4f20\u9012 <code>--yes</code> \u4ee5\u81ea\u52a8\u6279\u51c6\u66f4\u65b0\u3002</li> <li><code>config</code> (table): \u8981\u4f20\u9012\u7ed9\u5806\u6808\u7684\u914d\u7f6e\u503c\u5b57\u5178\u3002</li> <li><code>args</code> (table): \u8981\u4f20\u9012\u7ed9\u547d\u4ee4\u7684\u9644\u52a0\u5b57\u7b26\u4e32\u53c2\u6570\u5217\u8868\u3002</li> </ul> </li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>result</code> (table): \u4e00\u4e2a\u5305\u542b <code>success</code> (boolean)\u3001<code>stdout</code> (string) \u548c <code>stderr</code> (string) \u7684\u8868\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/pulumi/#stackpreviewoptions","title":"<code>stack:preview([options])</code>","text":"<p>\u901a\u8fc7\u8fd0\u884c <code>pulumi preview</code> \u9884\u89c8\u66f4\u65b0\u5c06\u8fdb\u884c\u7684\u66f4\u6539\u3002</p> <ul> <li>\u53c2\u6570: \u4e0e <code>stack:up</code> \u76f8\u540c\u3002</li> <li>\u8fd4\u56de: \u4e0e <code>stack:up</code> \u76f8\u540c\u3002</li> </ul>"},{"location":"zh/modules/pulumi/#stackrefreshoptions","title":"<code>stack:refresh([options])</code>","text":"<p>\u901a\u8fc7\u8fd0\u884c <code>pulumi refresh</code> \u5237\u65b0\u5806\u6808\u7684\u72b6\u6001\u3002</p> <ul> <li>\u53c2\u6570: \u4e0e <code>stack:up</code> \u76f8\u540c\u3002</li> <li>\u8fd4\u56de: \u4e0e <code>stack:up</code> \u76f8\u540c\u3002</li> </ul>"},{"location":"zh/modules/pulumi/#stackdestroyoptions","title":"<code>stack:destroy([options])</code>","text":"<p>\u901a\u8fc7\u8fd0\u884c <code>pulumi destroy</code> \u9500\u6bc1\u5806\u6808\u4e2d\u7684\u6240\u6709\u8d44\u6e90\u3002</p> <ul> <li>\u53c2\u6570: \u4e0e <code>stack:up</code> \u76f8\u540c\u3002</li> <li>\u8fd4\u56de: \u4e0e <code>stack:up</code> \u76f8\u540c\u3002</li> </ul>"},{"location":"zh/modules/pulumi/#stackoutputs","title":"<code>stack:outputs()</code>","text":"<p>\u68c0\u7d22\u5df2\u90e8\u7f72\u5806\u6808\u7684\u8f93\u51fa\u3002</p> <ul> <li>\u8fd4\u56de:<ul> <li><code>outputs</code> (table): \u5806\u6808\u8f93\u51fa\u7684 Lua \u8868\u3002</li> <li><code>error</code>: \u5982\u679c\u83b7\u53d6\u8f93\u51fa\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/pulumi/#_1","title":"\u793a\u4f8b","text":"<p>\u6b64\u793a\u4f8b\u663e\u793a\u4e86\u4e00\u4e2a\u5e38\u89c1\u6a21\u5f0f\uff1a\u90e8\u7f72\u4e00\u4e2a\u7f51\u7edc\u5806\u6808 (VPC)\uff0c\u7136\u540e\u4f7f\u7528\u5176\u8f93\u51fa (<code>vpcId</code>) \u6765\u914d\u7f6e\u548c\u90e8\u7f72\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u5806\u6808\u3002</p> <pre><code>command = function()\n  local pulumi = require(\"pulumi\")\n\n  -- 1. \u5b9a\u4e49 VPC \u5806\u6808\n  local vpc_stack = pulumi.stack(\"my-org/vpc/prod\", { workdir = \"./pulumi/vpc\" })\n\n  -- 2. \u90e8\u7f72 VPC\n  log.info(\"\u6b63\u5728\u90e8\u7f72 VPC \u5806\u6808...\")\n  local vpc_result = vpc_stack:up({ yes = true })\n  if not vpc_result.success then\n    return false, \"VPC \u90e8\u7f72\u5931\u8d25: \" .. vpc_result.stderr\n  end\n\n  -- 3. \u4ece\u5176\u8f93\u51fa\u4e2d\u83b7\u53d6 VPC ID\n  log.info(\"\u6b63\u5728\u83b7\u53d6 VPC \u8f93\u51fa...\")\n  local vpc_outputs, err = vpc_stack:outputs()\n  if err then\n    return false, \"\u83b7\u53d6 VPC \u8f93\u51fa\u5931\u8d25: \" .. err\n  end\n  local vpc_id = vpc_outputs.vpcId\n\n  -- 4. \u5b9a\u4e49\u5e94\u7528\u7a0b\u5e8f\u5806\u6808\n  local app_stack = pulumi.stack(\"my-org/app/prod\", { workdir = \"./pulumi/app\" })\n\n  -- 5. \u90e8\u7f72\u5e94\u7528\u7a0b\u5e8f\uff0c\u5c06 vpcId \u4f5c\u4e3a\u914d\u7f6e\u4f20\u9012\n  log.info(\"\u6b63\u5728\u5c06\u5e94\u7528\u7a0b\u5e8f\u5806\u6808\u90e8\u7f72\u5230 VPC: \" .. vpc_id)\n  local app_result = app_stack:up({\n    yes = true,\n    config = { [\"my-app:vpcId\"] = vpc_id }\n  })\n  if not app_result.success then\n    return false, \"\u5e94\u7528\u7a0b\u5e8f\u90e8\u7f72\u5931\u8d25: \" .. app_result.stderr\n  end\n\n  log.info(\"\u6240\u6709\u5806\u6808\u5747\u5df2\u6210\u529f\u90e8\u7f72\u3002\")\n  return true, \"Pulumi \u7f16\u6392\u5b8c\u6210\u3002\"\nend\n</code></pre>"},{"location":"zh/modules/python/","title":"Python \u6a21\u5757","text":"<p><code>python</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b9\u4fbf\u7684\u65b9\u5f0f\u6765\u7ba1\u7406 Python \u865a\u62df\u73af\u5883 (<code>venv</code>) \u5e76\u4ece\u60a8\u7684 <code>sloth-runner</code> \u4efb\u52a1\u4e2d\u6267\u884c\u811a\u672c\u3002\u8fd9\u5bf9\u4e8e\u6d89\u53ca\u57fa\u4e8e Python \u7684\u5de5\u5177\u6216\u811a\u672c\u7684\u5de5\u4f5c\u6d41\u7279\u522b\u6709\u7528\u3002</p>"},{"location":"zh/modules/python/#pythonvenvpath","title":"<code>python.venv(path)</code>","text":"<p>\u521b\u5efa\u4e00\u4e2a Python \u865a\u62df\u73af\u5883\u5bf9\u8c61\u3002\u8bf7\u6ce8\u610f\uff0c\u8fd9\u53ea\u5728 Lua \u4e2d\u521b\u5efa\u5bf9\u8c61\uff1b\u73af\u5883\u672c\u8eab\u5728\u6587\u4ef6\u7cfb\u7edf\u4e0a\u76f4\u5230\u60a8\u8c03\u7528 <code>:create()</code> \u540e\u624d\u88ab\u521b\u5efa\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>path</code> (string): \u5e94\u5728\u5176\u4e2d\u521b\u5efa\u865a\u62df\u73af\u5883\u7684\u6587\u4ef6\u7cfb\u7edf\u8def\u5f84 (\u4f8b\u5982, <code>./.venv</code>)\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>venv</code> (object): \u4e00\u4e2a\u865a\u62df\u73af\u5883\u5bf9\u8c61\uff0c\u5305\u542b\u4e0e\u5176\u4ea4\u4e92\u7684\u65b9\u6cd5\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/python/#venvcreate","title":"<code>venv:create()</code>","text":"<p>\u5728\u6307\u5b9a\u8def\u5f84\u7684\u6587\u4ef6\u7cfb\u7edf\u4e0a\u521b\u5efa\u865a\u62df\u73af\u5883\u3002</p> <ul> <li>\u8fd4\u56de:<ul> <li><code>error</code>: \u5982\u679c\u521b\u5efa\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u4e00\u4e2a\u9519\u8bef\u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/python/#venvpipcommand","title":"<code>venv:pip(command)</code>","text":"<p>\u5728\u865a\u62df\u73af\u5883\u7684\u4e0a\u4e0b\u6587\u4e2d\u6267\u884c <code>pip</code> \u547d\u4ee4\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>command</code> (string): \u8981\u4f20\u9012\u7ed9 <code>pip</code> \u7684\u53c2\u6570 (\u4f8b\u5982, <code>install -r requirements.txt</code>)\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>result</code> (table): \u4e00\u4e2a\u5305\u542b <code>pip</code> \u547d\u4ee4\u7684 <code>stdout</code>\u3001<code>stderr</code> \u548c <code>exit_code</code> \u7684\u8868\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/python/#venvexecscript_path","title":"<code>venv:exec(script_path)</code>","text":"<p>\u4f7f\u7528\u865a\u62df\u73af\u5883\u4e2d\u7684 Python \u89e3\u91ca\u5668\u6267\u884c Python \u811a\u672c\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>script_path</code> (string): \u8981\u6267\u884c\u7684 Python \u811a\u672c\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>result</code> (table): \u4e00\u4e2a\u5305\u542b\u811a\u672c\u6267\u884c\u7684 <code>stdout</code>\u3001<code>stderr</code> \u548c <code>exit_code</code> \u7684\u8868\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/python/#_1","title":"\u793a\u4f8b","text":"<p>\u6b64\u793a\u4f8b\u6f14\u793a\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u751f\u547d\u5468\u671f\uff1a\u521b\u5efa\u865a\u62df\u73af\u5883\u3001\u4ece <code>requirements.txt</code> \u6587\u4ef6\u5b89\u88c5\u4f9d\u8d56\u9879\u4ee5\u53ca\u8fd0\u884c Python \u811a\u672c\u3002</p> <pre><code>-- examples/python_venv_lifecycle_example.sloth\n\nModern DSLs = {\n  main = {\n    description = \"\u4e00\u4e2a\u6f14\u793a Python venv \u751f\u547d\u5468\u671f\u7684\u4efb\u52a1\u3002\",\n    create_workdir_before_run = true, -- \u4f7f\u7528\u4e34\u65f6\u5de5\u4f5c\u76ee\u5f55\n    tasks = {\n      {\n        name = \"run-python-script\",\n        description = \"\u521b\u5efa venv\uff0c\u5b89\u88c5\u4f9d\u8d56\u9879\u5e76\u8fd0\u884c\u811a\u672c\u3002\",\n        command = function(params) \n          local python = require(\"python\")\n          local workdir = params.workdir -- \u4ece\u7ec4\u4e2d\u83b7\u53d6\u4e34\u65f6\u5de5\u4f5c\u76ee\u5f55\n\n          -- 1. \u5c06\u6211\u4eec\u7684 Python \u811a\u672c\u548c\u4f9d\u8d56\u9879\u5199\u5165\u5de5\u4f5c\u76ee\u5f55\n          fs.write(workdir .. \"/requirements.txt\", \"requests==2.28.1\")\n          fs.write(workdir .. \"/main.py\", \"import requests\\nprint(f'Hello from Python! Using requests version: {requests.__version__}')\")\n\n          -- 2. \u521b\u5efa\u4e00\u4e2a venv \u5bf9\u8c61\n          local venv_path = workdir .. \"/.venv\"\n          log.info(\"\u6b63\u5728\u8bbe\u7f6e\u865a\u62df\u73af\u5883\u4e8e: \" .. venv_path)\n          local venv = python.venv(venv_path)\n\n          -- 3. \u5728\u6587\u4ef6\u7cfb\u7edf\u4e0a\u521b\u5efa venv\n          venv:create()\n\n          -- 4. \u4f7f\u7528 pip \u5b89\u88c5\u4f9d\u8d56\u9879\n          log.info(\"\u6b63\u5728\u4ece requirements.txt \u5b89\u88c5\u4f9d\u8d56\u9879...\")\n          local pip_result = venv:pip(\"install -r \" .. workdir .. \"/requirements.txt\")\n          if pip_result.exit_code ~= 0 then\n            log.error(\"Pip \u5b89\u88c5\u5931\u8d25: \" .. pip_result.stderr)\n            return false, \"\u672a\u80fd\u5b89\u88c5 Python \u4f9d\u8d56\u9879\u3002\"\n          end\n\n          -- 5. \u6267\u884c\u811a\u672c\n          log.info(\"\u6b63\u5728\u8fd0\u884c Python \u811a\u672c...\")\n          local exec_result = venv:exec(workdir .. \"/main.py\")\n          if exec_result.exit_code ~= 0 then\n            log.error(\"Python \u811a\u672c\u5931\u8d25: \" .. exec_result.stderr)\n            return false, \"Python \u811a\u672c\u6267\u884c\u5931\u8d25\u3002\"\n          end\n\n          log.info(\"Python \u811a\u672c\u6210\u529f\u6267\u884c\u3002\")\n          print(\"--- Python \u811a\u672c\u8f93\u51fa ---\")\n          print(exec_result.stdout)\n          print(\"----------------------------\")\n\n          return true, \"Python venv \u751f\u547d\u5468\u671f\u5b8c\u6210\u3002\"\n        end\n      }\n    }\n  }\n}\n</code></pre> <p>```</p>"},{"location":"zh/modules/salt/","title":"Salt \u6a21\u5757","text":"<p><code>salt</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6d41\u7545\u7684 API \u6765\u4e0e SaltStack \u8fdb\u884c\u4ea4\u4e92\uff0c\u5141\u8bb8\u60a8\u4ece <code>sloth-runner</code> \u5de5\u4f5c\u6d41\u4e2d\u8fd0\u884c\u8fdc\u7a0b\u6267\u884c\u547d\u4ee4\u548c\u7ba1\u7406\u914d\u7f6e\u3002</p>"},{"location":"zh/modules/salt/#saltclientoptions","title":"<code>salt.client([options])</code>","text":"<p>\u521b\u5efa\u4e00\u4e2a Salt \u5ba2\u6237\u7aef\u5bf9\u8c61\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>options</code> (table, \u53ef\u9009): \u4e00\u4e2a\u9009\u9879\u8868\u3002<ul> <li><code>config_path</code> (string): Salt master \u914d\u7f6e\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> </ul> </li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>client</code> (object): \u4e00\u4e2a <code>SaltClient</code> \u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/salt/#saltclient","title":"<code>SaltClient</code> \u5bf9\u8c61","text":"<p>\u6b64\u5bf9\u8c61\u8868\u793a Salt master \u7684\u5ba2\u6237\u7aef\uff0c\u5e76\u63d0\u4f9b\u7528\u4e8e\u5b9a\u4f4d minions \u7684\u65b9\u6cd5\u3002</p>"},{"location":"zh/modules/salt/#clienttargettarget_string-expr_form","title":"<code>client:target(target_string, [expr_form])</code>","text":"<p>\u6307\u5b9a\u547d\u4ee4\u7684\u76ee\u6807 minion\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>target_string</code> (string): \u76ee\u6807\u8868\u8fbe\u5f0f (\u4f8b\u5982, <code>\"*\"</code> \u8868\u793a\u6240\u6709 minions, <code>\"web-server-1\"</code>, \u6216\u4e00\u4e2a grain \u503c)\u3002</li> <li><code>expr_form</code> (string, \u53ef\u9009): \u8981\u4f7f\u7528\u7684\u5b9a\u4f4d\u7c7b\u578b (\u4f8b\u5982, <code>\"glob\"</code>, <code>\"grain\"</code>, <code>\"list\"</code>)\u3002\u9ed8\u8ba4\u4e3a glob\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>target</code> (object): \u4e00\u4e2a <code>SaltTarget</code> \u5bf9\u8c61\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/salt/#salttarget","title":"<code>SaltTarget</code> \u5bf9\u8c61","text":"<p>\u6b64\u5bf9\u8c61\u8868\u793a\u4e00\u4e2a\u7279\u5b9a\u7684\u76ee\u6807\uff0c\u5e76\u63d0\u4f9b\u53ef\u94fe\u63a5\u7684\u65b9\u6cd5\u6765\u6267\u884c Salt \u51fd\u6570\u3002</p>"},{"location":"zh/modules/salt/#targetcmdfunction-arg1-arg2","title":"<code>target:cmd(function, [arg1, arg2, ...])</code>","text":"<p>\u5728\u76ee\u6807\u4e0a\u6267\u884c Salt \u6267\u884c\u6a21\u5757\u51fd\u6570\u3002</p> <ul> <li>\u53c2\u6570:<ul> <li><code>function</code> (string): \u8981\u8fd0\u884c\u7684\u51fd\u6570\u7684\u540d\u79f0 (\u4f8b\u5982, <code>\"test.ping\"</code>, <code>\"state.apply\"</code>, <code>\"cmd.run\"</code>)\u3002</li> <li><code>arg1</code>, <code>arg2</code>, ... (any): \u8981\u4f20\u9012\u7ed9 Salt \u51fd\u6570\u7684\u9644\u52a0\u53c2\u6570\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li><code>result</code> (table): \u4e00\u4e2a\u5305\u542b <code>success</code> (boolean)\u3001<code>stdout</code> (string \u6216 table) \u548c <code>stderr</code> (string) \u7684\u8868\u3002\u5982\u679c Salt \u547d\u4ee4\u8fd4\u56de JSON\uff0c<code>stdout</code> \u5c06\u662f\u4e00\u4e2a\u89e3\u6790\u540e\u7684 Lua \u8868\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/salt/#_1","title":"\u793a\u4f8b","text":"<p>\u6b64\u793a\u4f8b\u6f14\u793a\u4e86\u5982\u4f55\u5b9a\u4f4d minions \u4ee5 ping \u5b83\u4eec\u5e76\u5e94\u7528 Salt \u72b6\u6001\u3002</p> <pre><code>command = function()\n  local salt = require(\"salt\")\n\n  -- 1. \u521b\u5efa\u4e00\u4e2a Salt \u5ba2\u6237\u7aef\n  local client = salt.client()\n\n  -- 2. \u5b9a\u4f4d\u6240\u6709 minions \u5e76 ping \u5b83\u4eec\n  log.info(\"\u6b63\u5728 ping \u6240\u6709 minions...\")\n  local ping_result = client:target(\"*\"):cmd(\"test.ping\")\n  if not ping_result.success then\n    return false, \"Ping minions \u5931\u8d25: \" .. ping_result.stderr\n  end\n  print(\"Ping \u7ed3\u679c:\")\n  print(data.to_yaml(ping_result.stdout)) -- stdout \u662f\u4e00\u4e2a\u8868\n\n  -- 3. \u5b9a\u4f4d\u4e00\u4e2a\u7279\u5b9a\u7684 web \u670d\u52a1\u5668\u5e76\u5e94\u7528\u4e00\u4e2a\u72b6\u6001\n  log.info(\"\u6b63\u5728\u5411 web-server-1 \u5e94\u7528 'nginx' \u72b6\u6001...\")\n  local apply_result = client:target(\"web-server-1\", \"glob\"):cmd(\"state.apply\", \"nginx\")\n  if not apply_result.success then\n    return false, \"\u5e94\u7528\u72b6\u6001\u5931\u8d25: \" .. apply_result.stderr\n  end\n\n  log.info(\"\u72b6\u6001\u6210\u529f\u5e94\u7528\u3002\")\n  return true, \"Salt \u64cd\u4f5c\u5b8c\u6210\u3002\"\nend\n</code></pre>"},{"location":"zh/modules/state/","title":"\ud83d\udcbe \u72b6\u6001\u7ba1\u7406\u6a21\u5757","text":"<p>\u72b6\u6001\u7ba1\u7406\u6a21\u5757\u63d0\u4f9b\u5f3a\u5927\u7684\u6301\u4e45\u5316\u72b6\u6001\u529f\u80fd\uff0c\u5305\u62ec\u539f\u5b50\u64cd\u4f5c\u3001\u5206\u5e03\u5f0f\u9501\u548cTTL\uff08\u751f\u5b58\u65f6\u95f4\uff09\u529f\u80fd\u3002\u6240\u6709\u6570\u636e\u90fd\u4f7f\u7528SQLite\u7684WAL\u6a21\u5f0f\u5728\u672c\u5730\u5b58\u50a8\uff0c\u4ee5\u83b7\u5f97\u6700\u5927\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002</p>"},{"location":"zh/modules/state/#_2","title":"\ud83d\ude80 \u6838\u5fc3\u7279\u6027","text":"<ul> <li>SQLite \u6301\u4e45\u5316: \u4f7f\u7528WAL\u6a21\u5f0f\u7684\u53ef\u9760\u5b58\u50a8</li> <li>\u539f\u5b50\u64cd\u4f5c: \u7ebf\u7a0b\u5b89\u5168\u7684\u589e\u91cf\u3001\u6bd4\u8f83\u4ea4\u6362\u3001\u8ffd\u52a0\u64cd\u4f5c</li> <li>\u5206\u5e03\u5f0f\u9501: \u5e26\u81ea\u52a8\u8d85\u65f6\u7684\u4e34\u754c\u533a</li> <li>TTL (\u751f\u5b58\u65f6\u95f4): \u81ea\u52a8\u952e\u8fc7\u671f</li> <li>\u6570\u636e\u7c7b\u578b: \u5b57\u7b26\u4e32\u3001\u6570\u5b57\u3001\u5e03\u5c14\u503c\u3001\u8868\u3001\u5217\u8868</li> <li>\u6a21\u5f0f\u5339\u914d: \u901a\u914d\u7b26\u952e\u641c\u7d22</li> <li>\u81ea\u52a8\u6e05\u7406: \u8fc7\u671f\u6570\u636e\u7684\u540e\u53f0\u6e05\u7406</li> <li>\u7edf\u8ba1\u4fe1\u606f: \u4f7f\u7528\u60c5\u51b5\u548c\u6027\u80fd\u6307\u6807</li> </ul>"},{"location":"zh/modules/state/#_3","title":"\ud83d\udccb \u57fa\u672c\u7528\u6cd5","text":""},{"location":"zh/modules/state/#_4","title":"\u8bbe\u7f6e\u548c\u83b7\u53d6\u503c","text":"<pre><code>-- \u8bbe\u7f6e\u503c\nstate.set(\"app_version\", \"v1.2.3\")\nstate.set(\"user_count\", 1000)\nstate.set(\"config\", {\n    debug = true,\n    max_connections = 100\n})\n\n-- \u83b7\u53d6\u503c\nlocal version = state.get(\"app_version\")\nlocal count = state.get(\"user_count\")\nlocal config = state.get(\"config\")\n\n-- \u5e26\u9ed8\u8ba4\u503c\u83b7\u53d6\nlocal theme = state.get(\"ui_theme\", \"dark\")\n\n-- \u68c0\u67e5\u5b58\u5728\u6027\nif state.exists(\"app_version\") then\n    log.info(\"\u5e94\u7528\u7248\u672c\u5df2\u914d\u7f6e\")\nend\n\n-- \u5220\u9664\u952e\nstate.delete(\"old_key\")\n</code></pre>"},{"location":"zh/modules/state/#ttl","title":"TTL (\u751f\u5b58\u65f6\u95f4)","text":"<pre><code>-- \u8bbe\u7f6e\u5e26TTL (60\u79d2)\nstate.set(\"session_token\", \"abc123\", 60)\n\n-- \u4e3a\u73b0\u6709\u952e\u8bbe\u7f6eTTL\nstate.set_ttl(\"user_session\", 300) -- 5\u5206\u949f\n\n-- \u68c0\u67e5\u5269\u4f59TTL\nlocal ttl = state.get_ttl(\"session_token\")\nlog.info(\"\u4ee4\u724c\u5728 \" .. ttl .. \" \u79d2\u540e\u8fc7\u671f\")\n</code></pre>"},{"location":"zh/modules/state/#_5","title":"\u539f\u5b50\u64cd\u4f5c","text":"<pre><code>-- \u539f\u5b50\u589e\u91cf\nlocal counter = state.increment(\"page_views\", 1)\nlocal bulk_counter = state.increment(\"downloads\", 50)\n\n-- \u539f\u5b50\u51cf\u91cf  \nlocal remaining = state.decrement(\"inventory\", 5)\n\n-- \u5b57\u7b26\u4e32\u8ffd\u52a0\nstate.set(\"log_messages\", \"\u542f\u52a8\u5e94\u7528\u7a0b\u5e8f\")\nlocal new_length = state.append(\"log_messages\", \" -&gt; \u8fde\u63a5\u5230\u6570\u636e\u5e93\")\n\n-- \u539f\u5b50\u6bd4\u8f83\u4ea4\u6362\nlocal old_version = state.get(\"config_version\")\nlocal success = state.compare_swap(\"config_version\", old_version, old_version + 1)\nif success then\n    log.info(\"\u914d\u7f6e\u5b89\u5168\u66f4\u65b0\")\nend\n</code></pre>"},{"location":"zh/modules/state/#_6","title":"\u5217\u8868\u64cd\u4f5c","text":"<pre><code>-- \u6dfb\u52a0\u9879\u76ee\u5230\u5217\u8868\nstate.list_push(\"deployment_queue\", {\n    app = \"frontend\",\n    version = \"v2.1.0\",\n    environment = \"staging\"\n})\n\n-- \u68c0\u67e5\u5217\u8868\u5927\u5c0f\nlocal queue_size = state.list_length(\"deployment_queue\")\nlog.info(\"\u961f\u5217\u4e2d\u7684\u9879\u76ee: \" .. queue_size)\n\n-- \u5904\u7406\u5217\u8868 (pop\u79fb\u9664\u6700\u540e\u4e00\u9879)\nwhile state.list_length(\"deployment_queue\") &gt; 0 do\n    local deployment = state.list_pop(\"deployment_queue\")\n    log.info(\"\u5904\u7406\u90e8\u7f72: \" .. deployment.app)\n    -- \u5904\u7406\u90e8\u7f72...\nend\n</code></pre>"},{"location":"zh/modules/state/#_7","title":"\u5206\u5e03\u5f0f\u9501\u548c\u4e34\u754c\u533a","text":"<pre><code>-- \u5c1d\u8bd5\u83b7\u53d6\u9501 (\u4e0d\u7b49\u5f85)\nlocal lock_acquired = state.try_lock(\"deployment_lock\", 30) -- 30\u79d2TTL\nif lock_acquired then\n    -- \u5173\u952e\u5de5\u4f5c\n    state.unlock(\"deployment_lock\")\nend\n\n-- \u5e26\u7b49\u5f85\u548c\u8d85\u65f6\u7684\u9501\nlocal acquired = state.lock(\"database_migration\", 60) -- \u7b49\u5f85\u6700\u591a60\u79d2\nif acquired then\n    -- \u6267\u884c\u8fc1\u79fb\n    state.unlock(\"database_migration\")\nend\n\n-- \u5e26\u81ea\u52a8\u9501\u7ba1\u7406\u7684\u4e34\u754c\u533a\nstate.with_lock(\"critical_section\", function()\n    log.info(\"\u6267\u884c\u5173\u952e\u64cd\u4f5c...\")\n\n    -- \u66f4\u65b0\u5168\u5c40\u8ba1\u6570\u5668\n    local counter = state.increment(\"global_counter\", 1)\n\n    -- \u66f4\u65b0\u65f6\u95f4\u6233\n    state.set(\"last_operation\", os.time())\n\n    log.info(\"\u5173\u952e\u64cd\u4f5c\u5b8c\u6210 - \u8ba1\u6570\u5668: \" .. counter)\n\n    -- \u51fd\u6570\u8fd4\u56de\u65f6\u81ea\u52a8\u91ca\u653e\u9501\n    return \"operation_success\"\nend, 15) -- 15\u79d2\u8d85\u65f6\n</code></pre>"},{"location":"zh/modules/state/#api","title":"\ud83d\udd0d API\u53c2\u8003","text":""},{"location":"zh/modules/state/#_8","title":"\u57fa\u672c\u64cd\u4f5c","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>state.set(key, value, ttl?)</code> key: string, value: any, ttl?: number success: boolean \u8bbe\u7f6e\u503c\uff0c\u53ef\u9009TTL <code>state.get(key, default?)</code> key: string, default?: any value: any \u83b7\u53d6\u503c\u6216\u8fd4\u56de\u9ed8\u8ba4\u503c <code>state.delete(key)</code> key: string success: boolean \u5220\u9664\u952e <code>state.exists(key)</code> key: string exists: boolean \u68c0\u67e5\u952e\u662f\u5426\u5b58\u5728 <code>state.clear(pattern?)</code> pattern?: string success: boolean \u6309\u6a21\u5f0f\u5220\u9664\u952e"},{"location":"zh/modules/state/#ttl_1","title":"TTL\u64cd\u4f5c","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>state.set_ttl(key, seconds)</code> key: string, seconds: number success: boolean \u4e3a\u73b0\u6709\u952e\u8bbe\u7f6eTTL <code>state.get_ttl(key)</code> key: string ttl: number \u83b7\u53d6\u5269\u4f59TTL (-1 = \u65e0TTL, -2 = \u4e0d\u5b58\u5728)"},{"location":"zh/modules/state/#_9","title":"\u539f\u5b50\u64cd\u4f5c","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>state.increment(key, delta?)</code> key: string, delta?: number new_value: number \u539f\u5b50\u589e\u91cf\u503c <code>state.decrement(key, delta?)</code> key: string, delta?: number new_value: number \u539f\u5b50\u51cf\u91cf\u503c <code>state.append(key, value)</code> key: string, value: string new_length: number \u539f\u5b50\u8ffd\u52a0\u5b57\u7b26\u4e32 <code>state.compare_swap(key, old, new)</code> key: string, old: any, new: any success: boolean \u539f\u5b50\u6bd4\u8f83\u4ea4\u6362"},{"location":"zh/modules/state/#_10","title":"\u5217\u8868\u64cd\u4f5c","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>state.list_push(key, item)</code> key: string, item: any length: number \u6dfb\u52a0\u9879\u76ee\u5230\u5217\u8868\u672b\u5c3e <code>state.list_pop(key)</code> key: string item: any | nil \u79fb\u9664\u5e76\u8fd4\u56de\u6700\u540e\u4e00\u9879 <code>state.list_length(key)</code> key: string length: number \u83b7\u53d6\u5217\u8868\u957f\u5ea6"},{"location":"zh/modules/state/#_11","title":"\u5206\u5e03\u5f0f\u9501","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>state.try_lock(name, ttl)</code> name: string, ttl: number success: boolean \u5c1d\u8bd5\u83b7\u53d6\u9501\u800c\u4e0d\u7b49\u5f85 <code>state.lock(name, timeout?)</code> name: string, timeout?: number success: boolean \u5e26\u8d85\u65f6\u83b7\u53d6\u9501 <code>state.unlock(name)</code> name: string success: boolean \u91ca\u653e\u9501 <code>state.with_lock(name, fn, timeout?)</code> name: string, fn: function, timeout?: number result: any \u4f7f\u7528\u81ea\u52a8\u9501\u6267\u884c\u51fd\u6570"},{"location":"zh/modules/state/#_12","title":"\u5b9e\u7528\u5de5\u5177","text":"\u51fd\u6570 \u53c2\u6570 \u8fd4\u56de\u503c \u63cf\u8ff0 <code>state.keys(pattern?)</code> pattern?: string keys: table \u6309\u6a21\u5f0f\u5217\u51fa\u952e <code>state.stats()</code> - stats: table \u83b7\u53d6\u7cfb\u7edf\u7edf\u8ba1\u4fe1\u606f"},{"location":"zh/modules/state/#_13","title":"\ud83d\udca1 \u5b9e\u9645\u7528\u4f8b","text":""},{"location":"zh/modules/state/#1","title":"1. \u90e8\u7f72\u7248\u672c\u63a7\u5236","text":"<pre><code>Modern DSLs = {\n    deployment_pipeline = {\n        tasks = {\n            prepare_deploy = {\n                command = function()\n                    -- \u68c0\u67e5\u6700\u540e\u90e8\u7f72\u7684\u7248\u672c\n                    local last_version = state.get(\"last_deployed_version\", \"v0.0.0\")\n                    local new_version = \"v1.2.3\"\n\n                    -- \u68c0\u67e5\u662f\u5426\u5df2\u90e8\u7f72\n                    if last_version == new_version then\n                        log.warn(\"\u7248\u672c \" .. new_version .. \" \u5df2\u90e8\u7f72\")\n                        return false, \"\u7248\u672c\u5df2\u90e8\u7f72\"\n                    end\n\n                    -- \u6ce8\u518c\u90e8\u7f72\u5f00\u59cb\n                    state.set(\"deploy_status\", \"in_progress\")\n                    state.set(\"deploy_start_time\", os.time())\n                    state.increment(\"total_deploys\", 1)\n\n                    return true, \"\u90e8\u7f72\u51c6\u5907\u5b8c\u6210\"\n                end\n            },\n\n            execute_deploy = {\n                depends_on = \"prepare_deploy\",\n                command = function()\n                    -- \u90e8\u7f72\u7684\u4e34\u754c\u533a\n                    return state.with_lock(\"deployment_lock\", function()\n                        log.info(\"\u4f7f\u7528\u9501\u6267\u884c\u90e8\u7f72...\")\n\n                        -- \u6a21\u62df\u90e8\u7f72\n                        exec.run(\"sleep 5\")\n\n                        -- \u66f4\u65b0\u72b6\u6001\n                        state.set(\"last_deployed_version\", \"v1.2.3\")\n                        state.set(\"deploy_status\", \"completed\")\n                        state.set(\"deploy_end_time\", os.time())\n\n                        -- \u8bb0\u5f55\u5386\u53f2\n                        state.list_push(\"deploy_history\", {\n                            version = \"v1.2.3\",\n                            timestamp = os.time(),\n                            duration = state.get(\"deploy_end_time\") - state.get(\"deploy_start_time\")\n                        })\n\n                        return true, \"\u90e8\u7f72\u6210\u529f\u5b8c\u6210\"\n                    end, 300) -- 5\u5206\u949f\u8d85\u65f6\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"zh/modules/state/#2-ttl","title":"2. \u5e26TTL\u7684\u667a\u80fd\u7f13\u5b58","text":"<pre><code>-- \u7f13\u5b58\u52a9\u624b\u51fd\u6570\nfunction get_cached_data(cache_key, fetch_function, ttl)\n    local cached = state.get(cache_key)\n    if cached then\n        log.info(\"\u7f13\u5b58\u547d\u4e2d: \" .. cache_key)\n        return cached\n    end\n\n    log.info(\"\u7f13\u5b58\u672a\u547d\u4e2d: \" .. cache_key .. \" - \u6b63\u5728\u83b7\u53d6...\")\n    local data = fetch_function()\n    state.set(cache_key, data, ttl or 300) -- \u9ed8\u8ba45\u5206\u949f\n    return data\nend\n\n-- \u5728\u4efb\u52a1\u4e2d\u4f7f\u7528\nModern DSLs = {\n    data_processing = {\n        tasks = {\n            fetch_user_data = {\n                command = function()\n                    local user_data = get_cached_data(\"user:123:profile\", function()\n                        -- \u6a21\u62df\u6602\u8d35\u7684\u83b7\u53d6\u64cd\u4f5c\n                        return {\n                            name = \"\u5f20\u4e09\",\n                            email = \"zhangsan@example.com\",\n                            preferences = {\"dark_mode\", \"notifications\"}\n                        }\n                    end, 600) -- \u7f13\u5b5810\u5206\u949f\n\n                    log.info(\"\u7528\u6237\u6570\u636e: \" .. data.to_json(user_data))\n                    return true, \"\u7528\u6237\u6570\u636e\u5df2\u83b7\u53d6\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"zh/modules/state/#3","title":"3. \u901f\u7387\u9650\u5236","text":"<pre><code>function check_rate_limit(identifier, max_requests, window_seconds)\n    local key = \"rate_limit:\" .. identifier\n    local current_count = state.get(key, 0)\n\n    if current_count &gt;= max_requests then\n        return false, \"\u901f\u7387\u9650\u5236\u8d85\u51fa\"\n    end\n\n    -- \u589e\u52a0\u8ba1\u6570\u5668\n    if current_count == 0 then\n        -- \u7a97\u53e3\u4e2d\u7684\u7b2c\u4e00\u4e2a\u8bf7\u6c42\n        state.set(key, 1, window_seconds)\n    else\n        -- \u589e\u52a0\u73b0\u6709\u8ba1\u6570\u5668\n        state.increment(key, 1)\n    end\n\n    return true, \"\u8bf7\u6c42\u5141\u8bb8\"\nend\n\n-- \u5728\u4efb\u52a1\u4e2d\u4f7f\u7528\nModern DSLs = {\n    api_tasks = {\n        tasks = {\n            make_api_call = {\n                command = function()\n                    local allowed, msg = check_rate_limit(\"api_calls\", 100, 3600) -- 100\u6b21\u8c03\u7528/\u5c0f\u65f6\n\n                    if not allowed then\n                        log.error(msg)\n                        return false, msg\n                    end\n\n                    -- \u8fdb\u884cAPI\u8c03\u7528\n                    log.info(\"\u8fdb\u884cAPI\u8c03\u7528...\")\n                    return true, \"API\u8c03\u7528\u5b8c\u6210\"\n                end\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"zh/modules/state/#_14","title":"\u2699\ufe0f \u914d\u7f6e\u548c\u5b58\u50a8","text":""},{"location":"zh/modules/state/#_15","title":"\u6570\u636e\u5e93\u4f4d\u7f6e","text":"<p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cSQLite\u6570\u636e\u5e93\u521b\u5efa\u5728: - Linux/macOS: <code>~/.sloth-runner/state.db</code> - Windows: <code>%USERPROFILE%\\.sloth-runner\\state.db</code></p>"},{"location":"zh/modules/state/#_16","title":"\u6280\u672f\u7279\u6027","text":"<ul> <li>\u5f15\u64ce: \u5e26WAL\u6a21\u5f0f\u7684SQLite 3</li> <li>\u5e76\u53d1\u8bbf\u95ee: \u652f\u6301\u591a\u4e2a\u540c\u65f6\u8fde\u63a5</li> <li>\u81ea\u52a8\u6e05\u7406: \u6bcf5\u5206\u949f\u81ea\u52a8\u6e05\u7406\u8fc7\u671f\u6570\u636e</li> <li>\u9501\u8d85\u65f6: \u8fc7\u671f\u9501\u81ea\u52a8\u6e05\u7406</li> <li>\u5e8f\u5217\u5316: \u590d\u6742\u5bf9\u8c61\u4f7f\u7528JSON\uff0c\u7b80\u5355\u7c7b\u578b\u4f7f\u7528\u539f\u751f\u683c\u5f0f</li> </ul>"},{"location":"zh/modules/state/#_17","title":"\u9650\u5236","text":"<ul> <li>\u672c\u5730\u8303\u56f4: \u72b6\u6001\u4ec5\u5728\u672c\u5730\u673a\u5668\u4e0a\u6301\u4e45\u5316</li> <li>\u5e76\u53d1\u6027: \u9501\u4ec5\u5728\u672c\u5730\u8fdb\u7a0b\u5185\u6709\u6548</li> <li>\u5927\u5c0f: \u9002\u5408\u5c0f\u5230\u4e2d\u578b\u6570\u636e\u96c6 (&lt; 1GB)</li> </ul>"},{"location":"zh/modules/state/#_18","title":"\ud83d\udd04 \u6700\u4f73\u5b9e\u8df5","text":"<ol> <li>\u5bf9\u4e34\u65f6\u6570\u636e\u4f7f\u7528TTL \u4ee5\u9632\u6b62\u5b58\u50a8\u81a8\u80c0</li> <li>\u5bf9\u4e34\u754c\u533a\u4f7f\u7528\u9501 \u4ee5\u907f\u514d\u7ade\u6001\u6761\u4ef6</li> <li>\u4f7f\u7528\u6a21\u5f0f\u8fdb\u884c\u6279\u91cf\u64cd\u4f5c \u7ba1\u7406\u76f8\u5173\u952e</li> <li>\u4f7f\u7528<code>state.stats()</code>\u76d1\u63a7\u5b58\u50a8\u5927\u5c0f</li> <li>\u4f7f\u7528\u539f\u5b50\u64cd\u4f5c \u800c\u4e0d\u662f\u8bfb-\u4fee\u6539-\u5199\u6a21\u5f0f</li> <li>\u4f7f\u7528<code>state.clear(pattern)</code>\u5b9a\u671f\u6e05\u7406\u8fc7\u671f\u952e</li> </ol> <p>\u72b6\u6001\u7ba1\u7406\u6a21\u5757\u5c06sloth-runner\u8f6c\u53d8\u4e3a\u6709\u72b6\u6001\u7684\u3001\u53ef\u9760\u7684\u590d\u6742\u4efb\u52a1\u7f16\u6392\u5e73\u53f0! \ud83d\ude80</p>"},{"location":"zh/modules/terraform/","title":"Terraform \u6a21\u5757","text":"<p><code>terraform</code> \u6a21\u5757\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u7ea7\u754c\u9762\uff0c\u7528\u4e8e\u7f16\u6392 <code>terraform</code> CLI \u547d\u4ee4\uff0c\u5141\u8bb8\u60a8\u76f4\u63a5\u5728 Sloth-Runner \u7ba1\u9053\u5185\u7ba1\u7406\u60a8\u7684\u57fa\u7840\u67b6\u6784\u751f\u547d\u5468\u671f\u3002</p>"},{"location":"zh/modules/terraform/#_1","title":"\u914d\u7f6e","text":"<p>\u6b64\u6a21\u5757\u9700\u8981\u5b89\u88c5 <code>terraform</code> CLI \u5e76\u53ef\u5728\u7cfb\u7edf\u7684 PATH \u4e2d\u4f7f\u7528\u3002\u6240\u6709\u547d\u4ee4\u90fd\u5fc5\u987b\u5728\u60a8\u7684 <code>.tf</code> \u6587\u4ef6\u6240\u5728\u7684\u7279\u5b9a <code>workdir</code> \u4e2d\u6267\u884c\u3002</p>"},{"location":"zh/modules/terraform/#_2","title":"\u51fd\u6570","text":""},{"location":"zh/modules/terraform/#terraforminitparams","title":"<code>terraform.init(params)</code>","text":"<p>\u521d\u59cb\u5316 Terraform \u5de5\u4f5c\u76ee\u5f55\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): \u5fc5\u9700\u3002 \u5305\u542b Terraform \u6587\u4ef6\u7684\u76ee\u5f55\u7684\u8def\u5f84\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u5305\u542b <code>success</code>\u3001<code>stdout</code>\u3001<code>stderr</code> \u548c <code>exit_code</code> \u7684\u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/terraform/#terraformplanparams","title":"<code>terraform.plan(params)</code>","text":"<p>\u521b\u5efa Terraform \u6267\u884c\u8ba1\u5212\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): \u5fc5\u9700\u3002 \u76ee\u5f55\u7684\u8def\u5f84\u3002</li> <li><code>out</code> (string): \u53ef\u9009\u3002 \u7528\u4e8e\u4fdd\u5b58\u751f\u6210\u7684\u8ba1\u5212\u7684\u6587\u4ef6\u540d\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/terraform/#terraformapplyparams","title":"<code>terraform.apply(params)</code>","text":"<p>\u5e94\u7528 Terraform \u8ba1\u5212\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): \u5fc5\u9700\u3002 \u76ee\u5f55\u7684\u8def\u5f84\u3002</li> <li><code>plan</code> (string): \u53ef\u9009\u3002 \u8981\u5e94\u7528\u7684\u8ba1\u5212\u6587\u4ef6\u7684\u8def\u5f84\u3002</li> <li><code>auto_approve</code> (boolean): \u53ef\u9009\u3002 \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u65e0\u9700\u4ea4\u4e92\u5f0f\u6279\u51c6\u5373\u53ef\u5e94\u7528\u66f4\u6539\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/terraform/#terraformdestroyparams","title":"<code>terraform.destroy(params)</code>","text":"<p>\u9500\u6bc1 Terraform \u7ba1\u7406\u7684\u57fa\u7840\u67b6\u6784\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): \u5fc5\u9700\u3002 \u76ee\u5f55\u7684\u8def\u5f84\u3002</li> <li><code>auto_approve</code> (boolean): \u53ef\u9009\u3002 \u5982\u679c\u4e3a <code>true</code>\uff0c\u5219\u65e0\u9700\u4ea4\u4e92\u5f0f\u6279\u51c6\u5373\u53ef\u9500\u6bc1\u8d44\u6e90\u3002</li> </ul> </li> <li>\u8fd4\u56de: \u7ed3\u679c\u8868\u3002</li> </ul>"},{"location":"zh/modules/terraform/#terraformoutputparams","title":"<code>terraform.output(params)</code>","text":"<p>\u4ece Terraform \u72b6\u6001\u6587\u4ef6\u8bfb\u53d6\u8f93\u51fa\u53d8\u91cf\u3002</p> <ul> <li><code>params</code> (table):<ul> <li><code>workdir</code> (string): \u5fc5\u9700\u3002 \u76ee\u5f55\u7684\u8def\u5f84\u3002</li> <li><code>name</code> (string): \u53ef\u9009\u3002 \u8981\u8bfb\u53d6\u7684\u7279\u5b9a\u8f93\u51fa\u7684\u540d\u79f0\u3002\u5982\u679c\u7701\u7565\uff0c\u5219\u6240\u6709\u8f93\u51fa\u90fd\u4f5c\u4e3a\u8868\u8fd4\u56de\u3002</li> </ul> </li> <li>\u8fd4\u56de:<ul> <li>\u6210\u529f\u65f6: \u8f93\u51fa\u7684\u5df2\u89e3\u6790 JSON \u503c\uff08\u53ef\u4ee5\u662f\u5b57\u7b26\u4e32\u3001\u8868\u7b49\uff09\u3002</li> <li>\u5931\u8d25\u65f6: <code>nil, error_message</code>\u3002</li> </ul> </li> </ul>"},{"location":"zh/modules/terraform/#_3","title":"\u5b8c\u6574\u751f\u547d\u5468\u671f\u793a\u4f8b","text":"<pre><code>local tf_workdir = \"./examples/terraform\"\n\n-- \u4efb\u52a1 1: Init\nlocal result_init = terraform.init({workdir = tf_workdir})\nif not result_init.success then return false, \"Init \u5931\u8d25\" end\n\n-- \u4efb\u52a1 2: Plan\nlocal result_plan = terraform.plan({workdir = tf_workdir})\nif not result_plan.success then return false, \"Plan \u5931\u8d25\" end\n\n-- \u4efb\u52a1 3: Apply\nlocal result_apply = terraform.apply({workdir = tf_workdir, auto_approve = true})\nif not result_apply.success then return false, \"Apply \u5931\u8d25\" end\n\n-- \u4efb\u52a1 4: Get Output\nlocal filename, err = terraform.output({workdir = tf_workdir, name = \"report_filename\"})\nif not filename then return false, \"Output \u5931\u8d25: \" .. err end\nlog.info(\"Terraform \u521b\u5efa\u7684\u6587\u4ef6: \" .. filename)\n\n-- \u4efb\u52a1 5: Destroy\nlocal result_destroy = terraform.destroy({workdir = tf_workdir, auto_approve = true})\nif not result_destroy.success then return false, \"Destroy \u5931\u8d25\" end\n</code></pre>"}]}